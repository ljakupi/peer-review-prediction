review_file_id,comments,score
729.json,strengths the authors propose a kernel based method that captures high order patterns differentiting different types of rumors by evaluating the similarities between their propagation tree structures weaknesses maybe the maths is not always clear in sect general discussion the authors propose a propagation tree kernel a kernel based method that captures high order patterns differentiating types of rumors by evaluating the similarities between their propagation tree structures the proposed approach detects rumors more quickly and with a higher accuracy compared to the one obtained by the state of the art methods the data set should be made public for research purposes typos need to be fixed e g any subgraph which have has tpk ptk table show s missing information needs to be added where was it published information needs to be in the same format e g vs figure is a bit small,4.0
338.json,strengths the related work is quite thorough and the comparison with the approach presented in this paper makes the hypothesis of the paper stronger the evaluation section is also extensive and thus the experiments are convincing weaknesses in section it is not clear what is exactly the dataset that you used for training the svm and your own model furthermore you only give the starting date for collecting the testing data but there is no other information related to the size of the dataset or the time frame when the data was collected this might also give some insight for the results and statistics given in section in table we can see that the number of reviewers is only slightly lower than the number of reviews posted at least for hotels which means that only a few reviewers posted more than one review in the labeled dataset how does this compare with the full dataset in table what is the exact number of reviewers in table to know what is the percentage of labeled reviewers it is also interesting to know how many reviews are made by one person on average if there are only a few reviewers that post more than one review i e not that much info to learn from the results would benefit from a thorough discussion general discussion this paper focuses on identifying spam reviews under the assumption that we deal with a cold start problem i e we do not have enough information to draw a conclusion the paper proposes a neural network model that learns how to represent new reviews by jointly using embedded textual information and behaviour information overall the paper is very well written and the results are compelling typos and or grammar the new reviewer only provide us jindal and liu make the first step the work is quite old you could use past tense to refer to it usage of short form can t couldn t what s instead of the prefered long form the following sentence is not clear and should be rephrased the new reviewer just posted one review and we have to filter it out immediately there is not any historical reviews provided to us,4.0
343.json,strengths i well organized and easy to understand ii provides detailed comparisons under various experimental settings and shows the state of the art performances weaknesses i in experiments this paper compares previous supervised approaches but the proposed method is the semi supervised approach even if the training data is enough to train general discussion this paper adopts a pre training approach to improve chinese word segmentation based on the transition based neural word segmentation this paper aims to pre train incoming characters with external resources punctuation soft segmentation pos and heterogeneous training data through multi task learning that is this paper casts each external source as an auxiliary classification task the experimental results show that the proposed method achieves the state of the art performances in six out of seven datasets this paper is well written and easy to understand a number of experiments prove the effectiveness of the proposed method however there exist an issue in this paper the proposed method is a semi supervised learning that uses external resources to pre train the characters furthermore this paper uses another heterogeneous training datasets even if it uses the datasets only for pre training nevertheless the baselines in the experiments are based on supervised learning in general the performance of semi supervised learning is better than that of supervised learning because semi supervised learning makes use of plentiful auxiliary information in the experiments this paper should have compared the proposed method with semi supervised approaches post author response what the reviewer concerned is that this paper used additional gold labeled dataset to pretrain the character embeddings some baselines in the experiments used label information where the labels are predicted automatically by their base models as the authors pointed out when insisting superiority of a method all circumstances should be same thus even if the gold dataset isn t used to train the segmentation model directly it seems to me that it is an unfair comparison because the proposed method used another gold dataset to train the character embeddings,3.0
752.json,strengths the paper demonstrates that seqseq models can be comparatively effectively applied to the tasks of amr parsing and amr realization by linearization of an engineered pre processed version of the amr graph and associated sentence combined with paired training iterative back translation of monolingual data combined with fine tuning while parsing performance is worse than other reported papers e g pust et al those papers used additional semantic information on the task of amr realization the paper demonstrates that utilizing additional monolingual data via back translation is effective relative to a seqseq model that does not use such information see note below about comparing realization results to previous non seqseq work for the realization task weaknesses at a high level the main weakness is that the paper aims for empirical comparisons but in comparing to other work multiple aspects dimensions are changing at the same time in some cases not comparable due to access to different information complicating comparisons for example with the realization results table pbmt pourdamghani et al is apparently trained on ldct which consists of sentences compared to the model of the paper which is trained on ldce which consists of sentences according to http amr isi edu download html this is used in making the claim of over points improvement over the state of the art pbmt in line and line and is only qualified in the caption of table to make a valid comparison the approach of the paper or pbmt needs to be re evaluated after using the same training data general discussion is there any overlap between the sentences in your gigaword sample and the test sentences of ldce apparently ldce contains data from the proxy report data in ldc deft narrative text source data r corpus ldce accessible with ldc account https catalog ldc upenn edu ldce it seems ldce contains data from gigaword https catalog ldc upenn edu ldce apparently amr corpus ldct also contained would ata from newswire articles selected from the english gigaword corpus fifth edition publicly accessible link https catalog ldc upenn edu docs ldct readme txt please check that there is no test set contamination line did these two modifications to the encoder make a significant difference in effectiveness what was the motivation behind these changes please make it clear in an appendix is fine for replication purposes whether the implementation is based on an existing seqseq framework line what was the final sequence length used consider adding such details in an appendix please label the columns of table presumably dev and test also there is a mismatch between table and the text table summarizes our development results for different rounds of self training it appears that only the results of the second round of self training are shown again the columns for table are not labeled but should the results for column for camr instead be the last line of table in http www aclweb org anthology s which is the configuration for verb rne srl wiki it looks like the second from last row of table in camr wang et al is currently being used on this note how does your approach handle the wikification information introduced in ldce stochastic is missing a reference to the example line this seems like a hypothesis to be tested empirically rather than a forgone conclusion as implied here given an extra page please add a concluding section how are you performing decoding are you using beam search as a follow up to line it does not appear that the actual vocabulary size used in the experiments is mentioned after preprocessing are there any remaining unseen tokens in dev test in other words is the unknown word replacement mechanism using the attention weights as described in section ever used for the realization case study it would be of interest to see performance on phenomena that are known limitations of amr such as quantification and tense https github com amrisi amr guidelines blob master amr md the paper would benefit from a brief discussion perhaps a couple sentences motivating the use of amr as opposed to other semantic formalisms as well as why the human annotated amr information signal might be useful as opposed to learning a model e g seqseq itself directly for a task e g machine translation for future work not taken directly into account in the scores given here for the review since the applicable paper is not yet formally published in the eacl proceedings for parsing what accounts for the difference from previous seqseq approaches namely between peng and xue and amr only as in table is the difference in effectiveness being driven by the architecture the preprocessing linearization data or some combination thereof consider isolating this difference incidentally the citation for peng and xue addressing the data sparsity issue in neural amr parsing should apparently be peng et al http eacl org index php program accepted papers https arxiv org pdf pdf the authors are flipped in the references section proofreading not necessarily in the order of occurrence note that these are provided for reference and did not influence my scoring of the paper outperform state of the art outperform the state of the art zhou et al extend zhou et al extend puzikov et al puzikov et al pos based features that pos based features that language pairs by creating language pairs by creating using a back translation mt system and mix it with the human translations using a back translation mt system and mix it with the human translations probbank style palmer et al propbank style palmer et al independent parameters independent parameters for the of tokens for of tokens maintaining same embedding sizes maintaining the same embedding sizes table similar table similar realizer the realizer the notation line the sets c and w are defined but never subsequently referenced however w could should be used in place of nl in line if they are referring to the same vocabulary,4.0
752.json,the authors use self training to train a seqseq based amr parser using a small annotated corpus and large amounts of unlabeled data they then train a similar seqseq based amr to text generator using the annotated corpus and automatic amrs produced by their parser from the unlabeled data they use careful delexicalization for named entities in both tasks to avoid data sparsity this is the first sucessful application of seqseq models to amr parsing and generation and for generation it most probably improves upon state of the art in general i really liked the approach as well as the experiments and the final performance analysis the methods used are not revolutionary but they are cleverly combined to achieve practial results the description of the approach is quite detailed and i believe that it is possible to reproduce the experiments without significant problems the approach still requires some handcrafting but i believe that this can be overcome in the future and that the authors are taking a good direction resolved by authors response however i have been made aware by another reviewer of a data overlap in the gigaword and the semeval dataset this is potentially a very serious problem if there is a significant overlap in the test set this would invalidate the results for generation which are the main achievemnt of the paper unless the authors made sure that no test set sentences made their way to training through gigaword i cannot accept their results resolved by authors response another question raised by another reviewer which i fully agree with is the point claim when comparing to a system tested on an earlier version of the amr dataset the paper could probably still claim improvement over state of the art but i am not sure i can accept the points claim in a direct comparison to pourdamghani et al why have not the authors also tested their system on the older dataset version or obtained pourdamghani et al scores for the newer version otherwise i just have two minor comments to experiments statistical significance tests would be advisable even if the performance difference is very big for generation the linearization order experiment should be repeated with several times with different random seeds to overcome the bias of the particular random order chosen the form of the paper definitely could be improved the paper is very dense at some points and proofreading by an independent person preferably an english native speaker would be advisable the model especially the improvements over luong et al could be explained in more detail consider adding a figure the experiment description is missing the vocabulary size used most importantly i missed a formal conclusion very much the paper ends abruptly after qualitative results are described and it does not give a final overview of the work or future work notes minor factual notes make it clear that you use the jamr aligner not the whole parser at also do you not use the recorded mappings also when testing the parser your non gigaword model only improves on other seqseq models by f points not at voters in figure should be person arg of vote in amr minor writing notes try rewording and simplifying text near inter sentitial punctuation is sometimes confusing and does not correspond to my experience with english syntax there are lots of excessive as well as missing commas there are a few typos e g some footnotes are missing full stops the linearization description is redundant at and could just refer to sect when refering to the algorithm or figures e g near enclose the references in brackets rather than commas i think it would be nice to provide a reference for amr itself and for the multi bleu script also mention that you remove amr variables in footnote consider renaming sect to linearization evaluation the order in tables and seems a bit confusing to me especially when your systems are not explicitly marked i would expect your systems at the bottom also table apparently lists development set scores even though its description says otherwise the labels in table are a bit confusing when you read the table before reading the text in figure it not entirely visible that you distinguish month names from month numbers as you state at bibliography lacks proper capitalization in paper titles abbreviations and proper names should be capitalized use curly braces to prevent bibtex from lowercasing everything the peng and xue citation is listed improperly there are actually four authors summary the paper presents first competitive results for neural amr parsing and probably new state of the art for amr generation using seqseq models with clever preprocessing and exploiting large a unlabelled corpus even though revisions to the text are advisable i liked the paper and would like to see it at the conference resolved by authors response however i am not sure if the comparison with previous state of the art on generation is entirely sound and most importantly whether the good results are not actually caused by data overlap of gigaword additional training set with the test set comments after the authors response i thank the authors for addressing both of the major problems i had with the paper i am happy with their explanation and i raised my scores assuming that the authors will reflect our discussion in the final paper,4.0
494.json,strengths nice clear application of linguistics ideas to distributional semantics demonstrate very clear improvements on both intrinsic and extrinsic eval weaknesses fairly straightforward extension of existing retrofitting work would be nice to see some additional baselines e g character embeddings general discussion the paper describes morph fitting a type of retrofitting for vector spaces that focuses specifically on incorporating morphological constraints into the vector space the framework is based on the idea of attract and repel constraints where attract constraints are used to pull morphological variations close together e g look looking and repel constraints are used to push derivational antonyms apart e g responsible irresponsible they test their algorithm on multiple different vector spaces and several language and show consistent improvements on intrinsic evaluation simlex and simverb they also test on the extrinsic task of dialogue state tracking and again demonstrate measurable improvements over using morphologically unaware word embeddings i think this is a very nice paper it is a simple and clean way to incorporate linguistic knowledge into distributional models of semantics and the empirical results are very convincing i have some questions comments below but nothing that i feel should prevent it from being published comments for authors i do not really understand the need for the morph simlex evaluation set it seems a bit suspect to create a dataset using the same algorithm that you ultimately aim to evaluate it seems to me a no brainer that your model will do well on a dataset that was constructed by making the same assumptions the model makes i do not think you need to include this dataset at all since it is a potentially erroneous evaluation that can cause confusion and your results are convincing enough on the standard datasets i really liked the morph fix baseline thank you for including that i would have liked to see a baseline based on character embeddings since this seems to be the most fashionable way currently to side step dealing with morphological variation you mentioned it in the related work but it would be better to actually compare against it empirically ideally we would have a vector space where morphological variants are just close together but where we can assign specific semantics to the different inflections do you have any evidence that the geometry of the space you end with is meaningful e g does looking look walk walking it would be nice to have some analysis that suggests the morphfitting results in a more meaningful space not just better embeddings,4.0
494.json,the authors propose morph fitting a method that retrofits any given set of trained word embeddings based on a morphologically driven objective that pulls inflectional forms of the same word together as in slow and slowing and pushes derivational antonyms apart as in expensive and inexpensive with this the authors aim to improve the representation of low frequency inflections of words as well as mitigate the tendency of corpus based word embeddings to assign similar representations to antonyms the method is based on relatively simple manually constructed morphological rules and is demonstrated on both english german italian and russian the experiments include intrinsic word similarity benchmarks showing notable performance improvements achieved by applying morph fitting to several different corpus based embeddings performance improvement yielding new state of the art results is also demonstrated for german and italian on an extrinsic task dialog state tracking strengths the proposed method is simple and shows nice performance improvements across a number of evaluations and in several languages compared to previous knowledge based retrofitting approaches faruqui et al it relies on a few manually constructed rules instead of a large scale knowledge base such as an ontology like previous retrofitting approaches this method is easy to apply to existing sets of embeddings and therefore it seems like the software that the authors intend to release could be useful to the community the method and experiments are clearly described weaknesses i was hoping to see some analysis of why the morph fitted embeddings worked better in the evaluation and how well that corresponds with the intuitive motivation of the authors the authors introduce a synthetic word similarity evaluation dataset morph simlex they create it by applying their presumably semantic meaning preserving morphological rules to simlex to generate many more pairs with morphological variability they do not manually annotate these new pairs but rather use the original similarity judgements from simlex the obvious caveat with this dataset is that the similarity scores are presumed and therefore less reliable furthermore the fact that this dataset was generated by the very same rules that are used in this work to morph fit word embeddings means that the results reported on this dataset in this work should be taken with a grain of salt the authors should clearly state this in their paper soricut and och is mentioned as a future source for morphological knowledge but in fact it is also an alternative approach to the one proposed in this paper for generating morphologically aware word representations the authors should present it as such and differentiate their work the evaluation does not include strong morphologically informed embedding baselines general discussion with the few exceptions noted i like this work and i think it represents a nice contribution to the community the authors presented a simple approach and showed that it can yield nice improvements using various common embeddings on several evaluations and four different languages i d be happy to see it in the conference minor comments line i found this phrasing unclear we then query of linguistic constraints section i suggest to elaborate a little more on what the delta is between the model used in this paper and the one it is based on in wieting it seemed to me that this was mostly the addition of the repel part line the method s cost function consists of three terms i suggest to spell this out in an equation line x and t in this equation and following ones are the vector representations of the words i suggest to denote that somehow also are the vectors l normalized before this process also when computing nearest neighbor examples do you use cosine or dot product please share these details line i suggest to move this text to section and make the note that you did not fine tune the params in the main text and not in a footnote line create creates seems like a wrong example for that rule i have read the author response,4.0
375.json,this paper addresses the network embedding problem by introducing a neural network model which uses both the network structure and associated text on the nodes with an attention model to vary the textual representation based on the text of the neighboring nodes strengths the model leverages both the network and the text to construct the latent representations and the mutual attention approach seems sensible a relatively thorough evaluation is provided with multiple datasets baselines and evaluation tasks weaknesses like many other papers in the network embedding literature which use neural network techniques inspired by word embeddings to construct latent representations of nodes in a network the previous line of work on statistical probabilistic modeling of networks is ignored in particular all network embedding papers need to start citing and comparing to the work on the latent space model of peter hoff et al and subsequent papers in both statistical and probabilistic machine learning publication venues p d hoff a e raftery and m s handcock latent space approaches to social network analysis j amer statist assoc this latent space network model which embeds each node into a low dimensional latent space was written as far back as and so it far pre dates neural network based network embeddings given that the aim of this paper is to model differing representations of social network actors different roles it should really cite and compare to the mixed membership stochastic blockmodel mmsb airoldi e m blei d m fienberg s e xing e p mixed membership stochastic blockmodels journal of machine learning research the mmsb allows each node to randomly select a different role when deciding whether to form each edge general discussion the aforementioned statistical models do not leverage text and they do not use scalable neural network implementations based on negative sampling but they are based on well principled generative models instead of heuristic neural network objective functions and algorithms there are more recent extensions of these models and inference algorithms which are more scalable and which do leverage text is the difference in performance between cene and cane in figure statistically insignificant a related question were the experiments repeated more than once with random train test splits were the grid searches for hyperparameter values mentioned in section performed with evaluation on the test set which would be problematic or on a validation set or on the training set,4.0
16.json,strengths this paper tries to use the information from arguments which is usually ignored yet actually quite important to improve the performance of event detection the framework is clear and simple with the help of the supervised attention mechanism an important method that has been used in many tasks such as machine translation the performance of their system outperforms the baseline significantly weaknesses the attention vector is simply the summation of two attention vectors of each part maybe the attention vector could be calculated in a more appropriate approach for the supervised attention mechanism two strategies are proposed both of them are quite straightforward some more complicated strategies can work better and can be tried general discussion although there are some places that can be improved this paper proposed a quite effective framework and the performance is good the experiment is solid it can be considered to be accepted,4.0
288.json,strengths the paper is very well written it shows how stylometric analysis can help in reasoning like text classification the results have important implications for design on nlp datasets the results may have important implications for many text classification tasks weaknesses i see few weaknesses in this paper the only true one is the absence of a definition of style which is a key concept in the paper general discussion this paper describes two experiments that explore the relationship between writing task and writing style in particular controlling for vocabulary and topic the authors show that features used in authorship attribution style analysis can go a long way towards distinguishing between a natural ending of a story an ending added by a different author and a purposefully incoherent ending added by a different author this is a great and fun paper to read and it definitely merits being accepted the paper is lucidly written and clearly explains what was done and why the authors use well known simple features and a simple classifier to prove a non obvious hypothesis intuitively it is obvious that a writing task greatly constraints style however proven in such a clear manner in such a controlled setting the findings are impressive i particularly like section and the discussion about the implications on design of nlp tasks i think this will be an influential and very well cited paper great work the paper is a very good one as is one minor suggestion i have is defining what the authors mean by style early on the authors seem to mean a set of low level easily computable lexical and syntactic features as is the usage is somewhat misleading for anyone outside of computational stylometrics the set of chosen stylistic features makes sense however were there no other options were other features tried and they did not work i think a short discussion of the choice of features would be informative,5.0
699.json,this paper proposes to use an encoder decoder framework for keyphrase generation experimental results show that the proposed model outperforms other baselines if supervised data is available strengths the paper is well organized and easy to follow the intuition of the proposed method is clear it includes enough details to replicate experiments although the application of an encoder decoder copy mechanism is straightforward experimental results are reasonable and support the claim generation of absent keyphrases presented in this paper weaknesses as said above there is little surprise in the proposed approach also as described in section the trained model does not transfer well to new domain it goes below unsupervised models one of the contribution of this paper is to maintain training corpora in good quantity and quality but it is not explicitly stated general discussion i like to read the paper and would be pleased to see it accepted i would like to know how the training corpus size and variation affects the performance of the proposed method also it would be beneficial to see the actual values of pg and pc along with examples in figure in the copyrnn model from my experience in running the copynet the copying mechanism sometimes works unexpectedly not sure why this happens,4.0
676.json,strengths the proposed methods can save memory and improve decoding speed on cpus without losing or a little loss performance weaknesses since the determination of the convolutional codes of algorithm and algorithm can affect the final performance i think it would be better if the authors can explore a good method for it and i think the argument of experiments show the proposed model achieves translation accuracies that approach the softmax while reducing memory usage on the order of to and also improving decoding speed on cpus by x to x in the abstract is not rigorous as far as i know your experiments setting with binary and hybrid on aspec corpus show the improvements of decoding speed on cpus by x but the bleu scores are too low so this is not a valid conclusion general discussion this paper proposes an efficient prediction method for neural machine translation which predicts a binary code for each word to reduce the complexity of prediction the authors also proposed to use the improved error correction binary codes method to improve the prediction accuracy and the hybrid softmax binary model to balance the prediction accuracy and efficiency the proposed methods can save memory and improve decoding speed without losing or a little loss performance i think this is a good paper,4.0
676.json,strengths this paper has high originality proposing a fundamentally different way of predicting words from a vocabulary that is more efficient than a softmax layer and has comparable performance on nmt if successful the approach could be impactful because it speeds up prediction this paper is nice to read with great diagrams it very clearly presented i like cross referencing the models with the diagrams in table including loss curves is appreciated weaknesses though it may not be possible in the time remaining it would be good to see a comparison i e bleu scores with previous related work like hierarchical softmax and differentiated softmax the paper is lacking a linguistic perspective on the proposed method compared to a softmax layer and hierarchical differentiated softmax is binary code prediction a natural way to predict words is it more or less similar to how a human might retrieve words from memory is there a theoretical reason to believe that binary code based approaches should be more or less suited to the task than softmax layers though the paper promises faster training speeds in the introduction table shows only modest less than x speedups for training presumably this is because much of the training iteration time is consumed by other parts of the network it would be useful to see the time needed for the output layer computation only general discussion it would be nice if the survey of prior work in explicitly related those methods to the desiderata in the introduction i e specify which they satisfy some kind of analysis of the qualitative strengths and weaknesses of the binary code prediction would be welcome what kind of mistakes does the system make and how does this compare to standard softmax and or hierarchical and differentiated softmax low level comments equation what is the difference between id w id w and w w consider defining gpgpu table highlight the best bleu scores in bold equation remind the reader that q is defined in equation and b is a function of w i was confused by this at first because w and h appear on the lhs but do not appear on the right and i did not know what b and q were,4.0
226.json,strengths this paper proposed a semi automated framework human generation auto expansion human post editing to construct a compositional semantic similarity evaluation data set the proposed framework is used to create a polish compositional semantic similarity evaluation data set which is useful for future work in developing polish compositional semantic models weaknesses the proposed framework has only been tested on one language it is not clear whether the framework is portable to other languages for example the proposed framework relies on a dependency parser which may not be available in some languages or in poor performance in some other languages the number of sentence pairs edited by leader judges is not reported so the correctness and efficiency of the automatic expansion framework can not be evaluated the fact that more than out of k of the post edited pairs need further post editing is worrying there are quite a number of grammatical mistakes here are some examples but not the complete and exhaustive list line on a displayed image picture in a displayed image picture line similarly as in similar to a proofread pass on the paper is needed general discussion,4.0
524.json,strengths elaborate evaluation data creation and evaluation scheme range of compared techniques baseline simple complex weaknesses no in depth analysis beyond overall evaluation results general discussion this paper compares several techniques for robust hpsg parsing since the main contribution of the paper is not a novel parsing technique but the empirical evaluation i would like to see a more in depth analysis of the results summarized in table and it would be nice to show some representative example sentences and sketches of its analyses on which the compared methods behaved differently please add edm precision and recall figures to table the edm f score is a result of a mixed effects of overall and partial coverage parse ranking efficiency of search etc the overall coverage figures in table are helpful but addition of edm recall to table would make the situations clearer minor comment is pacnv ut in table and the same as pacnv described in,3.0
524.json,strengths well written weaknesses although the title and abstract of the paper suggest that robust parsing methods for hpsg are being compared the actual comparison is limited to only a few techniques applied to a single grammar the erg where in the past the choice has been made to create a treebank for only those sentences that are in the coverage of the grammar since the erg is quite idiosyncratic in this respect i fear that the paper is not interesting for researchers working in other precision grammar frameworks the paper lacks comparison with robustness techniques that are routinely applied for systems based on other precision grammars such as various systems based on ccg lfg the alpage system for french alpino for dutch and there is probably more in the same spirit there is a reference for supertagging to dridan which is about supertagging for erg whereas supertagging for other precision grammar systems has been proposed at least a decade earlier the paper lacks enough detail to make the results replicable not only are various details not spelled out e g what are those limits on resource allocation but perhaps more importantly for some of the techniques that are being compared eg the robust unification and for the actual evaluation metric the paper refers to another paper that is still in preparation the actual results of the various techniques are somewhat disappointing with the exception of the csaw tb method the resulting parsing speed is extreme sometimes much slower than the baseline method where the baseline method is a method in which the standard resource limitations do not apply the csaw tb method is faster but not very accurate and in any case it is not a method introduced in this paper but an existing pcfg approximation technique it would be more interesting to have an idea of the results on a representative dataset consisting of both sentences that are in the coverage of the grammar and those that are not in that case a comparison with the real baseline system erg with standard settings could be obtained methodological issue the datasets semcor and wsjab consist of sentences which an older version of erg could not parse but a newer version could for this reason the problems in these two datasets are clearly very much biased it is no suprise therefore that the various techniques obtain much better results on those datasets but to this reviewer those results are somewhat meaningless minor edm is used before explained reverseability general discussion,2.0
524.json,strengths technique for creating dataset for evaluation of out of coverage items that could possibly be used to evaluation other grammars as well the writing in this paper is engaging and clear a pleasant surprise as compared to the typical acl publication weaknesses the evaluation datasets used are small and hence results are not very convincing particularly wrt to the alchemy dataset on which the best results have been obtained it is disappointing to see only f scores and coverage scores but virtually no deeper analysis of the results for instance a breakdown by type of error type of grammatical construction would be interesting it is still not clear to this reviewer what is the proportion of out of coverage items due to various factors running out of resources lack of coverage for genuine grammatical constructions in the long tail lack of coverage due to extra grammatical factors like interjections disfluencies lack of lexical coverage etc general discussion this paper address the problem of robustness or lack of coverage for a hand written hpsg grammar english resource grammar the paper compares several approaches for increasing coverage and also presents two creative ways of obtaining evaluation datasets a non trivial issue due to the fact that gold standard evaluation data is by definition available only for in coverage inputs although hand written precision grammars have been very much out of fashion for a long time now and have been superseded by statistical treebank based grammars it is important to continue research on these in my opinion the advantages of high precision and deep semantic analysis provided by these grammars has not been reproduced by non handwritten grammars as yet for this reason i am giving this paper a score of despite the shortcomings mentioned above,3.0
318.json,this work showed that word representation learning can benefit from sememes when used in an appropriate attention scheme authors hypothesized that sememes can act as an essential regularizer for wrl and wsi tasks and proposed se wl model which detects word senses and learn representations simultaneously though experimental results indicate that wrl benefits exact gains for wsi are unclear since a qualitative case study of a couple of examples has only been done overall paper is well written and well structured in the last paragraph of introduction section authors tried to tell three contributions of this work and are more of novelties of the work rather than contributions i see the main contribution of the work to be the results which show that we can learn better word representations unsure about wsi by modeling sememe information than other competitive baselines is neither a contribution nor a novelty the three strategies tried for se wrl modeling makes sense and can be intuitively ranked in terms of how well they will work authors did a good job explaining that and experimental results supported the intuition but the reviewer also sees mst as a fourth strategy rather than a baseline inspired by chen et al many wsi systems assume one sense per word given a context mst many times performed better than ssa and sac unless authors missed to clarify otherwise mst seems to be exactly like sat with a difference that target word is represented by the most probable sense rather than taking an attention weighted average over all its senses mst is still an attention based scheme where sense with maximum attention weight is chosen though it has not been clearly mentioned if target word is represented by chosen sense embedding or some function of it authors did not explain the selection of datasets for training and evaluation tasks reference page to sogou t text corpus did not help as reviewer does not know chinese language it was unclear which exact dataset was used as there are several datasets mentioned on that page why two word similarity datasets were used and how they are different like does one has more rare words than another since different models performed differently on these datasets the choice of these datasets did not allow evaluating against results of other works which makes the reviewer wonder about next question are proposed sat model results state of the art for chinese word similarity e g schnabel et al report a score of on wordsim data by using cbow word embeddings reviewer needs clarification on some model parameters like vocabulary sizes for words does sogou t contains billion unique words and word senses how many word types from hownet because of the notation used it is not clear if embeddings for senses and sememes for different words were shared reviewer hopes that is the case but then why dimensional embeddings were used for only sememes it would be better if complexity of model parameters can also be discussed may be due to lack of space but experiment results discussion lack insight into observations other than sat performing the best also authors claimed that words with lower frequency were learned better with sememes without evaluating on a rare words dataset i have read author response,4.0
318.json,strengths this paper proposes the use of hownet to enrich embedings the idea is interesting and gives good results weaknesses the paper is interesting but i am not sure the contibution is important enough for a long paper also the comparision with other works may not be fair authors should compare to other systems that use manually developed resources the paper is understandable but it would help some improvement on the english general discussion,3.0
477.json,strengths i motivation is well described ii provides detailed comparisons with various models across diverse languages weaknesses i the conclusion is biased by the selected languages ii the experiments do not cover the claim of this paper completely general discussion this paper issues a simple but fundamental question about word representation what subunit of a word is suitable to represent morphologies and how to compose the units to answer this question this paper applied word representations with various subunits characters character trigram and morphs and composition functions lstm cnn and a simple addition to the language modeling task to find the best combination in addition this paper evaluated the task for more than languages this is because languages are typologically diverse and the results can be different according to the word representation and composition function from their experimental results this paper concluded that character level representations are more effective but they are still imperfective in comparing them with a model with explicit knowledge of morphology another conclusion is that character trigrams show reliable perplexity in the majority of the languages however this paper leaves some issues behind first of all there could be some selection bias of the experimental languages this paper chose ten languages in four categories up to three languages per a category but one basic question with the languages is how can it be claimed that the languages are representatives of each category all the languages in the same category have the same tendency of word representation and composition function how can it be proved for instance even in this paper two languages belonging to the same typology agglutinative show different results therefore at least to me it seems to be better to focus on the languages tested in this paper instead of drawing a general conclusions about all languages there is some gap between the claim and the experiments is the language modeling the best task to prove the claim of this paper isn t there any chance that the claim of this paper breaks in other tasks further explanation on this issue is needed in section this paper evaluated the proposed method only for arabic is there any reason why the experiment is performed only for arabic there are plenty of languages with automatic morphological analyzers such as japanese and turkish this paper considers only character trigram among various n grams is there any good reason to choose only character trigram is it always better than character bigram or character fourgram in general language modeling with n grams is affected by corpus size and some other factors minor typos there is a missing reference in introduction line in page root and patter root and pattern line in page,3.0
134.json,strengths the paper is well written and easy to understand the methods and results are interesting weaknesses the evaluation and the obtained results might be problematic see my comments below general discussion this paper proposes a system for end to end argumentation mining using neural networks the authors model the problem using two approaches sequence labeling dependency parsing the paper also includes the results of experimenting with a multitask learning setting for the sequence labeling approach the paper clearly explains the motivation behind the proposed model existing methods are based on ilp manual feature engineering and manual design of ilp constraints however the proposed model avoids such manual effort moreover the model jointly learns the subtasks in argumentation mining and therefore avoids the error back propagation problem in pipeline methods except a few missing details mentioned below the methods are explained clearly the experiments are substantial the comparisons are performed properly and the results are interesting my main concern about this paper is the small size of the dataset and the large capacity of the used bi lstm based recurrent neural networks blc and blcc the dataset includes only around essays for training and essays for testing the size of the development set however is not mentioned in the paper and also the supplementary materials this is worrying because very few number of essays are left for training which is a crucial problem the total number of tags in the training data is probably only a few thousand compare it to the standard sequence labeling tasks where hundreds of thousands sometimes millions of tags are available for this reason i am not sure if the model parameters are trained properly the paper also does not analyze the overfitting problem it would be interesting to see the training and development loss values during training after each parameter update or after each epoch the authors have also provided some information that can be seen as the evidence for overfitting line our explanation is that taggers are simpler local models and thus need less training data and are less prone to overfitting for the same reason i am not sure if the models are stable enough mean and standard deviation of multiple runs different initializations of parameters need to be included statistical significance tests would also provide more information about the stability of the models and the reliability of results without these tests it is hard to say if the better results are because of the superiority of the proposed method or chance i understand that the neural networks used for modeling the tasks use their regularization techniques however since the size of the dataset is too small the authors need to pay more attention to the regularization methods the paper does not mention regularization at all and the supplementary material only mentions briefly about the regularization in lstm er this problem needs to be addressed properly in the paper instead of the current hyper parameter optimization method described in supplementary materials consider using bayesian optimization methods also move the information about pre trained word embeddings and the error analysis from the supplementary material to the paper the extra one page should be enough for this please include some inter annotator agreement scores the paper describing the dataset has some relevant information this information would provide some insight about the performance of the systems and the available room for improvement please consider illustrating figure with different colors to make the quality better for black and white prints edit thanks for answering my questions i have increased the recommendation score to please do include the f score ranges in your paper and also report mean and variance of different settings i am still concerned about the model stability for example the large variance of kiperwasser setting needs to be analyzed properly even the f changes in the range is relatively large including these score ranges in your paper helps replicating your work,4.0
134.json,the work describes a joint neural approach to argumentation mining there are several approaches explored including casting the problem as a dependency parsing problem trying several different parsers casting the problem as a sequence labeling problem multi task learning based on sequence labeling model underneath an out of the box neural model for labeling entities and relations lstm er ilp based state of the art models all the approaches are evaluated using f defined on concepts and relations dependency based solutions do not work well seq labeling solutions are effective the out of the box lstm er model performs very well especially on paragraph level the seq labeling and lstm er models both outperform the ilp approach a very comprehensive supplement was given with all the technicalities of training the models optimizing hyper parameters etc it was also shown that sequence labeling models can be greatly improved by the multitask approach with the claim task helping more than the relation task the aper is a very thorough investigation of neural based approaches to end to end argumentation mining major remarks my one concern is with the data set i am wondering if it a problem that essays in the train set and in the test set might be on the same topics consequently writers might use the same or similar arguments in both essays leading to information leakage from the train to the test set in turn this might give overly optimistic performance estimates though i think the same issues are present for the ilp models so your model does not have an unfair advantage still this may be something to discuss my other concern is that one of your best models lstm er is acutally just a an out of the box application of a model from related work however given the relative success of sequence based models and all the experiments and useful lessons learned i think this work deserves to be published minor remarks and questions i guess you are arguing that it possible to reconstruct the full graph once you get a tree as output still this part is not quite clear the ordering in this section is seq tagging dependency based mtl using seq tagging it would be much easier to follow if the order of the first two were reversed by the time i got here i would forgotten what stagt stood for what does it mean that it de couples them but jointly models them is not coupling them required to jointly model them i checked miwa and bansal and i could not find it it confusing when you say your system de couples relation info from entity info my best guess is that you mean it learns some tasks as the edges of the tree and some other tasks as the labels on those edges thus decoupling them in any case i recommend you make this part clearer are the f scores in the paragraph and essay settings comparable in particular for the relation tasks i am wondering if paragraph based models might miss some cross paragraph relations by default because they will never consider them,4.0
122.json,strengths this paper proposes a novel approach for dialogue state tracking that benefits from representing slot values with pre trained embeddings and learns to compose them into distributed representations of user utterances and dialogue context experiments performed on two datasets show consistent and significant improvements over the baseline of previous delexicalization based approach alternative approaches i e xavier glove program sl for pre training word embeddings have been investigated weaknesses although one of the main motivations for using embeddings is to generalize to more complex dialogue domains where delexicalization may not scale for the datasets used seem limited i wonder how the approach would compare with and without a separate slot tagging component on more complex dialogues for example when computing similarity between the utterance and slot value pairs one can actually limit the estimation to the span of the slot values this should be applicable even when the values do not match i think the examples in the intro is misleading shouldn t the dialogue state also include restaurantname the house this brings another question how does resolution of coreferences impact this task general discussion on the overall use of pre trained word embeddings is a great idea and the specific approach for using them is exciting,4.0
122.json,this paper presents a neural network based framework for dialogue state tracking the main contribution of this work is on learning representations of user utterances system outputs and also ontology entries all of which are based on pre trained word vectors particularly for the utterance representation the authors compared two different neural network models nbt dnn and nbt cnn the learned representations are combined with each other and finally used in the downstream network to make binary decision for a given slot value pair the experiment shows that the proposed framework achieved significant performance improvements compared to the baseline with the delexicalized approach it generally a quality work with clear goal reasonable idea and improved results from previous studies but the paper itself does not seem to be very well organized to effectively deliver the details especially to readers who are not familiar with this area first of all more formal definition of dst needs to be given at the beginning of this paper it is not clear enough and could be more confusing after coupling with slu my suggestion is to provide a general architecture of dialogue system described in section rather than section followed by the problem definition of dst focusing on its relationships to other components including asr slu and policy learning and it would also help to improve the readability if all the notations used throughout the paper are defined in an earlier section some symbols e g tq ts tv are used much earlier than their descriptions below are other comments or questions would it be possible to perform the separate slu with this model if no the term joint could be misleading that this model is able to handle both tasks could you please provide some statistics about how many errors were corrected from the original dstc dataset if it is not very huge the experiment could include the comparisons also with other published work including dstc entries using the same dataset what do you think about using rnns or lstms to learn the sequential aspects in learning utterance representations considering the recent successes of these recurrent networks in slu problems it could be effective to dst as well some more details about the semantic dictionary used with the baseline would help to imply the cost for building this kind of resources manually it would be great if you could give some samples which were not correctly predicted by the baseline but solved with your proposed models,4.0
56.json,strengths this paper presents an extension of many popular methods for learning vector representations of text the original methods such as skip gram with negative sampling glove or other pmi based approaches currently use word cooccurrence statistics but all of those approaches could be extended to n gram based statistics n gram based statistics would increase the complexity of every algorithm because both the vocabulary of the embeddings and the context space would be many times larger this paper presents a method to learn embeddings for ngrams with ngram context and efficiently computes these embeddings on similarity and analogy tasks they present strong results weaknesses i would have loved to see some experiments on real tasks where these embeddings are used as input beyond the experiments presented in the paper that would have made the paper far stronger general discussion even with the aforementioned weakness i think this is a nice paper to have at acl i have read the author response,4.0
56.json,strengths the idea to train wordvec type models with ngrams here specifically bigrams instead of words is excellent the range of experimental settings four wordvec type algorithms several word bigram conditions covers quite a bit of ground the qualitative inspection of the bigram embeddings is interesting and shows the potential of this type of model for multi word expressions weaknesses this paper would benefit from a check by a native speaker of english especially regarding the use of articles the description of the similarity and analogy tasks comes at a strange place in the paper datasets general discussion as is done at some point well into the paper it could be clarified from the start that this is simply a generalization of the original wordvec idea redefining the word as an ngram unigram and then also using bigrams it would be good to give a rationale why larger ngrams have not been used i have read the author response,4.0
56.json,this paper modifies existing word embedding algorithms glove skip gram ppmi svd to include ngram ngram cooccurance statistics to deal with the large computational costs of storing such expensive matrices the authors propose an algorithm that uses two different strategies to collect counts strengths the proposed work seems like a natural extension of existing work on learning word embeddings by integrating bigram information one can expect to capture richer syntactic and semantic information weaknesses while the authors propose learning embeddings for bigrams bibi case they actually do not evaluate the embeddings for the learned bigrams except for the qualitative evaluation in table a more quantitative evaluation on paraphrasing or other related tasks that can include bigram representations could have been a good contribution the evaluation and the results are not very convincing the results do not show consistent trends and some of the improvements are not necessarily statistically significant the paper reads clunkily due to significant grammar and spelling errors and needs a major editing pass general discussion this paper is an extension of standard embedding learning techniques to include information from bigram bigram coocurance while the work is interesting and a natural extension of existing work the evaluation and methods leaves some open questions apart from the ones mentioned in the weaknesses some minor questions for the authors why is there significant difference between the overlap and non overlap cases i would be more interested in finding out more than the quantitative difference shown on the tasks i have read the author response i look forward to seeing the revised version of the paper,3.0
335.json,this paper presents the gated self matching network for reading comprehension style question answering there are three key components in the solution a the paper introduces the gated attention based recurrent network to obtain the question aware representation for the passage here the paper adds an additional gate to attention based recurrent networks to determine the importance of passage parts and attend to the ones relevant to the question here they use word as well as character embeddings to handle oov words overall this component is inspired from wang and jiang b then the paper proposes a self matching attention mechanism to improve the representation for the question and passage by looking at wider passage context necessary to infer the answer this component is completely novel in the paper c at the output layer the paper uses pointer networks to locate answer boundaries this is also inspired from wang and jiang overall i like the paper and think that it makes a nice contribution strengths the paper clearly breaks the network into three component for descriptive purposes relates each of them to prior work and mentions its novelties with respect to them it does a sound empirical analysis by describing the impact of each component by doing an ablation study this is appreciated the results are impressive weaknesses the paper describes the results on a single model and an ensemble model i could not find any details of the ensemble and how was it created i believe it might be the ensemble of the character based and word based model can the authors please describe this in the rebuttal and the paper general discussion along with the ablation study it would be nice if we can have a qualitative analysis describing some example cases where the components of gating character embedding self embedding etc become crucial where a simple model does not get the question right but adding one or more of these components helps this can go in some form of appendix or supplementary,4.0
636.json,this work proposes to apply dilated convolutions for sequence tagging specifically named entity recognition it also introduces some novel ideas sharing the dilated convolution block predicting the tags at each convolution level which i think will prove useful to the community the paper performs extensive ablation experiments to show the effectiveness of their approach i found the writing to be very clear and the experiments were exceptionally thorough strengths extensive experiments against various architectures lstm lstm crf novel architectural training ideas sharing blocks weaknesses only applied to english ner this is a big concern since the title of the paper seems to reference sequence tagging directly section could be clearer for example i presume there is padding to make sure the output resolution after each block is the same as the input resolution might be good to mention this i think an ablation study of number of layers vs perf might be interesting response to author rebuttal thank you very much for a thoughtful response given that the authors have agreed to make the content be more specific to ner as opposed to sequence tagging i have revised my score upward,4.0
636.json,strengths the main strength promised by the paper is the speed advantage at the same accuracy level weaknesses presentation of the approach leaves a lot to be desired sections and need to be much clearer from concept definition to explaining the architecture and parameterization in particular section and the parameter tieing used need to be crystal clear since that is one of the main contributions of the paper more experiments supporting the vast speed improvements promised need to be presented the results in table are good but not great a speed up of x is nothing all that transformative general discussion what exactly is viterbi prediction the term concept is far from established the reader could guess but there must be a better way to phrase it reference weiss et al has a typo,3.0
266.json,strengths an interesting and comprehensive study of the effect of using special domain corpora for training word embeddings clear explanation of the assumptions contributions methodology and results thorough evaluation of various aspects of the proposal weaknesses some conclusions are not fully backed up by the numerical results e g the authors claim that for catalan the improvements of using specific corpora for training word vectors is more pronounced than english i am not sure why this conclusion is made based on the results e g in table none of the combination methods outperform the baseline for the dimension vectors general discussion the paper presents a set of simple yet interesting experiments that suggest word vectors here trained using the skip gram method largely benefit from the use of relevant in domain and subjective corpora the paper answers important questions that are of benefit to practitioners of natural language processing the paper is also very well written and very clearly organized,3.0
180.json,this paper presents a new dataset with annotations of products coming from online cybercrime forums the paper is clear and well written and the experiments are good every hypothesis is tested and compared to each other however i do have some concerns about the paper the authors took the liberty to change the font size and the line spacing of the abstract enabling them to have a longer abstract and to fit the content into the pages requirement i do not think this paper fits the tagging chunking parsing area as it is more an information extraction problem i have difficulties to see why some annotations such as sombody in fig are related to a product the basic results are very basic indeed and with all the tools available nowadays in nlp i am sure that it would have been possible to have more elaborate baselines without too much extra work domain adaptation experiments corroborate what we already know about user generated data where two forums on video games e g may have different types of users age gender etc leading to very different texts so this does not give new highlights on this specific problem,3.0
657.json,strengths this paper addresses in part the problem of interpreting long short term memory lstm neural network models trained to categorize written justifications in values affirmation essays this is definitely an interesting research question to do so the authors want to rely on approaches that have are standard in experimental psychology furthermore the authors also aim at validating sociological assumptions via this study weaknesses one of the main weaknesses of the paper lies in the fact that the goals are not clear enough one overall ambitious goal put forward by the authors is to use approaches from experimental psychology to interpret lstms however no clear methodology to do so is presented in the paper on the other hand if the goal is to validate sociological assumptions then one should do so by studying the relationships between gender markers and the written justifications independently on any model the claim that expected gender differences are a function of theories of gendered self construal is not proven in the study general discussion if the study is interesting it suffers from several weak arguments first of all the fact that the probability shift of a token in the lstm network are correlated with the corresponding svm coefficients is no proof that these probabilities are valid ways to interpret the model indeed a svm coefficients only reveal part of what is happening in the decision function of an svm classifie and b it is not because one coefficient provides an interpretation in one model that a correlated coefficient provides an explanation in another model furthermore the correlation coefficients are not that high so that the point put forward is not really backed up as mentioned before another problem lies in the fact that the authors seem to hesitate between two goals it would be better to clearly state one goal and develop it concerning the relation to experimental psychology which is a priori an important part of the paper it would be interesting to develop and better explain the multilevel bayesian models used to quantify the gender based self construal assumptions it is very difficult to assess whether the methodology used here is really appropriate without more details as this is an important aspect of the method it should be further detailed,2.0
483.json,the paper presents an application of pointer networks a recurrent neural network model original used for solving algorithmic tasks to two subtasks of argumentation mining determining the types of argument components and finding the links between them the model achieves state of the art results strengths thorough review of prior art in the specific formulation of argument mining handled in this paper simple and effective modification of an existing model to make it suitable for the task the model is mostly explained clearly strong results as compared to prior art in this task weaknesses this formulation of argumentation mining is just one of several proposed subtask divisions and this should be mentioned for example in claims are detected and classified before any supporting evidence is detected furthermore applied neural networks to this task so it is inaccurate to say as is claimed in the abstract of this paper that this work is the first nn based approach to argumentation mining two things must be improved in the presentation of the model what is the pooling method used for embedding features line and equation in line is not clear enough is ei the random variable representing the type of ac i or its identity both are supposedly modeled the latter by feature representation and need to be defined furthermore it seems like the lhs of equation should be a conditional probability there are several unclear things about table first why are the three first baselines evaluated only by macro f and the individual f scores are missing this is not explained in the text second why is only the pn model presented is this the same pn as in table or actually the joint model what about the other three it is not mentioned which dataset the experiment described in table was performed on general discussion there has to be a lengthier introduction to pointer networks mentioning recurrent neural networks in general for the benefit of readers unfamiliar with sequence to sequence models also the citation of sutskever et al in line should be at the first mention of the term and the difference with respect to recursive neural networks should be explained before the paragraph starting in line tree structure etc the elu activation requires an explanation and citation still not enough well known mc cl and pr should be explained in the label a sentence about how these hyperparameters were obtained would be appropriate the decision to do early stopping only by link prediction accuracy should be explained i e why not average with type accuracy for example inference at test time is briefly explained but would benefit from more details specify what the length of an ac is measured in words the referent of these in neither of these is unclear minimum should be maximum the performance w r t the amount of training data is indeed surprising but other models have also achieved almost the same results this is especially surprising because nns usually need more data it would be good to say this this could alternatively show that structural cues are less important for this task some minor typos should be corrected e g which is show line rinott ruty et al show me your evidence an automatic method for context dependent evidence detection emnlp laha anirban and vikas raykar an empirical evaluation of various deep learning architectures for bi sequence classification tasks coling,4.0
21.json,the paper is clearly written and the claims are well supported the related work in particular is very thorough and clearly establishes where the proposed work fits in the field i had two main questions about the method phrases are mentioned in section but only word representations are discussed how are phrase representations derived there is no explicit connection between m and m in the model but they are indirectly connected through the tanh scoring function how do the learned matrices compare to one another e g is m like m furthermore what would be the benefits drawbacks of linking the two together directly by enforcing some measure of dissimilarity additionally statistical significance of the observed improvements would be valuable typographical comments line word phase pair should be word phrase pair line i propose an alternate wording instead of entities are translated to say entities are mapped to at first i read that as a translation operation in the vector space which i think is not exactly what is being described line slightly improvement in f measure should be slight improvement in f measure line extraneous commas in citation line the most case should be the most likely case i am guessing line extraneous period and comma in citation,4.0
21.json,strengths interesting research problem the method in this paper looks quite formal the authors have released their dataset with the submission the design of experiments is good weaknesses the advantage and disadvantage of the transductive learning has not yet discussed general discussion in this paper the authors introduce a transductive learning approach for chinese hypernym prediction which is quite interesting problem the authors establish mappings from entities to hypernyms in the embedding space directly which sounds also quite novel this paper is well written and easy to follow the first part of their method preprocessing using embeddings is widely used method for the initial stage but it still a normal way to preprocess the input data the transductive model is an optimization framework for non linear mapping utilizing both labeled and unlabeled data the attached supplementary notes about the method makes it more clear the experimental results have shown the effectiveness of the proposed method in this paper the authors also released dataset which contributes to similar research for other researchers in future,4.0
440.json,strengths this paper presents an extension to a ccg parsing to include dependency information achieving this while maintaining speed and tractability is a very impressive feature of this approach the ability to precompute attachments is a nice trick i also really appreciated the evaluation of the effect of the head rules on normal form violations and would love to see more details on the remaining cases weaknesses i would like to see more analysis of certain dependency structures i am particularly interested in how coordination and relative clauses are handled when the predicate argument structure of ccg is at odds with the dependency structures normally used by other dependency parsers general discussion i am very happy with this work and feel it a very nice contribution to the literature the only thing missing for me is a more in depth analysis of the types of constructions which saw the most improvement english and japanese and a discussion mentioned above reconciling pred arg dependencies with those of other parsers,4.0
440.json,this paper describes a state of the art ccg parsing model that decomposes into tagging and dependency scores and has an efficient a decoding algorithm interestingly the paper slightly outperforms lee et al more expressive global parsing model presumably because this factorization makes learning easier it great that they also report results on another language showing large improvements over existing work on japanese ccg parsing one surprising original result is that modeling the first word of a constituent as the head substantially outperforms linguistically motivated head rules overall this is a good paper that makes a nice contribution i only have a few suggestions i liked the way that the dependency and supertagging models interact but it would be good to include baseline results for simpler variations e g not conditioning the tag on the head dependency the paper achieves new state of the art results on japanese by a large margin however there has been a lot less work on this data would it also be possible to train the lee et al parser on this data for comparison lewis he and zettlemoyer explore combined dependency and supertagging models for ccg and srl and may be worth citing,4.0
769.json,this paper presents a novel framework for modelling symmetric collaborative dialogue agents by dynamically extending knowledge graphs embeddings the task is rather simple two dialogue agents bot bot human human or human bot talk about their mutual friends there is an underlying knowledge base for each party in the dialogue and an associated knowledge graph items in the knowledge graph have embeddings that are dynamically updated during the conversation and used to generate the answers strengths this model is very novel for both goal directed and open ended dialogue the presented evaluation metrics show clear advantage for the presented model weaknesses in terms of the presentation mathematical details of how the embeddings are computed are not sufficiently clear while the authors have done an extensive evaluation they have not actually compared the system with an rl based dialogue manager which is current state of the art in goal oriented systems finally it is not clear how this approach scales to more complex problems the authors say that the kb is k but actually what the agent operates is about judging from table general discussion overall i think this is a good paper had the theoretical aspects of the paper been better presented i would give this paper an accept,3.0
627.json,this paper presents a dialogue agent where the belief tracker and the dialogue manager are jointly optimised using the reinforce algorithm it learns from interaction with a user simulator there are two training phases the first is an imitation learning phase where the system is initialised using supervising learning from a rule based model then there is a reinforcement learning phase where the system has jointly been optimised using the rl objective strengths this paper presents a framework where a differentiable access to the kb is integrated in the joint optimisation this is the biggest contribution of the paper weaknesses firstly this is not a truly end to end system considering the response generation was handcrafted rather than learnt also their ee model actually overfits to the simulator and performs poorly in human evaluation this begs the question whether the authors are actually selling the idea of ee learning or the soft kb access the soft kb access actually brings consistent improvement however the idea of end to end learning not so much the authors tried to explain the merits of ee in figure but i also fail to see the difference in addition the authors did not motivate the reason for using the reinforce algorithm which is known to suffer from high variance problem they did not attempt to improve it by using a baseline or perhaps considering the natural actor critic algorithm which is known to perform better general discussion apart from the mentioned weaknesses i think the experiments are solid and this is generally an acceptable paper however if they crystallised the paper around the idea which actually improves the performance the soft kb access but not the idea of ee learning the paper would be better,4.0
365.json,update after reading author response the alignment of the hidden units does not match with my intuition and experience but i am willing to believe i am wrong in this case discussing the alignment in the paper is important and maybe just sanity checking that the alignment goes away if you initialize with a different seed if what you are saying about how the new model is very different but only a little better performing a error reduction then i wonder about an ensemble of the new model and the old one seems like ensembling would provide a nice boost if the failures across models are distinct right anyhow this is a solid paper and i appreciate the author response i raise my review score to a strengths evidence of the attention mtl connection is interesting methods are appropriate models perform well relative to state of the art weaknesses critical detail is not provided in the paper models are not particularly novel general discussion this paper presents a new method for historical text normalization the model performs well but the primary contribution of the paper ends up being a hypothesis that attention mechanisms in the task can be learned via multi task learning where the auxiliary task is a pronunciation task this connection between attention and mtl is interesting there are two major areas for improvement in this paper the first is that we are given almost no explanation as to why the pronunciation task would somehow require an attention mechanism similar to that used for the normalization task why the two tasks normalization and pronunciation are related is mentioned in the paper spelling variation often stems from variation in pronunciation but why would doing mtl on both tasks result in an implicit attention mechanism and in fact one that is then only hampered by the inclusion of an explicit attention mechanism this remains a mystery the paper can leave some questions unanswered but at least a suggestion of an answer to this one would strengthen the paper the other concern is clarity while the writing in this paper is clear a number of details are omitted the most important one is the description of the attention mechanism itself given the central role that method plays it should be described in detail in the paper rather than referring to previous work i did not understand the paragraph about this in sec other questions included why you can compare the output vectors of two models figure while the output dimensions are the same i do not understand why the hidden layer dimensions of two models would ever be comparable usually how the hidden states are organized is completely different for every model at the very least it is permuted so i really did not understand figure the kappa statistic for attention vs mtl needs to be compared to the same statistic for each of those models vs the base model at the end of sec is that row an upper bound across all data sets lastly the paper analysis sec seems to imply that the attention and mtl approaches make large changes to the model comparing e g fig but the experimental improvements in accuracy for either model are quite small which seems like a bit of a contradiction,4.0
365.json,summary the paper applies a sequence to sequence seqseq approach for german historical text normalization and showed that using a grapheme to phoneme generation as an auxiliary task in a multi task learning mtl seqseq framework improves performance the authors argue that the mtl approach replaces the need for an attention menchanism showing experimentally that the attention mechanism harms the mtl performance the authors also tried to show statistical correlation between the weights of an mtl normalizer and an attention based one strengths novel application of seqseq to historical text correction although it has been applied recently to sentence grammatical error identification showed that using grapheme to phoneme as an auxiliary task in a mtl setting improves text normalization accuracy weaknesses instead of arguing that the mtl approach replaces the attention mechanism i think the authors should investigate why attention did not work on mtl and perhaps modify the attention mechanism so that it would not harm performance i think the authors should reference past seqseq mtl work such as and the mtl work in also worked on non attention seqseq models this paper only tested on one german historical text data set of documents it would be interesting if the authors can evaluate the same approach in another language or data set references allen schmaltz yoon kim alexander m rush and stuart shieber sentence level grammatical error identification as sequence to sequence correction in proceedings of the th workshop on innovative use of nlp for building educational applications minh thang luong ilya sutskever quoc v le oriol vinyals and lukasz kaiser multi task sequence to sequence learning iclr dong daxiang wu hua he wei yu dianhai and wang haifeng multi task learning for multiple language translation acl here is my reply to the authors rebuttal i am keeping my review score of which means i do not object to accepting the paper however i am not raising my score for reasons the authors did not respond to my questions about other papers on seqseq mtl which also avoided using attention mechanism so in terms of novelty the main novelty lies in applying it to text normalization it is always easier to show something i e attention in seqseq mtl is not working but the value would lie in finding out why it fails and changing the attention mechanism so that it works,3.0
365.json,strengths well written solid experimental setup and intriguing qualitative analysis weaknesses except for the qualitative analysis the paper may belong better to the applications area since the models are not particularly new but the application itself is most of its novelty general discussion this paper presents a sequence to sequence model with attention mechanisms and an auxiliary phonetic prediction task to tackle historical text normalization none of the used models or techniques are new by themselves but they seem to have never been used in this problem before showing and improvement over the state of the art most of the paper seem like a better fit for the applications track except for the final analysis where the authors link attention with multi task learning claiming that the two produce similar effects the hypothesis is intriguing and it supported with a wealth of evidence at least for the presented task i do have some questions on this analysis though in section are not you assuming that the hidden layer spaces of the two models are aligned is it safe to do so section i do not get what you mean by the errors that each of the models resolve independently of each other this is like symmetric difference that is if we combine the two models these errors are not resolved anymore on a different vein why is there no comparison with azawi model after reading the author response i am feeling more concerned than i was before about your claims of alignment in the hidden space of the two models if accepted i would strongly encourage the authors to make clear in the paper the discussion you have shared with us for why you think that alignment holds in practice,4.0
220.json,strengths great paper very well written interesting results creative method good and enlightening comparisons with earlier approaches in addition the corpus which is very carefully annotated will prove to be a valuable resource for other researchers i appreciated the qualitative discussion in section too many ml papers just give present a results table without much further ado but the discussion in this paper really provides insights for the reader weaknesses in section the sentence the rest of the model s input is set to zeroes is quite enigmatic until you look at figure some extra sentence here explaining what is going on would be helpful furthermore in figure in the input layers to the lstms it says embeddings d also for the networks taking dependency labels as input surely this is wrong or if it is correct please explain what you mean general discussion concerning the comment in lstms are excellent at modelling language sequences which is why we use this type of model this comment seems strange to me this is not a sequential problem in that sense for each datapoint you feed the network all words in an example in one go and the next example has nothing to do with the preceding one the lstm architecture could still be superior of course but not for the reason you state or have i misunderstood something i would be interested to hear the authors comments on this point,5.0
467.json,strengths the paper presents an iterative method to induce bilingual word embeddings using large monolingual corpora starting with very few or automatically obtainable numeral mappings between two languages compared to state of the art using larger bilingual dictionaries or parallel comparable corpora the results obtained with the presented method that relies on very little or no manually prepared input are exciting and impressive weaknesses i would have liked to see a discussion on the errors of the method and possibly a discussion on how the method could be adjusted to deal with them general discussion does the frequency of the seeds in the monolingual corpora matter it would be interesting to see the partial in the sense of after n number of iterations evolution of the mapping between words in the two languages for a few words what happens with different translations of the same word like different senses one big difference between german and english is the prevalence of compounds in german what happens to these compounds what are they mapped onto would a preprocessing step of splitting the compounds help using maybe only corpus internal unigram information what would be the upper bound for such an approach an analysis of errors e g words very far from their counterpart in the other language would be very interesting it would also be interesting to see a discussion of where these errors come from and if they could be addressed with the presented approach,4.0
467.json,this work proposes a self learning bootstrapping approach to learning bilingual word embeddings which achieves competitive results in tasks of bilingual lexicon induction and cross lingual word similarity although it requires a minimal amount of bilingual supervision the method leads to competitive performance even when the seed dictionary is extremely small dictionary items or is constructed without any language pair specific information e g relying on numerals shared between languages the paper is very well written admirably even so i find this work eclectic in a sense that its original contribution is not a breakthrough finding it is more a hort paper idea in my opinion but it connects the dots from prior work drawing inspiration and modelling components from a variety of previous papers on the subject including the pre embedding work on self learning bootstrapping which is not fully recognized in the current version of the paper i liked the paper in general but there are few other research questions that could should have been pursued in this work these along with only a partial recognition of related work and a lack of comparisons with several other relevant baselines are my main concern regarding this paper and they should be fixed in the updated version s self learning bootstrapping of bilingual vector spaces while this work is one of the first to tackle this very limited setup for learning cross lingual embeddings although not the first one see miceli barone and more works below this is the first truly bootstrapping self learning approach to learning cross lingual embeddings however this idea of bootstrapping bilingual vector spaces is not new at all it is just reapplied to learning embeddings and there is a body of work which used exactly the same idea with traditional count based bilingual vector spaces i suggest the authors to check the work of peirsman and pado naacl or vulic and moens emnlp and recognize the fact that their proposed bootstrapping approach is not so novel in this domain there is also related work of ellen riloff group on bootstrapping semantic lexicons in monolingual settings relation to artetxe et al i might be missing something here but it seems that the proposed bootstrapping algorithm is in fact only an iterative approach which repeatedly utilises the previously proposed model formulation of artetxe et al the only difference is the reparametrization line it is not clear to me whether the bootstrapping approach draws its performance from this reparametrization and whether it would work with the previous parametrization or the performance is a product of both the algorithm and this new parametrization perhaps a more explicit statement in the text is needed to fully understand what is going on here comparison with prior work several very relevant papers have not been mentioned nor discussed in the current version of the paper for instance the recent work of duong et al emnlp on learning crosslingual word embeddings without bilingual corpora seems very related to this work as the basic word overlap between the two titles reveals and should be at least discussed if not compared to another work which also relies on mappings with seed lexicons and also partially analyzes the setting with only a few hundred seed lexicon pairs is the work of vulic and korhonen acl on the role of seed lexicons in learning bilingual word embeddings these two papers might also help the authors to provide more details for the future work section e g the selection of reliable translation pairs might boost the performance further during the iterative process another very relevant work has appeared only recently smith et al iclr discuss offline bilingual word vectors orthogonal transformations and the inverted softmax this paper also discusses learning bilingual embeddings in very limited settings e g by relying only on shared words and cognates between two languages in a pair as a side note it would be interesting to report results obtained using only shared words between the languages such words definitely exist for all three language pairs used in the experiments this would also enable a direct comparison with the work of smith et al iclr which rely on this setup seed dictionary size and bilingual lexicon induction it seems that the proposed algorithm as discussed in section is almost invariant to the starting seed lexicon yielding very similar final bli scores regardless of the starting point while a very intriguing finding per se this also seems to suggest an utter limitation of the current offline approaches they seem to have hit the ceiling with the setup discussed in the paper vulic and korhonen acl showed that we cannot really improve the results by simply collecting more seed lexicon pairs and this work suggests that any number of starting pairs from to k is good enough to reach this near optimal performance which is also very similar to the numbers reported by dinu et al arxiv or lazaridou et al acl i would like to see more discussion on how to break this ceiling and further improve bli results with such offline methods smith et al iclr seem to report higher numbers on the same dataset so again it would be very interesting to link this work to the work of smith et al in other words the authors state that in future work they plan to fine tune the method so that it can learn without any bilingual evidence this is an admirable philosophically driven feat but from a more pragmatic point of view it seems more pragmatic to detect how we can go over the plateau ceiling which seems to be hit with these linear mapping approaches regardless of the number of used seed lexicon pairs figure convergence criterion training efficiency the convergence criterion although crucial for the entire algorithm both in terms of efficiency and efficacy is mentioned only as a side note and it is not entirely clear how the whole procedure terminates i suspect that the authors use the vanishing variation in crosslingual word similarity performance as the criterion to stop the procedure but that makes the method applicable only to languages which have a cross lingual word similarity dataset i might be missing here given the current description in the paper but i do not fully understand how the procedure stops for finnish given that there is no crosslingual word similarity dataset for english finnish minor there is a finnish web as a corpus wac corpus lines https www clarin si repository xmlui handle since the authors claim that the method could work with a seed dictionary containing only shared numerals it would be very interesting to include an additional language pair which does not share the alphabet e g english russian english bulgarian or even something more distant such as arabic and or hindi after the response i would like to thank the authors for investing their time into their response which helped me clarify some doubts and points raised in my initial review i hope that they would indeed clarify these points in the final version if given the opportunity,4.0
563.json,strengths the idea to investigate the types of relations between lexical items is very interesting and challenging the authors make a good argument why going beyond analogy testing makes sense weaknesses the paper does not justify or otherwise contextualize the choice of clustering for evaluation rather than using a classification task despite the fact that classification tasks are more straightforward to evaluate no attempt is being made to explain the overall level of the results how well would humans do on this task given only the words no context general discussion i have read the authors response,4.0
563.json,this paper investigates the application of distributional vectors of meaning in tasks that involve the identification of semantic relations similar to the analogical reasoning task of mikolov et al given an expression of the form x is for france what london is for the uk x can be approximated by the simple vector arithmetic operation london uk france the authors argue that this simple method can only capture very specific forms of analogies and they present a measure that aims at identifying a wider range of relations in a more effective way i admit i find the idea of a single vector space model being able to capture a number of semantic relationships and analogies rather radical and infeasible as the authors mention in the paper a number of studies already suggest for the opposite the reason is quite simple behind all these models lies some form of the distributional hypothesis words in similar contexts have similar meanings and this poses certain limitations in their expressive abilities for example words like big and small will always be considered as semantically similar from a vector perspective although they express opposite meanings since they occur in similar contexts so i cannot see how the example given in figure is relevant to the very nature of vector spaces or to any other semantic model for that matter there is a certain analogy between man king and woman queen but asking from a word space to capture has a relationships of the form owl has claws hence hospital has walls doesn t make much sense to me the motivation behind the main proposal of the paper a similarity measure that involves a form of cross comparison between vectors of words and vectors representing the contexts of the words is not clearly explained further the measure is tested on the relation categories of the semeval task with rather unsatisfactory results in almost all cases a simple baseline that takes into account only partial similarities between the tested word pairs present very high performance with a difference from the best performing model which seems to me statistically insignificant so from both a methodological and an experimental perspective the paper has weaknesses and in its current form seems to describe work in progress as such i am inclined against its presentation in acl formatting issue the authors use the latex styles for acl this should be fixed in case the paper is accepted authors response thank you for the clarifications i am still not comfortable with the idea of a metric or a vector space that tries to capture both semantic and relational similarity and i think you do not present enough experimental evidence that your method works i have to agree with one of the other reviewers that a more appropriate format for this work would be a short paper,2.0
563.json,this paper presents a comparison of several vector combination techniques on the task of relation classification strengths the paper is clearly written and easy to understand weaknesses my main complaint about the paper is the significance of its contributions i believe it might be suitable as a short paper but certainly not a full length paper unfortunately there is little original thought and no significantly strong experimental results to back it up the only contribution of this paper is an in out similarity metric which is itself adapted from previous work the results seem to be sensitive to the choice of clusters and only majorly outperforms a very naive baseline when the number of clusters is set to the exact value in the data beforehand i think that relation classification or clustering from semantic vector space models is a very interesting and challenging problem this work might be useful as an experimental nugget for future reference on vector combination and comparison techniques as a short paper unfortunately it does not have the substance to merit a full length paper,2.0
447.json,this paper proposed to explore discourse structure as defined by rhetorical structure theory rst to improve text categorization a rnn with attention mechanism is employed to compute a representation of text the experiments on various of dataset shows the effectiveness of the proposed method below are my comments from table it shows that unlabeled model performs better on four out of five datasets than the full model the authors should explain more about this because intuitively incorporating additional relation labels should bring some benefits is the performance of relation labelling so bad and it hurts the performance instead the paper also transforms the rst tree into a dependency structure as a pre process step instead of transforming how about keep the original tree structure and train a hierarchical model on that for the experimental datasets instead of comparing with only one dataset with each of the previous work the authors may want to run experiments on more common datasets used by previous work,4.0
369.json,this paper details a method of achieving translation from morphologically impoverished languages e g chinese to morphologically rich ones e g spanish in a two step process first a system translates into a simplified version of the target language second a system chooses morphological features for each generated target word and inflects the words based on those features while i wish the authors would apply the work to more than one language pair i believe the issue addressed by this work is one of the most important and under addressed problems with current mt systems the approach taken by the authors is very different than many modern approaches based on bpe and character level models and instead harkens back to approaches such as factored translation models koehn and hoang and translating into morphologically rich languages with synthetic phrases chahuneau et a both of which are unfortunately uncited i am also rather suspicious of the fact that the authors present only meteor results and no bleu or qualitative improvements if bleu scores do not rise perhaps the authors could argue why they believe their approach is still a net plus and back the claim up with meteor and example sentences furthermore the authors repeatedly talk about gender and number as the two linguistic features they seek to correctly handle but seem to completely overlook person perhaps this is because first and second person pronouns and verbs rarely occur in news but certainly this point at least merits brief discussion i would also like to see some discussion of why rescoring hurts with gender if the accuracy is very good shouldn the reranker learn to just keep the best finally while the content of this paper is good overall it has a huge amount of spelling grammar word choice and style errors that render it unfit for publication in its current form below is dump of some errors that i found overall i would like to this work in a future conference hopefully with more than one language pair more evaluation metrics and after further proofreading general error dump line zhand zhang line cfr crf whole related work section consistent use of cite when newcite is appropriate it feels like there a lot of filler it is important to mention that it is worth mentioning that etc line the popular phrase based mt system moses or pbmt systems in general line a software line academic and commercial level this should definitely be pluralized but are these even levels line a morphology based simplified target makes it sound like this simplified target uses morphology perhaps the authors mean a morphologically simplified target line decide on the morphological simplifications table extra space in cuestión on the first line and titulado in the last line table perhaps highlight differences between lines in this table somehow how is the simplification carried out is this simplifier hand written by the authors or does it use an existing tool line i e e g line train on or train for line our architecture is inspired by or collobert proposal inspires our architecture line drop this comma line this equation makes it look like all words share the same word vector w line this could also be casas blancas right how does the system choose between the sg and pl forms remind the reader of the source side conditioning here line this graph is just a lattice or perhaps more specifically a sausage lattice line insert e g or similiar e g producirse line misspelled syllable line i would like some examples or further clarity on what palabras llanas and palabras estrújulas are and how you handle all three of these special cases line and sentences longer than words line by means of zh seg no determiner or by means of the zh seg tool line are you sure this is an and and not an or line trained for instead of trained on line corpus copora line size is sizes are line would bigger embedding sizes help h and h are hardly unreasonable training times line seven and five being the best values line why increased from what to table these are hyperparameters and not just ordinary parameters of the model line coverage exceeds line descending line quadratic line space before cites line by far or by a large margin instead of by large line below line the standard phrase based zh seg citation lists the year as but the tool actually was released in,1.0
105.json,strengths the idea of hard monotonic attention is new and substantially different from others weaknesses the experiment results on morphological inflection generation is somewhat mixed the proposed model is effective if the amount of training data is small such as celex it is also effective if the alignment is mostly monotonic and less context sensitive such as russian german and spanish general discussion the authors proposed a novel neural model for morphological inflection generation which uses hard attention character alignments separately obtained by using a bayesian method for transliteration it is substantially different from the previous state of the art neural model for the task which uses soft attention where character alignment and conversion are solved jointly in the probabilistic model the idea is novel and sound the paper is clearly written the experiment is comprehensive the only concern is that the proposed method is not necessarily the state of the art in all conditions it is suitable for the task with mostly monotonic alignment and with less context sensitive phenomena the paper would be more convincing if it describe the practical merits of the proposed method such as the ease of implementation and computational cost,3.0
105.json,strengths a new encoder decoder model is proposed that explicitly takes into account monotonicity weaknesses maybe the model is just an ordinary birnn with alignments de coupled only evaluated on morphology no other monotone seqseq tasks general discussion the authors propose a novel encoder decoder neural network architecture with hard monotonic attention they evaluate it on three morphology datasets this paper is a tough one one the one hand it is well written mostly very clear and also presents a novel idea namely including monotonicity in morphology tasks the reason for including such monotonicity is pretty obvious unlike machine translation many seqseq tasks are monotone and therefore general encoder decoder models should not be used in the first place that they still perform reasonably well should be considered a strong argument for neural techniques in general the idea of this paper is now to explicity enforce a monotonic output character generation they do this by decoupling alignment and transduction and first aligning input output sequences monotonically and then training to generate outputs in agreement with the monotone alignments however the authors are unclear on this point i have a few questions how do your alignments look like on the one hand the alignments seem to be of the kind to many as in the running example fig that is input character can be aligned with zero or several output characters however this seems to contrast with the description given in lines where the authors speak of several input characters aligned to output character that is do you use to many many to or many to many alignments actually there is a quite simple approach to monotone seqseq in a first stage align input and output characters monotonically with a to many constraint one can use any monotone aligner such as the toolkit of jiampojamarn and kondrak then one trains a standard sequence tagger to predict exactly these to many alignments for example flog fliege your example on l first align as in f l o g f l ie ge now use any tagger could use an lstm if you like to predict f l ie ge sequence of length from f l o g sequence of length such an approach may have been suggested in multiple papers one reference could be section below my two questions here are a how does your approach differ from this rather simple idea b why did you not include it as a baseline further issues it really a pitty that you only tested on morphology because there are many other interesting monotonic seqseq tasks and you could have shown your system superiority by evaluating on these given that you explicitly model monotonicity cf also you perform on par or better l there seems to be a general cognitive bias among nlp researchers to map instances where they perform worse to on par and all the rest to better i think this wording should be corrected but otherwise i am fine with the experimental results you say little about your linguistic features from fig i infer that they include pos etc a where did you take these features from b is it possible that these are responsible for your better performance in some cases rather than the monotonicity constraints minor points equation please re write nn as text nn or similar l where should be lower case l and many more x ldots xn as far as i know the math community recommends to write x ldots xn but x cdots xn that is dots should be on the same level as surrounding symbols figure is it really necessary to use cyrillic font i can not even address your example here because i do not have your fonts l should be these inproceedings schnober etal coling author schnober carsten and eger steffen and do dinh erik l a n and gurevych iryna title still not there comparing traditional sequence to sequence models to encoder decoder neural networks on monotone string translation tasks booktitle proceedings of coling the th international conference on computational linguistics technical papers month december year address osaka japan publisher the coling organizing committee pages url http aclweb org anthology c after author response thanks for the clarifications i think your alignments got mixed up in the response somehow maybe a coding issue but i think you are aligning and later make many to many alignments from these i know that you compare to nicolai cherry and kondrak but my question would have rather been why not use x x in alignments as in schnober et al and then train a neural tagger on these e g bilstm i wonder how much your results would have differed from such a rather simple baseline a tagger is a monotone model to start with and given the monotone alignments everything stays monotone in contrast you start out with a more general model and then put hard monotonicity constraints on this notes from ac also quite relevant is cohn et al http www aclweb org anthology n is not your architecture also related to methods like the stack lstm which similarly predicts a sequence of actions that modify or annotate an input do you think you lose anything by using a greedy alignment in contrast to rastogi et al which also has hard monotonic attention but sums over all alignments,3.0
26.json,an end to end model for question answering over knowledge base with cross attention combining global knowledge this paper presents an approach for factoid question answering over a knowledge graph freebase by using a neural model that attempts to learn a semantic correlation correspondence between various aspects of the candidate answer e g answer type relation to question entity answer semantic etc and a subset of words of the question a separate correspondence component is learned for each aspect of the candidate answers the two key contributions of this work are the creation of separate components to capture different aspects of the candidate answer rather than relying on a single semantic representation and incorporating global context from the kb of the candidate answers the most interesting aspect of this work in my opinion is the separation of candidate answer representation into distinct aspects which gives us the neural model developer a little more control over guiding the nn models towards information that would be more beneficial in its decision making it sort of harkens to the more traditional algorithms that rely on feature engineering but in this case the feature engineering i e aspects is more subtle and less onerous i encourage the authors to continue refining this system along these lines while the high level idea is fairly clear to a reasonably informed reader the devil in the details would make it hard for some audience to immediately grasp key insights from this work some parts of the paper could benefit from more explanation specifically context aspect of candidate answers ec is not clearly explained in the paper therefore the last two sentences of section seem unclear mention of oov in the abstract and introduction need more explanation as such i think the current exposition in the paper assumes a deep understanding of prior work by the reader the experiments conducted in this paper restrict comparison to ir based system and the reasoning behind this decision is reasonable but it is not clear then why the work of yang et al which is described to be sp based is part of the comparison while i am all for including more systems in the comparison there seem to be some inconsistencies in what should and should not be compared additionally i see not harm in also mentioning the comparable performance numbers for the best sp based systems i observe in the paper that the embeddings are learned entirely from the training data i wonder how much impact the random initialization of these embeddings has on the end performance it would be interesting to determine and list the variance if any additionally if we were to start with pre trained embeddings e g from wordvec instead of the randomly initialized ones would that have any impact as i read the paper one possible direction of future work that occurred to me was to possibly include structured queries from sp based methods as part of the cross attention mechanism in other words in addition to using the various aspects of the candidate answers as features one could include structured queries that generate the produce that candidate answer as an additional aspect of the candidate answer an attention mechanism could then also focus on various parts of the structured query and its semantic matches to the input question as an additional signal for the nn model just a thought some notes regarding the positioning of the paper i hesitate to call the model proposed here attention models because per my admittedly limited understanding attention mechanisms apply to encoder decoder situations where semantics expressed in one structured form e g image sentence in one language natural language question etc are encoded into an abstract representation and then generated into another structured form e g caption sentence in another language structured query etc the attention mechanism allows the encoder to jump around and attend to different parts of the input instead of sequentially as the output is being generated by the decoder this paper does not appear to fit this notion and may be confusing to a broader audience thank you for clarifications in the author response,4.0
26.json,strengths this paper contributes to the field of knowledge base based question answering kb qa which is to tackle the problem of retrieving results from a structured kb based on a natural language question kb qa is an important and challenging task the authors clearly identify the contributions and the novelty of their work provide a good overview of the previous work and performance comparison of their approach to the related methods previous approaches to nn based kb qa represent questions and answers as fixed length vectors merely as a bag of words which limits the expressiveness of the models and previous work also don t leverage unsupervised training over kg which potentially can help a trained model to generalize this paper makes two major innovative points on the question answering problem the backbone of the architecture of the proposed approach is a cross attention based neural network where attention is used for capture different parts of questions and answer aspects the cross attention model contains two parts benefiting each other the a q attention part tries to dynamically capture different aspects of the question thus leading to different embedding representations of the question and the q a attention part also offer different attention weight of the question towards the answer aspects when computing their q a similarity score answer embeddings are not only learnt on the qa task but also modeled using transe which allows to integrate more prior knowledge on the kb side experimental results are obtained on web questions and the proposed approach exhibits better behavior than state of the art end to end methods the two contributions were made particularly clear by ablation experiment both the cross attention mechanism and global information improve qa performance by large margins the paper contains a lot of contents the proposed framework is quite impressive and novel compared with the previous works weaknesses the paper is well structured the language is clear and correct some minor typos are provided below page column line re read reread page column line pairs be pairs to be general discussion in equation the four aspects of candidate answer aspects share the same w and b how about using separate w and b for each aspect i would suggest considering giving a name to your approach instead of our approach something like ann or ca lstm yet something different from table in general i think it is a good idea to capture the different aspects for question answer similarity and cross attention based nn model is a novel solution for the above task the experimental results also demonstrate the effectiveness of the authors approach although the overall performance is weaker than sp based methods or some other integrated systems i think this paper is a good attempt in end to end kb qa area and should be encouraged,4.0
484.json,this paper proposes joint ctc attention end to end asr which utilizes both advantages in training and decoding strengths it provides a solid work of hybrid ctc attention framework in training and decoding and the experimental results showed that the proposed method could provide an improvement in japanese csj and mandarin chinese telephone speech recognition task weaknesses the only problem is that the paper sounds too similar with ref kim et al which will be officially published in the coming ieee international conference on acoustics speech and signal processing icassp march kim at al proposes joint ctc attention using mtl for english asr task and this paper proposes joint ctc attention using mtl joint decoding for japanese and chinese asr tasks i guess the difference is on joint decoding and the application to japanese chinese asr tasks however the difference is not clearly explained by the authors so it took sometimes to figure out the original contribution of this paper a title the title in ref kim et al is joint ctc attention based end to end speech recognition using multi task learning while the title of this paper is joint ctc attention end to end speech recognition i think the title is too general if this is the first paper about joint ctc attention than it is absolutely ok or if ref kim et al will remain only as pre published arxiv then it might be still acceptable but since kim et al will officially publish in ieee conference much earlier than this paper then a more specified title that represents the main contribution of this paper in contrast with the existing publication would be necessary b introduction the author claims that we propose to take advantage of the constrained ctc alignment in a hybrid ctc attention based system during training we attach a ctc objective to an attention based encoder network as a regularization as proposed by kim at al taking advantage of the constrained ctc alignment in a hybrid ctc attention is the original idea from kim at al so the whole argument about attention based end to end asr versus ctc based asr and the necessary of ctc attention combination is not novel furthermore the statement we propose as proposed by kim et al is somewhat weird we can build upon someone proposal with additional extensions but not just re propose other people proposal therefore what would be important here is to state clearly the original contribution of this paper and the position of the proposed method with respect to existing literature c experimental results kim at al applied the proposed method on english task while this paper applied the proposed method on japanese and mandarin chinese tasks i think it would be interesting if the paper could explain in more details about the specific problems in japanese and mandarin chinese tasks that may not appear in english task for example how the system could address multiple possible outputs i e kanji hiragana and katakana given japanese speech input without using any linguistic resources this could be one of the important contributions from this paper general discussion i think it would be better to cite ref kim et al from the official ieee icassp conference rather than pre published arxiv kim s hori t watanabe s joint ctc attention based end to end speech recognition using multi task learning ieee international conference on acoustics speech and signal processing icassp march pp to appear,3.0
715.json,strengths the authors focus on a very challenging task of answering open domain question from wikipedia authors have developed a document retriever to retrieve relevant wikipedia articles for a question and document retriever to retrieve the exact answer from the retrieved paragraphs authors used distant supervision to fine tune their model experiments show that the document reader performs better than wikisearch api and document reader model does better than some recent models for qa weaknesses the final results are inferior to some other models as presented by the authors also no error analysis is provided general discussion the proposed systems by the authors is end to end and interesting however i have some concerns below document retriever authors have shown a better retrieval performance than wiki search however it is not described as to how exactly the api is used wikisearch may not be a good baseline for querying questions api suits structured retrieval more why do not the authors use some standard ir baselines for this distant supervision how effective and reliable was distant supervision clearly the authors had to avoid using many training examples because of this but whatever examples the authors could use what fraction was actually close to correct some statistics would be helpful to understand if some more fine tuning of distant supervision could have helped full wikipedia results this was the main aim of the authors and as authors themselves said the full system gives a performance of when correct doc given when correct paragraph is given clearly that should be a motivation to work more on the retrieval aspect for webquestions the results are much inferior to yodaqa and that raises the question whether wikipedia itself is sufficient to answer all the open domain questions should authors think of an integrated model to address this overall the final results shown in tables and are inferior to some other models while authors only use wikipedia the results are not indicative of this being the best strategy other points the f value in table is different from that in table both dev and test table why not no femb error analysis some error analysis is required in various components of the system are there some specific type of questions where the system does not perform well is there any way one can choose which question is a good candidate to be answered by wikipedia and use this method only for those questions for webquestions ds degrades the performance further,3.0
216.json,strengths the idea of assigning variable length document segments with dependent topics is novel this prior knowledge is worth incorporated in the lda based framework whereas we do not have full knowledge on recent lda literature we find the part of related work quite convincing the method proposed for segment sampling with o m complexity is impressive it is crucial for efficient computation weaknesses compared to balikas coling work the paper has a weaker visualization fig which makes us doubt about the actual segmenting and assigning results of document it could be more convincing to give a longer exemplar and make color assignment consistent with topics listed in figure since the model is more flexible than that of balikas coling it may be underfitting could you please explain this more general discussion the paper is well written and structured the intuition introduced in the abstract and again exemplified in the introduction is quite convincing the experiments are of a full range solid and achieves better quantitative results against previous works if the visualization part is stronger or explained why less powerful visualization it will be more confident another concern is about computation efficiency since the seminal lda work proposed to use variational inference which is faster during training compared to mcmc we wish to see the author s future development,4.0
216.json,strengths well written well organized incorporate topical segmentation to copula lda to enable the joint learning of segmentation and latent models experimental setting is well designed and show the superiority of the proposed method from several different indicators and datasets weaknesses no comparison with novel segmentation methods general discussion this paper presents segldacop a joint latent model for topics and segments this model is based on the copula lda and incorporates the topical segmentation to the copula lda the authors conduct comprehensive experiments by using several different datasets and evaluation metrics to show the superiority of their model this paper is well written and well organized the proposed model is a reasonable extension of the copula lda to enable the joint inference of segmentations and topics experimental setting is carefully designed and the superiority of the proposed model is fairly validated one concern is that the authors only use the simple np segmentation and single word segmentation as segments of the previous method as noted in the paper there are many work to smartly generate segments before running lda though it is largely affected by the bias of statistical or linguistic tools used the comparison with more novel state of the art segments would be preferable to precisely show the validity of the proposed method minor comment in line latent radom topics latent random topics,4.0
67.json,strengths the paper tackles an important issue that is building ontologies or thesauri the methods make sense and seem well chosen methods and setups are well detailed it looks like the authors outperform the state of the art approach but see below for my concerns weaknesses the main weaknesses for me are evaluation and overall presentation writing the list of baselines is hard to understand some methods are really old and it does not seem justified to show them here e g mpttern memb is apparently the previous state of the art but there is no mention to any reference while it looks like the method outperforms the previous best performing approach the paper is not convincing enough especially on the first dataset the difference between the new system and the previous state of the art one is pretty small the paper seriously lacks proofreading and could not be published until this is fixed for instance i noted errors in the first column of page the ciline hierarchy is very shallow levels only however apparently it has been used in the past by other authors i would expect that the deeper the more difficult it is to branch new hyponym hypernyms this can explain the very high results obtained even by previous studies general discussion the approach itself is not really original or novel but it is applied to a problem that has not been addressed with deep learning yet for this reason i think this paper is interesting but there are two main flaws the first and easiest to fix is the presentation there are many errors typos that need to be corrected i started listing them to help but there are just too many of them the second issue is the evaluation in my opinion technically the performances are better but it does not feel convincing as explained above what is memb is it the method from shwartz et al maybe if not what performance did this recent approach have i think the authors need to reorganize the evaluation section in order to properly list the baseline systems clearly show the benefit of their approach and where the others fail significance tests also seem necessary given the slight improvement on one dataset,2.0
169.json,strengths useful application for teachers and learners supports fine grained comparison of gec systems weaknesses highly superficial description of the system evaluation not satisfying general discussion the paper presents an approach of automatically enriching the output of gec systems with error types this is a very useful application because both teachers and learners can benefit from this information and many gec systems only output a corrected version without making the type of error explicit it also allows for finer grained comparison of gec systems in terms of precision in general and error type specific figures for recall and precision unfortunately the description of the system remains highly superficial the core of the system consists of a set of manually created rules but the paper does not provide any details about these rules the authors should e g show some examples of such rules specify the number of rules tell us how complex they are how they are ordered could some early rule block the application of a later rule etc instead of presenting relevant details of the system several pages of the paper are devoted to an evaluation of the systems that participated in conll table which takes one entire page list results for all systems and the text repeats many facts and figures that can be read off the table the evaluation of the proposed system is not satisfying in several aspects first the annotators should have independently annotated a gold standard for the test sentences instead of simply rating the output of the system given a fixed set of tags it should be possible to produce a gold standard for the rather small set of test sentences it is highly probable that the approach taken in the paper yields considerably better ratings for the annotations than comparison with a real gold standard see e g marcus et al for a comparison of agreement when reviewing pre annotated data vs annotating from scratch second it is said that all raters individually considered at least of our rule based error types to be either good or acceptable multiple rates should not be considered individually and their ratings averaged this way this is not common practice if each of the bad scores were assigned to different edits we do not learn about their distribution from the paper of the edits were considered bad by some annotator this sounds much worse than the average as calculated in the paper third no information about the test data is provided e g how many error categories they contain or which error categories are covered according to the cateogories rated as good by the annotators forth what does it mean that edit boundaries might be unusual a more precise description plus examples are at need here could this be problematic for the application of the system the authors state that their system is less domain dependent as compared to systems that need training data i am not sure that this is true e g i suppose that hunspell vocabulary probably does not cover all domains in the same detail and manually created rules can be domain dependent as well and are completely language dependent a clear drawback as compared to machine learning approaches moreover the test data used here fce test conll are from one domain only student essays it remains unclear why a new set of error categories was designed one reason for the tags is given to be able to search easily for underspecified categories like noun in general it seems to me that the tagset presented in nicholls supports such searches as well or why not using the conll tagset then the conll gold standard could have been used for evaluation to sum up the main motivation of the paper remains somewhat unclear is it about a new system but the most important details of it are left out is it about a new set of error categories but hardly any motivation or discussion of it is provided is it about evaluating the conll systems but the presentation of the results remains superficial typos l and others c f cf l and others m m superscribed l f what does this mean check references for incorrect case e g l esl esl e g l fleiss kappa,2.0
169.json,the paper presents a novel approach for evaluating grammatical error correction gec systems this approach makes it possible to assess the performance of gec systems by error type not only in terms of recall but also in terms of precision which was previously not possible in general since system output is usually not annotated with error categories strengths the proposed evaluation is an important stepping stone for analyzing gec system behavior the paper includes evaluation for a variety of systems the approach has several advantages over previous work it computes precision by error type it is independent of manual error annotation it can assess the performance on multi token errors the automatically selected error tags for pre computed error spans are mostly approved of by human experts weaknesses a key part the rules to derive error types are not described the classifier evaluation lacks a thorough error analysis and based upon that it lacks directions of future work on how to improve the classifier the evaluation was only performed for english and it is unclear how difficult it would be to use the approach on another language classifier and classifier evaluation it is unclear on what basis the error categories were devised are they based on previous work although the approach in general is independent of the alignment algorithm the rules are probably not but the authors do not provide details on that the error categories are a major part of the paper and the reader should at least get a glimpse of how a rule to assign an error type looks like unfortunately the paper does not apply the proposed evaluation on languages other than english it also does not elaborate on what changes would be necessary to run the classifier on other languages i assume that the rules used for determining edit boundaries as well as for determining the error tags depend on the language the pre processing pipeline to a certain extent and therefore need to be adapted also the error categories might need to be changed the authors do not provide any detail on the rules for assigning error categories how many are there overall per error type how complex are they to estimate the effort necessary to use the approach on another language the error spans computed in the pre processing step seem to be inherently continuous which is also the case with the m scorer which is problematic since there are errors which can only be tagged accurately when the error span is discontinuous in german for example verbs with separable prefixes are separated from each other in the main clause st constituent verb other constituents verb prefix would the classifier be able to tag discontinuous edit spans the authors write that all human judges rated at least of the automatically assigned error tags as appropriate despite the degree of noise introduced by automatic edit extraction i would be more cautious with this judgment since the raters might also have been more forgiving when the boundaries were noisy in addition they were not asked to select a tag without knowing the system output but could in case of noisy boundaries be more biased towards the system output additionally there was no rating option between bad not appropriate and appropriate which might also have led raters to select appropriate over bad to make the evaluation more sound the authors should also evaluate how the human judges rate the classifier output if the boundaries were manually created i e without the noise introduced by faulty boundaries the classifier evaluation lacks a thorough error analysis it is only mentioned that bad is usually traced back to a wrong pos tag questions i would like to see addressed when did raters select bad when appropriate does the rating by experts point at possibilities to improve the classifier gold reference vs auto reference it is unclear on what data the significance test was performed exactly did you test on the f scores if so i do not think this is a good idea since it is a derived measure with weak discriminative power the performance in terms of recall an precision can be totally different but have the same f score also at the beginning of section the authors refer to the mismatch between automatic and reference in terms of alignment and classification but as far as i can tell the comparison between gold and reference is only in terms of boundaries and not in terms of classification error type evaluation i do not think it is surprising that teams line failed to correct any unnecessary token error for at least two of the systems there is a straightforward explanation why they cannot handle superfluous words the most obvious is ufc their rule base approach works on pos tags ng et al and it is just not possible to determine superfluous words based on pos alone rozovskaya roth provide an explanation why amu performs poorly on superfluous words the authors do not analyze or comment the results in table with respect to whether the systems were designed to handle the error type for some error types there is a straight forward mapping between error type in the gold standard and in the auto reference for example for word order error it remains unclear whether the systems failed completely on specific error types or were just not designed to correct them cuui for example is reported with precision recall although it does not target word order errors in the cuui case and there are probably similar cases this also points at an error in the classification which is neither analyzed nor discussed please report also raw values for tp fp tn fn in the appendix for table this makes it easier to compare the systems using other measures also it seems that for some error types and systems the results in table are based only on a few instances this would also be made clear when reporting the raw values your write all but teams iitb and ipn achieved the best score in at least category which suggests that different approaches to gec complement different error types it would be nice to mention here that this is in line with previous research multi token error analysis is helpful for future work but the result needs more interpretation some systems are probably inherently unable to correct such errors but none of the systems were trained on a parallel corpus of learner data and fluent in the sense of sakaguchi et al corrections other the authors should have mentioned that for some of the gec approaches it was not impossible before to provide error annotations e g systems with submodules for one error type each admittedly the system would need to be adapted to include the submodule responsible for a change in the system output still the proposed approach enables to compare gec systems for which producing an error tagged output is not straightforward to other systems in a unified way references some titles lack capitalizations url for sakaguchi et al needs to be wrapped page information is missing for efron and tibshirani author response i agree that your approach is not fatally flawed and i think this review actually points out quite some positive aspects the approach is good but the paper is not ready the basis for the paper are the rules for classifying errors and the lack of description is a major factor this is not just a matter about additional examples if the rules are not seen as a one off implementation they need to be described to be replicable or to adapt them generalization to other languages should not be an afterthought it would be serious limitation if the approach only worked on one language by design even if you do not perform an adaption for other languages your approach should be transparent enough for others to estimate how much work such an adaptation would be and how well it could reasonably work just stating that most research is targeted at esl only reinforces the problem you write that the error types certain systems tackle would be usually obvious from the tables i do not think it is as simple as that see the cuui example mentioned above as well as the unnecessary token errors there are five systems that do not correct them table and it should therefore be obvious that they did not try to tackle them however in the paper you write that there is also no obvious explanation as to why these teams had difficulty with this error type,2.0
66.json,this paper describes several ways to encode arbitrarily long sequences of digits using something called the major system in the major system each digit is mapped to one or more characters representing consonantal phonemes the possible mappings between digit and phoneme are predefined the output of an encoding is typically a sequence of words constrained such that digits in the original sequence correspond to characters or digraphs in the output sequence of words vowels added surrounding the consonant phonemes to form words are unconstrained this paper describes several ways to encode your sequence of digits such that the output sequence of words is more memorable generally by applying syntactic constraints and heuristics i found this application of natural language processing concepts somewhat interesting as i have not read an acl paper on this topic before however i found the paper and ideas presented here to have a rather old school feel with much of the focus on n gram models for generation frequent pos tag sequences and other heuristics this paper really could have been written years ago i am not sure that there is enough novelty in the ideas here to warrant publication in acl in there is no contribution to nlp itself e g in terms of modeling or search and not a convincing contribution to the application area which is just an instance of constrained generation since you start with one sequence and output another sequence with a very straightforward monotonic mapping it seems like a character based sequence to sequence encoder decoder model sequence to sequence learning with neural networks sutskever et al would work rather well here very likely with very fluent output and fewer moving parts e g trigram models and pos tag and scoring heuristics and postprocessing with a bigram model you can use large amounts of training from an arbitrary genre and do not need to rely on an already tagged corpus like in this paper or worry about a parser this would be a paper,2.0
66.json,strengths this paper presents a sentence based approach to generating memorable mnemonics for numbers the evaluation study presented in the paper shows that the sentence based approach indeed produces memorable mnemonics for short digit numbers e g officiate wasteland overall the paper presents the problem the background literature and the solution in sufficient detail because memorizing numbers e g phone numbers and account numbers is sufficiently common this is an interesting problem weaknesses the proposed solution does not seem to scale up well for longer numbers seems to work well with digit numbers though but many numbers that people need to memorize such as phone numbers and credit card numbers are longer than digits besides a number may have a structure e g a phone number has a country code area code personal number which people exploit while memorizing numbers as stated above this paper addresses an important problem but the current solution needs to be improved further several ideas have been listed by the authors in section general discussion the current presented approach in comparison to existing approaches is promising,3.0
201.json,strengths this paper presents a x x x array of accuracy results based on systematically changing the parameters of embeddings models context type position sensitive embedding model task accuracy context type linear syntactic position sensitive true false embedding model skip gram bow glove task word similarity analogies pos ner chunking text classific tasks the aim of these experiments was to investigate the variation in performance as these parameters are changed the goal of the study itself is interesting for the acl community and similar papers have appeared before as workshop papers and have been well cited such as nayak et al paper mentioned below weaknesses since this paper essentially presents the effect of systematically changing the context types and position sensitivity i will focus on the execution of the investigation and the analysis of the results which i am afraid is not satisfactory a the lack of hyper parameter tuning is worrisome e g unless otherwise notes the number of word embedding dimension is set to it still enlarges the context vocabulary about times in practice most hyper parameters are the same as levy et al best configuration this is worrisome because lack of hyperparameter tuning makes it difficult to make statements like method a is better than method b e g bound methods may perform better with a lower dimensionality than unbound models since their effective context vocabulary size is larger b the paper sometimes presents strange explanations for its results e g experimental results suggest that although it hard to find any universal insight the characteristics of different contexts on different models are concluded according to specific tasks what does this sentence even mean sequence labeling tasks tend to classify words with the same syntax to the same category the ignorance of syntax for word embeddings which are learned by bound representation becomes beneficial these two sentences are contradictory if a sequence labeling task classified words with same syntax to same category then syntx becomes a ver valuable feature bound representation ignorance of syntax should cause a drop in performance just like other tasks which does not happen c it is not enough to merely mention lai et al who have also done a systematic study of the word embeddings and similarly the paper evaluating word embeddings using a representative suite of practical tasks nayak angeli manning appeared at the repeval workshop at acl should have been cited i understand that the focus of nayak et al paper is not exactly the same as this paper however they provide recommendations about hyperparameter tuning and experiment design and even provide a web interface for automatically running tagging experiments using neural networks instead of the simple linear classifiers used in the current paper d the paper uses a neural bow words classifier for the text classification tasks but a simple linear classifier for the sequence labeling tasks what is the justification for this choice of classifiers why not use a simple neural classifier for the tagging tasks as well i raise this point since the tagging task seems to be the only task where bound representations are consistently beating the unbound representations which makes this task the odd one out general discussion finally i will make one speculative suggestion to the authors regarding the analysis of the data as i said earlier this paper main contribution is an analysis of the following table context type position sensitive embedding model task accuracy so essentially there are accuracy values that we want to explain in terms of the aspects of the model it may be beneficial to perform factor analysis or some other pattern mining technique on this sample data,2.0
201.json,strengths this paper systematically investigated how context types linear vs dependency based and representations bound word vs unbound word affect word embedding learning they experimented with three models generalized bag of words generalized skip gram and glove in multiple different tasks word similarity word analogy sequence labeling and text classification overall it is well written and structured the experiments are very thoroughly evaluated the analysis could help researchers to choose different word embeddings or might even motivate new models the attached software can also benefit the community weaknesses the novelty is limited general discussion for the dependency based context types how does the dependency parsing affect the overall performance is it fair to compare those two different context types since the dependency based one has to rely on the predicted dependency parsing results in this case corenlp while the linear one does not,4.0
256.json,review acl paper this paper extends the line of work which models generation in dialogue as a sequence to sequence generation problem where the past n utterances the dialogue context are encoded into a context vector plus potential other hand crafted features which is then decoded into a response the nth turn in the dialogue as it stands such models tend to suffer from lack of diversity specificity and local coherence in the kinds of response they tend to produce when trained over large dialogue datasets containing many topics e g cornell opensubtitles ubuntu etc rather than attempting to produce diverse responses using the decoder e g through word by word beam search which has been shown not to work very well even lose crucial information about grammar and valid sequences or via a different objective function such as in li et al s work the authors introduce a latent variable z over which a probability distribution is induced as part of the network at prediction time after encoding utterances to k a context z is sampled and the decoder is greedily used to generate a response from this the evaluation shows small improvements in bleu scores over a vanilla seqseq model that does not involve learning a probability distribution over contexts and sampling from this the paper is certainly impressive from a technical point of view i e in the application of deep learning methods specifically conditioned variational auto encoders to the problem of response generation and its attendant difficulties in training such models their use of information retrieval techniques to get more than one reference response is also interesting i have some conceptual comments on the introduction and the motivations behind the work some on the model architecture and the evaluation which i write below in turn comments on the introduction and motivations the authors seem not fully aware of the long history of this field and its various facets whether from a theoretical perspective or from an applied one the dialogue manager typically takes a new utterance and the dialogue context as input and generates discourse level decisions this is not accurate traditionally at least the job of the dialogue manager is to select actions dialogue acts in a particular dialogue context the action chosen is then passed to a separate generation module for realisation dialogue management is usually done in the context of task based systems which are goal driven the dialogue manager is to choose actions which are optimal in some sense e g reach a goal e g book a restaurant in as few steps as possible see publications from lemon pietquin rieser keizer and colleagues and various publications from steve young milica gasic and colleagues for an overview of the large literature on reinforcement learning and mdp models for task based dialogue systems the authors need to make a clear distinction between task based goal oriented dialogue and chatbots social bots the latter being usually no more than a language model albeit a sophisticated one though see wen et al what is required from these two types of system is usually distinct whereas the former is required to complete a task the latter is perhaps only required to keep the user engaged indeed the data driven methods that have been used to build such systems are usually very different the authors refer to open domain conversation i would suggest that there is no such thing as open domain conversation conversation is always in the context of some activity and for doing achieving something specific in the world and it is this overarching goal the overarching activity this overarching genre which determines the outward shape of dialogues and determines what sorts of dialogue structure are coherent coherence itself is activity context specific indeed a human is not capable of open domain dialogue if they are faced with a conversational topic or genre that they have never participated in they would embarrass themselves with utterances that would look incoherent and out of place to others already familiar with it think of a random person on the street trying to follow the conversations at some coffee break at acl this is the fundamental problem i see with systems that attempt to use data from an extremely diverse open ended set of conversational genres e g movie subtitles in order to train one model mushing everything together so that what emerges at the other end is just very good grammatical structure or very generic responses comments on the model architecture rather than generate from a single encoded context the authors induce a distribution over possible contexts sample from this and generate greedily with the decoder it seems to me that this general model is counter intuitive and goes against evidence from the linguistic psycholinguistic literature on dialogue this literature shows that people tend to resolve potential problems in understanding and acceptance very locally i e make sure they agree on what the context of the conversation is and only then move on with the rest of the conversation so that at any given point there is little uncertainty about the current context of the conversation the massive diversity one sees results from the diversity in what the conversation is actually trying to achieve see above diversity in topics and contexts etc so that in a given fixed context there is a multitude of possible next actions all coherent but leading the conversation down a different path it therefore seems strange to me at least to shift the burden of explaining diversity and coherence in follow up actions to that of the linguistic verbal surface contexts in which they are uttered though of course uncertainty here can also arise as a result of mismatches in vocabulary grammars concepts people s backgrounds etc but this probably wouldn t explain much of the variation in follow up response in fact at least as far as task based dialogue systems are concerned the challenge is to capture synonymy of contexts i e dialogues that are distinct on the surface but lead to the same or similar context either in virtue of interactional and syntactic equivalence relations or synonymy relations that might hold in a particular domain between words or sequences of words e g what is your destination where would you like to go in a flight booking domain see e g bordes weston and kalatzis eshghi lemon the latter use a grammar to cluster semantically similar dialogues comments on the evaluation the authors seek to show that their model can generate more coherent and more diverse responses the evaluation method though very interesting seems to address coherence but not diversity despite what they say in section the precision and recall metrics measure distance between ground truth utterances and the ones the model generates but not that between the generated utterances themselves unless i m misunderstanding the evaluation method see e g li et al who measure diversity by counting the number distinct n grams in the generated responses furthermore i m not sure that the increase in bleu scores are meaningful they are very small in the qualitative assessment of the generated responses one certainly sees more diversity and more contentful utterances in the examples provided but i can t see how frequent such cases in fact are also it would have made for a stronger more meaningful paper if the authors had compared their results with other work e g li et al that use very different methods to promote diversity e g by using a different objective function the authors in fact do not mention this or characterise it properly despite actually referring to li et al,4.0
256.json,this paper presents a neural sequence to sequence model for encoding dialog contexts followed by decoding system responses in open domain conversations the authors introduced conditional variational autoencoder cvae which is a deep neural network based generative model to learn the latent variables for describing responses conditioning dialog contexts and dialog acts the proposed models achieved better performances than the baseline based on rnn encoder decoder without latent variables in both quantitative and qualitative evaluations this paper is well written with clear descriptions theoretically sound ideas reasonable comparisons and also detailed analysis i have just a few minor comments as follows would it be possible to provide statistical significance of the results from the proposed models compared to the baseline in quantitative evaluation the differences do not seem that much for some metrics considering the importance of dialog act in kgcvae model the da tagging performances should affect the quality of the final results would it be there any possibility to achieve further improvement by using better da tagger recently deep learning models have achieved better performances than svm also in da tagging what do you think about doing human evaluation as a part of qualitative analysis it could be costly but worth a try to analyze the results in more pragmatic perspective as a future direction it could be also interesting if kgcvae model is applied to more task oriented human machine conversations which usually have much richer linguistic features available than open conversation in table blue recall needs to be corrected to bleu recall,5.0
606.json,this paper introduces a new approach to semantic parsing in which the model is equipped with a neural sequence to sequence seqseq model referred to as the programmer which encodes a natural language question and produces a program the programmer is also equipped with a key variable memory component which stores a entities in the questions b values of intermediate variables formed during execution of intermediate programs these variables are referred to further build the program the model is also equipped with certain discrete operations such as argmax or hop to next edges in a kb a separate component interpreter computer executes these operations and stores intermediate values as explained before since the programmer is inherently a seqseq model the interpreter computer also acts as a syntax type checker only allowing the decoder to generate valid tokens for example the second argument to the hop operation has to be a kb predicate finally the model is trained with weak supervision and directly optimizes the metric which is used to evaluate the performance f score because of the discrete operations and the non differentiable reward functions the model is trained with policy gradients reinforce since gradients obtained through reinforce have high variance it is common to first pretrain the model with a max likelihood objective or find some good sequences of actions trained through some auxiliary objective this paper takes a latter approach in which it finds good sequences via an iterative maximum likelihood approach the results and discussion sections are presented in a very nice way and the model achieves sota results on the webquestions dataset when compared to other weakly supervised model the paper is written clearly and is very easy to follow this paper presents a new and exciting direction and there is scope for a lot of future research in this direction i would definitely love to see this presented in the conference questions for the authors important ones first another alternative way of training the model would be to bootstrap the parameters theta from the iterative ml method instead of adding pseudo gold programs in the beam line would be deleted did you try that and if so why do you think it didn t work what was the baseline model in reinforce did you have a separate network which predicts the value function this must be discussed in the paper in detail were there programs which required multiple hop operations or were they limited to single hops if there were can you provide an example i will understand if you are bound by word limit of the response can you give an example where the filter operation would be used i did not follow the motivation behind replacing the entities in the question with special ent symbol minor comments line describe describing line decoder reads decoder generates,5.0
606.json,this paper introduces neural symbolic machines nsms a deep neural model equipped with discrete memory to facilitate symbolic execution an nsm includes three components a manager that provides weak supervision for learning a differentiable programmer based on neural sequence to sequence model which encodes input instructions and predicts simplified lisp programs using partial execution results stored in external discrete memories a symbolic computer that executes programs and provide code assistance to the programmer to prune search space the authors conduct experiments on a semantic parsing task webquestionssp and show that nsm is able to model language compositionality by saving and reusing intermediate execution results augmented reinforce is superior than vanilla reinfroce for sequence prediction problems and nsm trained end to end with weak supervision is able to outperform existing sate of the art method stagg strengths the idea of using discrete symbolic memories for neural execution models is novel although in implementation it may simply reduce to copying previously executed variable tokens from an extra buffer this approach is still impressive since it works well for a large scale semantic parsing task the proposed revised reinforce training schema using imperfect hypotheses derived from maximum likelihood training is interesting and effective and could inspire future exploration in mixing ml rl training for neural sequence to sequence models the scale of experiments is larger than any previous works in modeling neural execution and program induction the results are impressive the paper is generally clear and well written although there are some points which might require further clarification e g how do the keys vi in fig of variable tokens involved in computing action probabilities conflicting notations v is used to refer to variables in tab and memory keys in fig overall i like this paper and would like to see it in the conference weaknesses choice of dataset the authors use webquestionssp as the testbed why not using the most popular webquestions berant et al benchmark set since nsm only requires weak supervision using webquestions would be more intuitive and straightforward plus it could facilitate direct comparison with main stream qa research analysis of compositionality one of the contribution of this work is the usage of symbolic intermediate execution results to facilitate modeling language compositionality one interesting question is how well questions with various compositional depth are handled simple one hop questions are the easiest to solve while complex multi hop ones that require filtering and superlative operations argmax min would be highly non trivial the authors should present detailed analysis regarding the performance on question sets with different compositional depth missing references i find some relevant papers in this field missing for example the authors should cite previous rl based methods for knowledge based semantic parsing e g berant and liang the sequence level reinforce training method of ranzato et al which is closely related to augmented reinforce and the neural enquirer work yin et al which uses continuous differentiable memories for modeling neural execution misc why is the reinforce algorithm randomly initialized algo instead of using parameters pre trained with iterative ml what is kg server in figure,4.0
554.json,strengths the paper is trying to bridge the gap between stochastic gradient mcmc and stochastic optimization in deep learning context given dropout dropconnect and variational inference are commonly used to reduce the overfit the more systematic way to introduce analyse such bayesian learning based algorithms would benefit deep learning community for language modeling tasks the proposed sg mcmc optimizer dropout outperforms rmsprop dropout which clearly shows that uncertainty modeling would help reducing the over fitting hence improving accuracy the paper has provided the details about the model experiment setups so the results should be easily reproduced weaknesses the paper does not dig into the theory profs and show the convergence properties of the proposed algorithm the paper only shows the comparison between sg mcmc vs rmsprop and did not conduct other comparison it should explain more about the relation between psgld vs rmsprop other than just mentioning they are conterparts in two families the paper does not talk about the training speed impact with more details general discussion,4.0
554.json,strengths this paper explores a relatively under explored area of practical application of ideas behind bayesian neural nets in nlp tasks with a bayesian treatment of the parameters of rnns it is possible to incorporate benefits of model averaging during inference further their gradient based sampling approximation to the posterior estimation leads to a procedure which is easy to implement and is potentially much cheaper than other well known techniques for model averaging like ensembling the effectiveness of this approach is shown on three different tasks language modeling image captioning and sentence classification and performance gains are observed over the baseline of single model optimization weaknesses exact experimental setup is unclear the supplementary material contains important details about burn in number of epochs and samples collected that should be in the main paper itself moreover details on how the inference is performed would be helpful were the samples that were taken following hmc for a certain number of epochs after burn in on the training data fixed for inference for every tilda y during test time same samples were used according to eqn also an explicit clarification regarding an independence assumption that p d theta p y x theta p y theta x p x which lets one use the conditional rnn model if i understand correctly for the potential u theta would be nice for completeness in terms of comparison this paper would also greatly benefit from a discussion experimental comparison with ensembling and distillation methods sequence level knowledge distillation kim and rush distilling an ensemble of greedy dependency parsers into one mst parser kuncoro et al which are intimately related by a similar goal of incorporating effects of model averaging further discussion related to preference of hmc related sampling methods over other sampling methods or variational approximation would be helpful finally equation hints at the potential equivalence between dropout and the proposed approach and the theoretical justification behind combining sgld and dropout by making the equivalence more concrete would lead to a better insight into the effectiveness of the proposed approach general discussion points addressed above,4.0
104.json,this paper addresses the problem of disambiguating linking textual entity mentions into a given background knowledge base in this case english wikipedia its title and introduction are a little overblown misleading since there is a lot more to bridging text and knowledge than the edl task but edl is a core part of the overall task nonetheless the method is to perform this bridging via an intermediate layer of representation namely mention senses thus following two steps mention to mention sense and mention sense to entity various embedding representations are learned for the words the mention senses and the entities which are then jointly trained to maximize a single overall objective function that maximizes all three types of embedding equally technically the approach is fairly clear and conforms to the current deep processing fashion and known best practices regarding embeddings while one can suggest all kinds of alternatives it s not clear they would make a material difference rather my comments focus on the basic approach it is not explained however exactly why a two step process involving the mention senses is better than a simple direct one step mapping from word mentions to their entities this is the approach of yamada et al in what is called here the align algorithm table shows that the two step mpme and even its simplification spme do better by why exactly what is the exact difference and additional information that the mention senses have compareed to the entities to understand please check if the following is correct and perhaps update the paper to make it exactly clear what is going on for entities their profiles consist of neighboring entities in a relatedness graph this graph is built i assume by looking at word level relatedness of the entity definitions pages in wikipedia the profiles are extended skip gram based embeddings for words their profiles are the standard distributional semantics approach without sense disambiguation for mention senses their profiles are the standard distributional semantics approach but with sense disambiguation sense disambiguation is performed using a sense based profile language model from local context words and neighboring mentions as mentioned briefly just before section but without details this is a problem point in the approach how exactly are the senses created and differentiated who defines how many senses a mention string can have if this is done by looking at the knowledge base then we get a bijective mapping between mention senses and entities that is there is exactly one entity for each mention sense even if there may be more entities in that case are the sense collection s definitional profiles built starting with entity text as seed words if so what information is used at the mention sense level that is not used at the entity level just and exactly the words in the texts that reliably associate with the mention sense but that do not occur in the equivalent entity webpage in wikipedia how many such words are there on average for a mention sense that is how powerful necessary is it to keep this extra differentiation information in a separate space the mention sense space as opposed to just loading these additional words into the entity space by adding these words into the wikipedia entity pages if the above understanding is essentially correct please update section of the paper to say so for to me it is the main new information in the paper it is not true as the paper says in section that this is the first work to deal with mention ambiguity in the integration of text and knowledge representations so there is no exact baselines for comparison the tac kbp evaluations for the past two years have hosted edl tasks involving eight or nine systems all performing exactly this task albeit against freebase which is considerably larger and more noisy than wikipedia please see http nlp cs rpi edu kbp on a positive note i really liked the idea of the smoothing parameter in section post response i have read the authors responses i am not really satisfied with their reply about the kbp evaluation not being relevant but that they are interested in the goodness of the embeddings instead in fact the only way to evaluate such goodness is through an application no one really cares how conceptually elegant an embedding is the question is does it perform better,4.0
387.json,strengths a deep cnn framework is proposed to extract and combine cognitive features with textual features for sentiment analysis and sarcasm detection the ideas is interesting and novelty weaknesses replicability would be an important concern researchers cannot replicate the system method for improvement due to lack of data for feature extraction general discussion overall this paper is well written and organized the experiments are conducted carefully for comparison with previous work and the analysis is reasonable i offer some comments as follows does this model be suitable on sarcastic non sarcastic utterances the authors should provide more details for further analysis why the eye movement data would be useful for sarcastic non sarcastic sentiment classification beyond the textual features the authors should provide more explanations,3.0
503.json,this one is a tough call because i do think that there are some important salvageable technial results in here notably the parsing algorithm but the paper as a whole has very little cohesion it is united around an overarching view of formal languages in which a language being probabilistic or not is treated as a formal property of the same variety as being closed under intersection or not in my opinion what it means for a formal language to be probabilistic in this view has not been considered with sufficient rigor for this viewpoint to be compelling i should note by the way that the value of the formal results provided mostly does not depend on the flimsiness of the overarching story so what we have here is not bad research but a badly written paper this needs more work i find it particulary puzzling that the organization of the paper leaves so little space for elucidating the parsing result that soundness and completeness are relegated to a continuation of the paper in the form of supplementary notes i also find the mention of probabilistic languages in the title of the paper to be very disingenuous there is in fact no probabilistic reasoning in this submission the sigificance of the intersection closure result of section is also being somewhat overstated i think unless there is something i am not understanding about the restrictions on the right hand sides of rules in which case please elaborate this is merely a matter of folding a finite intersection into the set of non terminal labels,2.0
503.json,the paper is concerned in finding such a family of graph languages that is closed under intersection and can be made probabilistic strengths the introduction shows relevance the overall aim high level context and is nice to read the motivation is clear and interesting the paper is extremely clear but requires close reading and much formal background it nicely takes into account certain differences in terminology it was interesting to see how the hyper edge grammars generalize familiar grammars and earley algorithm for example predict applies to nonterminal edges and scan applies to terminal edges if the parsing vs validation in nlp context is clarified the paper is useful because it is formally correct nice contribution instructive and can give new ideas to other researchers the described algorithm can be used in semantic parsing to rerank hypergraphs that are produced by another parser in this restricted way the method can be part of the machinery what we in nlp use in natural language parsing and thus relevant to the acl weaknesses reranking use is not mentioned in the introduction it would be a great news in nlp context if an earley parser would run in linear time for nlp grammars unlike special kinds of formal language grammars unfortunately this result involves deep assumptions about the grammar and the kind of input linear complexity of parsing of an input graph seem right for a top down deterministic grammars but the paper does not recognise the fact that an input string in nlp usually gives rise to an exponential number of graphs in other words the parsing complexity result must be interpreted in the context of graph validation or where one wants to find out a derivation of the graph for example for the purposes of graph transduction via synchronous derivations to me the paper should be more clear in this as a random reader may miss the difference between semantic parsing from strings and parsing of semantic parses the current work there does not seem to be any control of the linear order of arity edges it might be useful to mention that if the parser is extended to string inputs with the aim to find the best hypergraph for a given external nodes then the item representations of the subgraphs must also keep track of the covered arity edges this makes the string parser variant exponential easily correctable typos or textual problems lines is misleading while intersection and probs are true such distribution cannot refer to the discussion in the above line i think you should rather talk about validation or recognition algorithms than parsing algorithms as parsing in nlp means usually completely different thing that is much more challenging due to the lexical and structural ambiguity lines are unclear what are the elements of attg in what sense they are pairwise distinct compare example where extg and attg e are not disjoint sets l move rank definition earlier and remove redundancy l rather immediately derives perhaps add be l give an example of a nontrivial internal path l define a subgraph of a hypergraph l l since there are two propositions you may want to tell how they contribute to what is quoted l add for table axiom this is only place where this is introduced as an axiom link to the text that says it is a trigger general discussion it might be useful to tell about msol graph languages and their yields which are context free string languages what happens if the grammar is ambiguous and not top down deterministic what if there are exponential number of parses even for the input graph due to lexical ambiguity or some other reasons how would the parser behave then would not the given earley recogniser actually be strictly polynomial to m or k even a synchronous derivation of semantic graphs can miss some linguistic phenomena where a semantic distinction is expressed by different linguistic means e g one language may add an affix to a verb when another language may express the same distinction by changing the object i am suggesting that although amr increases language independence in parses it may have such cross lingual challenges i did not fully understand the role of the marker in subgraphs it was elided later and not really used l i already started to miss the remark of lines at this point it seems that the normal order is not unique can you confirm this it is nice that def cond introduces lexical anchors to predictions compare the anchors in lexicalized grammars l are you sure that non crossing links do not occur when parsing linearized sentences to semantic graphs significant questions to the authors linear complexity of parsing of an input graph seem right for a top down deterministic grammars but the paper does not recognise the fact that an input string in nlp usually gives rise to an exponential number of graphs in other words the parsing complexity result must be interpreted in the context of graph validation or where one wants to find out a derivation of the graph for example for the purposes of graph transduction via synchronous derivations what would you say about parsing complexity in the case the rgg is a non deterministic possibly ambiguous regular tree grammar but one is interested to use it to assign trees to frontier strings like a context free grammar can one adapt the given earley algorithm to this purpose by guessing internal nodes and their edges although this question might seem like a confusion it is relevant in the nlp context what prevents the rggs to generate hypergraphs whose arity edges words are then linearised what principle determines how they are linearised is the linear order determined by the earley paths and normal order used in productions or can one consider an actual word order in strings of a natural language there is no clear connection to non context free string languages or sets of non projective dependency graphs used in semantic parsing what is written on lines is just misleading lines mention that hrgs can be used to generate non context free languages are these graph languages or string languages how an nlp expert should interpret the implicit fact that rggs generate only context free languages does this mean that the graphs are noncrossing graphs in the sense of kuhlmann jonsson,3.0
145.json,review multimodal word distributions strengths overall a very strong paper weaknesses the comparison against similar approaches could be extended general discussion the main focus of this paper is the introduction of a new model for learning multimodal word distributions formed from gaussian mixtures for multiple word meanings i e representing a word by a set of many gaussian distributions the approach extend the model introduced by vilnis and mccallum which represented word as unimodal gaussian distribution by using a multimodal the current approach attain the problem of polysemy overall a very strong paper well structured and clear the experimentation is correct and the qualitative analysis made in table shows results as expected from the approach there s not much that can be faulted and all my comments below are meant to help the paper gain additional clarity some comments  it may be interesting to include a brief explanation of the differences between the approach from tian et al and the current one both split single word representation into multiple prototypes by using a mixture model  there are some missing citations that could me mentioned in related work as efficient non parametric estimation of multiple embeddings per word in vector space neelakantan a shankar j passos a mccallum emnlp do multi sense embeddings improve natural language understanding li and jurafsky emnlp topical word embeddings liu y liu z chua t sun m aaai  also the inclusion of the result from those approaches in tables and could be interesting  a question to the authors what do you attribute the loss of performance of wgm against wg in the analysis of swcs i have read the response,4.0
145.json,this work uses gaussian mixtures to represent words and demonstrates its potential in capturing multiple word meanings for polysemy the training process is done based on a max margin objective the expected likelihood kernel is used as the similarity between two words distributions experiment results on word similarity and entailment tasks show the effectiveness of the proposed work strengths the problem is clearly motivated and defined gaussian mixtures are much more expressive than deterministic vector representations it can potentially capture different word meanings by its modes along with probability mass and uncertainty around those modes this work represents an important contribution to word embedding this work propose a max margin learning objective with closed form similarity measurement for efficient training this paper is mostly well written weaknesses see below for some questions general discussion in the gaussian mixture models the number of gaussian components k is usually an important parameter in the experiments of this paper k is set to what is your criteria to select k does the increase of k hurt the performance of this model what does the learned distribution look like for a word that only has one popular meaning i notice that you use the spherical case in all the experiments the covariance matrix reduces to a single number is this purely for computation efficiency i wonder what is the performance of using a general diagonal covariance matrix since in this more general case the gaussian mixture defines different degrees of uncertainty along different directions in the semantic space which seems more interesting minor comments table is not referred to in the text in reference luong et al lacks the publication year i have read the response,4.0
779.json,this paper proposes a novel strategy for zero resource translation where source pivot and pivot target parallel corpora are available a teacher model for p target pivot is first trained on the pivot target corpus then a student model for p target source is trained to minimize relative entropy with respect to the teacher on the source pivot corpus when using word level relative entropy over samples from the teacher this approach is shown to outperform previous variants on standard pivoting as well as other zero resource strategies this is a good contribution a novel idea clearly explained and with convincing empirical support unlike some previous work it makes fairly minimal assumptions about the nature of the nmt systems involved and hence should be widely applicable i have only a few suggestions for further experiments first it would be interesting to see how robust this approach is to more dissimilar source and pivot languages where intuitively the true p target source and p target pivot will be further apart second given the success of introducing word based diversity it was surprising not to see a sentence n best or sentence sampling experiment this would be more costly but not much more so since you re already doing beam search with the teacher finally related to the previous it might be interesting to explore transition from word based diversity to sentence based as the student converges and no longer needs the signal from low probability words some further comments line despite its simplicity due to its simplicity target sentence y target word y i assume that k and k mean that you compare probabilities of the most probable and most probable words in the current context if so how is the current context determined greedily or with a beam section the comparison with an essentially uniform distribution doesn t seem very informative here it would be extremely surprising if p y z were not significantly closer to p y x than to uniform it would be more interesting to know to what extent p y z still provides a useful signal as p y x gets better this would be easy to measure by comparing p y z to models for p y x trained on different amounts of data or for different numbers of iterations another useful thing to explore in this section would be the effect of the mode approximation compared to n best for sentence level scores it s odd that word beam does worse than word greedy since word beam should be closer to word sampling do you have an explanation for this the claimed advantage of sent beam here looks like it may just be noise given the high variance of these curves,4.0
779.json,in this paper the authors present a method for training a zero resource nmt system by using training data from a pivot language unlike other approaches mostly inspired in smt the author s approach doesn t do two step decoding instead they use a teacher student framework where the teacher network is trained using the pivot target language pairs and the student network is trained using the source pivot data and the teacher network predictions of the target language strengths the results the authors present show that their idea is promising also the authors present several sets of results that validate their assumptions weaknesses however there are many points that need to be address before this paper is ready for publication crucial information is missing can you flesh out more clearly how training and decoding happen in your training framework i found out that the equations do not completely describe the approach it might be useful to use a couple of examples to make your approach clearer also how is the montecarlo sampling done organization the paper is not very well organized for example results are broken into several subsections while they d better be presented together the organization of the tables is very confusing table is referred before table this made it difficult to read the results inconclusive results after reading the results section it s difficult to draw conclusions when as the authors point out in their comparisons this can be explained by the total size of the corpus involved in their methods not so useful information while i appreciate the fleshing out of the assumptions i find that dedicating a whole section of the paper plus experimental results is a lot of space general discussion other we observe that word level models tend to have lower valid loss compared with sentence level methods is it valid to compare the loss from two different loss functions sec the notations are not clear what does script y means how do we get p y x this is never explained eq deserves some explanation or better removed what approach did you use you should talk about that here do you mean nitty gritty import important inline citation style can significantly outperform assumption needs to be rewritten a target sentence y from x should be close to that from its counterpart z,3.0
684.json,this paper presents a gated attention mechanism for machine reading a key idea is to extend attention sum reader kadlec et al to multi hop reasoning by fine grained gated filter it interesting and intuitive for machine reading i like the idea along with significant improvement on benchmark datasets but also have major concerns to get it published in acl the proposed ga mechanism looks promising but not enough to convince the importance of this technique over other state of the art systems because engineering tricks presented boost a lot on accuracy and are blended in the result incomplete bibliography nearly all published work in reference section refers arxiv preprint version this makes me and future readers suspicious if this work thoroughly compares with prior work please make them complete if the published version is available result from unpublished work ga ga baseline in table and is mentioned as previous work that is unpublished preprint i do not think this is necessary at all alternately i would like the author to replace it with vanilla ga or variant of the proposed model for baseline it does not make sense that result from the preprint which will end up being the same as this acl submission is presented in the same manuscript for fair blind review i did not search on arvix archive though conflict on table and ga table is the same as k as in table and ga fix l w is for k in table does this mean that ga is actually as reader it not clear that ga is re implementation of as i assumed k as in table uses also glove initialization and token attention but it does not seem in ga i wish the proposed method compared with prior work in related work section i e what is differ from related work fig shows benefit of gated attention which translates multi hop architecture and it very impressive it would be great to see any qualitative example with comparison,4.0
684.json,this paper presents an interesting model for reading comprehension by depicting the multiplicative interactions between the query and local information around a word in a document and the authors proposed a new gated attention strategy to characterize the relationship the work is quite solid with almost state of art result on the whole four cloze style datasets achieved some of the further improvement can be helpful for the similar tasks nevertheless i have some concerns on the following aspect the authors have referred many papers from arxiv but i think some really related works are not included such as the works from caiming xiong et al https openreview net pdf id rjekjwvclx and the work form shuohang wang et al https openreview net pdf id b qpqxl both of them concentrated on enhancing the attention operation to modeling the interaction between documents and queries although these works are not evaluated on the cloze style corpus but the squad an experimental or fundamental comparison may be necessary there have been some studies that adopts attention mechanism or its variants specially designed for the reading comprehension tasks and the work actually share the similar ideas with this paper my suggestion is to conduct some comparisons with such work to enhance the experiments of this paper,3.0
684.json,strengths paper is very well written and every aspect of the model is well motivated and clearly explained the authors have extensively covered the previous work in the area the approach achieves state of the art results across several text comprehension data sets in addition the experimental evaluation is very thorough weaknesses different variants of the model achieve state of the art performance across various data sets however the authors do provide an explanation for this i e size of data set and text anonymization patterns general discussion the paper describes an approach to text comprehension which uses gated attention modules to achieve state of the art performance compared to previous attention mechanisms the gated attention reader uses the query embedding and makes multiple passes multi hop architecture over the document and applies multiplicative updates to the document token vectors before finally producing a classification output regarding the answer this technique somewhat mirrors how humans solve text comprehension problems results show that the approach performs well on large data sets such as cnn and daily mail for the cbt data set some additional feature engineering is needed to achieve state of the art performance overall the paper is very well written and model is novel and well motivated furthermore the approach achieves state of the art performance on several data sets i had only minor issues with the evaluation the experimental results section does not mention whether the improvements e g in table are statistically significant and if so which test was used and what was the p value also i could not find an explanation for the performance on cbt cn data set where the validation performance is superior to nse but test performance is significantly worse,4.0
562.json,strengths zero shot relation extraction is an interesting problem the authors have created a large dataset for relation extraction as question answering which would likely be useful to the community weaknesses comparison and credit to existing work is severely lacking contributions of the paper do not seen particularly novel general discussion the authors perform relation extraction as reading comprehension in order to train reading comprehension models to perform relation extraction they create a large dataset of m querified converted to natural language relations by asking mechanical turk annotators to write natural language queries for relations from a schema they use the reading comprehension model of seo et al adding the ability to return no relation as the original model must always return an answer the main motivation result of the paper appears to be that the authors can perform zero shot relation extraction extracting relations only seen at test time this paper is well written and the idea is interesting however there are insufficient experiments and comparison to previous work to convince me that the paper s contributions are novel and impactful first the authors are missing a great deal of related work neelakantan at al https arxiv org abs perform zero shot relation extraction using rnns over kb paths verga et al https arxiv org abs perform relation extraction on unseen entities the authors cite bordes et al https arxiv org pdf pdf who collect a similar dataset and perform relation extraction using memory networks which are commonly used for reading comprehension however they merely note that their data was annotated at the relation level rather than at the triple relation entity pair level but couldn t bordes et al have done the same in their annotation if there is some significant difference here it is not made clear in the paper there is also a naacl paper https www aclweb org anthology n n n pdf which performs relation extraction using a new model based on memory networks and i m sure there are more your work is so similar to much of this work that you should really cite and establish novelty wrt at least some of them as early as the introduction that how early i was wondering how your work differed and it was not made clear second the authors neither evaluate their model on another dataset or evaluate any previously published models on their dataset this makes their empirical results extremely weak given that there is a wealth of existing work that performs the same task and the lack of novelty of this work the authors need to include experiments that demonstrate that their technique outperforms others on this task or otherwise show that their dataset is superior to others e g since it is much larger than previous does it allow for better generalization,2.0
562.json,the paper models the relation extraction problem as reading comprehension and extends a previously proposed reading comprehension rc model to extract unseen relations the approach has two main components queryfication converting a relation into natural question authors use crowdsourcing for this part applying rc model on the generated questions and sentences to get the answer spans authors extend a previously proposed approach to accommodate situations where there is no correct answer in the sentence my comments the paper reads very well and the approach is clearly explained in my opinion though the idea of using rc for relation extraction is interesting and novel the approach is not novel a part of the approach is crowdsourced and the other part is taken directly from a previous work as i mention above relation extraction is a well studied problem and there are plenty of recently published works on the problem however authors do not compare their methods against any of the previous works this raises suspicion on the effectiveness of the approach as seen from table the performance numbers of the proposed method on the core task are not very convincing however this maybe because of the dataset used in the paper hence a comparison with previous methods would actually help assess how the current method stands with the state of the art slot filling data preparation you say we took the first sentence s in d to contain both e and a how can you get the answer sentence for all the relations of an entity from the first sentence of the entity wikipedia article please clarify this see the following paper they have a set of rules to locate answer sentences corresponding to an entity property in its wikipedia page wu fei and daniel s weld open information extraction using wikipedia proceedings of the th annual meeting of the association for computational linguistics association for computational linguistics overall i think the paper presents an interesting approach however unless the effectiveness of the approach is demonstrated by comparing it against recent works on relation extraction the paper is not ready for publication,2.0
108.json,strengths the paper is well written except for a few places as described below the problem the paper tackles is useful the proposed approach multigraph based model is a variant of mh the empirical result is solid weaknesses clarification is needed in several places in section in addition to the description of the previous model mh you need point out the issues of mh which motivate you to propose a new model in section i do not see the reason why separators are introduced what additional info they convene beyond t i o section does not seem to provide useful info regarding why the new model is superior the discussion in section is so abstract that i do not get the insights why the new model is better than mh can you provide examples of spurious structures general discussion the paper presents a new model for detecting overlapping entities in text the new model improves the previous state of the art mh in the experiments on a few benchmark datasets but it is not clear why and how the new model works better,3.0
108.json,the paper suggests an approach based on multigraphs several edges may link two nodes for detecting potentially overlapping entities strengths the problem itself could be rather interesting especially for crossing entities to decide which one might actually be mentioned in some text the technique seems to work although the empirically results do not show some dramatic effect i like that some words are spent on efficiency compared to a previous system the paper in general is well written but also needs some further polishing in some details see minor remarks below weaknesses the problem itself is not really well motivated why is it important to detect china as an entity within the entity bank of china to stay with the example in the introduction i do see a point for crossing entities but what is the use case for nested entities this could be much more motivated to make the reader interested as for the approach itself some important details are missing in my opinion what is the decision criterion to include an edge or not in lines several different options for the i kt nodes are mentioned but it is never clarified which edges should be present as for the empirical evaluation the achieved results are better than some previous approaches but not really by a large margin i would not really call the slight improvements as outperformed as is done in the paper what is the effect size does it really matter to some user that there is some improvement of two percentage points in f what is the actual effect one can observe how many important entities are discovered that have not been discovered by previous methods furthermore what performance would some simplistic dictionary based method achieve that could also be used to find overlapping things and in a similar direction what would some commercial system like google nlp cloud that should also be able to detect and link entities would have achieved on the datasets just to put the results also into contrast of existing commercial systems as for the result discussion i would have liked to see some more emphasis on actual crossing entities how is the performance there this in my opinion is the more interesting subset of overlapping entities than the nested ones how many more crossing entities are detected than were possible before which ones were missed and maybe why is the performance improvement due to better nested detection only or also detecting crossing entities some general error discussion comparing errors made by the suggested system and previous ones would also strengthen that part general discussion i like the problems related to named entity recognition and see a point for recognizing crossing entities however why is one interested in nested entities the paper at hand does not really motivate the scenario and also sheds no light on that point in the evaluation discussing errors and maybe advantages with some example cases and an emphasis on the results on crossing entities compared to other approaches would possibly have convinced me more so i am only lukewarm about the paper with maybe a slight tendency to rejection it just seems yet another try without really emphasizing the in my opinion important question of crossing entities minor remarks first mention of multigraph some readers may benefit if the notion of a multigraph would get a short description previously noted by many previous sounds a little odd solving this task which one e g why in italics time linear in n when n is sentence length does it really matter whether it is linear or cubic spurious structures in the introduction it is not clear what is meant regarded as a chunk np chunking noun phrase chunking since they set who pervious previous of lu and roth the following five types in sentences with no large numbers spell out the small ones please types of states what is a state in a hyper graph later state seems to be used analogous to node i would place commas after the enumeration items at the end of page and a period after the last one what are child nodes in a hypergraph in figure it was not obvious at first glance why this is a hypergraph colors are not visible in b w printing why are some nodes edges in gray it is also not obvious how the highlighted edges were selected and why the others are in gray why should both entities be detected in the example of figure what is the difference to just knowing the long one denoting sometimes in brackets sometimes not why please place footnotes not directly in front of a punctuation mark but afterwards footnote due to the missing edge how determined that this one should be missing on whether the separator defines how determined in the mention hypergraph last paragraph before to represent the entity separator cs how is the cs edge chosen algorithmically here comma after equation to find out sounds a little odd here we extract entities  footnote we make two sounds odd we conduct or something like that nested vs crossing remark in footnote why is this good why not favor crossing examples to clarify the combination of states alone does not the simple first order assumption that is what in the previous section we see that our model demonstrated have shown used in this experiments these each of these distinct interpretations published on their website the statistics of each dataset are shown allows us to use to make use omit to use tried to follow as close tried to use the features suggested in previous works as close as possible following lu and roth please do not use references as nouns following lu and roth using the bilou scheme highlighted in bold what about the effect size significantly better in what sense effect size in genia dataset on the genia dataset outperforms by about points i would not call that outperform that the genia dataset this low recall which one due to an insufficient table all f scores seems rather similar to me again outperform seems a bit of a stretch here is more confident why does this increase recall converge than the mention hypergraph references some paper titles are lowercased others not why,2.0
333.json,strengths the authors propose a selective encoding model as extension to the sequence to sequence framework for abstractive sentence summarization the paper is very well written and the methods are clearly described the proposed methods are evaluated on standard benchmarks and comparison to other state of the art tools are presented including significance scores weaknesses there are some few details on the implementation and on the systems to which the authors compared their work that need to be better explained general discussion major review i wonder if the summaries obtained using the proposed methods are indeed abstractive i understand that the target vocabulary is build out of the words which appear in the summaries in the training data but given the example shown in figure i have the impression that the summaries are rather extractive the authors should choose a better example for figure and give some statistics on the number of words in the output sentences which were not present in the input sentences for all test sets page lines i understand the mathematical difference between the vector hi and s but i still have the feeling that there is a great overlap between them both represent the meaning are both indeed necessary did you trying using only one of them which neural network library did the authors use for implementing the system there is no details on the implementation page section which training data was used for each of the systems that the authors compare to diy you train any of them yourselves minor review page line although the difference between abstractive and extractive summarization is described in section this could be moved to the introduction section at this point some users might no be familiar with this concept page lines please provide a reference for this passage this approach achieves huge success in tasks like neural machine translation where alignment between all parts of the input and output are required page section last paragraph the contribution of the work is clear but i think the authors should emphasize that such a selective encoding model has never been proposed before is this true further the related work section should be moved to before the methods section figure vs table the authors show two examples for abstractive summarization but i think that just one of them is enough further one is called a figure while the other a table section lines and please provide references for the following two passages in the sequence to sequence machine translation mt model the encoder and decoder are responsible for encoding input sentence information and decoding the sentence representation to generate an output sentence some previous works apply this framework to summarization generation tasks figure what is mlp it seems not to be described in the paper page lines the sigmoid function and the element wise multiplication are not defined for the formulas in section page first column many elements of the formulas are not defined b equation w equation and u equation v equation page line the readout state rt is not depicted in figure workflow table what does ref mean section model parameters and training explain how you achieved the values to the many parameters word embedding size gru hidden states alpha beta and epsilon beam size page line remove the word in this line sgd as our optimizing algorithms instead of sgd as our the optimizing algorithms page beam search please include a reference for beam search figure is there a typo in the true sentence council of europe again slams french prison conditions again or against typo supper script superscript times,4.0
333.json,strengths the paper is very clear and well written it proposes a novel approach to abstractive sentence summarization basically sentence compression that is not constrained to having the words in the output be present in the input excellent comparison with many baseline systems very thorough related work weaknesses the criticisms are very minor it would be best to report rouge f score for all three datasets the reasons for reporting recall on one are understandable the summaries are all the same length but in that case you could simply report both recall and f score the related work should come earlier in the paper the paper could use some discussion of the context of the work e g how the summaries compressions are intended to be used or why they are needed general discussion rouge is fine for this paper but ultimately you would want human evaluations of these compressions e g on readability and coherence metrics or an extrinsic evaluation,4.0
333.json,the paper presents a new neural approach for summarization they build on a standard encoder decoder with attention framework but add a network that gates every encoded hidden state based on summary vectors from initial encoding stages overall the method seems to outperform standard seqseq methods by points on three different evaluation sets overall the technical sections of the paper are reasonably clear equation needs more explanation i could not understand the notation the specific contribution the selective mechanism seems novel and could potentially be used in other contexts the evaluation is extensive and does demonstrate consistent improvement one would imagine that adding an additional encoder layer instead of the selective layer is the most reasonable baseline given the gru baseline uses only one bi gru this adds expressivity and this seems to be implemented luong nmt my one concern is lstm gru mismatch is the benefit coming from just gru switch the quality of the writing especially in the intro abstract related work is quite bad this paper does not make a large departure from previous work and therefore a related work nearby the introduction seems more appropriate in related work one common good approach is highlighting similarities and differences between your work and previous work in words before they are presented in equations simply listing works without relating them to your work is not that useful placement of the related work near the intro will allow you to relieve the intro of significant background detail and instead focus on more high level,4.0
276.json,the paper proposes an approach to sequence labeling with multitask learning where language modeling is uses as the auxiliary objective thus a bidirectional neural network architecture learns to predict the output labels as well as to predict the previous or next word in the sentence the joint objectives lead to improvements over the baselines in grammatical error detection chunking ner and pos tagging strengths the contribution is quite well written and easy to follow for the most part the model is exposed in sufficient detail and the experiments are thorough within the defined framework the benefits of introducing an auxiliary objective are nicely exposed weaknesses the paper shows very limited awareness of the related work which is extensive across the tasks that the experiments highlight tables only show the three systems proposed by the contribution baseline dropout and lmcost while some very limited comparisons are sketched textually a contribution claiming novelty and advancements over the previous state of the art should document these improvements properly at least by reporting the relevant scores together with the novel ones and ideally through replication the datasets used in the experiments are all freely available the previous results well documented and the previous systems are for the most part publicly available in my view for a long paper it is a big flaw not to treat the previous work more carefully in that sense i find this sentence particularly troublesome the baseline results are comparable to the previous best results on each of these benchmarks the reader is here led to believe that the baseline system somehow subsumes all the previous contributions which is shady on first read and factually incorrect after a quick lookup in related work the paper states new state of the art results for error detection on both fce and conll datasets looking into the conll shared task report it is not straightforward to discern whether the latter part of the claim does holds true also as per rei and yannakoudakis paper the paper should support the claim by inclusion replication of the related work general discussion the pos tagging is left as more of an afterthought the comparison to plank et al is at least partly unfair as they test across multiple languages in the universal dependencies realm showing top level performance across language families which i for one believe to be far more relevant than wsj benchmarking how does the proposed system scale up down to multiple languages low resource languages with limited training data etc the paper leaves a lot to ask for in that dimension to further substantiate its claims i like the idea of including language modeling as an auxiliary task i like the architecture and sections in general in my view there is a big gap between those sections and the ones describing the experiments i suggest that this nice idea should be further fleshed out before publication the rework should include at least a more fair treatment of related work if not replication and at least a reflection on multilinguality the data and the systems are all there as signs of the field growing maturity the paper should in my view partake in reflecting this maturity and not step away from it in faith that these improvements can be implemented before the publication deadline i vote borderline,3.0
276.json,strengths the article is well written what was done is clear and straightforward given how simple the contribution is the gains are substantial at least in the error correction task weaknesses the novelty is fairly limited essentially another permutation of tasks in multitask learning and only one way of combining the tasks is explored e g it would have been interesting to see if pre training is significantly worse than joint training one could initialize the weights from an existing rnn lm trained on unlabeled data etc general discussion i was hesitating between a and a while the experiments are quite reasonable and the combinations of tasks sometimes new there quite a bit of work on multitask learning in rnns much of it already cited so it hard to get excited about this work i nevertheless recommend acceptance because the experimental results may be useful to others post rebuttal i have read the rebuttal and it did not change my opinion of the paper,4.0
775.json,this paper proposes an approach for classifying literal and metaphoric adjective noun pairs the authors create a word context matrix for adjectives and nouns where each element of the matrix is the pmi score they then use different methods for selecting dimensions of this matrix to represent each noun adjective as a vector the geometric properties of average nouns and adjective vectors and their normalized versions are used as features in training a regression model for classifying the pairs to literal or metaphor expressions their approach performs similarly to previous work that learns a vector representation for each adjective supervision and zero shot learning the authors argue that their approach requires less supervision compared to previous work and can do zero shot learning i don t think this is quite right and given that it seems to be one of the main points of the paper i think it is worth clarifying the approach proposed in the paper is a supervised classification task the authors form vector representations from co occurrence statistics and then use the properties of these representations and the gold standard labels of each pair to train a classifier the model similarly to any other supervised classifier can be tested on words that did not occur in the training data but the model does not learn from such examples moreover those words are not really unseen because the model needs to have a vector representation of those words interpretation of the results the authors provide a good overview of the previous related work on metaphors however i am not sure what the intuition about their approach is that is using the geometric properties such as vector length in identifying metaphors for example why are the normalized vectors considered it seems that they don t contribute to a better performance moreover the most predictive feature is the noun vector the authors explain that this is a side effect of the data which is collected such that each adjective occurs in both metaphoric and literal expressions as a result the adjective vector is less predictive it seems that the proposed approach might be only suitable for the given data this shortcoming is two fold a from the theoretical perspective and especially since the paper is submitted to the cognitive track it is not clear what we learn about theories of metaphor processing b from the nlp applications standpoint i am not sure how generalizable this approach is compared to the compositional models novelty the proposed approach for representing noun adjective vectors is very similar to that of agres et al it seems that the main contribution of the paper is that they use the geometric properties to classify the vectors,3.0
775.json,this paper presents a method for metaphor identification based on geometric approach certainly very interesting piece of work i enjoyed learning a completely new perspective however i have a few issues i like them to be addressed by the authors i would like to read author response on the following issues strengths a geometric approach to metaphor interpretation is a new research strand altogether the paper is well written author claim is the beauty of their model lies in its simplicity i do agree with their claim but the implication of the simplicity is not been addressed in simple ways please refer the weakness section weaknesses regarding writing no doubt the paper is well written but the major issue with the paper is its lucidness indeed poetic language elegance is applaud able but clarity in scientific writing is very much needed i hope you will agree with most of the stuff being articulated here https chairs blog acl org last minute writing advice let me put my objections on writing here while providing a method which is effectively zero shot left readers in the blank the notion of zero shot has not been introduced yet figure most neutral least metaphoric how did you arrive at such differentiations talk more about data otherwise the method is less intuitive i enjoyed reading the analysis section but it is not clear why the proposed simple as claimed method can over perform than other existing techniques putting some examples would be better i believe technicality a strength of this model is its simplicity indeed but the implication is not vivid from the writing mathematical and technical definition of a problem is one aspect but the implication from the definition is quite hard to be understood when that the note able contribution of the paper comparing to previous research this paper shows only marginal accuracy gain comparison only with one previous work and then claiming that the method is capable of zero shot is slightly overstated is the method extendable to twitter let say general discussion,3.0
237.json,strengths this paper deals with the issue of finding word polarity orientation in an unsupervised manner using word embeddings weaknesses the paper presents an interesting and useful idea however at this moment it is not applied to any test case the ideas on which it is based are explained in an intuitive manner and not thoroughly justified general discussion this is definitely interesting work the paper would benefit from more experiments being carried out comparison with other methods for example the use of the normalized google distance by authors such as balahur and montoyo http ieeexplore ieee org abstract document and the application of the knowledge obtained to a real sentiment analysis scenario at this point the work although promising is in its initial phase,2.0
561.json,the paper introduces a general method for improving nlp tasks using embeddings from language models context independent word representations have been very useful and this paper proposes a nice extension by using context dependent word representations obtained from the hidden states of neural language models they show significant improvements in tagging and chunking tasks from including embeddings from large language models there is also interesting analysis which answers several natural questions overall this is a very good paper but i have several suggestions too many experiments are carried out on the test set please change tables and to use development data it would be really nice to see results on some more tasks ner tagging and chunking do not have many interesting long range dependencies and the language model might really help in those cases i would love to see results on srl or ccg supertagging the paper claims that using a task specific rnn is necessary because a crf on top of language model embeddings performs poorly it was not clear to me if they were backpropagating into the language model in this experiment but if not it certainly seems like there is potential for that to make a task specific rnn unnecessary,4.0
561.json,the paper proposes an approach where pre trained word embeddings and pre trained neural language model embeddings are leveraged i e concatenated to improve the performance in english chunking and ner on the respective conll benchmarks and on an out of domain english ner test set the method records state of the art scores for the two tasks strengths for the most part the paper is well written and easy to follow the method is extensively documented the discussion is broad and thorough weaknesses sequence tagging does not equal chunking and ner i am surprised not to see pos tagging included in the experiment while more sequence tagging tasks would be welcome grammatical error detection supersense tagging ccg supertagging etc this way the paper is on chunking and ner for english not for sequence tagging in general as it lacks both the multilingual component and the breadth of tasks while i welcomed the extensive description of the method i do think that figures and overlap and that only one would have sufficed related to that the method itself is rather straightforward and simple while this is by all means not a bad thing it seems that this contribution could have been better suited for a short paper since i do enjoy the more extensive discussion section i do not necessarily see it as a flaw but the core of the method itself does not strike me as particularly exciting it more of a focused contribution short paper description from the call than substantial work long paper general discussion bottomline the paper concatenates two embeddings and sees improvements in english chunking and ner as such does it warrant publication as an acl long paper i am ambivalent so i will let my score reflect that even if i slightly lean towards a negative answer why mainly because i would have preferred to see more breadth a more sequence tagging tasks and b more languages also we do not know how well this method scales to low er resource scenarios what if the pre trained embeddings are not available what if they were not as sizeable as they are the experiments do include a notion of that but still far above the low resource range could they not have been learned in a multi task learning setup in your model that would have been more substantial in my view for these reasons i vote borderline but with a low originality score the idea of introducing context via the embeddings is nice in itself but this particular instantiation of it leaves a lot to ask for,3.0
86.json,summary the paper proposes a neural model for predicting python syntax trees from text descriptions guided by the actual python grammar the model generates tree nodes sequentially in a depth first fashion key ideas include injecting the information from the parent node as part of the lstm input a pointer network for copying the terminals and unary closure which collapses chains of unary productions to reduce the tree size the model is evaluated on three datasets from different domains and outperforms almost all previous work strengths the paper is overall very well written the explanation of system is clear and the analysis is thorough the system itself is a natural extension of various ideas the most similar work include tree based generation with parent feeding dong and lapata and various rnn based semantic parsing with copy mechanism jia and liang ling et al the guidance of parsing based on grammar is also explored in chen liang et al https arxiv org abs where a code assist system is used to ensure that the code is valid nevertheless the model is this paper stands out as it is able to generate much longer and more complex programs than most previous work mentioned weaknesses the evaluation is done on code accuracy exact match and bleu score these metrics especially bleu might not be the best metrics for evaluating the correctness of programs for instance the first example in table shows that while the first two lines in boxes a and b are different they have the same semantics another example is that variable names can be different evaluation based on what the code does e g using test cases or static code analysis would be more convincing another point about evaluation other systems e g nmt baseline may generate code with syntactic error would it be possible to include the result on the highest scoring well formed code e g using beam search that these baseline systems generate this would give a fairer comparison since these system can choose to prune malformed code general discussion lines some approaches that use domain specific languages were also guided by a grammar one example is berant and liang which uses a pretty limited grammar for logical forms table in addition to comparing to that line of work emphasizing that the grammar in this paper is much larger than most previous work would make this work stronger lines for the parent feeding mechanism is the child index being used in other words is pt different when generating a first child versus a second child in seqtree dong and lapata the two non terminals would have different hidden states line are the possible tokens embedded is it assumed that the set of possible tokens is known beforehand the examples in the appendix are nice i have read the author response,4.0
86.json,strengths the approach proposed in the paper seems reasonable and the experimental results make the approach seem promising there are two features of the approach one feature is that the approach is for general purpose programming languages it might be applicable to java c etc however proof is still needed another feature is its data driven syntactic neural model which is described in section together with section i think by the neural model it brings around improvement over another same purpose approach lpn in accuracy according to the experimental data overall this is nice work with clear motivation methodology data analysis and well organized presentation weaknesses at line the authors mentioned hypothesis space i did not know what it means until i read the supplementary materials because such materials will not be included in the full paper in my opinion it is better to give some explanation on hypothesis space section introduces the grammar model and section describes action probability estimation my understanding is that the latter is a part of the former the two section titles do not reflect this relation at least section does not explain all about the grammar model about the experimental data i am wondering how the authors train their model before doing the experiments how many datasets are used is it true that more the model get trained more accuracy can be obtained how about the efficiency of the two approaches the one in the paper and lpn are there differences between the neural network based approaches that are used for code generation of general purpose language and those of domain specific ones the authors claim that their approach scale up to generation of complex programs i did not find any argument in the paper to backup this conclusion minor comments line the underlying syntax the syntax of which language nl or pl line are there any constraints on x line the decoder uses a rnn the decoder uses an rnn reference format is inconsistent general discussion this paper proposes a data driven syntax based neural network model for code generation in general purpose programming langauge i e python the main idea of the approach is first to generate a best possible ast using a probabilistic grammar model for a given statement in natural language and then ecode ast into surce code using deterministic generation tools generating code from an ast is relatively easy the key point is the first step experimental results provided in the paper show the proposed approach outperform some other state of the art approaches,4.0
520.json,this paper proposes a method for generating datasets of pictures from simple building blocks as well as corresponding logical forms and language descriptions the goal seems to be to have a method where the complexity of pictures and corresponding desciptions can be controlled and parametrized the biggest downside seems to be that the maximally achievable complexity is very limited and way below the complexity typically faced with image captioning and other multimodal tasks the relative simplicity is also a big difference to the referenced babi tasks which cover the whole qualitative spectrum of easy to hard reasoning tasks whereas in the proposed method a qualitatively easy image reconition task can only be quantitatively made harder by increasing the number of objects noise etc in unnatural ways this is also reflected in the experimental section whenever the experimental performance results are not satisfying these cases seem like basic over underfitting issues that may easily be tackled by restricting extending the capacity of the networks or using more data it is hard for me to spot any other qualitative insight in the introduction it is stated that the goal is not too achieve optimal performance but to find out whether architectures are able to successfully demonstrate the desired understanding there is a fundamental contradiction here in that the proposed task on the one side is meant to provide a measure as to whether architectures demontrate understanding on the other hand the score is not supposed to be taken as meaningful seriously general comments the general approach should be made more tangible earlier i e in the introction rather than in section,2.0
520.json,strengths the authors introduce a new software package called shapeworld for automatically generating data for image captioning problems the microworld used to generate the image captions is simple enough to make the data being generated and errors by a model readily interpretable however the authors demonstrate that configurations of the packages produce data that is challenging enough to serve as a good benchmark for ongoing research weaknesses the primary weakness of this paper is that it does look a bit like a demo paper the authors do provides experiments that evaluate a reasonable baseline image captioning system on the data generated by shapeworld however similar experiments are included in demo papers the paper includes a hyperlink to the software package on github that presumably unmasks the authors of the paper general discussion scientific progress often involves some something analogous to vygotsky zone of proximal development whereby progress can be made more quickly if research focuses on problems with just the right level of difficulty e g the use of tidigits for speech recognition research in the early s this paper is exciting since it offers a simple microworld that is easy for researchers to completely comprehend but that also is just difficult enough for existing models the strengths of the work are multiplied by the fact that the software is opensource is readily available on github and generates the data in a format that can be easily used with models built using modern deep learning libraries e g tensorflow the methods used by the software package to generate the artificial data are clearly explained it is also great that the authors did experiments with different configurations of their software and a baseline image caption model in order to demonstrate the strengths and weakness of existing techniques my only real concern with this paper is whether the community would be better served by placing it in the demo section publishing it in the non demo long paper track might cause confusion as well as be unfair to authors who correctly submitted similar papers to the acl demo track,2.0
222.json,strengths when introducing the task the authors use illustrative examples as well as the contributions of this paper related works section covers the state of the art at the same time pointing similarities and differences between related works and the proposed method the presentation of the method is very clear since the authors separate the tagging scheme and the end to end model another strong point of this work is the baselines used to compare the proposed methods with several classical triplet extraction methods at last the presentation of examples from dataset used to illustrate the advantages and disadvantages of the methods was very important these outputs complement the explanation of tagging and evaluation of triplets weaknesses one of the main contributions of this paper is a new tagging scheme described in section however there are already other schemes for ner and re being used such as io bio and bilou did the authors perform any experiment using other tagging scheme for this method regarding the dataset in line page the authors cite the number of relations but they do not mention the number or the type of named entities in section the evaluation criteria of triplets are presented these criteria were based on previous work as i see it the stage of entity identification is not complete if you consider only the head of the entity regarding example s shown in table the output of the lstm lstm bias was considered correct the text states that the relation role is wrong although it is not clear if the relation role is considered in the evaluation general discussion this paper proposes a novel tagging scheme and investigates the end to end models to jointly extract entities and relations the article is organized in a clear way and it is well written which makes it easy to understand the proposed method,5.0
367.json,strengths the paper addresses a long standing problem concerning automatic evaluation of the output of generation translation systems the analysis of all the available metrics is thorough and comprehensive the authors demonstrate a new metric with a higher correlation with human judgements the bibliography will help new entrants into the field weaknesses the paper is written as a numerical analysis paper with very little insights to linguistic issues in generation the method of generation the differences in the output from a different systems and human generated reference it is unclear if the crowd source generated references serve well in the context of an application that needs language generation general discussion overall the paper could use some linguistic examples and a description of the different systems at the risk of dropping a few tables to help the reader with intuitions,3.0
760.json,the paper proposes a recurrent neural architecture that can skip irrelevant input units this is achieved by specifying r of words to read at each skim k max jump size and n max of jumps allowed an lstm processes r words predicts the jump size k in k signals stop skips the next k words and continues until either the number of jumps reaches n or the model reaches the last word while the model is not differentiable it can be trained by standard policy gradient the work seems to have been heavily influenced by shen et al who apply a similar reinforcement learning approach including the same variance stabilization to multi pass machine reading strengths the work simulates an intuitive skimming behavior of a reader mirroring shen et al who simulate self terminated repeated reading a major attribute of this work is its simplicity despite the simplicity the approach yields favorable results in particular the authors show through a well designed synthetic experiment that the model is indeed able to learn to skip when given oracle jump signals in text classification using real world datasets the model is able to perform competitively with the non skimming model while being clearly faster the proposed model can potentially have meaningful practical implications for tasks in which skimming suffices e g sentiment classification it suggests that we can obtain equivalent results without consuming all data in a completely automated fashion to my knowledge this is a novel finding weaknesses it a bit mysterious on what basis the model determines its jumping behavior so effectively other than the synthetic dataset i am thinking of a case where the last part of the given sentence is a crucial evidence for instance the movie was so so and boring to the last minute but then its ending blew me away in this example the model may decide to skip the rest of the sentence after reading so so and boring but by doing so it will miss the turning point ending blew me away and mislabel the instance as negative for such cases a solution can be running the skimming model in both directions as the authors suggest as future work but in general the model may require more sophisticated architecture for controlling skimming it seems one can achieve improved skimming by combining it with multi pass reading presumably in reverse directions that how humans read to understand text that can not be digested in one skim indeed that how i read this draft overall the work raises an interesting problem and provides an effective but intuitive solution,4.0
326.json,strengths the authors use established neural network methods adversarial networks goodfellow et al nips to take advantage of different chinese work breaking test sets with different notions of what counts as a word in chinese this paper could have implications for many nlp tasks where we have slightly different notions of what counts as correct we have been thinking of that problem in terms of adaptation but it is possible that goodfellow et al is a more useful way of thinking about this problem weaknesses we need a name for the problem mentioned above how about the elusive gold standard i prefer that term to multi criteria the motivation seems to be unnecessarily narrow the elusive gold standard comes up in all sorts of applications not just chinese word segmentation the motivation makes unnecessary assumptions about how much the reader knows about chinese when you do not know much about something you think it is easier than it is many non chinese readers like this reviewer think that chinese is simpler than it is it is easy to assume that chinese word segmentation is about as easy as tokenizing english text into strings delimited by white space but my guess is that iaa inter annotator agreement is pretty low in chinese the point you are trying to make in table is that there is considerable room for disagreement among native speakers of chinese i think it would help if you could point out that there are many nlp tasks where there is considerable room for disagreement some tasks like machine translation information retrieval and web search have so much room for disagreement that the metrics for those tasks have been designed to allow for multiple correct answers for other tasks like part of speech tagging we tend to sweep the elusive gold standard problem under a rug and hope it will just go away but in fact progress on tagging has stalled because we do not know how to distinguish differences of opinions from errors when two annotators return two different answers it is a difference of opinion but when a machine returns a different answer the machine is almost always wrong this reader got stuck on the term adversary i think the nips paper used that because it was modeling noise under murphy law it is often wise to assume the worst but i do not think it is helpful to think of differences of opinion as an adversarial game like chess in chess it makes sense to think that your opponent is out to get you but i am not sure that the most helpful way to think about differences of opinion i think it would clarify what you are doing to say that you are applying an established method from nips that uses the term adversarial to deal with the elusive gold standard problem and then point out that the elusive gold standard problem is a very common problem you will study it in the context of a particular problem in chinese but the problem is much more general than that general discussion i found much of the paper unnecessarily hard going i am not up on chinese or the latest in nips which does not help but even so there are some small issues with english and some larger problems with exposition consider table line makes an assertion about the first block and depth of networks specifically which lines in table support that assertion i assume that p and r refer to precision and recall but where is that explained i assume that f is the standard f measure and oov is out of vocabulary but again i should not have to assume such things there are many numbers in table what counts as significance which numbers are even comparable can we compare numbers across cols is performance on one collection comparable to performance on another line suggests that the adversarial method is not significant what should i take away from table line claims that you have a significant solution to what i call the elusive gold standard problem but which numbers in table justify that claim small quibbles about english works work in many places work is a mass noun not a count noun unlike conclusion one can say one conclusion two conclusions but more less some work not one work two works line each dataset not each datasets line three datasets use traditional chinese as city ckip and the other five use simplified chinese line random randomize,4.0
326.json,the paper proposes a method to train models for chinese word segmentation cws on datasets having multiple segmentation criteria strengths multi criteria learning is interesting and promising the proposed model is also interesting and achieves a large improvement from baselines weaknesses the proposed method is not compared with other cws models the baseline model bi lstm is proposed in and however these model is proposed not for cws but for pos tagging and ne tagging the description in this paper we employ the state of the art architecture in section is misleading the purpose of experiments in section is unclear in sec the purpose is that investigating datasets in traditional chinese and simplified chinese could help each other however in the experimental setting the model is separately trained on simplified chinese and traditional chinese and the shared parameters are fixed after training on simplified chinese what is expected to fixed shared parameters general discussion the paper should be more interesting if there are more detailed discussion about the datasets that adversarial multi criteria learning does not boost the performance zhiheng huang wei xu and kai yu bidirectional lstm crf models for sequence tagging arxiv preprint arxiv xuezhe ma and eduard hovy end to end sequence labeling via bi directional lstm cnns crf arxiv preprint arxiv,4.0
12.json,the paper proposes a method to recognize time expressions from text it is a simple rule based method which is a strong advantage as an analysis tool since time expression recognition should be a basic process in applications experiments results show that the proposed method outperforms the state of the art rule based methods and machine learning based method for time expression recognition it is great but my concern is generality of the method the rules in the method were designed based on observations of corpora that are used for evaluation as well hence i m afraid that the rules over fit to these corpora similarly domains of these corpora may have affected the rule design there is no statistic nor discussion to show overlaps in time expressions in the observed corpora if it was shown that time expressions in these corpora are mostly overlap the fact should have supported generality of the rules anyway it was better that the experiments have been conducted using a new corpus that was distinct from rule design process in order to show that the proposed method is widely effective,3.0
214.json,this paper proposed a macro discourse structure scheme the authors carried out a pilot study annotating a corpus consisting of news articles from chinese treebank they then built a model to recognize the primary secondary relations and discourse relations joint elaboration sequence background cause result in this corpus the paper is poorly written and i have difficulties to follow it i strongly suggest that the authors should find a native english speaker to carefully proofread the paper regarding the content i have several concerns the logic of the paper is not clear and justifiable what are logical semantics and pragmatic function line i would prefer the authors to define them properly macro discourse structure there are some conflicts of the definition between macro structure and micro structure figure demonstrates the combination of macro discourse structure and micro discourse structure there the micro discourse structure is presented within paragraphs however in the specific example of micro discourse structure shown in figure the micro level discourse structure is beyond the paragraph boundary and captures the discourse relations across paragraphs this kind of micro level discourse structure is indeed similar to the macro structure proposed by the authors in figure and it also genre independent so why can not we just use the structure in figure what is the advantage of macro discourse structure proposed in figure for me it genre dependent and does not provide richer information compared to figure by the way why sentence and sentence are missing in figure is it because they are subtitles but sentence which is a subtitle is present there corpus construction section is not informative enough without a detailed example it hard to know the meaning of discourse topic lead abstract paragraph topics line and you were saying you explore the relationships between micro structure and macro structure but i can not find the correspondent part table is about agreement study the authors claimed its very difficult to achieve high consistence because the judgments of relation and structure are very subjective our measurement data is only taken on the layer of leaf nodes first what are the leaf nodes in the macro level they are paragraphs in the micro level they are edus should we report the agreement study for macro level and micro level separately second it seems for me that the authors only take a subset of data to measure the agreement this does not reflect the overall quality of the whole corpus i e high agreement on the leaf nodes annotation does not ensure that we will get high agreement on the non leaf nodes annotation some other unclear parts in section table discourse structure discourse relation are not clear what is discourse structure and what is discourse relation table amount of macro discourse relations still not clear to me you mean the discourse relations between paragraphs but in figure these relations can exist both between sentences and between paragraphs experiments since the main purpose of the paper is to provide richer discourse structure both on macro and micro level i would expect to see some initial results in this direction the current experiment is not very convincing a no strong baselines b features are not clearly described and motivated c i do not understand why only a sub set of discourse relations from table is chosen to perform the experiment of discourse relation recognition in general i think the paper needs major improvement and currently it is not ready for acceptance,2.0
214.json,this paper presents a unified annotation that combines macrostructures and rst structure in chinese news articles essentially rst structure is adopted for each paragraph and macrostructure is adopted on top of the paragraphs while the view that nuclearity should not depend on the relation label itself but also on the context is appealing i find the paper having major issues in the annotation and the experiments detailed below the notion of primary secondary relationship is advocated much in the paper but later in the paper that it became clear this is essentially the notion of nuclearity extended to macrostructure and making it context dependent instead of relation dependent even then the status nuclear nuclear nuclear satellite satellite nuclear are redefined as new concepts descriptions of established theories in discourse are often incorrect for example there is rich existing work on pragmatic functions of text but it is claimed to be something little studied there are errors in the related work section e g treating rst and the chinese dependency discourse treebank as different as coherence and cohesion the computational approach subsection lacking any reference to work after the performance table of nuclearity classification confusing prior work for sentence level and document level parsing for the annotation i find the macro structure annotation description confusing furthermore statistics for the macro labels are not listed reported the agreement calculation is also problematic the paper stated that our measurement data is only taken on the layer of leaf nodes i do not think this can verify the validity of the annotation there are multiple mentions in the annotation procedure that says prelim experiments show this is a good approach but how finally it is unclear how the kappa values are calculated since this is a structured task is this the same calculation as rst discourse treebank it is said in the paper that nuclearity status closely associates with the relation label itself so what is the baseline performance that just uses the relation label note that some features are not explained at all e g what are hierarchical characteristics the main contribution of the paper is the combination of macro and micro structure however in the experiments only relations at the micro level are evaluated even so only among handpicked ones i do not see how this evaluation can be used to verify the macro side hence supporting the paper the paper contains numerous grammatical errors also there is no text displayed in figure to illustrate the example,1.0
193.json,this paper introduces ucca as a target representation for semantic parsing and also describes a quite successful transition based parser for inference into that representation i liked this paper a lot i believe there is a lot of value simply in the introduction of ucca not new but i believe relatively new to this community which has the potential to spark new thinking about semantic representations of text i also think the model was well thought out while the model itself was fairly derivative of existing transition based schemes the extensions the authors introduced to make the model applicable in this domain were reasonable and well explained at what i believe to be an appropriate level of detail the empirical evaluation was pretty convincing the results were good as compared to several credible baselines and the authors demonstrated this performance in multiple domains my biggest complaint about this paper is the lack of multilingual evaluation especially given that the formalism being experimented with is exactly one that is supposed to be fairly universal i am reasonably sure multilingual ucca corpora exist in fact i think the k leagues corpus used in this paper is one such so it would be good to see results in a language other than english one minor point in section the authors refer to their model as grammarless which strikes me as not quite correct it true that the ucca representation is not derived from linguistic notions of syntax but it still defines a way to construct a compositional abstract symbolic representation of text which to me is precisely a grammar this is clearly a quibble and i do not know why it irked me enough that i feel compelled to address it but it did edited to add thanks to the authors for their response,5.0
557.json,strengths the paper is clearly written and well structured the system newly applied several techniques including global optimization to end to end neural relation extraction and the direct incorporation of the parser representation is interesting the proposed system has achieved the state of the art performance on both ace and conll data sets the authors include several analyses weaknesses the approach is incremental and seems like just a combination of existing methods the improvements on the performance percent points on dev are relatively small and no significance test results are provided general discussion major comments the model employed a recent parser and glove word embeddings how did they affect the relation extraction performance in prediction how did the authors deal with illegal predictions minor comments local optimization is not completely local it considers structural correspondences between incremental decisions so this explanation in the introduction is misleading points in figures and should be connected with straight lines not curves how are entities represented in segment some citations are incomplete kingma et al is accepted to iclr and li et al misses pages,4.0
107.json,this paper presents several weakly supervised methods for developing ners the methods rely on some form of projection from english into another language the overall approach is not new and the individual methods proposed are improvements of existing methods for an acl paper i would have expected more novel approaches one of the contributions of the paper is the data selection scheme the formula used to calculate the quality score is quite straightforward and this is not a bad thing however it is unclear how the thresholds were calculated for table the paper says only that different thresholds were tried was this done on a development set there is no mention of this in the paper the evaluation results show clearly that data selection is very important but one may not know how to tune the parameters for a new data set or a new language pair another contribution of the paper is the combination of the outputs of the two systems developed in the paper i tried hard to understand how it works but the description provided is not clear the paper presents a number of variants for each of the methods proposed does it make sense to combine more than two weakly supervised systems did the authors try anything in this direction it would be good to know a bit more about the types of texts that are in the in house dataset,3.0
384.json,strengths the model if theoretically solid and motivated by formal semantics weaknesses the paper is about is a relation extraction but the majority of literature about taxonomization is not referenced in the paper inter alia flati tiziano vannella daniele pasini tommaso navigli roberto multiwibi the multilingual wikipedia bitaxonomy project soren auer christian bizer georgi kobilarov jens lehmann richard cyganiak and zachary ive dbpedia a nucleus for a web of open data gerard de melo and gerhard weikum menta inducing multilingual taxonomies from wikipedia zornitsa kozareva and eduard h hovy a semi supervised method to learn and construct taxonomies using the web vivi nastase michael strube benjamin boerschinger caecilia zirn and anas elghafari wikinet a very large scale multi lingual concept network simone paolo ponzetto and michael strube deriving a large scale taxonomy from wikipedia simone paolo ponzetto and michael strube taxonomy induction based on a collaboratively built knowledge repository fabian m suchanek gjergji kasneci and gerhard weikum yago a large ontology from wikipedia and wordnet paola velardi stefano faralli and roberto navigli ontolearn reloaded a graph based algorithm for taxonomy induction experiments are poor they only compare against hearst patterns without taking into account the works previously cited general discussion the paper is easy to follow and the supplementary material is also well written and useful however the paper lack of references of is a relation extraction and taxonomization literature the same apply for the experiments in fact no meaningful comparison is performed and the authors not even take into account the existence of other systems more recent than hearst patterns i read authors answers but still i am not convinced that they could not perform more evaluations i understand that they have a solid theoretical motivation but still i think that comparison are very important to asses if the theoretical intuitions of the authors are confirmed also in practice while it true that all the works i suggested as comparison build taxonomies is also true that a comparison is possible considering the edges of a taxonomy anyway considering the detailed author answer and the discussion with the other reviewer i can rise my score to even if i still think that this paper is poor of experiments and does not frame correctly in the is a relation extraction taxonomy building literature,3.0
384.json,strengths this is a novel approach to modeling the compositional structure of complex categories that maintains a set theoretic interpretation of common nouns and modifiers while also permitting a distributional interpretation of head modification the approach is well motivated and clearly defined and the experiments show that show that this decomposed representation can improve upon the hearst pattern derived isa relations upon which it is trained in terms of coverage weaknesses the experiments are encouraging however it would be nice to see roc curves for the new approach alone not in an ensemble with hearst patterns table tells us that modsi increases coverage at the cost of precision and figure tells us that modsi matches hearst pattern precision for the high precision region of the data however neither of these tell us whether the model can distinguish between the high and low precision regions and the roc curves which would tell us this are only available for ensembled models i believe that eqn has an unnecessary w since it is already the case that w d rangle e p o langle discussion overall this is a nice idea that is well described and evaluated i think this paper would be a good addition to acl,4.0
691.json,overview the paper proposes a new model for training sense embeddings grounded in a lexical semantic resource in this case wordnet there is no direct evaluation that the learned sense vectors are meaningful instead the sense vectors are combined back into word embeddings which are evaluated in a downstream task pp attachment prediction strengths pp attachment results seem solid weaknesses whether the sense embeddings are meaningful remains uninvestigated the probabilistic model has some details that are hard to understand are the lambdawi hyperparameters or trained where does rank come from is this taken from the sense ranks in wordnet related work the idea of expressing embeddings of words as a convex combination of sense embeddings has been proposed a number of times previously for instance johansson and nieto piña embedding a semantic network in a word space naacl decomposed word embeddings into ontology grounded sense embeddings based on this idea also in unsupervised sense vector training this idea has been used for instance by arora et al linear algebraic structure of word senses with applications to polysemy minor comments no need to define types and tokens this is standard terminology why is the first lambawi in equation needed if the probability is unnormalized general discussion,2.0
150.json,strengths the authors present a novel adaptation of encoder decoder neural mt using an approach that starts and ends with characters but in between works with representations of morphemes and characters the authors release both their code as well as their final learned models for fr en cs en and en cs this is helpful in validating their work as well as for others looking to replicate and extends this work the system reported appears to produce translation results of reasonable quality even after the first training epoch with continued progress in future epochs the system appears to learn reasonable morphological tokenizations and appears able to handle previously unseen words even nonce words by implicitly backing off to morphemes weaknesses in the paper the authors do not explicitly state which wmt test and dev sets their results are reported on this is problematic for readers wishing to compare the reported results to existing work for example the results at matrix statmt org the only way this reviewer found to get this information was to look in the readme of the code supplement which indicates that the test set was newstest and the dev test was newstest this should have been explicitly described in the paper the instructions given in the software readme are ok but not great the training and testing sections each could be enhanced with explicit examples of how to run the respective commands the software itself should respond to a help flag which it currently does not the paper describes a level architecture but the diagram in figure appears to show fewer than layers what is going on the caption should be more explicit and if this figure is not showing all of the layers then there should be a figure somewhere even if it in an appendix showing all of the layers the results show comparison to other character based neural systems but do not show state of the art results for other types of mt system wmt and matrix statmt org has reported results for other systems on these datasets and it appears that the state of the art is much higher than any of the results reported in this paper that should be acknowledged and ideally should be discussed there are a handful of minor english disfluencies misspellings and minor latex issues such as reverse quotation marks these should be corrected general discussion paper is a nice contribution to the existing literature on character based neural mt,4.0
150.json,strengths in general the paper is well structured and clear it is possible to follow most of the explanation the ideas presented are original and the results obtained are quite interesting weaknesses i have some doubts about the interpretation of the results in addition i think that some of the claims regarding the capability of the method proposed to learn morphology are not propperly backed by scientific evidence general discussion this paper explores a complex architecture for character level neural machine translation nmt the proposed architecture extends a classical encoder decoder architecture by adding a new deep word encoding layer capable of encoding the character level input into sub word representations of the source language sentence in the same way a deep word decoding layer is added to the output to transform the target language sub word representations into a character sequence as the final output of the nmt system the objective of such architecture is to take advantage of the benefits of character level nmt reduction of the size of the vocabulary and flexibility to deal with unseen words and at the same time improving the performance of the whole system by using an intermediate representation of sub words to reduce the size of the input sequence of characters in addition the authors claim that their deep word encoding model is able to learn morphology better than other state of the art approaches i have some concerns regarding the evaluation the authors compare their approach to other state of the art systems taking into account two parameters training time and bleu score however i do not clearly see the advantage of the model proposed dcnmt in front of other approaches such as bpechar the difference between both approaches as regards bleu score is very small in cs en and in en cs and it is hard to say if one of them is outperforming the other one without statistical significance information has statistical significance been evaluated as regards the training time it is worth mentioning that the bpechar for cs en takes days less than dcnmt for en cs training time is not provided why not and for en fr bpechar is not evaluated i think that a more complete comparison with this system should be carried out to prove the advantages of the model proposed my second concern is on the section where authors start claiming that they investigated about the ability of their system to learn morphology however the section only contains a examples and some comments on them even though these examples are very well chosen and explained in a very didactic way it is worth noting that no experiments or formal evaluation seem to have been carried out to support the claims of the authors i would definitely encourage authors to extend this very interesting part of the paper that could even become a different paper itself on the other hand this section does not seem to be a critical point of the paper so for the current work i may suggest just to move this section to an appendix and soften some of the claims done regarding the capabilities of the system to learn morphology other comments doubts and suggestions there are many acronyms that are used but are not defined such as lstm hgru cnn or pca or which are defined after starting to use them such as rnn or bpe even though some of these acronyms are well known in the field of deep learning i would encourage the authors to defined them to improve clearness the concept of energy is mentioned for the first time in section even though the explanation provided is enough at that point it would be nice to refresh the idea of energy in section where it is used several times and providing some hints about how to interpret it a high energy on a character would be indicating that the current morpheme should be split at that point in addition the concept of peak in figure is not described when the acronym bpe is defined capital letters are used but then for the rest of mentions it is lower cased is there a reason for this i am not sure if it is necessary to say that no monolingual corpus is used in section it seems that there is something wrong with figure a since the colours for the energy values are not shown for every character in table the results for model chung et al for cs en were not taken from the papers since they are not reported if the authors computed these results by themselves as it seems they should mention it i would not say that french is morphologically poor but rather that it is not that rich as slavic languages such as czech why a link is provided for wmt training corpora but not for wmt several references are incomplete typos is the bilingual parallel corpora provided are the bilingual parallel corpora provided luong and manning uses luong and manning use hgru it is hgru it is coveres covers both consists of two layer rnn each has both consist of two layer rnn each have the only difference between cnmt and dcnmt is cnmt the only difference between cnmt and dcnmt is that cnmt,3.0
516.json,strengths the paper offers a natural and useful extension to recent efforts in interactive topic modeling namely by allowing human annotators to provide multiple anchor words to machine induced topics the paper is well organized and the combination of synthetic and user experiments make for a strong paper weaknesses the paper is fairly limited in scope in terms of the interactive topic model approaches it compares against i am willing to accept this since they do make reference to most of them and explain that these other approaches are not necessarily fast enough for interactive experimentation or not conducive to the types of interaction being considered with an anchoring interface some level of empirical support for these claims would have been nice though it would also have been nice to see experiments on more than one data set newsgroups which is now sort of beaten to death general discussion in general this is a strong paper that appears to offer an incremental but novel and practical contribution to interactive topic modeling the authors made the effort to vet several variants of the approach in simulated experiments and to conduct fairly exhaustive quantitative analyses of both simulated and user experiments using a variety of metrics that measure different facets of topic quality,4.0
516.json,strengths clear description of methods and evaluation successfully employs and interprets a variety of evaluations solid demonstration of practicality of technique in real world interactive topic modeling weaknesses missing related work on anchor words evaluation on newsgroups is not ideal theoretical contribution itself is small general discussion the authors propose a new method of interactive user specification of topics called tandem anchors the approach leverages the anchor words algorithm a matrix factorization approach to learning topic models by replacing the individual anchors inferred from the gram schmidt algorithm with constructed anchor pseudowords created by combining the sparse vector representations of multiple words that for a topic facet the authors determine that the use of a harmonic mean function to construct pseudowords is optimal by demonstrating that classification accuracy of document topic distribution vectors using these anchors produces the most improvement over gram schmidt they also demonstrate that their work is faster than existing interactive methods allowing interactive iteration and show in a user study that the multiword anchors are easier and more effective for users generally i like this contribution a lot it is a straightforward modification of an existing algorithm that actually produces a sizable benefit in an interactive setting i appreciated the authors efforts to evaluate their method on a variety of scales while i think the technical contribution in itself is relatively small a strategy to assemble pseudowords based on topic facets the thoroughness of the evaluation merited having it be a full paper instead of a short paper it would have been nice to see more ideas as to how to build these facets in the absence of convenient sources like category titles in newsgroups or when initializing a topic model for interactive learning one frustration i had with this paper is that i find evaluation on newsgroups to not be great for topic modeling the documents are widely different lengths preprocessing matters a lot users have trouble making sense of many of the messages and naive bag of words models beat topic models by a substantial margin classification tasks are useful shorthand for how well a topic model corresponds to meaningful distinctions in the text by topic a task like classifying news articles by section or reviews by the class of the subject of the review might be more appropriate it would also have been nice to see a use case that better appealed to a common expressed application of topic models which is the exploration of a corpus there were a number of comparisons i think were missing as the paper contains little reference to work since the original proposal of the anchor word model in addition to comparing against standard gram schmidt it would have been good to see the method from lee et al low dimensional embeddings for interpretable anchor based topic inference i also would have liked to have seen references to nguyen et al evaluating regularized anchor words and nguyen et al is your anchor going up or down fast and accurate supervised topic models both of which provide useful insights into the anchor selection process i had some smaller notes entire dataset i m not quite sure what you mean here i think you are claiming that it takes too long to do one pass my assumption would have been you would use only a subset of the data to retrain the model instead of a full sweep so it would be good to clarify what you mean any reason you did not consider the and operator or element wise max they seem to correspond to the ideas of union and intersection from the or operator and element wise min and it wasn t clear to me why the ones you chose were better options usenet should be capitalized why fewer than as that is a pretty aggressive boundary also did you remove headers footers and or quotes from the messages i would have liked to see a bit more explanation of what this tells us about confusion using tandem anchors overall i think this paper is a meaningful contribution to interactive topic modeling that i would like to see available for people outside the machine learning community to investigate classify and test hypotheses about their corpora post response i appreciate the thoughtful responses of the authors to my questions i would maintain that for some of the complimentary related work that it useful to compare to non interactive work even if it does something different,4.0
239.json,strengths this paper proposed an interesting and important metric for evaluating the quality of word embeddings which is the data efficiency when it is used in other supervised tasks another interesting point in the paper is that the authors separated out three questions whether supervised task offers more insights to evaluate embedding quality how stable is the ranking vs labeled data set size the benefit to linear vs non linear models overall the authors presented comprehensive experiments to answer those questions and the results see quite interesting to know for the research community weaknesses the overall result is not very useful for ml practioners in this field because it merely confirms what has been known or suspected i e it depends on the task at hand the labeled data set size the type of the model etc so the result in this paper is not very actionable the reviewer noted that this comprehensive analysis deepens the understanding of this topic general discussion the paper presentation can be improved specifically the order of the figures tables in the paper should match the order they are mentioned in the papers right now their order seems quite random several typos l etc please use a spell checker equation is not very useful and its exposition looks strange it can be removed and leave just the text explanations l mentions the appendix but it is not available in the paper missing citation for the public skip gram data set in l the claim in l is too strong it must be explained more clearly i e when it is useful and when it is not the observation in l is very interesting and important it will be good to follow up on this and provide concrete evidence or example from some embedding some visualization may help too in l should provide examples of such specialized word embeddings and how they are different than the general purpose embedding figuer is too small to read,3.0
444.json,this paper studies how to properly evaluate systems that produce ghostwriting of rap lyrics the authors present manual evaluation along three key aspects fluency coherence and style matching they also introduce automatic metrics that consider uniqueness via maximum training similarity and stylistic similarity via rhyme density i can find some interesting analysis and discussion in the paper the way for manually evaluating style matching especially makes sense to me there also exist a few important concerns for me i am not convinced about the appropriateness of only doing fluency coherence ratings at line level the authors mention that they are following wu but i find that work actually studying a different setting of hip hop lyrical challenges and responses which should be treated at line level in nature while in this work a full verse consists of multiple lines that normally should be topically and structurally coherent currently i cannot see any reason why not to evaluate fluency coherence for a verse as a whole also i do not reckon that one should count so much on automatic metrics if the main goal is to generate similar yet unique lyrics for uniqueness evaluation the calculations are performed on verse level however many rappers may only produce lyrics within only a few specific topics or themes if a system can only extract lines from different verses presumably we might also get a fluent coherent verse with low verse level similarity score but we can hardly claim that the system generalizes well for stylistic similarity with the specified artist i do not think rhyme density can say it all as it is position independent and therefore may not be enough to reflect the full information of style of an artist it does not seem that the automatic metrics have been verified to be well correlated with corresponding real manual ratings on uniqueness or stylistic matching i also wonder if one needs to evaluate semantic information commonly expressed by a specified rapper as well other than only caring about rhythm meanwhile i understand the motivation for this study is the lack of sound evaluation methodology however i still find one statement particularly weird our methodology produces a continuous numeric score for the whole verse enabling better comparison is enabling comparisons really more important than making slightly vague but more reliable more convincing judgements minor issue incorrect quotation marks in line,2.0
501.json,the paper proposes a task of selecting the most appropriate textual description for a given scene image from a list of similar options it also proposes couple of baseline models an evaluation metrics and human evaluation score strengths the paper is well written and well structured it is clear with its contributions and well supports them by empirical evidence so the paper is very easy to read the paper is well motivated a method of selecting the most appropriate caption given a list of misleading candidates will benefit other image caption understanding models by acting as a post generation re ranking method weaknesses i am not sure if the proposed algorithm for decoys generation is effective which as a consequence puts the paper on questions for each target caption the algorithm basically picks out those with similar representation and surface form but do not belong to the same image but a fundamentally issue with this approach is not belonging to the image a does not mean not appropriate to describe image a especially when the representation and surface form are close so the ground truth labels might not be valid as we can see in figure the generated decoys are either too far from the target to be a good decoy giraffe vs elephant or fair substitutes for the target small boy playing kites vs boy flies a kite thus i am afraid that the dataset generated with this algorithm can not train a model to really go beyond key word recognition which was claimed as contribution in this paper as shown in figure most decoys can be filtered by key word mismatch giraffe vs elephant pan vs bread frisbee vs kite etc and when they can not be separated by key word match they look very tempting to be a correct option furthermore it is interesting that humans only do correctly on on a sampled test set does it mean that those examples are really too hard even for human to correctly classify or are some of the decoys in fact good enough to be the target substitute or even better so that human choose them over ground truth targets general discussion i think this is a well written paper with clear motivation and substantial experiments the major issue is that the data generating algorithm and the generated dataset do not seem helpful for the motivation this in turn makes the experimental conclusions less convincing so i tend to reject this paper unless my concerns can be fully addressed in rebuttal,2.0
501.json,strengths the dmc task seems like a good test of understanding language and vision i like that the task has a clear evaluation metric the failure of the caption generation model on the dmc task is quite interesting this result further demonstrates that these models are good language models but not as good at capturing the semantics of the image weaknesses the experiments are missing a key baseline a state of the art vqa model trained with only a yes no label vocabulary i would have liked more details on the human performance experiments how many of the of incorrectly predicted images are because the captions are genuinely ambiguous could the data be further cleaned up to yield an even higher human accuracy general discussion my concern with this paper is that the data set may prove to be easy or gameable in some way the authors can address this concern by running a suite of strong baselines on their data set and demonstrating their accuracies i am not convinced by the current set of experiments because the chosen neural network architectures appear quite different from the state of the art architectures in similar tasks which typically rely on attention mechanisms over the image another nice addition to this paper would be an analysis of the data set how many tokens does the correct caption share with distractors on average what kind of understanding is necessary to distinguish between the correct and incorrect captions i think this kind of analysis really helps the reader understand why this task is worthwhile relative to the many other similar tasks the data generation technique is quite simple and would not really qualify as a significant contribution unless it worked surprisingly well notes i could not find a description of the ffnn architecture in either the paper or the supplementary material it looks like some kind of convolutional network over the tokens but the details are very unclear i am also confused about how the veqseq ffnn model is applied to both classification and caption generation is the loglikelihood of the caption combined with the ffnn prediction during classification is the ffnn score incorporated during caption generation the fact that the caption generation model performs statistically significantly worse than random chance needs some explanation how is this possible this description of the neural network is hard to understand the final paragraph of the section makes it clear however consider starting the section with it,2.0
805.json,strengths originality of the core evaluation measure good accuracy of proposed similarity measure and large number and diversity of datasets for evaluation weaknesses some typos line to design of a new to design a new line figure figure line among the the top among the top line figure should be introduced within the article body line the dataset was contains the dataset contains line table table a tensorflow should be replaced by textflow imprecisions features computation accuracy of lemma pos or wordnet synset should be detailed in the paper and it should be discussed if it impacts the general similarity accuracy evaluation or not the neural networks are said to be implemented in python but the code is not said to be available to be able to repeat the experiment the training and evaluation sets are said to be shared but it is not said how on demand under license to be able to repeat the experiment general discussion,4.0
741.json,this paper presents a graph based approach for producing sense disambiguated synonym sets from a collection of undisambiguated synonym sets the authors evaluate their approach by inducing these synonym sets from wiktionary and from a collection of russian dictionaries and then comparing pairwise synonymy relations using precision recall and f against wordnet and babelnet for the english synonym sets or ruthes and yet another russnet for the russian synonym sets the paper is very well written and structured the experiments and evaluations or at least the prose parts are very easy to follow the methodology is sensible and the analysis of the results cogent i was happy to observe that the objections i had when reading the paper such as the mismatch in vocabulary between the synonym dictionaries and gold standards ended up being resolved or at least addressed in the final pages the one thing about the paper that concerns me is that the authors do not seem to have properly understood the previous work which undercuts the stated motivation for this paper the first instance of this misunderstanding is in the paragraph beginning on line where omegawiki is lumped in with wiktionary and wikipedia in a discussion of resources that are not formally structured and that contain undisambiguated synonyms in reality omegawiki is distinguished from the other two resources by using a formal structure a relational database based on word senses rather than orthographic forms translations synonyms and other semantic annotations in omegawiki are therefore unambiguous the second and more serious misunderstanding comes in the three paragraphs beginning on lines and here the paper claims that both babelnet and uby rely on english wordnet as a pivot for mapping of existing resources and criticizes this mapping as being error prone though it is true that babelnet uses wordnet as a pivot uby does not uby is basically a general purpose specification for the representation of lexical semantic resources and of links between them it exists independently of any given lexical semantic resource including wordnet and of any given alignment between resources including ones based on similarity of dictionary definitions or cross lingual links its maintainers have made available various databases adhering to the uby spec these contain a variety of lexical semantic resources which have been aligned with a variety of different methods a given uby database can be queried for synsets but uby itself does not generate those synsets users are free to produce their own databases by importing whatever lexical semantic resources and alignments thereof are best suited to their purposes the three criticisms of uby on lines to are therefore entirely misplaced in fact i think at least one of the criticisms is not appropriate even with respect to babelnet the authors claim that watset may be superior to babelnet because babelnet mapping and use of machine translation are error prone the implication here is that watset method is error free or at least significantly less error prone this is a very grandiose claim that i do not believe is supported by what the authors ought to have known in advance about their similarity based sense linking algorithms and graph clustering algorithms let alone by the results of their study i think this criticism ought to be moderated also i think the third criticism babelnet reliance on wordnet as a pivot somewhat misses the point surely the most important issue to highlight is not the fact that the pivot is english but rather that its synsets are already manually sense annotated i think the last paragraph of and the first two paragraphs of should be extensively revised they should focus on the general problem of generating synsets by sense level alignment translation of lsrs see gurevych et al for a survey rather than particularly on babelnet which uses certain particular methods and uby which does not use any particular methods but can aggregate the results of existing ones it may be helpful to point out somewhere that although alignment translation methods can be used to produce synsets or to enrich existing ones that not always an explicit goal of the process sometimes it just a serendipitous if noisy side effect of aligning translating resources with differing granularities finally at several points in the paper lines the synsets of twsi of jobimtext are criticized for including too many words that are hypernyms co hypnomyms etc instead of synonyms but is this problem really unique to twsi and jobimtext that is how often do hypernyms co hypernyms etc appear in the output of watset we can get only a very vague idea of this from comparing tables and which analyze only synonym relations if watset really is better at filtering out words with other semantic relations then it would be nice to see some quantitative evidence of this some further relatively minor points that should nonetheless be fixed lines to the sentence about kiselev et al seems rather useless why bother mentioning their analysis if you are not going to tell us what they found line it took me a long time to figure out how wat has any relation to discover the correct word sense i suppose this is supposed to be a pun on what maybe it would have been better to call the approach whatset or at least consider rewording the sentence to better explain the pun figure is practically illegible owing to the microscopic font please increase the text size similarly tables and are too small to read comfortably please use a larger font to save space consider abbreviating the headers p r f and maybe reporting scores in the range instead of which will eliminate a leading from each column lines wiktionary is a moving target to help others replicate or compare against your work please indicate the date of the wiktionary database dump you used throughout the constant switching between times and computer modern is distracting the root of this problem is a longstanding design flaw in the acl latex style file but it exacerbated by the authors decision to occasionally set numbers in math mode even in running text please fix this by removing usepackage times from the preamble and replacing it with either usepackage newtxtext usepackage newtxmath or usepackage mathptmx references i gurevych j eckle kohler and m matuschek linked lexical knowledge bases foundations and applications volume of synthesis lectures on human language technologies chapter linking algorithms pages morgan claypool i have read the author response,4.0
741.json,strengths the paper proposes a new method for word sense induction from synonymy dictionaries the method presents a conceptual improvement over existing ones and demonstrates robust performance in empirical evaluation the evaluation was done thoroughly using a number of benchmarks and strong baseline methods weaknesses just a couple of small points i would like to see more discussion of the nature of the evaluation first one observes that all models scores are relatively low under f is there room for much improvement or is there a natural ceiling of performance due to the nature of the task the authors discuss lexical sparsity of the input data but i wonder how much of the performance gap this sparsity accounts for second i would also like to see some discussion of the evaluation metric chosen it is known that word senses can be analyzed at different levels of granularity which can naturally affect the scores of any system another point is that it is not clear how the authors obtained vectors for word senses that they used in if the senses are only determined after this step and anyway senses are not marked in the input corpora general discussion i recommend the paper for presentation at the acl meeting solid work,4.0
350.json,strengths improves over the state of the art method might be applicable for other domains weaknesses not much novelty in method not quite clear if data set is general enough for other domains general discussion this paper describes a rule based method for generating additional weakly labeled data for event extraction the method has three main stages first it uses freebase to find important slot fillers for matching sentences in wikipedia using all slot fillers is too stringent resulting in too few matches next it uses framenet to to improve reliability of labeling trigger verbs and to find nominal triggers lastly it uses a multi instance learning to deal with the noisily generated training data what i like about this paper is that it improves over the state of the art on a non trival benchmark the rules involved do not seem too obfuscated so i think it might be useful for the practitioner who is interested to improve ie systems for other domains on the other hand some some manual effort is still needed for example for mapping freebase event types to ace event types as written in section line this also makes it difficult for future work to calibrate apple to apple against this paper apart from this the method also does not seem too novel other comments i am also concern with the generalizability of this method to other domains section line says that event types are selected from freebase how are they selected what is the coverage on the event types in the ace data the paper is generally well written although i have some suggestions for improvement section line uses arguments liked time location if you mean roles or arguments or maybe you want to use actual realizations of time and location as examples there are minor typos for e g line is missing a that but this is not a major concern i have for this paper,3.0
33.json,strengths innovative idea sentiment through regularization experiments appear to be done well from a technical point of view useful in depth analysis of the model weaknesses very close to distant supervision mostly poorly informed baselines general discussion this paper presents an extension of the vanilla lstm model that incorporates sentiment information through regularization the introduction presents the key claims of the paper previous cnn approaches are bad when no phrase level supervision is present phrase level annotation is expensive the contribution of this paper is instead a simple model using other linguistic resources the related work section provides a good review of sentiment literature however there is no mention of previous attempts at linguistic regularization e g yog the explanation of the regularizers in section is rather lengthy and repetitive the listing on p could very well be merged with the respective subsection notation in this section is inconsistent and generally hard to follow most notably p is sometimes used with a subscript and sometimes with a superscript the parameter beta is never explicitly mentioned in the text it is not entirely clear to me what constitutes a position t in the terminology of the paper t is a parameter to the lstm output so it seems to be the index of a sentence thus t is the preceding sentence and pt is the prediction for this sentence however the description of the regularizers talks about preceding words not sentences but still uses my assumption here is that pt is actually overloaded and may either mean the sentiment of a sentence or a word however this should be made clearer in the text one dangerous issue in this paper is that the authors tread a fine line between regularization and distant supervision in their work the problem here is that there are many other ways to integrate lexical information from about polarity negation information etc into a model e g by putting the information into the features the authors compare against a re run or re implementation of teng et al nscl model here it would be important to know whether the authors used the same lexicons as in their own work if this is not the case the comparison is not fair also i do not understand why the authors cannot run nscl on the mr dataset when they have access to an implementation of the model would this not just be a matter of swapping the datasets the remaining baselines do not appear to be using lexical information which makes them rather poor i would very much like to see a vanilla lstm run where lexical information is simply appended to the word vectors the authors end the paper with some helpful analysis of the models these experiments show that the model indeed learns intensification and negation to some extent in these experiments it would be interesting to know how the model behaves with out of vocabulary words with respect to the lexicons does the model learn beyond memorization and does generalization happen for words that the model has not seen in training minor remark here the figures and tables are too small to be read in print the paper is mostly well written apart from the points noted above it could benefit from some proofreading as there are some grammatical errors and typos left in particular the beginning of the abstract is hard to read overall the paper pursues a reasonable line of research the largest potential issue i see is a somewhat shaky comparison to related work this could be fixed by including some stronger baselines in the final model for me it would be crucial to establish whether comparability is given in the experiments and i hope that the authors can shed some light on this in their response yog http www aclweb org anthology p update after author response thank you for clarifying the concerns about the experimental setup nscl i do now believe that the comparison is with teng et al is fair lstm good to know that you did this however this is a crucial part of the paper as it stands the baselines are weak marginal improvement is still too vague better would be an open comparison including a significance test oov i understand how the model is defined but what is the effect on oov words this would make for a much more interesting additional experiment than the current regularization experiments,3.0
777.json,strengths the deviation between vocal users and average users is an interesting discovery that could be applied as a way to identify different types of users weaknesses i see it as an initial work on a new topic that should be expanded in the future a possible comparison between matrix factorization and similar topics in distributional semantics e g latent semantic analysis would be useful general discussion in this paper the authors describe an approach for modeling the stance sentiment of twitter users about topics in particular they address the task of inter topic preferences modeling this task consists of measuring the degree to which the stances about different topics are mutually related this work is claimed to advance state of the art in this task since previous works were case studies while the proposed one is about unlimited topics on real world data the adopted approach consists of the following steps a set of linguistic patterns was manually created and through them a large number of tweets expressing stance towards various topics was collected next the texts were expressed as triples containing user topic and evaluation the relationships represented by the tuples were arranged as a sparse matrix after matrix factorization a low rank approximation was performed the optimal rank was identified as the definition of cosine similarity is used to measure the similarity between topics and thus detect latent preferences not represented in the original sparse matrix finally cosine similarity is also used to detect inter topic preferences a preliminary empirical evaluation shows that the model predicts missing topics preferences moreover predicted inter topic preferences moderately correlate with the corresponding values from a crowdsourced gold standard collection of preferences according to the overview discussed in the related work section there are no previous systems to be compared in the latter task i e prediction of inter topic preferences and for this reason it is promising i listed some specific comments below rows and high quality what makes them high quality if not properly defined i would remove all the occurrences of high quality in the paper row and caption of figure i would remove the term generic row this section collect we collected or this section explains how we collected row ironies irony row i support tpp since the procedure can detect various patterns such as to a or this is a maybe the author should explain that all possible patterns containing the topic are collected and next manually filtered rows and unuseful useless row including are including row of or it are not topics but i guess terms retrieved by mistakes as topics rows i would remove the first sentence and start with twitter user rows i like the procedure used to find the optimal k in previous works this number is often assumed while it is useful to find it empirically row let is it call,3.0
331.json,strengths this paper presents an approach to creating concept maps using crowdsourcing the general ideas are interesting and the main contribution lies in the collection of the dataset as such i imagine that the dataset will be a valuable resource for further research in this field clearly a lot of effort has gone into this work weaknesses overall i felt this paper a bit overstated in placed as an example the authors claim a new crowdsourcing scheme as one of their contributions this claims is quite strong though and it reads more like the authors are applying best practice in crowdsourcing to their work this isn t a novel methods then it s rather a well thought and sound application of existing knowledge similarly the authors claim that they develop and present a new corpus this seems true and i can see how a lot of effort was invested in its preparation but then section reveals that actually this is based on an existing dataset this is more a criticism of the presentation than the work though general discussion where do the summary sentences come from for the crowdsource task aren t they still quite subjective where do the clusters come from are they part of the tacb dataset in expert annotators are used to create the gold standard concept maps more information is needed in this section i would say as it seems to be quite crucial how were they trained what made them experts,3.0
433.json,strengths nice results nice data set not so much work on creole like languages especially english weaknesses a global feeling of deja vu a lot of similar techniques have been applied to other domains other ressource low languages replace word embeddings by clusters and neural models by whatever was in fashion years ago and we can find more or less the same applied to urdu or out of domain parsing i liked this paper though but i would have appreciated the authors to highlight more their contributions and position their work better within the literature general discussion this paper presents a set of experiments designed a to show the effectiveness of a neural parser in a scarce resource scenario and b to introduce a new data set of creole english from singapour called singlish while this data set is relatively small annotated sentences used with k unlabeled sentences for word embeddings induction the authors manage to present respectable results via interesting approach even though using features from relatively close languages are not unknown from the parsing community see all the line of work on parsing urdu hindi on arabic dialect using msa based parsers and so on assuming we can see singlish as an extreme of out of domain english and given all the set of experiments i wonder why the authors didn t try the classical technique on domain adaptation namely training with uden of the singlish within a cross fold experiment just so we can have another interesting baseline with and without word embeddings with bi lingual embeddings if enough parallel data is available i think that paper is interesting but i really would have appreciated more positioning regarding all previous work in parsing low ressources languages and extreme domain adaptation a table presenting some results for irish and other very small treebanks would be nice also how come the iaa is so low regarding the labeled relations note after reading the authors answer thanks for your clarifications especially for redoing the iaa evaluation i raised my recommendation to i hope it will get accepted,4.0
433.json,the authors construct a new dataset of singaporean english singlish sentences annotated with universal dependencies they show that they can improve the performance of a pos tagger and a dependency parser on the singlish corpus by integrating english syntactic knowledge via a neural stacking model strengths singlish is a low resource language the nlp community needs more data for low resource languages and the dataset accompanying this paper is a useful contribution there is also relatively little nlp research on creoles and the potential of using transfer learning to analyze creoles and this paper makes a nice contribution in that area the experimental setup used by the authors is clear they provide convincing evidence that incorporating knowledge from an english trained parser into a singlish parser outperforms both an english only parser and a singlish only parser on the singlish data they also provide a good overview of the relevant differences between english and singlish for the purposes of syntactic parser and a useful analysis of how different parsing models handle these singlish specific constructions weaknesses there are three main issues i see with this paper there is insufficient comparison to the ud annotation of non english languages many of the constructions they bring up as specific to singlish are also present in other ud languages and the annotations should ideally be consistent between singlish and these languages i would like to see an analysis on the impact of training data size a central claim of this paper is that using english data can improve performance on a low resource language like singlish how much more singlish data would be needed before the english data became unnecessary what happens if you train a single pos dep parsing model on the concatenated ud web and singlish datasets this is much simpler than incorporating neural stacking the case for neural stacking is stronger if it can outperform this baseline general discussion line pos taggers and dependency parsers perform poorly on such singlish texts based on our observations be more clear that you will quantify this later as such it seems a bit hand wavy line comparison to neural network models for multi lingual parsing as far as i can tell you do not directly try the approach of mapping singlish and english word embeddings into the same embedding space line introduction of ud eng at this point it is appropriate to point out that the singlish data is also web data so the domain matches ud eng line all borrowed words are annotated according to their original meanings does this mean they have the same pos as in the language from which they were borrowed or the pos of their usage in singlish figure standard english glosses would be very useful in understanding the constructions and checking the correctness of the ud relations used line topic prominence you should compare with the dislocated label in ud from the ud paper the dislocated relation captures preposed topics and postposed elements the syntax you are describing sounds similar to a topic comment style syntax if it is different then you should make it clear how line second noun phrases used to modify the predicate with the presence of a preposition is regarded as a nsubj nominal subject here i need a gloss to determine if this analysis makes sense if the phrase is really being used to modify the predicate then this should not be nsubj ud makes a distinction between core arguments nsubj dobj etc and modifiers if this is a case of modification then you should use one of the modification relations not a core argument relation should clarify the language here line in ud eng standards predicative be is the only verb used as a copula which often depends on its complement to avoid copular head this is an explicit decision made in ud to increase parallelism with non copular languages e g singlish you should call this out i think the rest of the discussion of copula handling is not necessary line np deletion noun phrase np deletion often results in null subjects or objects this is common in other languages zero anaphora in e g spanish italian russian japanese would be good to point this out and also point to how this is dealt with in ud in those languages i believe the same way you handle it ling subj verb inversion is common in interrogatives in other languages fue marta al supermercado did marta go to the supermarket tag questions are present in english though perhaps are not as frequent you should make sure that your analysis is consistent with these languages sec data selection and annotation the way you chose the singlish sentences of course an english parser will do poorly they are chosen to be disimilar to sentences an english parser has seen before but do you have a sense of how a standard english parser does overall on singlish if it is not filtered this way how common are sentences with out of vocabulary terms or the constructions you discussed in a language will not necessarily capture unusual sentence structure particularly around long distance dependencies did you investigate whether this method did a good job of capturing sentences with the grammatical differences to english you discussed in section line the inter annotator agreement has an unlabeled attachment score uas of and a labeled attachment score las of what s the agreement on pos tags is this integrated with las note that in silveira et al which produced ud eng they measured inter annotator agreement on a per token basis why the discrepancy pos tagging and dep parsing sections for both pos tagging and dep parsing i d like to see some analysis on the effect of training set size e g how much more singlish data would be needed to train a pos tagger dep parser entirely on singlish and get the same accuracy as the stacked model what happens if you just concatenate the datasets e g train a model on a hybrid dataset of en and singlish and see what the result is line typo pre rained should be pre trained the neural stacking model leads to the biggest improvement over nearly all categories except for a slightly lower yet competitive performance on np deletion cases seems that the english data strongly biases the parser to expect an explicit subj obj you could try deleting subj obj from some english sentences to improve performance on this construction,4.0
68.json,strengths the paper broadens the applicability of readability scores to an additional language and produces a well validated applicability score for vietnamese weaknesses the greatest weaknesses with respect to acl are that readability scores are of limited interest within the field of computational linguistics while they are somewhat useful in educational and public communication fields their impact on the progress of computational linguistics is limited a minor weakness is in the writing the paper has numerous minor grammatical errors although the discussion compares the performance of the pds and pdw features from the previous work it is unclear how poorly the previous readability measures perform relevant to the one developed here for practical purposes general discussion this paper would be a stronger candidate for inclusion if the corpus and importantly labels developed were released it could be used more widely than the development of scalar readability metrics and would enable e g investigation of application of more powerful feature selection methods,2.0
68.json,strengths new dataset nlp on resource poor language weaknesses incomplete related work references no comparison with recent methods and approaches lack of technical contribution weak experiments general discussion in this paper the authors present a simple formula for readability assessment of vietnamese text using a combination of features such as word count sentence length etc they train a simple regression model to estimate the readability of the documents one of the major weaknesses of the paper its lack of technical contribution while early work in readability assessment employed simple methods like the one outlined in this paper recent work on predicting readability uses more robust methods that rely on language models for instance eg http www cl cam ac uk mx readabilitybea pdf http www personal umich edu kevynct pubs itl readability invited article v camera pdf a comparison with such methods could be a useful contribution and make the paper stronger especially if simple methods such as those outlined in this paper can compete with more complicated models baseline experiments with smog gunning fog index etc should also be presented as well as the other vietnamese metrics and datasets that the authors cite another problem is that while previous readability indices were more selective and classified content into granular levels corresponding to grade levels for instance the authors use a coarse classification scheme to label documents as easy medium and hard which makes the metric uninteresting also why not use a classifier the work is probably a bit too pre mature and suffers from significant weaknesses to be accepted at this stage i would encourage the authors to incorporate suggested feedback to make it better the paper also has quite a few grammatical errors which should be addressed in any future submission,1.0
68.json,the authors present a new formula for assessing readability of vietnamese texts the formula is developed based on a multiple regression analysis with three features furthermore the authors have developed and annotated a new text corpus with three readability classes easy middle hard research on languages other than english is interesting and important especially when it comes to low resource languages therefore the corpus might be a nice additional resource for research but it seems that the authors will not publish it is that right however i do not think the paper is convincing in its current shape or will influence future research here are my reasons the authors provide no reasons why there is a need for delevoping a new formula for readability assessments given that there already exist two formulas for vietnamese with almost the same features what are the disadvantages of those formulas and why is the new formula presented in this paper better in general the experimental section lacks comparisons with previous work and analysis of results the authors claim that the accuracy of their formula on their corpus is good and can be applied in practice what would be the accuracy of other formulas that already exist and what are the pros and cons of those existing formulas compared to the new one as mentioned before an analysis of results is missing e g which word sentence lengths number of difficult words are considered as easy middle hard by their model a few examples how their formula could be applied in a practical application would be nice as well the related work section is rather a background section since it only presents previously published formulas what i am missing is a more general discussion of related work there are some papers that might be interesting for that e g dubay the principles of readability or rabin determining difficulty levels of text written in languages other than english since vietnamese is syllable based and not word based i am wondering how the authors get words in their study do they use a particular approach for merging syllables and if yes which approach do they use and what is the accuracy of the approach all in all the content of the paper experiments comparisons analysis discussion related work is not enough for a long paper additional remarks the language needs improvements equations the usage of parentheses and multiplying operators is inconsistent related works section the usage of capitalized first letters is inconsistent,1.0
130.json,strengths this paper proposes to apply nlp to speech transcripts narratives and descriptions in order to identify patients with mci mild cognitive impairment icd code f the authors claim that they were able to distinguish between healthy control participants and patients with mci lines however in the conclusion lines they say that accuracy ranging from to means that it is not easy to distinguish between healthy subjects and those with cognitive impairments so the paper beginning is more optimistic than the conclusion but anyway the message is encouraging and the reader becomes curious to see more details about what has been actually done the corpus submitted in the dataset is constructed for healthy patients and control participants only and it is non understandable for people who do not speak portuguese it would be good to incorporate more technological details in the article and probably to include at least one example of a short transcript that is translated to english and eventually a part of a sample network with embeddings for this transcript weaknesses the paper starts with a detailed introduction and review of relevant work some of the cited references are more or less nlp background so they can be omitted e g salton in section other references are not directly related to the topic e g sentiment classification and pedestrian detection in images lines and they can be omitted too in general lines section can be shortened as well etc etc the suggestion is to compress the first pages focusing the review strictly on the paper topic and consider the technological innovation in more detail incl samples of english translations of the abcd and or cindarela narratives the relatively short narratives in portuguese esp in abcd dataset open the question how the similarities between words have been found in order to construct word embeddings in lines the authors explain that they generate word level networks from continuous word representations what is the source for learning the continuous word representations are these the datasets abcd cinderella only or external corpora were used in lines it is written that sub word level n grams networks were used to generate word embeddings again what is the source for the training are we sure that the two kinds of networks together provide better accuracy and what are the out of vocabulary words line from where they come general discussion it is important to study how nlp can help to discover cognitive impairments from this perspective the paper is interesting another interesting aspect is that it deals with nlp for portuguese and it is important to explain how one computes embeddings for a language with relatively fewer resources compared to english the text needs revision shortening sections compressing and adding more explanations about the experiments some clarification about the nurc sp n ef and d transcription norms can be given technical comments line as it a lightweight shouldn t this be as in a lightweight line pln nlp line out of cookie out of the cookie some words are repeated twice table row column lines the doi number is the same as the one at lines the link behind the title at lines points to the next paper in the list,3.0
130.json,strengths this paper explores is problem of identifying patients with mild cognitive impairment mci by analyzing speech transcripts available from three different datasets a graph based method leveraging co occurrence information between words found in transcripts is described features are encoded using different characteristics of the graph lexical syntactic properties and many others results are reported using fold cross validation using a number of classifiers different models exhibit different performance across the three datasets this work targets a well defined problem and uses appropriate datasets weaknesses the paper suffers from several drawbacks the paper is hard to read due to incorrect usage of english the current manuscript would benefit a lot from a review grammar and spellings the main machine learning problem being addressed is poorly described what was a single instance of classification it seems every transcripts was classified as mci or no mci if this is the case the dataset descriptions should describe the numbers at a transcript level tables and should describe the data not the study that produced the transcripts the age of the patients is irrelevant for the classification task a lot of text pages is consumed in simply describing the datasets with details that do not affect the end classification task also i was unsure why numbers did not add up for e g in section the text says people were involved but the total number of males and females in table are less than what is the motivation behind enriching the graph why not represent each word by a node in the graph and connect them by the similarity between their vectors irrespective of co occurrence the datsets are from a biomedical domain no domain specific tools have been leveraged since dataset class distribution is unclear it is unclear to determine if accuracy is a good measure for evaluation in either case since it is a binary classification task f would have been a desirable metric results are reported unto decimal places on very small datasets transcripts without statistical tests over increments therefore it is unclear if the gains are significant,2.0
130.json,the paper describes a novel application of mostly existing representations features sets and methods namely detecting mild cognitive impairment mci in speech narratives the nature of the problem datasets and domain are thoroughly described while missing some detail the proposed solution and experiments sound reasonable overall i found the study interesting and informative in terms of drawbacks the paper needs some considerable editing to improve readability details on some key concepts appear to be missing for example details on the multi view learning used are omitted the set of linguistic features needs to be clarified it is not entirely clear what datasets were used to generate the word embeddings presumably the datasets described in the paper which appear to be too small for that purpose it is also not clear why disfluencies filled pauses false starts repetitions etc were removed from the dataset one might suggest that they are important features in the context of mci it is also not clear why the most popular tf idf weighting scheme was not used for the bow classifications in addition tests for significance are not provided to substantiate the conclusions from the experiments lastly the related work is described a bit superficially detailed comments are provided below abstract the abstract needs to be shortened see detailed notes below lines need rephrasing however mci disfluencies produce agrammatical speech impacting in parsing results impacting the parsing results lines you mean correct grammatical errors in transcripts manually it is not clear why this should be performed doesn t the fact that grammatical errors are present indicate mci only after reading the introduction and related work sections it becomes clear what you mean perhaps include some examples of disfluencies lines need rephrasing as it a lightweight and language independent representation lines need rephrasing it is not immediately clear which exactly are the datasets maybe the other two cinderella and line a year not sure what exactly per year means line needs rephrasing lines it is not obvious why bow will also have problems with disfluencies some explanation will be helpful lines what do you mean by the best scenario line in public corpora of dementia bank a link or citation to dementia bank will be helpful line a link or citation describing the picnic picture of the western aphasia battery will be helpful line an explanation as to what the wml subtest is will be helpful line is missing citations lines this appears to be the core of the related work and it is described a bit superficially for example it will be helpful to know precisely what methods were used to achieve these tasks and how they compare to this study line please refer to the conference citation guidelines i believe they are something along these lines aluisio et al used line the definition of pln appears to be missing lines could you some rephrasing lemmatization is not necessarily a last step in text pre processing and normalization in fact there are also additional common normalization preprocessing steps omitted lines did you create the word embeddings using the mci datasets or external datasets line consisted of consist of lines need to be rewritten manually segmented of the dementiabank and cinderella what do you mean by segmented segmented into sentences why weren t all datasets automatically segmented abcd is not defined you itemized the datasets in i and ii but subsequently you refer to dataset which is a bit confusing maybe one could explicitly name the datasets as opposed to referring to them as first second third table caption the demographic information is present but there are no any additional statistics of the dataset as described lines it is not clear why filled pauses false starts repetitions etc were removed one might suggest that they are important features in the context of mci line multidisciplinary team with psychiatrists consisting of psychiatrists lines a link or citation describing the transcription norms will be helpful section it is not clear what dataset was used to generate the word embeddings line the shortest path as defined in feature section linguistic features needs to be significantly expanded for clarity also please check the conference guidelines regarding additional pages supplementary material line in this work term frequency was in this work term frequency was also why not tf idf as it seems to be the most common weighting scheme the sentence on lines needs to be rewritten line what do you mean by the threshold parameter the threshold for the word embedding cosine distance line is missing a period section classification algorithms details on exactly what scheme of multi view learning was used are entirely omitted statistical significance of result differences is not provided,3.0
87.json,strengths nicely written and understandable clearly organized targeted answering of research questions based on different experiments weaknesses minimal novelty the first sentence heuristic has been in the summarization literature for many years this work essentially applies this heuristic evolved in the keyword extraction setting this is not to say that the work is trivial it is just not really novel lack of state of the art very recent methods the experiment on the system evaluation vs state of the art systems simply uses strong baselines even though the experiment answers the question does it perform better than baselines i am not confident it illustrates that the system performs better than the current state of the art this somewhat reduces the value of the paper general discussion overall the paper is good and i propose that it be published and presented on the other hand i would propose that the authors position themselves and the system performance with respect to martinez romo juan lourdes araujo and andres duque fernandez semgraph extracting keyphrases following a novel semantic graph based approach journal of the association for information science and technology with which the work holds remarkable resemblance in some points le tho thi ngoc minh le nguyen and akira shimazu unsupervised keyphrase extraction introducing new kinds of words to keyphrases australasian joint conference on artificial intelligence springer international publishing,4.0
649.json,strengths this paper proposes an evaluation metric for automatically evaluating the quality of dialogue responses in non task oriented dialogue the metric operates on continuous vector space representations obtained by using rnns and it comprises two components one that compares the context and the given response and the other that compares a reference response and the given response the comparisons are conducted by means of dot product after projecting the response into corresponding context and reference response spaces these projection matrices are learned by minimizing the squared error between the model predictions and human annotations i think this work gives a remarkable step forward towards the evaluation of non task oriented dialogue systems different from previous works in this area where pure semantic similarity was pursued the authors are going beyond pure semantic similarity in a very elegant manner by learning projection matrices that transform the response vector into both context and reference space representations i am very curious on how your projection matrices m and n differ from the original identity initialization after training the models i think the paper will be more valuable if further discussion on this is introduced rather than focusing so much on resulting correlations weaknesses the paper also leaves lots questions related to the implementation for instance it is not clear whether the human scores used to train and evaluate the system were single amt annotations or the resulting average of few annotations also it is not clear how the dataset was split into train dev test and whether n fold cross validation was conducted or not also it would be nice to better explain why in table correlation for adem related scores are presented for the validation and test sets while for the other scores they are presented for the full dataset and test set the section on pre training with vhred is also very clumsy and confusing probably it is better to give less technical details but a better high level explanation of the pre training strategy and its advantages general discussion there are many obvious cases where these metrics fail as they are often incapable of considering the semantic similarity between responses see figure be careful with statements like this one this is not a problem of semantic similarity opposite to it the problem is that completely different semantic cues might constitute pragmatically valid responses then semantic similarity itself is not enough to evaluate a dialogue system response dialogue system response evaluation must go beyond semantics this is actually what your m and n matrices are helping to do an accurate model that can evaluate dialogue response quality automatically what could be considered an automatic turing test the original intention of turing test was to be a proxy to identify define intelligent behaviour it actually proposes a test on intelligence based on an intelligent machine capability to imitate human behaviour in such a way that it would be difficult for a common human to distinguish between such a machine responses and actual human responses it is of course related to dialogue system performance but i think it is not correct to say that automatically evaluating dialogue response quality is an automatic turing test actually the title itself towards an automatic turing test is somehow misleading the simplifying assumption that a good chatbot is one whose responses are scored highly on appropriateness by human evaluators this is certainly the correct angle to introduce the problem of non task oriented dialogue systems rather than turing test regarding this there has been related work you might like to take a look at as well as to make reference to in the wochat workshop series see the shared task description and corresponding annotation guidelines in the discussion session and has has been used and it has been used,4.0
654.json,general discussion this paper extends zhou and xu acl approach to semantic role labeling based on deep bilstms in addition to applying recent best practice techniques leading to further quantitative improvements the authors provide an insightful qualitative analysis of their results the paper is well written and has a clear structure the authors provide a comprehensive overview of related work and compare results to a representative set of other srl models that hace been applied on the same data sets i found the paper to be interesting and convincing it is a welcome research contribution that not only shows that nns work well but also analyzes merits and shortcomings of an end to end learning approach strengths strong model insightful discussion error analysis weaknesses little to no insights regarding the srl task itself,4.0
654.json,this paper presents a new state of the art deep learning model for semantic role labeling srl that is a natural extension of the previous state of the art system zhou and xu with recent best practices for initialization and regularization in the deep learning literature the model gives a relative error reduction which is a big gain on this task the paper also gives in depth empirical analyses to reveal the strengths and the remaining issues that give a quite valuable information to the researchers in this field even though i understand that the improvement of point in f measure is a quite meaningful result from the engineering point of view i think the main contribution of the paper is on the extensive analysis in the experiment section and a further in depth investigation on analysis section the detailed analyses shown in section are performed in a quite reasonable way and give both comparable results in srl literature and novel information such as relation between accuracies in syntactic parsing and srl this type of analysis had often been omitted in recent papers however it is definitely important for further improvement the paper is well written and well structured i really enjoyed the paper and would like to see it accepted,4.0
382.json,strengths this paper presents a step in the direction of developing more challenging corpora for training sentence planners in data to text nlg which is an important and timely direction weaknesses it is unclear whether the work reported in this paper represents a substantial advance over perez beltrachini et al method for selecting content the authors do not directly compare the present paper to that one it appears that the main novelty of this paper is the additional analysis which is however rather superficial it is good that the authors report a comparison of how an nnlg baseline fares on this corpus in comparison to that of wen et al however the bleu scores in wen et al paper appear to be much much higher suggesting that this nnlg baseline is not sufficient for an informative comparison general discussion the authors need to more clearly articulate why this paper should count as a substantial advance over what has been published already by perez beltrachini et al and why the nnlg baseline should be taken seriously in contrast to lrec it is not so common for acl to publish a main session paper on a corpus development methodology in the absence of some new results of a system making use of the corpus the paper would also be stronger if it included an analysis of the syntactic constructions in the two corpora thereby more directly bolstering the case that the new corpus is more complex the exact details of how the number of different path shapes are determined should also be included and ideally associated with the syntactic constructions finally the authors should note the limitation that their method does nothing to include richer discourse relations such as contrast consequence background etc which have long been central to nlg in this respect the corpora described by walker et al jair and isard lrec are more interesting and should be discussed in comparison to the method here references marilyn walker amanda stent françois mairesse and rashmi prasad individual and domain adaptation in sentence planning for dialogue journal of artificial intelligence research jair amy isard the methodius corpus of rhetorical discourse structures and generated texts proceedings of the tenth conference on language resources and evaluation lrec portorož slovenia may addendum following author response thank you for the informative response as the response offers crucial clarifications i have raised my overall rating re the comparison to perez beltrachini et al while this is perhaps more important to the pc than to the eventual readers of the paper it still seems to this reviewer that the advance over this paper could have been made much clearer while it is true that perez beltrachini et al just cover content selection this is the key to how this dataset differs from that of wen et al there does not really seem to be much to the complete methodology of constructing the data to text dataset beyond obvious crowd sourcing steps to the extent these steps are innovative or especially crucial this should be highlighted here it is interesting that of the crowd sourced texts were rejected during the verification step related to reviewer concerns it would be interesting to see some examples of what was rejected and to what extent this indicates higher quality texts than those in wen et al dataset beyond that the main point is really that collecting the crowd sourced texts makes it possible to make the comparisons with the wen et al corpus at both the data and text levels which this reviewer can see is crucial to the whole picture re the nnlg baseline the issue is that the relative difference between the performance of this baseline on the two corpora could disappear if wen et al substantially higher scoring method were employed the assumption that this relative difference would remain even with fancier methods should be made explicit e g by acknowledging the issue in a footnote even with this limitation the comparison does still strike this reviewer as a useful component of the overall comparison between the datasets re whether a paper about dataset creation should be able to get into acl without system results though this indeed not unprecedented the key issue is perhaps how novel and important the dataset is likely to be and here this reviewer acknowledges the importance of the dataset in comparison to existing ones even if the key advance is in the already published content selection work finally this reviewer concurs with reviewer about the need to clarify the role of domain dependence and what it means to be wide coverage in the final version of the paper if accepted,4.0
382.json,strengths potentially valuable resource paper makes some good points weaknesses awareness of related work see below is what the authors are trying to do domain independent microplanning even possible see below are the crowdsourced texts appropriate see below general discussion this is an interesting paper which presents a potentially valuable resource and i in many ways i am sympathetic to it however i have some high level concerns which are not addressed in the paper perhaps the authors can address these in their response i was a bit surprised by the constant reference and comparison to wen which is a fairly obscure paper i have not previously heard of it would be better if the authors justified their work by comparison to well known corpora such as the ones they list in section also there are many other nlg projects that looked at microplanning issue when verbalising dbpedia indeed there was a workshop in with many papers on nlg and dbpedia https webnlg sciencesconf org and http aclweb org anthology w w see also previous work by duboue and kutlak i would like to see less of a fixation on wen and more awareness of other work on nlg and dbpedia microplanning tends to be very domain genre dependent for example pronouns are used much more often in novels than in aircraft maintenance manuals this is why so much work has focused on domain dependent resources so there are some real questions about whether it is possible even in theory to train a wide coverage microplanner the authors do not discuss this at all they need to show they are aware of this concern i would be concerned about the quality of the texts obtained from crowdsourcing a lot of people dont write very well so it is not at all clear to me that gathering example texts from random crowdsourcers is going to produce a good corpus for training microplanners remember that the ultimate goal of microplanning is to produce texts that are easy to read imitating human writers which is what this paper does along with most learning approaches to microplanning makes sense if we are confident that the human writers have produced well written easy to read texts which is a reasonable assumption if the writers are professional journalists for example but a very dubious one if the writers are random crowdsourcers from a presentational perspective the authors should ensure that all text in their paper meets the acl font size criteria some of the text in fig and especially fig is tiny and very difficult to read this text should be the same font size as the text in the body of the paper i will initially rate this paper as borderline i look forward to seeing the author response and will adjust my rating accordingly,3.0
117.json,strengths the paper addresses a relevant topic learning the mapping between natural language and kb relations in the context of qa where we have only partial information for one of the arguments and in the case of having a very large number of possible target relations the proposal consists in a new method to combine two different representations of the input text a word level representation i e with segmentation of the target relation names and also the input text and relations as a single token i e without segmentation of relation names nor input text it seems that the main contribution in qa is the ability to re rank entities after the entity linking step results show an improvement compared with the state of the art weaknesses the approach has been evaluated in a limited dataset general discussion i think section fits better inside related work so the can become section with the proposal thus new section can be splitted more properly,4.0
588.json,contents this paper proposes a new task and provides a dataset the task is to predict blanked out named entities from a text with the help of an external definitional resource in particular freebase these named entities are typically rare that is they do not appear often in the corpus such that it is not possible to train models specifically for each entity the paper argues convincingly that this is an important setting to explore along with multiple baselines two neural network models for the problem are presented that make use of the external resource one of which also accumulates evidence across contexts in the same text strengths the collection of desiderata for the task is well chosen to advance the field predicting blanked out named entities a task that has already shown to be interesting in the cnn daily mail dataset but in a way that makes the task hard for language models and the focus on rare entities should drive the field towards more interesting models the collection of baselines is well chosen to show that neither a nn model without external knowledge nor a simple cosine similarity based model with external knowledge can do the task well the two main models are chosen well the text is clear and well argued weaknesses i was a bit puzzled by the fact that using larger contexts beyond the sentences with blanks in them did not help the models after all you were in a way using additional context in the hierenc model which accumulates knowledge from other contexts there are two possible explanations either the sentences with blanks in them are across the board more informative for the task than the sentences without this is the explanation suggested in the paper but it seems a bit unintuitive that this should be the case another possible explanation is that the way that you were using additional context in hierenc using the temporal network is much more useful than by enlarging individual contexts c and feeding that larger c into the recurrent network do you think that that could be what is going on general discussion i particularly like the task and the data that this paper proposes this setup can really drive the field forward i think this in my mind is the main contribution,4.0
588.json,general discussion the paper deals with the task of predicting missing entities in a given context using the freebase definitions of those entities the authors highlight the importance of the problem given that the entities come from a long tailed distribution they use popular sequence encoders to encode the context and the definitions of candidate entities and score them based on their similarity with the context while it is clear that the task is indeed important and the dataset may be useful as a benchmark the approach has some serious weaknesses and the evaluation leaves some questions unanswered strengths the proposed task requires encoding external knowledge and the associated dataset may serve as a good benchmark for evaluating hybrid nlu systems weaknesses all the models evaluated except the best performing model hierenc do not have access to contextual information beyond a sentence this does not seem sufficient to predict a missing entity it is unclear whether any attempts at coreference and anaphora resolution have been made it would generally help to see how well humans perform at the same task the choice of predictors used in all models is unusual it is unclear why similarity between context embedding and the definition of the entity is a good indicator of the goodness of the entity as a filler the description of hierenc is unclear from what i understand each input hi to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary this does not seem to be a good idea since presumably only one of those instantiations is correct this would most likely introduce a lot of noise the results are not very informative given that this is a rare entity prediction problem it would help to look at type level accuracies and analyze how the accuracies of the proposed models vary with frequencies of entities questions to the authors an important assumption being made is that de are good replacements for entity embeddings was this assumption tested have you tried building a classifier that just takes hi e as inputs i have read the authors responses i still think the task dataset could benefit from human evaluation this task can potentially be a good benchmark for nlu systems if we know how difficult the task is the results presented in the paper are not indicative of this due to the reasons stated above hence i am not changing my scores,2.0
79.json,this paper considers the problem of kb completion and proposes itransf for this purpose unlike stranse that assigns each relation an independent matrix this paper proposes to share the parameters between different relations a model is proposed where a tensor d is constructed that contains various relational matrices as its slices and a selectional vector alpha is used to select a subset of relevant relational matrix for composing a particular semantic relation the paper then discuss a technique to make alpha sparse experimental results on two standard benchmark datasets shows the superiority of itransf over prior proposals the paper is overall well written and the experimental results are good however i have several concerns regarding this work that i hope the authors will answer in their response just by arranging relational matrices in a tensor and selecting or more appropriately considering a linearly weighted sum of the relational matrices does not ensure any information sharing between different relational matrices this would have been the case if you had performed some of a tensor decomposition and projected the different slices relational matrices into some common lower dimensional core tensor it is not clear why this approach was not taken despite the motivation to share information between different relational matrices the two requirements a to share information across different relational matrices and b make the attention vectors sparse are some what contradictory if the attention vector is truly sparse and has many zeros then information will not flow into those slices during optimisation the authors spend a lot of space discussing techniques for computing sparse attention vectors the authors mention in page that ell regularisation did not work in their preliminary experiments however no experimental results are shown for ell regularisation nor they explain why ell is not suitable for this task to this reviewer it appears as an obvious baseline to try especially given the ease of optimisation you use ell instead and get into np hard optimisations because of it then you propose a technique and a rather crude approximation in the end to solve it all that trouble could be spared if ell was used the vector alpha is performing a selection or a weighing over the slices of d it is slightly misleading to call this as attention as it is a term used in nlp for a more different type of models see attention model used in machine translation it is not clear why you need to initialise the optimisation by pre trained embeddings from transe why cannot you simply randomly initialise the embeddings as done in transe and then update them it is not fair to compare against transe if you use transe as your initial point learning the association between semantic relations is an idea that has been used in related problems in nlp such as relational similarity measurement turney jair and relation adaptation bollegala et al ijcai it would be good to put the current work with respect to such prior proposals in nlp for modelling inter relational correlation similarity thanks for providing feedback i have read it,3.0
96.json,strengths a new dataset would be useful for other researchers in this area an algorithm with sentiment words based machine translation is proposed to interpret sarcasm tweets weaknesses do not provide detailed statistics of constructed dataset integrating sentiment word clustering with machine translation techniques only is simple and straightforward novelty may be a challenging issue general discussion overall this paper is well written the experiments are conducted carefully and the analysis is reasonable i offer some comments as follows according to data collection process each tweet should be annotated five times how to determine which one is regarded as gold standard for measure performance the mt technique moses is well known but it may not be a good baseline another mt technique rnn should be put together for comparison differ from most work focuses on sarcasm detection the research topic is interesting it attempts to interpret sarcasm for reflecting semantics,3.0
96.json,this paper focuses on interpreting sarcasm written in twitter identifying sentiment words and then using a machine translation engine to find an equivalent not sarcastic tweet edit thank you for your answers i appreaciate it i added one line commenting about it strengths among the positive aspects of your work i would like to mention the parallel corpus you presented i think it will be very useful for other researchers in the area for identifying and interpreting sarcasm in social media an important contribution is also the attempt to evaluate the parallel corpora using existing measures such as the ones used in mt tasks but also because you used human judgements to evaluate the corpora in aspects fluency adequacy and equivalent sentiment room for improvement tackling the problem of interpretation as a monolingual machine translations task is interesting while i do appreciate the intent to compare the mt with two architectures i think that due the relatively small dataset needed for rnn used it was predictable that the neural interpretation is performing worse than moses interpretation you came to the same conclusion after seeing the results in table in addition to comparing with this architecture i would have liked to see other configuration of the mt used with moses or at least you should provide some explanation of why you use the configuration described in lines through to me this choice is not justified thank you for your response i understand it is difficult to write down all the details but i hope you include a line with some of your answer in the paper i believe this could add valuable information when you presented sing it is clear that you evaluate some of its components beforehand i e the mt but other important components are not evaluated particularly the clustering you used of positive and negative words while you did said you used k means as a clustering algorithm it is not clear to me why you wanted to create clusters with words why not test with other number of k instead of and for positive and negative words respectively also you could try another algorithm beside kmeans for instance the star clustering algorithm aslam et al that do not require a k parameter thanks for clarifying you say that sign searches the tweet for sentiment words if it found one it changes it for the cluster id that contain that word i am assuming that there is not a limit for the number of sentiment words found and the mt decides by itself how many sentiment words to change for example for the tweet provided in section constantly being irritated anxious and depressed is a great feeling the clustering stage of sign should do something like constantly being cluster i cluster j and cluster k is a cluster h feeling is that correct if not please explain what sign do thanks for clarifying minor comments in line section you said sign context s interpretations differ from the original sarcastic tweet in of the cases which come closer to the in the gold standard human interpretations this means that of the human interpretations are the same as the original tweet do you have any idea why is that in section line you could eliminate the footnote by adding its cluster id or its cluster number references aslam javed a pelekhov ekaterina and rus daniela the star clustering algorithm for static and dynamic information organization journal of graph algorithms and applications http eudml org doc,4.0
727.json,strengths an interesting task the paper is very clearly written easy to follow the created data set may be useful for other researchers a detailed analysis of the performance of the model weaknesses no method adapted from related work for a result comparison some explanations about the uniqueness of the task and discussion on limitations of previous research for solving this problem can be added to emphasize the research contributions further general discussion the paper presents supervised and weakly supervised models for frame classification in tweets predicate rules are generated exploiting language based and twitter behavior based signals which are then supplied to the probabilistic soft logic framework to build classification models political frames are classified in tweets in a multi label classification task the experimental results demonstrate the benefit of the predicates created using the behavior based signals please find my more specific comments below the paper should have a discussion on how frame classification differs from stance classification are they both under the same umbrella but with different levels of granularity the paper will benefit from adding a brief discussion on how exactly the transition from long congressional speech to short tweets adds to the challenges of the task for example does past research rely on any specific cross sentential features that do not apply to tweets consider adapting the method of a frame classification work on congressional speech or a stance classification work on any text to the extent possible due to its limitations on twitter data to compare with the results of this work it seems weakly supervised and unsupervised these two terms have been interchangeably used in the paper if this is not the case please clarify in author response i believe weakly supervised is the more technically correct terminology under the setup of this work that should be used consistently throughout the initial unlabeled data may not have been labeled by human annotators but the classification does use weak or noisy labels of some sort and the keywords do come from experts the presented method does not use completely unsupervised data as traditional unsupervised methods such as clustering topic models or word embeddings would the calculated kappa may not be a straightforward reflection of the difficulty of frame classification for tweets lines viewing it as a proof is a rather strong claim the kappa here merely represents the annotation difficulty disagreement many factors can contribute to a low value such as poorly written annotation guidelines selection of a biased annotator lack of annotator training etc on top of any difficulty of frame classification for tweets by human annotators which the authors actually intend to relate to cohen s kappa is strong enough for this task in my opinion to rely on the annotated labels eq lines will ignore any contextual information such as negation or conditional hypothetical statements impacting the contributing word when calculating similarity of a frame and a tweet will this have any effect on the frame prediction model did the authors consider using models that can determine similarity with larger text units such as perhaps using skip thought vectors or vector compositionality methods an ideal set up would exclude the annotated data from calculating statistics used to select the top n bi tri grams line mentions entire tweets data set has been used otherwise statistics from any test fold or labeled data in the weakly supervised setup still leaks into the selection process i do not think this would have made any difference in the current selection of the bi tri grams or results as the size of the unlabeled data is much larger but would have constituted a cleaner experimental setup please add precision and recall results in table minor please double check any rules for footnote placements concerning placement before or after the punctuation,4.0
727.json,strengths the authors address a very challenging nuanced problem in political discourse reporting a relatively high degree of success the task of political framing detection may be of interest to the acl community the paper is very well written weaknesses quantitative results are given only for the author psl model and not compared against any traditional baseline classification algorithms making it unclear to what degree their model is necessary poor comparison with alternative approaches makes it difficult to know what to take away from the paper the qualitative investigation is interesting but the chosen visualizations are difficult to make sense of and add little to the discussion perhaps it would make sense to collapse across individual politicians to create a clearer visual general discussion the submission is well written and covers a topic which may be of interest to the acl community at the same time it lacks proper quantitative baselines for comparison minor comments line a year should be provided for the boydstun et al citation it s unclear to me why similar behavior time of tweeting should necessarily be indicative of similar framing and no citation was given to support this assumption in the model the related work goes over quite a number of areas but glosses over the work most clearly related e g psl models and political discourse work while spending too much time mentioning work that is only tangential e g unsupervised models using twitter data section it is unclear whether wordvec was trained on their dataset or if they used pre trained embeddings the authors give no intuition behind why unigrams are used to predict frames while bigrams trigrams are used to predict party the authors note that temporal similarity worked best with one hour chunks but make no mention of how important this assumption is to their results if the authors are unable to provide full results for this work it would still be worthwhile to give the reader a sense of what performance would look like if the time window were widened table caption should make it clear these are f scores as well as clarifying how the f score is weighted e g micro macro this should also be made clear in the evaluation metrics section on page,3.0
818.json,summary this paper aims to learn common sense relationships between object categories e g comparative size weight strength rigidness and speed from unstructured text the key insight of the paper is to leverage the correlation of action verbs to these comparative relations e g x throw y x larger y strengths the paper proposes a novel method to address an important problem of mining common sense attribute relations from text weaknesses i would have liked to see more examples of objects pairs action verbs and predicted attribute relations what are some interesting action verbs and corresponding attributes relations the paper also lacks analysis discussion on what kind of mistakes their model makes the number of object pairs in the dataset is very small how many distinct object categories are there how scalable is this approach to larger number of object pairs it a bit unclear how the frame similarity factors and attributes similarity factors are selected general discussion suggestions the authors should discuss the following work and compare against mining attributes attribute distributions directly and then getting a comparative measure what are the advantages offered by the proposed method compared to a more direct approach extraction and approximation of numerical attributes from the web dmitry davidov ari rappoport acl minor typos in the abstract line the authors mention ix dimensions but in the paper there is only five line above the above line object first first line more skimp a smaller line selctional selectional,4.0
818.json,the paper studies an interesting problem of extracting relative physical knowledge of actions and objects from unstructured text by inference over a factor graph that consists of two types of subgraphs action graph and object graph the paper stems from the key insight common knowledge about physical world influences the way people talk even though it is rarely explicitly stated strengths the paper tries to solve an interesting and challenging problem the problem is hard due to reporting bias and the key insight approach in the paper is inspiring the model is innovative and clearly described and the idea of handling text sparsity with semantic similarity factors is also appropriate the empirical evidence well supports the effectiveness of the model compared to other baselines the paper is well written with informative visualization except for some minor errors like six dimensions in abstract but five everywhere else weaknesses the benefits and drawbacks of model components are still somehow under discussed and hard to tell with the limited quantitative results in the paper for example is there any inherent discrepancy between cross verb frame similarity within verb frame similarity and action object compatibility frames of a throw b and c thrown by d share a verb primitive throw so should it infer c d by within verb if a b is given on the other side frames of c thrown by d and e kicked by f share the frame xxx by so if f e is known is d c inferred how does the current model deal with such discrepancy the paper might be better if it has more qualitative analysis and more evidence also needs to be provided to gauge how difficult the task dataset is for example are the incorrectly classified actions objects also ambiguous for human on what types of actions objects does the model tend to make mistakes is the verb with more frame types usually harder than others for the model more interestingly how are the mistakes made are they incorrectly enforced by any proposed semantic similarity i think more analysis on the model components and qualitative results may inspire more general framework for this task general discussion after author response after reading the response i tend to keep my current rating and accept this paper the response well addresses my concerns and i tend to believe that necessary background and experimental analysis can be added given some re organization of the paper and one extra page as it is not hard before author response i think this paper is in general solid and interesting i tend to accept it but it would be better if the questions above can be answered,4.0
376.json,strengths useful modeling contribution and potentially useful annotated data for an important problem event extraction for the relationships between countries as expressed in news text weaknesses many points are not explained well in the paper general discussion this work tackles an important and interesting event extraction problem identifying positive and negative interactions between pairs of countries in the world or rather between actors affiliated with countries the primary contribution is an application of supervised structured neural network models for sentence level event relation extraction while previous work has examined tasks in the overall area to my knowledge there has not been any publicly availble sentence level annotated data for the problem the authors here make a contribution as well by annotating some data included with the submission if it is released it could be useful for future researchers in this area the proposed models which seem to be an application of various tree structured recursive neural network models demonstrate a nice performance increase compared to a fairly convincing broad set of baselines if we are able to trust them see below the paper also presents a manual evaluation of the inferred time series from a news corpus which is nice to see i am torn about this paper the problem is a terrific one and the application of the recursive models seems like a contribution to this problem unfortunately many aspects of the models experimentation and evaluation are not explained very well the same work with a more carefully written paper could be really great some notes baselines need more explanation for example the sentiment lexicon is not explained for the svm the lstm classifier is left highly unspecified l there are multiple different architectures to use an lstm for classification how was it trained is there a reference for the approach are the authors using off the shelf code in which case please refer and cite which would also make it easier for the reader to understand and replicate if necessary it would be impossible to replicate based on the two line explanation here the supplied code does not seem to include the baselines just the recursive nn models it great the authors supplied code for part of the system so i do not want to penalize them for missing it but this is relevant since the paper itself has so few details on the baselines that they could not really be replicated based on the explanation in the paper how were the recursive nn models trained the visualization section is only a minor contribution there is not really any innovation or findings about what works or does not work here line by line l unclear why is this problem difficult compared to what also the sentence is somewhat ungrammatical l the trees are binarized but how footnote the tensor version needs citation to explain what is being referred to l how are non state verbs defined does the definition of event word s here come from any particular previous work that motivates it please refer to something appropriate or related footnote of course the collapsed form does not work because the authors are not using dependency labels the point of stanford collapsed form is to remove prepositions from the dependeny path and instead incorporate them into the labels l how are the cameo tabari categories mapped to positive and negative entries is performance sensitive to this mapping it seems like a hard task there are hundreds of those cameo categories did the authors consider using the goldstein scaling which has been used in political science as well as the cited work by o connor et al or is it bad to use for some reason l what is the sentiment lexicon and why is it appropriate for the task l not clear we failed at finding an alpha meeting the requirements for the ft model what does that mean what are the requirements what did the authors do in their attempt to find it l l precision and recall values are based on neg and pos classes what does this mean so there a x contingency table of gold and predicted pos neu neg classes but this sentence leaves ambiguous how precision and recall are calculated from this information aggregations this seems fine though fairly ad hoc is this temporal smoothing function a standard one there not much justification for it especially given something simpler like a fixed window average could have been used visualizations this seems pretty ad hoc without much justification for the choices the graph visualization shown does not seem to illustrate much should also discuss related work in d spatial visualization of country country relationships by peter hoff and michael ward l unions of countries is not a well defined concept mmybe the authors mean international organizations l how were these strong and weak peaks selected in particular how were they chosen if there were more than such peaks l this needs more examples or explanation of what it means to judge the polarity of a peak what does it look like if the algorithm is wrong how hard was this to assess what was agreement rate if that can be judged l the authors claim gerrish and o connor et al have a different purpose and outputs than the authors work that not right both those works try to do both extract time series or other statistical information about the polarity of the relationships between countries and also extract topical keywords to explain aspects of the relationships the paper here is only concerned with and less concerned with but certainly the previous work addresses it fine to not address but this last sentence seems like a pretty odd statement that raises the question gerrish and o connor both conduct evaluations with an external database of country relations developed in political science mid military interstate disputes why do not the authors of this work do this evaluation as well there are various weaknesses of the mid data but the evaluation approach needs to be discussed or justified,2.0
726.json,this paper proposes an approach to learning a semantic parser using an encoder decoder neural architecture with the distinguishing feature that the semantic output is full sql queries the method is evaluated over two standard datasets geo and atis as well as a novel dataset relating to document search this is a solid well executed paper which takes a relatively well established technique in the form of an encoder decoder with some trimmings e g data augmentation through paraphrasing and uses it to generate sql queries with the purported advantage that sql queries are more expressive than other semantic formalisms commonly used in the literature and can be edited by untrained crowd workers familiar with sql but not semantic parsing i buy that sql is more expressive than the standard semantic formalisms but then again were there really any queries in any of your three datasets where the standard formalisms are unable to capture the full semantics of the query i e are they really the best datasets to showcase the expressivity of sql also in terms of what your model learns what fraction of sql does it actually use i e how much of the extra expressivity in sql is your model able to capture also does it have biases in terms of the style of queries that it tends to generate that is i wanted to get a better sense of not just the potential of sql but the actuality of what your model is able to capture and the need for extra expressivity relative to the datasets you experiment over somewhat related to this at the start of section you assert that it harder to directly produce sql you never actually show this and this seems to be more a statement of the expressivity of sql than anything else which returns me to the question of how much of sql is the model actually generating next i would really have liked to have seen more discussion of the types of sql queries your model generates esp for the second part of the evaluation over the scholar dataset specifically when the query is ill formed in what ways is it ill formed when a crowd worker is required to post edit the query how much effort does that take them equally how correct are the crowd workers at constructing sql queries are they always able to construct perfect queries experience would suggest that this is a big ask in a similar vein to having more error analysis in the paper i would have liked to have seen agreement numbers between annotators esp for incomplete result queries which seems to rely heavily on pre existing knowledge on the part of the annotator and therefore be highly subjective overall what the paper achieves is impressive and the paper is well executed i just wanted to get more insights into the true ability of the model to generate sql and a better sense of what subset of the language it generates a couple of other minor things l non linguists can write sql why refer to non linguists here most linguists would not be able to write sql queries either way i think the point you are trying to make is simply that annotators without specific training in the semantic translation of queries are able to perform the task l is is it is l it not clear what an anonymized utterance is at this point of the paper l am i right in saying that you paraphrase only single words at a time presumably you exclude entities from paraphrasing l introduce a visual variable in terms of line type to differentiate the three lines for those viewing in grayscale there are various inconsistencies in the references casing issues e g freebase ccg wang et al is missing critical publication details and there is an in in for wong and mooney,4.0
419.json,the paper introduces a simple and effective method for morphological paradigm completion in low resource settings the method uses a character based seqseq model trained on a mix of examples in two languages a resource poor language and a closely related resource rich language each training example is annotated with a paradigm properties and a language id thus the model enables transfer learning across languages when the two languages share common characters and common paradigms while the proposed multi lingual solution is not novel similar architectures have been explored in syntax language modeling and mt the novelty of this paper is to apply the approach to morphology experimental results show substantial improvements over monolingual baselines and include a very thorough analysis of the impact of language similarities on the quality of results the paper is interesting very clearly written i think it ll be a nice contribution to the conference program detailed comments my main question is why the proposed general multilingual methodology was limited to pairs of languages rather than to sets of similar languages for example all romance languages could be included in the training to improve spanish paradigm completion and all slavic languages with cyrillic script could be mixed to improve ukrainian it would be interesting to see the extension of the models from bi lingual to multilingual settings i think arabic is not a fair and fairly meaningless baseline given how different is its script and morphology from the target languages a more interesting baseline would be e g a language with a partially shared alphabet but a different typology for example a slavic language with latin script could be used as a baseline language for romance languages if arabic is excluded and if we consider a most distant language in the same the same family as a baseline experimental results are still strong a half page discussion of contribution of arabic as a regularizer also adds little to the paper i d just remove arabic from all the experiments and would add a regularizer which according to footnote works even better than adding arabic as a transfer language related work is missing a line of work on language universal rnn models that use basically the same approach they learn shared parameters for inputs in multiple languages and add a language tag to the input to mediate between languages related studies include a multilingual parser ammar et al language models tsvetkov et al and machine translation johnson et al minor i don t think that the claim is correct in line that pos tags are easy to transfer across languages transfer of pos annotations is also a challenging task references waleed ammar george mulcaire miguel ballesteros chris dyer and noah a smith many languages one parser tacl yulia tsvetkov sunayana sitaram manaal faruqui guillaume lample patrick littell david mortensen alan w black lori levin and chris dyer polyglot neural language models a case study in cross lingual phonetic representation learning naacl melvin johnson mike schuster quoc v le maxim krikun yonghui wu zhifeng chen nikhil thorat et al google multilingual neural machine translation system enabling zero shot translation arxiv preprint arxiv response to author response thanks for your response i am looking forward to reading the final version,4.0
462.json,strengths the approach described in the manuscript outperformed the previous approaches and achieved the state of the art result regarding data the method used the combination of market and text data the approach used word embeddings to define the weight of each lexicon term by extending it to the similar terms in the document weaknesses deep learning based methods were known to be able to achieve relatively good performances without much feature engineering in sentimental analysis more literature search is needed to compare with the related works would be better the approach generally improved performance by feature based methods without much novelty in model or proposal of new features general discussion the manuscript described an approach in sentimental analysis the method used a relatively new method of using word embeddings to define the weight of each lexicon term however the novelty is not significant enough,2.0
462.json,strengths weaknesses general discussion this paper investigates sentiment signals in companies annual k filing reports to forecast volatility the authors evaluate information retrieval term weighting models which are seeded with a finance oriented sentiment lexicon and expanded with word embeddings pca is used to reduce dimensionality before support vector regression is applied for similarity estimation in addition to text based features the authors also use non text based market features e g sector information and volatility estimates multiple fusion methods to combine text features with market features are evaluated comments it would be interesting to include two more experimental conditions namely a simple trigram svm which does not use any prior sentiment lexica and features that reflect delta idfs scores for individual features as an additional baseline it would be good to see binary features this paper could corroborate your references https pdfs semanticscholar org d ccaaaeeefeebebea pdf,2.0
97.json,strengths this paper tries to tackle a very practical problem automated short answer scoring sas in particular for japanese which has not gotten as much attention as say english language sas weaknesses the paper simply reads like a system description and is light on experiments or insights the authors show a lack of familiarity with more recent related work aimed at english sas both in terms of methodology and evaluation here are a couple https www aclweb org anthology w w w pdf page https www aclweb org anthology n n n pdf there was also a recent kaggle competition that generated several methodologies https www kaggle com c asap sas general discussion to meet acl standards i would have preferred to see more experiments feature ablation studies algorithm comparisons that motivated the final system design as well as some sort of qualitative evaluation with a user study of how the mixed initiative user interface features led to improved scores as it is it feels like a work in progress without any actionable new methods or insights also pearson spearman correlation and kappa scores are considered more appropriate than accuracy for these sorts of ordinal human scores,2.0
97.json,this paper presents a text classification method based on pre training technique using both labeled and unlabeled data the authors reported experimental results with several benchmark data sets including trec data and showed that the method improved overall performance compared to other comparative methods i think the approach using pre training and fine tuning itself is not a novel one but the originality is the use of both labeled and unlabeled data in the pre training step the authors compare their results against three baselines i e without pre training and a deep learning with unsupervised pre training using deep autoencoders but i think that i would be interesting to compare the method against other methods presented in the introduction section,3.0
395.json,this paper outlines a method to learn sense embeddings from unannotated corpora using a modular sense selection and representation process the learning is achieved by a message passing scheme between the two modules that is cast as a reinforcement learning problem by the authors strengths the paper is generally well written presents most of its ideas clearly and makes apt comparisons to related work where required the experiments are well structured and the results are overall good though not outstanding however there are several problems with the paper that prevent me from endorsing it completely weaknesses my main concern with the paper is the magnification of its central claims beyond their actual worth the authors use the term deep in their title and then several times in the paper but they use a skip gram architecture which is not deep this is misrepresentation also reinforcement learning is one of the central claims of this paper however to the best of my understanding the motivation and implementation lacks clarity section tries to cast the task as a reinforcement learning problem but goes on to say that there are major drawbacks due to which a q learning algorithm is used this algorithm does not relate to the originally claimed policy furthermore it remains unclear how novel their modular approach is their work seems to be very similar to em learning approaches where an optimal sense is selected in the e step and an objective is optimized in the m step to yield better sense representations the authors do not properly distinguish their approach nor motivative why rl should be preferred over em in the first place the authors make use of the term pure sense representations multiple times and claim this as a central contribution of their paper i am not sure what this means or why it is beneficial they claim linear time sense selection in their model again it is not clear to me how this is the case a highlighting of this fact in the relevant part of the paper would be helpful finally the authors claim state of the art results however this is only on a single maxsimc metric other work has achieved overall better results using the avgsimc metric so while state of the art is not everything about a paper the claim that this paper achieves it in the abstract and intro is at least a little misleading,3.0
395.json,this paper describes a novel approach for learning multi sense word representations using reinforcement learning a cbow like architecture is used for sense selection computing a score for each sense based on the dot product between the sum of word embeddings in the current context and the corresponding sense vector a second module based on the skip gram model is used to train sense representations given results from the sense selection module in order to train these two modules the authors apply q learning where the q value is provided by the cbow based sense selection module the reward is given by the skip gram negative sampling likelihood additionally the authors propose an approach for determining the number of senses for each word non parametrically by creating new senses when the q values for existing scores have a score under the resulting approach achieves good results under the maxsimc metric and results comparable to previous approaches under avgsimc the authors suggest that their approach could be used to improve the performance for downstream tasks by replacing word embeddings with their most probable sense embedding it would have been nice to see this claim explored perhaps in a sequential labeling task such as pos tagging or ner especially in light of previous work questioning the usefulness of multi sense representations in downstream tasks i found it somewhat misleading to suggest that relying on maxsimc could reduce overhead in a real world application as the sense disambiguation step with associated parameters would still be required in addition to the sense embeddings a clustering based approach using a weighted average of sense representations would have similar overhead the claims about improving over wordvec using of the data are also not particularly surprising on scws these are misleading contributions as they do not advance differ much from previous work the modular quality of their approach results in a flexibility that i think could have been explored further the sense disambiguation module uses a vector averaging cbow approach a positive aspect of their model is that they should be able to substitute other context composition approaches using alternative neural architecture composition techniques relatively easily the paper applies an interesting approach to a problem that has been explored now in many ways the results on standard benchmarks are comparable to previous work but not particularly surprising interesting however the approach goes beyond a simple extension of the skip gram model for multi sense representation learning by providing a modular framework based on reinforcement learning ideally this aspect would be explored further but overall the approach itself may be interesting enough on its own to be considered for acceptance as it could help move research in this area forward there are a number of typos that should be addressed line representations selects th note thank you to the authors for their response,4.0
792.json,strengths the presentation of the paper up until the final few sections is excellent and the paper reads very well at the start the paper has a clear structure and the argumentation is for the most part good the paper addresses an important problem by attempting to incorporate word order information into word and sense embeddings and the proposed solution is interesting weaknesses unfortunately the results are rather inconsistent and one is not left entirely convinced that the proposed models are better than the alternatives especially given the added complexity negative results are fine but there is insufficient analysis to learn from them moreover no results are reported on the word analogy task besides being told that the proposed models were not competitive this could have been interesting and analyzed further some aspects of the experimental setup were unclear or poorly motivated for instance w r t to corpora and datasets see details below unfortunately the quality of the paper deteriorates towards the end and the reader is left a little disappointed not only w r t to the results but with the quality of the presentation and the argumentation general discussion the authors aim to learn representations for both words and senses in a shared emerging space this is only done in the lstmembedsw version which rather consisently performs worse than the alternatives in any case what is the motivation for learning representations for words and senses in a shared semantic space this is not entirely clear and never really discussed in the paper the motivation for or intuition behind predicting pre trained embeddings is not explicitly stated also are the pre trained embeddings in the lstmembedsw model representations for words or senses or is a sum of these used again if different alternatives are possible which setup is used in the experiments the importance of learning sense embeddings is well recognized and also stressed by the authors unfortunately however it seems that these are never really evaluated if they are this remains unclear most or all of the word similarity datasets considers words independent of context what is the size of the training corpora for instance using different proportions of babelwiki and sew is shown in figure however the comparison is somewhat problematic if the sizes are substantially different the size of semcor is moreover really small and one would typically not use such a small corpus for learning embeddings with e g wordvec if the proposed models favor small corpora this should be stated and evaluated some of the test sets are not independent i e ws wssim and wsrel which makes comparisons problematic in this case giving three wins as opposed to one the proposed models are said to be faster to train by using pre trained embeddings in the output layer however no evidence to support this claim is provided this would strengthen the paper table why not use the same dimensionality for a fair er comparison a section on synonym identification is missing under similarity measurement that would describe how the multiple choice task is approached a reference to table is missing there is no description of any training for the word analogy task which is mentioned when describing the corresponding dataset,2.0
19.json,strengths the approach is novel and the results are very promising beating state of the art weaknesses the linguistic motivation behind the paper is troublesome see below i feel that the paper would benefit a lot from a more thoughtful interpretation of the results general discussion this paper presents an approach for zero pronoun resolution in chinese the authors advocate a novel procedure for generating large amount of relevant data from unlabeled documents these data are then integrated smartly in an nn based architecture at a pre training step the results improve on state of the art i have mixed feelings about this study on the one hand the approach seems sound and shows promising results beating very recent systems e g chen ng on the other hand the way the main contribution is framed is very disturbing from the linguistic point of view in particular zero pronoun resolution is linguistically speaking a context modeling task requiring accurate interpretation of discourse salience semantic and syntactic clues it starts from the assumption that zero pronouns are used in specific contexts where full nps should not normally be possible from this perspective generating zp data via replacing nominal with zeroes blank does not sound very convincing and indeed as the authors themselves show the pre training module alone does not achieve a reasonable performance to sum it up i do not think that these generated pseudo data can be called azp data it seems more likely that they encode some form of selectional preferences it would be nice if the authors could invest some effort in better understanding what exactly the pre training module learns and then reformulate the corresponding sections the paper can benefit from a proofreading by a native speaker of english for example the sentence on lines is not grammatical other points lines are there any restrictions on the nouns and especially pronouns for example do you use this strategy for very common pronouns as english it if so how do you guarantee that the two occurrences of the same token are indeed coreferent line the term antecedent is typically used to denote a preceding mention coreferent with the anaphor which is not what you mean here line ontonotes typo lines it has been shown that evaluation on gold annotated data does not provide reliable estimation of performance and indeed all the recent studies of coreference evaluate on system mentions for example the studies of chen ng you are citing provide different types of evaluation including those on system mentions please consider rerunning your experiments to get a more realistic evaluation setup line i do not understand what the dagger over the system name means is your improvement statistically significant on all the domains including bn and tc line learn typo section in this section you use the abbreviation azp instead of zp without introducing it please unify the terminology references please double check for capitalization,4.0
481.json,in this work the authors extend ms coco by adding an incorrect caption to each existing caption with only one word of difference the authors demonstrate that two state of the art methods one for vqa and one for captioning perform extremely poorly at a determining if a caption is fake b determining which word in a fake caption is wrong and c selecting a replacement word for a given fake word this work builds upon a wealth of literature regarding the underperformance of vision language models relative to their apparent capacities i think this work makes concrete some of the big fundamental questions in this area are vision language models doing interesting things or not the authors consider a nice mix of tasks and models to shed light on the broken ness of these settings and perform some insightful analyses of factors associated with model failure e g figure my biggest concerns with the paper are similarity to ding et al that being said i do think the authors make some really good points ding et al generate similar captions but the ones here differ by only one word and still break the models i think that a justifiably fundamental difference that observation demonstrates that ding et al engineering is not a requirement as this simple approach still breaks things catastrophically another concern is the use of neuraltalk to select the hardest foils while a clever idea i am worried that the use of this model creates a risk of self reinforcement bias i e neuraltalk biases are now fundamentally baked in to foil coco i think the results section could be a bit longer relative to the rest of the paper e g i would have liked more than one paragraph i liked this part overall i do like this paper as it nicely builds upon some results that highlight defficiencies in vision language integration in the end the ding et al similarity is not a game breaker i think if anything this work shows that vision language models are so easy to fool ding et al method is not even required small things i would have liked to have seen another baseline that simply concatenates bow extracted cnn features and trains a softmax classifier over them the blind model is a nice touch but what about a dumb vision langauge baseline i bet that would do close to as well as the lstm co attention that could have made the point of the paper even stronger what is a supercategory is this from wordnet is this from coco i understand the idea but not the specifics has been were that than artefact undesirable artifacts i would have included a chance model in t table is line a constant prediction baseline is it if so can not we flip all of the blind predictions to get a better baseline i am not entirely clear and i think a chance line here would fix a lot of this confusion ariplane after reading the author response i think this author response is spot on both my concerns of neuraltalk biases and additional baselines were addressed and i am confident that these can be addressed in the final version so i will keep my score as is,4.0
706.json,thanks for the response i look forward to reading about the effect of incentives and the ambiguity of the language in the domain review before author response the paper proposes a way to build natural language interfaces by allowing a set of users to define new concepts and syntax it an non trivial extension of s i wang p liang and c manning learning language games through interaction questions what is the size of the vocabulary used is it possible to position this paper with respect to previous work on inverse reinforcement learning and imitation learning strengths the paper is well written it provides a compelling direction solution to the problem of dealing with a large set of possible programs while learning natural language interfaces weaknesses the authors should discuss the effect of the incentives on the final performance were other alternatives considered while the paper claims that the method can be extended to more practical domains it is not clear to me how straightforward it is going to be how sensitive is the method to the size of the vocabulary required in a domain would increased ambiguity in natural language create new problems these questions are not discussed in the current experiments a real world application would definitely strengthen the paper even more,4.0
706.json,strengths this paper reports on an interesting project to enable people to design their own language for interacting with a computer program in place of using a programming language the specific construction that the authors focus on is the ability for people to make definitions very nicely they can make recursive definitions to arrive at a very general way of giving a command the example showing how the user could generate definitions to create a palm tree was motivating the approach using learning of grammars to capture new cases seems like a good one weaknesses this seems to be an extension of the acl paper on a similar topic it would be helpful to be more explicit about what is new in this paper over the old one there was not much comparison with previous work no related work section the features for learning are interesting but it not always clear how they would come into play for example it would be good to see an example of how the social features influenced the outcome i did not otherwise see how people work together to create a language general discussion,4.0
614.json,this paper proposes integrating word sense inventories into existing approaches for the lexical substitution task by using these inventories to filter candidates to do so the authors first propose a metric to measure the mutual substitutability of sense inventories with human judgments for the lexsub task and empirically measure the substitutability of inventories from various sources such as wordnet and ppdb next they propose clustering different paraphrases of a word from ppdb using a multi view clustering approach to automatically generate a sense inventory instead of using the aforementioned inventories finally they use these clusters with a naive majority in top wsd technique to filter existing ranked list of substitution candidates strengths the key idea of marrying vector space model based approaches and sense inventories for the lexsub task is useful since these two techniques seem to have complementary information especially since the vector space models are typically unaware of sense and polysemy the oracle evaluation is interesting as it gives a clear indication of how much gain can one expect in the best case and while there is still a large gap between the oracle and actual scores we can still argue for the usefulness of the proposed approach due to the large difference between the unfiltered gap and the oracle gap weaknesses i do not understand effectiveness of the multi view clustering approach almost all across the board the paraphrase similarity view does significantly better than other views and their combination what then do we learn about the usefulness of the other views there is one empirical example of how the different views help in clustering paraphrases of the word lip but there is no further analysis about how the different clustering techniques differ except on the task directly without a more detailed analysis of differences and similarities between these views it is hard to draw solid conclusions about the different views the paper is not fully clear on a first read specifically it is not immediately clear how the sections connect to each other reading more like disjoint pieces of work for instance i did not understand the connections between section and section so adding forward backward pointer references to sections should be useful in clearing up things relatedly the multi view clustering section needs editing since the subsections seem to be out of order and citations seem to be missing lines and the relatively poor performance on nouns makes me uneasy while i can expect twsi to do really well due to its nature the fact that the oracle gap for ppdbclus is higher than most clustering approaches is disconcerting and i would like to understand the gap better this also directly contradicts the claim that the clustering approach is generalizable to all parts of speech since the performance clearly is not uniform general discussion the paper is mostly straightforward in terms of techniques used and experiments even then the authors show clear gains on the lexsub task by their two pronged approach with potentially more to be gained by using stronger wsd algorithms some additional questions for the authors lines why do you add hypernyms hyponyms lines why does x p need to be symmetric lines the weighting scheme seems kind of arbitrary was this indeed arbitrary or is this a principled choice is the high performance of substclus p ascribable to the fact that the number of clusters was tuned based on this view would tuning the number of clusters based on other matrices affect the results and the conclusions what other related tasks could this approach possibly generalize to or is it only specific to lexsub,4.0
614.json,strengths the paper presents a new method that exploits word senses to improve the task of lexical substitutability results show improvements over prior methods weaknesses as a reader of a acl paper i usually ask myself what important insight can i take away from the paper and from a big picture point of view what does the paper add to the fields of natural language processing and computational linguistics how does the task of lexical substitutability in general and this paper in particular help either in improving an nlp system or provide insight about language i can not find a good answer answer to either question after reading this paper as a practitioner who wants to improve natural language understanding system i am more focused on the first question does the lexical substitutability task and the improved results compared to prior work presented here help any end application given the current state of high performing systems any discrete clustering of words or longer utterances often break down when compared to continuous representations words see all the papers that utilitize discrete lexical semantics to achieve a task versus words distributed representations used as an input to the same task e g machine translation question answering sentiment analysis text classification and so forth how do the authors motivate work on lexical substitutability given that discrete lexical semantic representations often do not work well the introduction cites a few papers from several years back that are mostly set up in small data scenarios and given that this word is based on english i do not see why one would use this method for any task i would be eager to see the authors responses to this general question of mine as a minor point to further motivate this consider the substitutes presented in table tasha snatched it from him to rip away the paper tasha snatched it from him to rip away the sheet to me these two sentences have varying meanings what if he was holding on to a paper bag in that scenario can the word paper be substituted by sheet at least in my understanding it cannot hence there is so much subjectivity in this task that lexical substitutes can completely alter the semantics of the original sentence minor point s citations in section are missing addition i have read the author response and i am sticking to my earlier evaluation of the paper,2.0
182.json,dear authors thanks for replying to our review comments which clarifies some detail questions i appreciate your promise to publish the code which will be very helpful to other researchers based on this i increased my overall score to strengths well written extensive experiments good results weaknesses nothing ground breaking application of existing technologies code not available results are as could be expected general discussion why did not you use established audio features such as mfccs minor details l and other places a lstm an lstm l l and other places why are there hyphens after the text l explanation of convolution is not clear table should appear earlier on page already cited l is d cnn a standard approach in video processing alternatives l the should probably positioned above the y l to check overfitting did you mean to avoid l put names in or write them italic to make it easier to recognize them l a svm an svm l output are wrong numerus either outputs or use is l superflous whitespace after layer l concatenation should not be in a new line l why do not you know the exact number of persons l remove comma after since l doesnt does not l insert hand the after other references need some cleanup l superflous whitespace l munich l what is acl l superflous l volume l superflous new lines l indent linguistics properly,4.0
660.json,the paper presents two approaches for generating english poetry the first approach combine a neural phonetic encoder predicting the next phoneme with a phonetic orthographic hmm decoder computing the most likely word corresponding to a sequence of phonemes the second approach combines a character language model with a weigthed fst to impose rythm constraints on the output of the language model for the second approach the authors also present a heuristic approach which permit constraining the generated poem according to theme e g love or poetic devices e g alliteration the generated poems are evaluated both instrinsically by comparing the rythm of the generated lines with a gold standard and extrinsically by asking human evaluators to i determine whether the poem was written by a human or a machine and ii rate poems wrt to readability form and evocation the results indicate that the second model performs best and that human evaluators find it difficult to distinguish between human written and machine generated poems this is an interesting clearly written article with novel ideas two different models for poetry generation one based on a phonetic language model the other on a character lm and convincing results for the evaluation more precision about the evaluators and the protocol would be good did all evaluators evaluate all poems and if not how many judgments were collected for each poem for each task you mention non english native speakers poems are notoriously hard to read how fluent were these in the second model character based perhaps i missed it but do you have a mechanism to avoid generating non words if not how frequent are non words in the generated poems in the first model why use an hmm to transliterate from phonetic to an orhographic representation rather than a crf since overall you rule out the first model as a good generic model for generating poetry it might have been more interesting to spend less space on that model and more on the evaluation of the second model in particular i would have been interested in a more detailed discussion of the impact of the heuristic you use to constrain theme or poetic devices how do these impact evaluation results could they be combined to jointly constrain theme and poetic devices the combination of a neural mode with a wfst is reminiscent of the following paper which combine character based neural model to generate from dialog acts with an wfst to avoid generating non words you should relate your work to theirs and cite them natural language generation through character based rnns with finite state prior knowledge goyal raghav and dymetman marc and gaussier eric and lig uni coling,4.0
660.json,the paper describes two methodologies for the automatic generation of rhythmic poetry both rely on neural networks but the second one allows for better control of form strengths good procedure for generating rhythmic poetry proposals for adding control of theme and poetic devices alliteration consonance asonance strong results in evaluation of rhythm weaknesses poor coverage of existing literature on poetry generation no comparison with existing approaches to poetry generation no evaluation of results on theme and poetic devices general discussion the introduction describes the problem of poetry generation as divided into two subtasks the problem of content the poem semantics and the problem of form the aesthetic rules the poem follows the solutions proposed in the paper address both of these subtasks in a limited fashion they rely on neural networks trained over corpora of poetry represented at the phonetic or character level depending on the solution to encode the linguistic continuity of the outputs this does indeed ensure that the outputs resemble meaningful text to say that this is equivalent to having found a way of providing the poem with appropriate semantics would be an overstatement the problem of form can be said to be addressed for the case of rhythm and partial solutions are proposed for some poetic devices aspects of form concerned with structure at a larger scale stanzas and rhyme schemes remain beyond the proposed solutions nevertheless the paper constitutes a valuable effort in the advancement of poetry generation the review of related work provided in section is very poor it does not even cover the set of previous efforts that the authors themselves consider worth mentioning in their paper the work of manurung et al and misztal and indurkhya is cited later in the paper page but it is not placed in section with respect to the other authors mentioned there a related research effort of particular relevance that the authors should consider is gabriele barbieri françois pachet pierre roy and mirko degli esposti markov constraints for generating lyrics with style in proceedings of the th european conference on artificial intelligence ecai luc de raedt christian bessiere didier dubois patrick doherty and paolo frasconi eds ios press amsterdam the netherlands the netherlands doi https doi org this work addresses very similar problems to those discussed in the present paper n gram based generation and the problem of driving generation process with additional constraints the authors should include a review of this work and discuss the similarities and differences with their own another research effort that is related to what the authors are attempting and has bearing on their evaluation process is stephen mcgregor matthew purver and geraint wiggins process based evaluation of computer generated poetry in proceedings of the inlg workshop on computational creativity and natural language generation pages edinburgh september c association for computational linguistics this work is also similar to the current effort in that it models language initially at a phonological level but considers a word n gram level superimposed on that and also features a layer representint sentiment some of the considerations mcgregor et al make on evaluation of computer generated poetry are also relevant for the extrinsic evaluation described in the present paper another work that i believe should be considered is generating topical poetry m ghazvininejad x shi y choi and k knight proc emnlp this work generates iambic pentameter by combining finite state machinery with deep learning it would be interesting to see how the proposal in the current paper constrasts with this particular approach although less relevant to the present paper the authors should consider extending their classification of poetry generation systems they mention rule based expert systems and statistical approaches to include evolutionary solutions they already mention in their paper the work of manurung which is evolutionary in nature operating over tag grammars in any case the paper as it stands holds little to no effort of comparison to prior approaches to poetry generation the authors should make an effort to contextualise their work with respect to previous efforts specially in the case were similar problems are being addressed barbieri et al or similar methods are being applied ghazvininejad et al,3.0
94.json,strengths the paper makes several novel contributions to transition based dependency parsing by extending the notion of non monotonic transition systems and dynamic oracles to unrestricted non projective dependency parsing the theoretical and algorithmic analysis is clear and insightful and the paper is admirably clear weaknesses given that the main motivation for using covington algorithm is to be able to recover non projective arcs an empirical error analysis focusing on non projective structures would have further strengthened the paper and even though the main contributions of the paper are on the theoretical side it would have been relevant to include a comparison to the state of the art on the conll data sets and not only to the monotonic baseline version of the same parser general discussion the paper extends the transition based formulation of covington dependency parsing algorithm for unrestricted non projective structures by allowing non monotonicity in the sense that later transitions can change structure built by earlier transitions in addition it shows how approximate dynamic oracles can be formulated for the new system finally it shows experimentally that the oracles provide a tight approximation and that the non monotonic system leads to improved parsing accuracy over its monotonic counterpart for the majority of the languages included in the study the theoretical contributions are in my view significant enough to merit publication but i also think the paper could be strengthened on the empirical side in particular it would be relevant to investigate in an error analysis whether the non monotonic system improves accuracy specifically on non projective structures such an analysis can be motivated on two grounds i the ability to recover non projective structures is the main motivation for using covington algorithm in the first place ii non projective structures often involved long distance dependencies that are hard to predict for a greedy transition based parser so it is plausible that the new system would improve the situation another point worth discussion is how the empirical results relate to the state of the art in light of recent improvements thanks to word embeddings and neural network techniques for example the non monotonicity is claimed to mitigate the error propagation typical of classical greedy transition based parsers but another way of mitigating this problem is to use recurrent neural networks as preprocessors to the parser in order to capture more of the global sentence context in word representations are these two techniques competing or complementary a full investigation of these issues is clearly outside the scope of the paper but some discussion would be highly relevant specific questions why were only out of the data sets from the conll x shared task used i am sure there is a legitimate reason and stating it explicitly may prevent readers from becoming suspicious do you have any hypothesis about why accuracy decreases for basque with the non monotonic system similar but weaker trends can be seen also for turkish catalan hungarian and perhaps german how do your results compare to the state of the art on these data sets this is relevant for contextualising your results and allowing readers to estimate the significance of your improvements author response i am satisfied with the author response and see no reason to change my previous review,4.0
37.json,strengths relatively clear description of context and structure of proposed approach relatively complete description of the math comparison to an extensive set of alternative systems weaknesses weak results summary of side by side human comparison in section some disfluency agrammaticality general discussion the article proposes a principled means of modeling utterance context consisting of a sequence of previous utterances some minor issues past turns in table could be numbered making the text associated with this table lines less difficult to ingest currently readers need to count turns from the top when identifying references in the authors description and may wonder whether second third and last imply a side specific or global enumeration some reader confusion may be eliminated by explicitly defining what segment means in segment level as occurring on line previously on line this seemingly same thing was referred to as a sequence sequence similarity matrix the two terms appear to be used interchangeably but it is not clear what they actually mean despite the text in section it seems the authors may mean word subsequence and word subsequence to word subsequence where sub implies not the whole utterance but not sure currently the variable symbol n appears to be used to enumerate words in an utterance line as well as utterances in a dialogue line the authors may choose two different letters for these two different purposes to avoid confusing readers going through their equations the statement this indicates that a retrieval based chatbot with smn can provide a better experience than the state of the art generation model in practice at the end of section appears to be unsupported the two approaches referred to are deemed comparable in out of cases with the baseline better than the proposed method in our of the remaining cases the authors are encouraged to assess and present the statistical significance of this comparison if it is weak their comparison permits to at best claim that their proposed method is no worse rather than better than the vhred baseline the authors may choose to insert into figure the explicit first layer second layer and third layer labels they use in the accompanying text their is a pervasive use of to meet as in a response candidate can meet each utterace on line which is difficult to understand spelling gated recurrent unites respectively on line should be removed punctuation on line and is exchanged baseline model over baseline model by one cannot neglects,4.0
352.json,this paper introduces new configurations and training objectives for neural sequence models in a multi task setting as the authors describe well the multi task setting is important because some tasks have shared information and in some scenarios learning many tasks can improve overall performance the methods section is relatively clear and logical and i like where it ended up though it could be slightly better organized the organization that i realized after reading is that there are two problems shared features end up in the private feature space and private features end up in the shared space there is one novel method for each problem that organization up front would make the methods more cohesive in any case they introduce one method that keeps task specific features out of shared representation adversarial loss and another to keep shared features out of task specific representations orthogonality constraints my only point of confusion is the adversarial system after lstm output there is another layer d s kt thetad relying on parameters u and b this output is considered a probability distribution which is compared against the actual this means it is possible it will just learn u and b that effectively mask task specific information from the lstm outputs and does not seem like it can guarantee task specific information is removed before i read the evaluation section i wrote down what i hoped the experiments would look like and it did most of it this is an interesting idea and there are a lot more experiments one can imagine but i think here they have the basics to show the validity of their methods it would be helpful to have best known results on these tasks my primary concern with this paper is the lack of deeper motivation for the approach i think it is easy to understand that in a totally shared model there will be problems due to conflicts in feature space the extension to partially shared features seems like a reaction to that issue one would expect that the useful shared information is in the shared latent space and each task specific space would learn features for that space maybe this works and maybe it does not but the logic is clear to me in contrast the authors seem to start from the assumption that this shared private model has this issue i expected the argument flow to be fully shared obviously has this problem shared private seems to address this in practice shared private does not fully address this issue for reasons a b c we introduce a method that more effectively constrains the spaces table helped me to partially understand what is going wrong with shared private and what your methods do some terms are usually one connotation or another and that general trend can probably get them into the shared feature space this simple explanation an example and a more logical argument flow would help the introduction and make this a really nice reading paper finally i think this research ties into some other uncited mtl work which does deep hierarchical mtl supervised pos tagging at a lower level chunking at the next level up ccg tagging higher etc they then discuss at the end some of the qualities that make mtl possible and conclude that mtl only works when tasks are sufficiently similar the asp mtl paper made me think of this previous work because potentially this model could learn what sufficiently similar is i e if two tasks are not sufficiently similar the shared model would learn nothing and it would fall back to learning two independent systems as compared to a shared private model baseline that might overfit and perform poorly inproceedings sogaarddeep title deep multi task learning with low level tasks supervised at lower layers author s o gaard anders and goldberg yoav booktitle proceedings of the th annual meeting of the association for computational linguistics volume pages year organization association for computational linguistics,4.0
352.json,paper summary this paper presents a method for learning well partitioned shared and task specific feature spaces for lstm text classifiers multiclass adversarial training encourages shared space representations from which a discriminative classifier cannot identify the task source and are thus generic the models evaluates are a fully shared shared private and adversarial shared private the lattermost asp model is one of the main contributions they also use orthogonality constraints to help reward shared and private spaces that are distinct the asp model has lower error rate than single task and other multi task neural models they also experiment with a task level cross validation to explore whether the shared representation can transfer across tasks and it seems to favourably finally there is some analysis of shared layer activations suggesting that the asp model is not being misled by strong weights learned on a specific inappropriate task review summary good ideas well expressed and tested some minor comments strengths this is a nice set of ideas working well together i particularly like the focus on explicitly trying to create useful shared representations these have been quite successful in the cv community but it appears that one needs to work quite hard to create them for nlp sections and are very clearly expressed the task level cross validation in section is a good way to evaluate the transfer there is an implementation and data weaknesses there are a few minor typographic and phrasing errors individually these are fine but there are enough of them to warrant fixing l the infantile cart is slightly odd was this a real example from the data l are different in differ in l working adversarially towards working against or competing with l two matrics two matrices l are hyperparameter are hyperparameters section has a number of number agreement errors l and should be closely re edited the shading on the final row of tables and prints strangely there is mention of unlabelled data in table and semi supervised learning in section but i didn t see any results on these experiments were they omitted or have i misunderstood the error rate differences are promising in tables and but statistical significance testing would help make them really convincing especially between sp mlt and asp mtl results to highlight the benefit of adversarial training it should be pretty straightforward to adapt the non parametric approximate randomisation test see http www lr pi titech ac jp takamura pubs randtest pdf for promising notes a reference to the chinchor paper to produce these the colours are inconsistent in the caption of figure b in a blue is used for ours but this seems to have swapped for b this is worth checking or i may have misunderstood the caption general discussion i wonder if there s some connection with regularisation here as the effect of the adversarial training with orthogonal training is to help limit the shared feature space it might be worth drawing that connection to other regularisation literature,4.0
489.json,comments after author response thanks for your response particularly for the clarification wrt the hypothesis i agree with the comment wrt cross modal mapping what i do not share is the kind of equation visual referential that you seem to assume a referent can be visually presented but visual information can be usefully added to a word representation in aggregate form to encode perceptual aspects of the words meaning the same way that it is done for textual information for instance the fact that bananas are yellow will not frequently be mentioned in text and adding visual information extracted from images will account for this aspect of the semantic representation of the word this is kind of technical and specific to how we build distributional models but it also relevant if you think of human cognition probably our representation for banana has some aggregate information about all the bananas we have seen and touched tasted etc it would be useful if you could discuss this issue explicitly differentiating between multi modal distributional semantics in general and the use of cross modal mapping in particular also wrt the all models perform similarly comment i really urge you if the paper is accepted to state it in this form even if it does not completely align with your hypotheses goals you have enough results that do it is a better description of the results and more useful for the community than clinging to the n th digit difference and this is to a large extent independent of whether the difference is actually statistical significant or not if one bridge has chances of collapsing and another one the difference may be statistically significant but that does not really make the first bridge a better bridge to walk on btw small quibble could you find a kind of more compact and to the point title more geared towards either generally what you explore or to what you find the paper tackles an extremely interesting issue that the authors label referential word meaning namely the connection between a word meaning and the referents objects in the external world it is applied to if i understood it correctly they argue that this is different from a typical word meaning representation as obtained e g with distributional methods because one thing is the abstract lexical meaning of a word and the other which label is appropriate for a given referent with specific properties in a specific context although context is something they explicitly leave aside in this paper this hypothesis has been previously explored in work by schlangen and colleagues cited in the paper the paper explores referential word meaning empirically on a specific version of the task of referential expression generation reg namely generating the appropriate noun for a given visually represented object strengths the problem they tackle i find extremely interesting as they argue reg is a problem that had previously been addressed mainly using symbolic methods that did not easily allow for an exploration of how speakers choose the names of the objects the scope of the research goes beyond reg as such as it addresses the link between semantic representations and reference more broadly i also like how they use current techniques and datasets cross modal mapping and word classifiers the referit dataset containing large amounts of images with human generated referring expressions to address the problem at hand there are a substantial number of experiments as well as analysis into the results weaknesses the main weakness for me is the statement of the specific hypothesis within the general research line that the paper is probing i found it very confusing as a result it is also hard to make sense of the kind of feedback that the results give to the initial hypothesis especially because there are a lot of them and they do not all point in the same direction the paper says this paper pursues the hypothesis that an accurate model of referential word meaning does not need to fully integrate visual and lexical knowledge e g as expressed in a distributional vector space but at the same time has to go beyond treating words as independent labels the first part of the hypothesis i do not understand what is it to fully integrate or not to fully integrate visual and lexical knowledge is the goal simply to show that using generic distributional representation yields worse results than using specific word adapted classifiers trained on the dataset if so then the authors should explicitly discuss the bounds of what they are showing specifically word classifiers must be trained on the dataset itself and only word classifiers with a sufficient amount of items in the dataset can be obtained whereas word vectors are available for many other words and are obtained from an independent source even if the cross modal mapping itself is trained on the dataset moreover they use the simplest ridge regression instead of the best method from lazaridou et al so any conclusion as to which method is better should be taken with a grain of salt however i am hoping that the research goal is both more constructive and broader please clarify the paper uses three previously developed methods on a previously available dataset the problem itself has been defined before in schlangen et al in this sense the originality of the paper is not high as the paper itself also points out the authors select a very limited subset of the referit dataset with quite a small vocabulary words i am not even sure why they limited it this way see detailed comments below some aspects could have been clearer see detailed comments the paper contains many empirical results and analyses and it makes a concerted effort to put them together but i still found it difficult to get the whole picture what is it exactly that the experiments in the paper tell us about the underlying research question in general and the specific hypothesis tested in particular how do the different pieces of the puzzle that they present fit together general discussion added after author response despite the weaknesses i find the topic of the paper very relevant and also novel enough with an interesting use of current techniques to address an old problem reg and reference more generally in a way that allows aspects to be explored that have not received enough attention the experiments and analyses are a substantial contribution even though as mentioned above i would like the paper to present a more coherent overall picture of how the many experiments and analyses fit together and address the question pursued detailed comments section is missing the following work in computational semantic approaches to reference abhijeet gupta gemma boleda marco baroni and sebastian pado distributional vectors encode referential attributes proceedings of emnlp aurelie herbelot and eva maria vecchi building a shared world mapping distributional to model theoretic semantic spaces proceedings of emnlp how does roy work go beyond early reg work focusses links flat hit k metric flat section please put the numbers related to the dataset in a table specifying the image regions number of res overall number of words and number of object names in the original referit dataset and in the version you use by the way will you release your data i put a for data because in the reviewing form you marked yes for data but i can not find the information in the paper cannot be considered to be names image object names what is the semantically annotated portion of referit why do not you just keep girl in this example and more generally the head nouns of non relational res more generally could you motivate your choices a bit more so we understand why you ended up with such a restricted subset of referit which features list how did you extract them suggest that lexical or at least distributional knowledge is detrimental when learning what a word refers to in the world how does this follow from the results of frome et al and norouzi et al why should cross modal projection give better results it a very different type of task setup than object labeling these numbers belong in the data section table are the differences between the methods statistically significant they are really numerically so small that any other conclusion to the methods perform similarly seems unwarranted to me especially the this suggests part table also the sim wap method has the highest accuracy for hit almost identical to wac this is counter intuitive given the and results any idea of what is going on section why did you define your ensemble classifier by hand instead of learning it also your method amounts to majority voting right table the order of the models is not the same as in the other tables text table you report cosine distances but discuss the results in terms of similarity it would be clearer and more in accordance with standard practice in cl imo if you reported cosine similarities table you do not comment on the results reported in the right columns i found it very curious that the gold top k data similarities are higher for transfer sim wap whereas the results on the task are the same i think that you could squeeze more information wrt the phenomenon and the models out of these results format of wac section i like the idea of the task a lot but i was very confused as to how you did and why i do not understand lines what is the task exactly an example would help testsets ff why not mix in the train set examples with hypernyms and non hypernyms more even more wrt what ff previous cross modal mapping models force i do not understand this claim larger test sets i think that you could even exploit referit more using more of its data before moving on to other datasets,4.0
489.json,after author response i accept the response about emphasizing novelty of the task and comparison with previous work also increase ratings for the dataset and software that are promised to become public before the article publishing general the paper presents an interesting empirical comparison of referring expression generation models the main novelty lies in the comparison of a yet unpublished model called sim wap in press by anonymous the model is described in section but it is not clear whether it is extended or modified anyhow in the current paper the novelty of the paper may be considered as the comparison of the unpublished sim wap model to existing models this complicates evaluation of the novelty because similar experiments were already performed for the other two models and it is unclear why this comparison was not performed in the paper where sim wap model was presented a significant novelty might be the combined model yet this is not stated clearly and the combination is not described with enough details the contribution of the paper may be considered the following the side by side comparison of the methods for reg analysis of zero shot experiment results which mostly confirms similar observations in previous works analysis of the complementarity of the combined model weaknesses unclear novelty and significance of contributions the work seems like an experimental extension of the cited anonymous paper where the main method was introduced another weakness is the limited size of the vocabulary in the zero shot experiments that seem to be the most contributive part additionally the authors never presented significance scores for their accuracy results this would have solidified the empirical contribution of the work which its main value my general feeling is that the paper is more appropriate for a conference on empirical methods such as emnlp lastly i have not found any link to any usable software existing datasets have been used for the work observations by sections abstract we compare three recent models further in the abstract you write that you also experiment with the combination of approaches in section you write that we present a model that exploits distributional knowledge for learning referential word meaning as well but explore and compare different ways of combining visual and lexical aspects of referential word meaning which eventually might be a better summarization of the novelty introduced in the paper and give more credit to the value of your work my suggestion is to re write the abstract and eventually even some sections in the paper focusing on the novel model and results and not just stating that you compare models of others introduction determining such a name is is typo concerning e g concerning e g having disjunct extensions specify or exemplify please building in figure building in figure c section following e g lazaridou et al e g should be omitted section associate the top n words with their corresponding distributional vector what are the values of n that you used if there were any experiments for finding the optimal values please describe because this is original work the use top n k is not obvious and not obvious why it should be optimal how about finding similar vectors to each in top section we annotate its training instances with a fine grained similarity signal according to their object names please exemplify language quite a few typos in the draft generally language should be cleaned up as well such as also i believe the use of american english spelling standard is preferable e g summarise summarize please double check with your conference track chairs,4.0
173.json,strengths weaknesses many grammar errors such as the abstract general discussion,4.0
371.json,the paper describes an idea to learn phrasal representation and facilitate them in rnn based language models and neural machine translation strengths the idea to incorporate phrasal information into the task is interesting weaknesses the description is hard to follow proof reading by an english native speaker would benefit the understanding the evaluation of the approach has several weaknesses general discussion in equation and the authors mention a phrase representation give a fix length word embedding vector but this is not used in the model the representation is generated based on an rnn what the propose of this description why are you using gru for the pyramid and lstm for the sequential part is the combination of two architectures a reason for your improvements what is the simplified version of the gru why is it performing better how is it performing on the large data set what is the difference between rnnsearch groundhog and rnnsearch baseline in table what is the motivation for only using the ending phrases and e g not using the starting phrases did you use only the pyramid encoder how is it performing that would be a more fair comparison since it normally helps to make the model more complex why did you run rnnsearch several times but pbnmt only once section what is the intent of this section,2.0
371.json,this paper proposed a new phrasal rnn architecture for sequence to sequence generation they have evaluated their architecture based on i the language modelling test evaluated on ptb and fbis and ii chinese english machine translation task on nist mt evaluation sets the phrasal rnn prnn architecture is achieved by generating subnetworks of phrases strengths a new phrasal architecture weaknesses technical it unclear whether there is a limit set on the phrase length of the prnn maybe i have missed this in the paper if there is please be more explicit about it because it affects the model quite drastically if for every sentence the largest phrase length is the sentence length it because if the largest phrase length is the sentence length then model can be simplified into a some sort of convolution rnn where the each state of the rnn goes through some convolution layer before a final softmax and attention if there is a limit set on the phrase length of prnn then it makes the system more tractable but that would also mean that the phrases are determined by token ngrams which produces a sliding window of the pyramid encoders for each sentence where there are instance where the parameter for these phrases will be set close to zero to disable the phrases and these phrases would be a good intrinsic evaluation of the prnn in addition to evaluating it purely on perplexity and bleu extrinsically the usage of attention mechanism without some sort of pruning might be problematic at the phrasal level the author have opted for some sort of greedy pruning as described in the caption of figure but i support given a fixed set of phrase pairs at train time the attention mechanism at the phrasal level can be pre computed but at inference apply the attention on new data at test time this might be kind of problematic when the architecture is scaled to a larger dataset empirical one issue with the language modelling experiment is the choice of evaluation and train set possibly a dataset like common crawl or enwiki would be more appropriate for language modelling experiments the main issue of the paper is in the experiments and results reporting it needs quite a bit of reworking the evaluation on ptb table is not a fair one since the model was trained on a larger corpus fbis and then tested on ptb the fact that the previous study reported a perplexity baseline using lstm and the lstm perplexity of provided by the author showed that the fbis gives an advantage to computing the language model perplexity when tested on ptb also regarding section please cite appropriate publications the previous work presented in the tables and are the previous work using the same training set additionally why is not the the gru version of prnnv reported in the fbis evaluation in table the result section cannot be simply presenting a table without explanation still on the result sections although it clear that bleu and perplexity are objective automatic measure to evaluate the new architecture it not really okay to put up the tables and show the perplexity and bleu scores without some explanation e g in table it necessary to explain why the lstm perplexity from previous work is higher than the author implementation same in table the result presented in table do not match the description in section it not true that the prnn outperforms both pbsmt and enc dec model the authors should make it clear that on different evaluation sets the scores differs and it the averaged test scores that prnn performs better please also make it clear whether the test avg is a micro average all testsets are concatenated and evaluated as one set or macro average average taken across the scores of individual test sets score for table please also include the significance of the bleu improvement made by the prnn with respect to the the baseline see https github com jhclark multeval general discussion as the main contribution of this work is on the phrasal effect of the new rnn architecture it rather important to show that the phrases are more coherent than the vanilla lstm rnn model thus the bleu evaluation is insufficient a closer look at evaluating the phrases in a subset of the evaluation set would be necessary to support the claims does the baseline system groundhog contains the attention mechanism if so please be more specific in describing it in section and table if not please remove the attention layer after the encoder in figure also the lack of attention mechanism provides a disadvantage to the baseline enc dec system and it unclear whether the prnn can outperform or be an additive feature to the enc dec system with an attention mechanism the unfair disadvantage is even more prevalent when the prnn uses multiple phrasal attention layers within a single sentence while a simple enc dec system without attention is used as a benchmark question would not a simpler way to get phrasal rnn is to put the pyramid rnns of a phrase into some soft of a average pooling layer minor issues figure is a little redundant i think figure is enough to compare it against the prnn figure and also possibly figure can be combined into the pyramid part of figure and more space can be freed up to further explain the results section please do not abuse figure table captions whenever possible please try to keep the description of the tables and figures in text please put the verbose caption description in the main text for figure and table spacing in between some of the equations can also be reduced e g in latex use vspace mm,2.0
768.json,strengths a well written paper examining the use of context in lexical entailment task is a great idea a well defined approach and experimental set up and good analysis of the results weaknesses some information is missing or insufficient e g the table captions should be more descriptive a clear description for each of the word type features should be given general discussion the paper presents a proposal of consideration of context in lexical entailment task the results from the experiments demonstrate that context informed models do better than context agnostic models on the entailment task i liked the idea of creating negative examples to get negative annotations automatically in the two ways described in the paper based on wordnet positive examples new dataset an interesting method to develop dataset i also liked the idea of transforming already used context agnostic representations into contextualized representations experimenting with different ways to get contextualized representations i e mask vs contetxvec and testing the model on different datasets generalizability not just across different datasets but also cross linguistically motivations for various decisions in the experimental design were good to see e g why authors used the split they used for context ppdb it showed that they thought out clearly what exactly they were doing and why lines authors might want to state briefly how the class weights were determined and added to account for the unbalanced data in the context wn experiments would it affect direct comparisons with previous work in what ways change in line directionality directionality as in table suggested change in line is a hierarchy of wordnet is a hierarchy of wordnet for the sake of completeness represent mask also in figure i have read the author response,4.0
768.json,this paper proposes a method for recognizing lexical entailment specifically hypernymy in context the proposed method represents each context by averaging min pooling and max pooling its word embeddings these representations are combined with the target word embedding via element wise multiplication the in context representation of the left hand side argument is concatenated to that of the right hand side argument creating a single vectorial representation of the input this input is then fed into a logistic regression classifier in my view the paper has two major weaknesses first the classification model used in this paper concat linear classifier was shown to be inherently unable to learn relations in do supervised distributional methods really learn lexical inference relations levy et al second the paper makes superiority claims in the text that are simply not substantiated in the quantitative results in addition there are several clarity and experiment setup issues that give an overall feeling that the paper is still half baked classification model concatenating two word vectors as input for a linear classifier was mathematically proven to be incapable of learning a relation between words levy et al what is the motivation behind using this model in the contextual setting while this handicap might be somewhat mitigated by adding similarity features all these features are symmetric including the euclidean distance since l r r l why do we expect these features to detect entailment i am not convinced that this is a reasonable classification model for the task superiority claims the authors claim that their contextual representation is superior to contextvec this is not evident from the paper because the best result f in both table and table excluding ppdb features is the th row to my understanding this variant does not use the proposed contextual representation in fact it uses the contextvec representation for the word type this experiment uses ready made embeddings glove and parameters contextvec that were tuned on completely different datasets with very different sizes comparing the two is empirically flawed and probably biased towards the method using glove which was a trained on a much larger corpus in addition it seems that the biggest boost in performance comes from adding similarity features and not from the proposed context representation this is not discussed miscellaneous comments i liked the wordnet dataset using the example sentences is a nice trick i don t quite understand why the task of cross lingual lexical entailment is interesting or even reasonable some basic baselines are really missing instead of the random baseline how well does the all true baseline perform what about the context agnostic symmetric cosine similarity of the two target words in general the tables are very difficult to read the caption should make the tables self explanatory also it is unclear what each variant means perhaps a more precise description in text of each variant could help the reader understand what are the ppdb specific features this is really unclear i could not understand table is overfull in table the f of random should be typo in line should be table author response thank you for addressing my comments unfortunately there are still some standing issues that prevent me from accepting this paper the problem i see with the base model is not that it is learning prototypical hypernyms but that it mathematically not able to learn a relation it appears that we have a different reading of tables and maybe this is a clarity issue but it prevents me from understanding how the claim that contextual representations substantially improve performance is supported furthermore it seems like other factors e g similarity features have a greater effect,2.0
355.json,this paper proposes a joint neural modelling approach to pas analysis in japanese based on grid rnns which it compares variously with a conventional single sequence rnn approach this is a solidly executed paper targeting a well established task from japanese but achieving state of the art results at the task and presenting the task in a mostly accessible manner for those not versed in japanese having said that i felt you could have talked up the complexity of the task a bit e g wrt your example in figure talking through the inherent ambiguity between the nom and acc arguments of the first predicate as the nom argument of the second predicate and better describing how the task contrasts with srl largely through the ambiguity in zero pronouns i would also have liked to have seen some stats re the proportion of zero pronouns which are actually intra sententially resolvable as this further complicates the task as defined i e needing to implicitly distinguish between intra and inter sentential zero anaphors one thing i was not sure of here in the case of an inter sentential zero pronoun for the argument of a given predicate what representation do you use is there simply no marking of that argument at all or is it marked as an empty argument my reading of the paper is that it is the former in which case there is no explicit representation of the fact that there is a zero pronoun which seems like a slightly defective representation which potentially impacts on the ability of the model to capture zero pronouns some discussion of this would have been appreciated there are some constraints that do not seem to be captured in the model which some of the ilp based methods for srl explicitly model e g a given predicate will generally have only one argument of a given type esp nom and acc and a given argument generally only fills one argument slot for a given predicate i would have liked to have seen some analysis of the output of the model to see how well the model was able to learn these sorts of constraints more generally given the mix of numbers in table between single seq and multi seq where it is really only nom where there is any improvement for multi seq i would have liked to have seen some discussion of the relative differences in the outputs of the two models are they largely identical or very different but about the same in aggregate e g in what contexts do you observe differences between the two models some analysis like this to shed light on the internals of the models would have made the difference between a solid and a strong paper and is the main area where i believe the paper could be improved other than including results for srl but that would take quite a bit more work the presentation of the paper was good with the figures aiding understanding of the model there were some low level language issues but nothing major l the error propagation error propagation l an solution a solution l and figure a bread bread l the independence independence l the good good l from their model of their model l significent significance l both of both and watch casing in your references e g japanese lstm conll ilp,4.0
323.json,the paper introduces an extension of the entity grid model a convolutional neural network is used to learn sequences of entity transitions indicating coherence permitting better generalisation over longer sequences of entities than the direct estimates of transition probabilities in the original model this is a nice and well written paper instead of proposing a fully neural approach the authors build on existing work and just use a neural network to overcome specific issues in one step this is a valid approach but it would be useful to expand the comparison to the existing neural coherence model of li and hovy the authors admit being surprised by the very low score the li and hovy model achieves on their task this makes the reader wonder if there was an error in the experimental setup if the other model low performance is corpus dependent and if so what results the model proposed in this paper would achieve on a corpus or task where the other model is more successful a deeper investigation of these factors would strengthen the argument considerably in general the paper is very fluent and readable but in many places definite articles are missing e g on lines and probably more i would suggest proofreading the paper specifically with article usage in mind the expression limits the model to do x which is used repeatedly sounds a bit unusual maybe limits the model capacity to do x or stops the model from doing x would be clearer final recommendation adjusted to after considering the author response i agree that objective difficulties running other people software should not be held against the present authors the efforts made to test the li and hovy system and the problems encountered in doing so should be documented in the paper i would also suggest that the authors try to reproduce the results of li and hovy on their original data sets as a sanity check unless they have already done so just to see if that works for them,4.0
323.json,the paper proposes a convolutional neural network approach to model the coherence of texts the model is based on the well known entity grid representation for coherence but puts a cnn on top of it the approach is well motivated and described i especially appreciate the clear discussion of the intuitions behind certain design decisions e g why cnn and the section titled why it works there is an extensive evaluation on several tasks which shows that the proposed approach beats previous methods it is however strange that one previous result could not be reproduced the results on li hovy suggest an implementation or modelling error that should be addressed still the model is a relatively simple neuralization of the entity grid model i did not understand why dimensional vectors are necessary to represent a four dimensional grid entry or a few more in the case of the extended grid how does this help i can see that optimizing directly for coherence ranking would help learn a better model but the difference of transition chains for up to k sentences vs k might not make such a big difference especially since many wsj articles may be very short the writing seemed a bit lengthy the paper repeats certain parts in several places for example the introduction to entity grids in particular section also presents related work thus the first of section are a repetition and should be deleted or worked into section where necessary the rest of section should probably be added in section under a subsection then rename section as related work overall this seems like a solid implementation of applying a neural network model to entity grid based coherence but considering the proposed consolidation of the previous work i would expect a bit more from a full paper such as innovations in the representations other features or tasks minor points this paper may benefit from proof reading by a native speaker there are articles missing in many places e g the wsj corpus x the brown toolkit x etc p bottom left column figure figure p firstly secondly first second p limits the model to prevents the model from considering consider removing the tandard final paragraph in section since it is not necessary to follow such a short paper,3.0
148.json,strengths this article puts two fields together text readability for humans and machine comprehension of texts weaknesses the goal of your paper is not entirely clear i had to read the paper times and i still do not understand what you are talking about the article is highly ambiguous what it talks about machine comprehension or text readability for humans you miss important work in the readability field section has completely unrelated discussion of theoretical topics i have the feeling that this paper is trying to answer too many questions in the same time by this making itself quite weak questions such as does text readability have impact on rc datasets should be analyzed separately from all these prerequisite skills general discussion the title is a bit ambiguous it would be good to clarify that you are referring to machine comprehension of text and not human reading comprehension because reading comprehension and readability usually mean that you say that your dataset analysis suggested that the readability of rc datasets does not directly affect the question difficulty but this depends on the method features used for answer detection e g if you use pos dependency parse features you need to proofread the english of your paper there are some important omissions like the question is easy to solve simply look on page how do you annotate datasets with metrics here you are mixing machine reading comprehension of texts and human reading comprehension of texts which although somewhat similar are also quite different and also large areas readability of text is not difficulty of reading contents check this dubay w h the principles of readability costa mesa ca impact information it would be good if you put more pointers distinguishing your work from readability of questions for humans because this article is highly ambiguous e g on page these two examples show that the readability of the text does not necessarily correlate with the difficulty of the questions you should add for machine comprehension section again are you referring to such skills for humans or for machines if for machines why are you citing papers for humans and how sure are you they are referring to machines too how many questions the annotators had to annotate were the annotators clear they annotate the questions keeping in mind machines and not people,4.0
49.json,strengths the paper presents an interesting extension to attention based neural mt approaches which leverages source sentence chunking as additional piece of information from the source sentence the model is modified such that this chunking information is used differently by two recurrent layers while one focuses in generating a chunk at a time the other focuses on generating the words within the chunk this is interesting i believe readers will enjoy getting to know this approach and how it performs the paper is very clearly written and alternative approaches are clearly contrasted the evaluation is well conducted has a direct contrast with other papers and evaluation tables and even though it could be strengthened see my comments below it is convincing weaknesses as always more could be done in the experiments section to strengthen the case for chunk based models for example table indicates good results for model and model compared to previous papers but a careful reader will wonder whether these improvements come from switching from lstms to grus in other words it would be good to see the gru tree to sequence result to verify that the chunk based approach is still best another important aspect is the lack of ensembling results the authors put a lot of emphasis is claiming that this is the best single nmt model ever published while this is probably true in the end the best wat system for eng jap is at if i am reading the table correctly it an ensemble of if the authors were able to report that their way chunk based ensemble comes top of the table then this paper could have a much stronger impact finally table would be more interesting if it included decoding times the authors mention briefly that the character based model is less time consuming presumably based on eriguchi et al but no cite is provided and no numbers from chunk based decoding are reported either is the chunk based model faster or slower than word based similar who know adding a column to table with decoding times would give more value to the paper general discussion overall i think the paper is interesting and worth publishing i have minor comments and suggestions to the authors about how to improve their presentation in my opinion of course i think they should clearly state early on that the chunks are supplied externally in other words that the model does not learn how to chunk this only became apparent to me when reading about cabocha on page i do not think it mentioned earlier and it is important i do not see why the authors contrast against the char based baseline so often in the text at least a couple of times they boast a bleu gain i do not think readers are bothered readers are interested in gains over the best baseline it would be good to add a bit more detail about the way unks are being handled by the neural decoder or at least add a citation to the dictionary based replacement strategy being used here the sentence in line we train a gru that encodes a source sentence into a single vector is not strictly correct the correct way would be to say that you do a bidirectional encoder that encodes the source sentence into a set of vectors at least that what i see in figure the motivating example of lines is a bit weird does you depend on bite or does it depend on the source side because if it does not depend on bite then the argument that this is a long dependency problem does not really apply,4.0
49.json,summary this paper introduces chunk level architecture for existing nmt models three models are proposed to model the correlation between word and chunk modelling on the target side in the existing nmt models strengths the paper is well written and clear about the proposed models and its contributions the proposed models to incorporating chunk information into nmt models are novel and well motivated i think such models can be generally applicable for many other language pairs weaknesses there are some minor points listed as follows figure i am a bit surprised that the function words dominate the content ones in a japanese sentence sorry i may not understand japanese in all equations sequences vectors like matrices should be represented as bold texts to distinguish from scalars e g hi xi c s equation sj instead of sj line all encoder states should be referred to bidirectional rnn states line a bit confused about the phrase non sequential information such as chunks is chunk still sequential information equation a bit confused e g perhaps insert k into s w like s w k to indicate the word in a chunk some questions for the experiments table source language statistics for the baselines why not running a baseline without using any chunk information instead of using li et al baseline vsrc is different it would be easy to see the effect of chunk based models did li et al and other baselines use the same pre processing and post processing steps other baselines are not very comparable after authors response i still think that li et al baseline can be a reference but the baseline from the existing model should be shown figure baseline result will be useful for comparison chunks in the translated examples are generated automatically by the model or manually by the authors is it possible to compare the no of chunks generated by the model and by the bunsetsu chunking toolkit in that case the chunk information for dev and test in table will be required btw the authors response did not address my point here i am bit surprised about the beam size used in the decoding process i suppose large beam size is likely to make the model prefer shorter generated sentences past tenses should be used in the experiments e g line we use used line we perform performed use used general discussion overall this is a solid work the first one tackling the chunk based nmt and it well deserves a slot at acl,4.0
496.json,strengths the authors have nice coverage of a different range of language settings to isolate the way that relatedness and amount of morphology interact i e translating between closely related morphologically rich languages vs distant ones in affecting what the system learns about morphology they include an illuminating analysis of what parts of the architecture end up being responsible for learning morphology particularly in examining how the attention mechanism leads to more impoverished target side representations their findings are of high interest and practical usefulness for other users of nmt weaknesses they gloss over the details of their character based encoder there are many different ways to learn character based representations and omitting a discussion of how they do this leaves open questions about the generality of their findings also their analysis could have been made more interesting had they chosen languages with richer and more challenging morphology such as turkish or finnish accompanied by finer grained morphology prediction and analysis general discussion this paper brings insight into what nmt models learn about morphology by training nmt systems and using the encoder or decoder representations respectively as input feature representations to a pos or morphology tagging classification task this paper is a straightforward extension of does string based neural mt learn source syntax using the same methodology but this time applied to morphology their findings offer useful insights into what nmt systems learn,4.0
496.json,strengths this paper describes experiments that aim to address a crucial problem for nmt understanding what does the model learn about morphology and syntax etc very clear objectives and experiments effectively laid down good state of the art review and comparison in general this paper is a pleasure to read sound experimentation framework encoder decoder recurrent layer outputs are used to train pos morphological classifiers they show the effect of certain changes in the framework on the classifier accuracy e g use characters instead of words experimentation is carried out on many language pairs interesting conclusions derived from this work and not all agree with intuition weaknesses the contrast of character based vs word based representations is slightly lacking nmt with byte pair encoding is showing v strong performance in the literature it would have been more relevant to have bpe in the mix or replace word based representations if three is too many section while higher layers are more focused on word meaning similar sentence in section i am ready to agree with this intuition but i think the experiments in this paper do not support this particular sentence therefore it should not be included or it should be clearly stressed that this is a reasonable hypothesis based on indirect evidence translation performance improves but morphology on higher layers does not discussion this is a fine paper that presents a thorough and systematic analysis of the nmt model and derives several interesting conclusions based on many data points across several language pairs i find particularly interesting that a the target language affects the quality of the encoding on the source side in particular when the target side is a morphologically poor language english the pos tagger accuracy for the encoder improves b increasing the depth of the encoder does not improve pos accuracy more experiments needed to determine what does it improve c the attention layer hurts the quality of the decoder representations i wonder if a and c are actually related the attention hurts the decoder representation which is more difficult to learn for a morphologically rich language in turn the encoders learn based on the global objective and this backpropagates through the decoder would this not be a strong indication that we need separate objectives to govern the encoder decoder modules of the nmt model,4.0
435.json,this paper proposes a method for detecting causal relations between clauses using neural networks deep learning although as in many studies the networks are not particularly deep indeed while certain discourse connectives are unambiguous regarding the relation they signal e g because is causal the paper takes advantage of a recent dataset called altlex by hidey and mckeown to solve the task of identifying causal vs non causal relations when the relation is not explicitly marked arguing that convolutional networks are not as adept as representing the relevant features of clauses as lstms the authors propose a classification architecture which uses a glove based representation of clauses input in an lstm layer followed by three densely connected layers tanh and a final decision layer with a softmax the best configuration of the system improves by f over hidey and mckeown one svm classifier several examples of generalizations where the system performs well are shown indicator words that are always causal in the training data but are found correctly to be non causal in the test data therefore i appreciate that the system is analyzed qualitatively and quantitatively the paper is well written and the description of the problem is particularly clear however a clarification of the differences between this task and the task of implicit connective recognition would be welcome this could possibly include a discussion of why previous methods for implicit connective recognition cannot be used in this case it is very appreciable that the authors uploaded their code to the submission site i inspected it briefly but did not execute it uploading the older data with the code is also useful as it provides many examples it was not clear to me what is the meaning of the coding in the tsv files given that the paper mentions binary classification i wonder also given that this is the data from hidey and mckeown if the authors have the right to repost it as they do one point to clarify in the paper would be the meaning of bootstrapping which apparently extends the corpus by about while the construction of the corpus is briefly but clearly explained in the paper the additional bootstrapping is not while it is certainly interesting to experiment with neural networks on this task the merits of the proposed system are not entirely convincing it seems indeed that the best configuration among options is found on the test data and it is this best configuration that is announced as improving over hidey by f however a fair comparison would involve selecting the best configuration on the devset moreover it is not entirely clear how significant the improvement is on the one hand it should be possible given the size of the dataset to compute some statistical significance indicators on the other hand one should consider also the reliability of the gold standard annotation itself possibly from the creators of the dataset upon inspection the annotation obtained from the english simpleenglish wikipedia is not perfect and therefore the scores might need to be considered with a grain of salt finally neural methods have been previously shown to outperform human engineered features for binary classification tasks so in a sense the results are rather a confirmation of a known property it would be interesting to see experiments with simpler networks used as baselines e g a layer lstm the analysis of results could try to explain why the neural method seems to favor precision over recall,3.0
103.json,this paper proposes a method for evaluating topic quality based on using word embeddings to calculate similarity either directly or indirectly via matrix factorisation achieving impressive results over standard datasets the proposed method represents a natural but important next step in the evolutionary path of research on topic evaluation the thing that troubled me most with the results was that while you achieve state of the art results for all three datasets there are large inconsistencies in which methods perform and which methods perform less well below the state of the art in practice none of the proposed methods consistently beats the state of the art and the svd based methods perform notably badly over the genomics dataset for someone who wants to take your method off the shelf and use it over any arbitrary dataset this is a considerable worry i suspect that the lower results for svd over genomics relate to the proportion of oov terms see comment below and that it may be possible to automatically predict which method will perform best based on vocab match with glove etc but there is no such discussion in the paper other issues the proposed method has strong similarities with methods proposed in the lexical chaining literature which i would encourage the authors to read up on and include in any future version of the paper you emphasis that your method has no parameters but the word embedding methods have a large number of parameters which are implicit in your method not a huge deal but worth acknowledging how does your method deal with oov terms e g in the genomics dataset i e terms not present in the pretrained glove embeddings are they simply ignored what impact does this have on the method low level issues in your description of word embeddings in section you implicitly assume that the length of the vector is unimportant in saying that cosine similarity can be used to measure the similarity between two vectors if the vectors are unit length this is unproblematic but wordvec actually does not return unit length vectors the pre trained vectors have been normalised post hoc and if you run wordvec yourself the vector length is certainly not uniform a small detail but important the graphs in figure are too small to be readable,2.0
103.json,this paper proposes a new method for the evaluation of topic models that partitions the top n words of each topic into clusters or buckets based on cosine similarity of their associated word embeddings in the simplest setup the words are considered one by one and each is either put into an existing bucket â if its cosine similarity to the other words in the bucket is below a certain threshold â or a new bucket is created for the word two more complicated methods based on eigenvectors and reorganisation are also suggested the method is evaluated on three standard data sets and in a weakly supervised text classification setting it outperforms or is en par with the state of the art rã der et al the basic idea behind the paper is rather simple and has a certain ad hoc flavour the authors do not offer any new explanations for why topic quality should be measurable in terms of wordâ word similarity it is not obvious to me why this should be so given that topics and word embeddings are defined with respect to two rather different notions of context document vs sequential context at the same time the proposed method seems to work quite well i would like to see some significance tests for table though overall the paper is clearly written even though there are some language issues also i found the description of the techniques in section a bit hard to follow i believe that this is mostly due to the authors using passive voice the threshold is computed as in places were they were actually making a design choice i find that the authors should try to explain the different methods more clearly with one subsection per method there seems to be some space for that the authors did not completely fill the pages of content and they could easily downsize the rather uninformative trace of the method on page one question that i had was how sensitive the proposed technique was to different word embeddings for example how would the scores be if the authors had used wordvec instead of glove,3.0
98.json,this paper presents results on the ud treebanks to test delexicalized transfer parsers and an unsupervised parser which is enriched with external probabilities the paper is interesting but i think it could be improved further mcdonald et al presented of averaged accuracy over languages on the same languages our transfer parser on ud reached mcdonald et al could not use the ud treebanks since they were not available you should definitely state that this is the case here in footnote you say we used the malt parser with its default feature set tuning in this specific delexicalized task would probably bring a bit better results you are using maltparser with default settings why do not you use maltoptimizer optimizing one model would be very easy in the same way mstparser could be optimized further in the same line why do not you use more recent parsers that produce better results these parsers have been already applied to universal dependencies with the leave one out setup see references below for instance the authors say that the unsupervised parser performs better for languages from less resourced language families non indo european it would be interesting to see whether this holds with more recent and cross lingual parsers probabilities why do you use this probabilities it seems like a random decision tables esp at least we need more details or a set of experiments to see whether they make sense or not there are some papers that the authors should take into account cross lingual dependency parsing with universal dependencies and predicted pos labels j tiedemann one model two languages training bilingual parsers with harmonized treebanks d vilares ma alonso c gã³mez rodrã guez it presents results with maltparser and for results with more recent parsers and also delexicalized parsers crosslingual dependency parsing based on distributed representations jiang guo wanxiang che david yarowsky haifeng wang and ting liu in proc of acl many languages one parser w ammar g mulcaire m ballesteros c dyer na smith minor points i do not think we need table and table this could be solved with a footnote to the ud website perhaps table should be included due to the probabilities but table definitely not,2.0
98.json,this paper evaluates a minimally supervised dependency parser a version of the dmv model with manually set prior probabilities on most of the treebanks from universal dependencies v it reports results that are on average slightly lower than a couple of delexicalized transfer parsers but sometimes substantially better on a few non indo european languages the idea of biasing an otherwise unsupervised parser with some basic universal rules have been used a number of times before in the literature so the main value of the present paper is an empirical evaluation of this approach on the new ud treebanks however the approach and evaluation leaves some questions unanswered first of all i want to know why only unlabeled parsing is considered this may have been appropriate or at least necessary before dependency labels were standardised but the whole point of ud is to give a uniform analysis in terms of typed dependencies and any parsing approach that does not take this into account seems misguided and since the approach is based on manually defined universal rules it would have been easy enough to formulate rules for labeled dependencies second i would like to know more about how the prior probabilities were set or in other words what universal grammar they are meant to encode and how were alternatives tested and if so how were they evaluated in the present version of the paper we are just presented with a bunch of numbers without any explanation or justification except that they are â based on ud annotation styleâ third one of the main claims of the paper is that the unsupervised system works better for non indo european languages this seems to be supported by the raw numbers but what exactly is going on here what types of dependencies are handled better by the unsupervised system even though a full error analysis would be out of scope in a short paper an analysis of a small sample could be really interesting finally the comparison to the delexicalized transfer parsers seems to be biased by a number of factors restricting it to unlabeled dependencies is one such thing since the delexicalized parser could easily have produced labeled dependencies another thing is the amount of training data which was arbitrarily restricted to tokens per treebank finally it seems that the delexicalized parsers were not properly tuned just replacing word forms and lemmas by underscores without revising the feature models is not likely to produce optimal results,3.0
163.json,the aim of this paper is to show that distributional information stored in word vector models contain information about pos labels they use a version of the bnc annotated with ud pos and in which words have been replaced by lemmas they train word embeddings on this corpus then use the resulting vectors to train a logistic classifier to predict the word pos evaluations are performed on the same corpus using cross validation as well as on other corpora results are clearly presented and discussed and analyzed at length the paper is clear and well written the main issue with this paper is that it does not contain anything new in terms of nlp or ml it describe a set of straightforward experiments without any new nlp or ml ideas or methods results are interesting indeed in so far that they provide an empirical grounding to the notion of pos in that regard it is certainly worth being published in a quantitative emprirical linguistic venue on another note the literature on pos tagging and pos induction using word embeddings should be cited more extensively cf for instance lin ammar duer and levin ling et al emnlp plank sã gaard and goldberg,2.0
163.json,general comments this paper presents an exploration of the connection between part of speech tags and word embeddings specifically the authors use word embeddings to draw some interesting if not somewhat straightforward conclusions about the consistency of pos tags and the clear connection of word vector representations to pos the detailed error analysis outliers of classification is definitely a strong point of this paper however the paper seems to have missing one critical main point the reason that corpora such as the bnc were pos tagged in the first place unlike a purely linguistic exploration of morphosyntactic categories which are underlined by a semantic prototype theory e g see croft these corpora were created and tagged to facilitate further nlp tasks mostly parsing the whole discussion could then be reframed as whether the distinctions made by the distributional vectors are more beneficial to parsing as compared to the original tags or upos for that matter also this paper is missing a lot of related work in the context of distributional pos induction i recommend starting with the review christodoulopoulos et al and adding some more recent non dnn work including blunsom and cohn yatbaz et al etc in light of this body of work the results of section are barely novel there are systems with more restrictions in terms of their external knowledge that achieve comparable results specific issues in the abstract one of the contributed results is that distributional vectors do contain information about pos affiliation unless i am misunderstanding the sentence this is hardly a new result especially for english every distributionally based pos induction system in the past years that presents many to one or cluster purity numbers shows the same result the assertion in lines relations between vectors are mostly semantic is not correct the mikolov or colobert paper and subsequent work shows that there is a lot of syntactic information in these vectors also see previous comment about cluster purity scores in fact you revert that statement in the beginning of section lines why move to upos surely the fine grained distinctions of the original tagset are more interesting i do not understand footnote were these failed attempts performed by you or other works under what criteria did they fail what about brown cluster vectors they almost perfectly align with upos tags is the observation that proper nouns are not much similar to common nouns lines that interesting does not the existence of the the most frequent function word almost singlehandedly explain this difference while i understand the practical reasons for analysing the most frequent word tag pairs it would be interesting to see what happens in the tail both in terms of the vectors and also for the types of errors the classifier makes you could then try to imagine alternatives to pure distributional and morphological since you are lemmatizing features that would allow better generalizations of the pos tags to these low frequency words minor issues change the sentential references to newcite e g mikolov et al b showed,2.0
7.json,i am buying some of the motivation the proposed method is much faster to train than it is to train a neural network also it keeps some properties of the distribution when going to lower dimensionality however i am not convinced why it is so important for vectors to be transformable with ppmi most importantly there is no direct comparison to related work detailed comments p the definition of kendall tau that the authors use is strange this is not the original formula i am not sure what it is and where it comes from p why not use spearman correlation as is standard in semantic tasks and as teh authors do at evaluation time the datasets chosen for evaluation are not the standard ones for measuring semantic relatedness that the nlp community prefers it is nice to try other sets but i would recommend to also include results on the standard ones i can only see two lines on figure where is the third line there is no direct comparison to related work just a statement that some typos large extend extent,2.0
7.json,the paper presents a positive only projection pop word embedding method this is a random projection method with a random projection matrix whose expected value is positive the authors argue that this enables the application of ppmi which is not possible with an expected value of and that being a random projection method their computation is efficient my main reservation about this paper has to do with its clarity particularly i could not understand the core difference between the method proposed in the paper and previous random projection methods hence i could not understand how and whether the advantages the authors argue to achieve hold it was hard to follow the arguments of the paper starting from the introduction some of the arguments of the paper are not supported line sentence starts with in addition line sentence starts with since line sentence starts with thus while i have worked on vector space modeling who has not i am not an expert to random projections and have not used them in my research it was hard for me to understand the logic behind this research avenue from the paper i believe that a paper should be self contained and possible to follow by people with some experience in the field the paper has lots of english mistakes to a large extend such ppmi in addition i cannot see why the paper is evaluating only on men there are a couple of standard benchmarks men wordseim simlex and a couple of others if you present a new method i feel that it is insufficient to evaluate only on one dataset unless you provide a good justification i recommend that the authors will substantially improve the presentation in the paper and will resubmit to another conference,2.0
143.json,this paper describes four methods of obtaining multilingual word embeddings and a modified qvec metric for evaluating the efficacy of these embeddings the embedding methods are multicluster uses a dictionary to map words to multilingual clusters cluster embeddings are then obtained which serve as embeddings for the words that reside in each cluster multicca extends the approach presented by faruqui and dyer for embedding bilingual words to multilingual words by using english embeddings as the anchor space bilingual dictionaries otherlanguage english are then used to obtain projections from other monolingual embeddings for words in other languages to the anchor space multiskip extends the approach presented by luong et al b for embedding using source and target context via alignment to the multilingual case by extending the objective function to include components for all available parallel corpora translation invariance uses a low rank decomposition of the word pmi matrix with an objective with includes bilingual alignment frequency components may only work for bilingual embeddings the evaluation method uses cca to maximize the correlation between the word embeddings and possibly hand crafted linguistic data basis vectors are obtained for the aligned dimensions which produce a score which is invariant to rotation and linear transformations the proposed method also extends this to multilingual evaluations in general the paper is well written and describes the work clearly a few major issues what is the new contribution with respect to the translation invariance embedding approach of gardner et al if it is the extension to multilingual embeddings a few lines explaining the novelty would help the use of super sense annotations across multiple languages is a problem the number of features in the intersection of multiple languages may become really small how do the authors propose to address this problem beyond footnote how much does coverage affect the score in table for example for dependency parsing multi cluster and multicca have significantly different coverage numbers with scores that are close in general the results in table do not tell a consistent story mainly for most of the intrinsic metrics the multilingual embedding techniques do not seem to perform the best given that one of the primary goals of this paper was to create embeddings that perform well under the word translation metric intra language it is disappointing that the method that performs best by far is the invariance approach it is also strange that the multi cluster approach which discards inter cluster word and language semantic information performs the best with respect to the extrinsic metrics other questions for the authors what is the loss in performance by fixing the word embeddings in the dependency parsing task what was the gain by simply using these embeddings as alternatives to the random embeddings in the lstm stack parser is table an average over the embeddings described in section are there any advantages of using the multi skip approach instead of learning bilingual embeddings and performing multi cca to learning projections across the distinct spaces the dictionary extraction approach from parallel corpora via alignments or from google translate may not reflect the challenges of using real lexicons did you explore the use of any real multi lingual dictionaries,3.0
143.json,this paper proposes two dictionary based methods for estimating multilingual word embeddings one motivated in clustering multicluster and another in canonical correlation analysis multicca in addition a supersense similarity measure is proposed that improves on qvec by substituting its correlation component with cca and by taking into account multilingual evaluation the evaluation is performed on a wide range of tasks using the web portal developed by the authors it is shown that in some cases the proposed representation methods outperform two other baselines i think the paper is very well written and represents a substantial amount of work done the presented representation learning and evaluation methods are certainly timely i also applaud the authors for the meticulous documentation my general feel about this paper however is that it goes perhaps in too much breadth at the expense of some depth i would prefer to see a thorougher discussion of results e g regarding the conflicting outcome for multicluster between and language set up regarding the effect of estimation parameters and decisions in multicluster cca so while i think the paper is of high practical value to me and the research community improved qvec measure web portal i frankly have not learned that much from reading it i e in terms of research questions addressed and answered below are some more concrete remarks it would make sense to include the correlation results table for monolingual qvec and qvec cca as well after all it is stated in l that the proposed qvec cca is an improvement over qvec minor l a combination of several cross lingual word similarity datasets this sounds as though they are of different nature whereas they are really of the same kind just different languages right p two equations exceed the column margin lines and only mention coulmance et al and guo et al when referring to the multiskip baseline but section then only mentions luong et al so what is the correspondence between these works while i think the paper does reasonable justice in citing the related works there are more that are relevant and could be included multilingual embeddings and clustering chandar a p s lauly s larochelle h khapra m m ravindran b raykar v c and saha a an autoencoder approach to learning bilingual word representations in nips hill f cho k jean s devin c and bengio y embedding word similarity with neural machine translation arxiv preprint arxiv lu a wang w bansal m gimpel k livescu k deep multilingual correlation for improved word embeddings in naacl faruqui m dyer c an information theoretic approach to bilingual word clustering in acl multilingual training of embeddings for the sake of better source language embeddings suster s titov i and van noord g bilingual learning of multi sense embeddings with discrete autoencoders in naacl hlt guo j che w wang h and liu t learning sense specific word embeddings by exploiting bilingual resources in coling more broadly translational context has been explored e g in diab m resnik p an unsupervised method for word sense tagging using parallel corpora in acl,3.0
129.json,the paper describes a method for in domain data selection for smt with a convolutional neural network classifier applying the same framework as johnson and zhang the method performs about bleu points better than language model based data selection and unlike the other methods is robust even if only a very small in domain data set is provided the paper claims improvements of bleu points however from the results we see that improvements of this magnitude are only achieved if there are in domain data in the training set training only on the in domain data already produces bleu it might be interesting to also compare this to a system which interpolates separate in and out domain models the more impressive result in my opinion comes from the second experiment which demonstrates that the cnn classifier is still effective if there is very little in domain data however the second experiment is only run on the zhen task which includes actual in domain data in the training set possibly making selection easier would the result also hold for the other tasks where there is no in domain data in the training set the results for the enes and enzh task already point in this direction since the development sets only contain a few hundred sentence pairs i think the claim would be better supported if results were reported for all tasks when only sentence pairs are used for training when translating social media text one often has to face very different problems from other domains the most striking being a high oov rate due to non conventional spelling for latin scripts at least the texts can also contain special character sequences such as usernames hashtags or emoticons was there any special preprocessing or filtering step applied to the data since data selection cannot address the oov problem it would be interesting to know in more detail what kinds of improvements are made through adaptation via data selection maybe by providing examples the following remarks concern specific sections section it could be made clearer how the different vectors word embeddings segment vectors and one hot vectors are combined in the model an illustration of the architecture would be very helpful what was the designated loss function section for completeness sake it could be mentioned how the system weights were tuned,4.0
66.json,this paper presents a stack lstm parser based on the work of henderson et al on joint syntactic semantic transition based parsing and dyer et al on stack lstm syntactic parsing the use of the transition system from the former and the stack lstm from the latter shows interesting results compared to the joint systems on the conll and shared tasks i like this paper a lot because it is well written well explained the related work is good and the results are very interesting the methodology is sound with a minor concern regarding the chinese embeddings leading me to believe than very good embeddings can be more informative than a very clever model moreover the description of the system is clear the hyperparameters are justified and the discussion is interesting the only thing i would say is that the proposed system lacks originality in the sense that the work of henderson et al puts the basis of semi synchronised joint syntax semantic transition based parsing several years ago and dyer et al came up with the stack lstm last year so it is not a new method per say but in my opinion we were waiting for such a parser to be designed and so i am glad it was done here,5.0
66.json,general comments the paper presents a joint syntactic and semantic transition based dependency parser inspired from the joint parser of henderson et al the authors claim two main differences vectorial representations are used for the whole parser state instead of the top elements of the stack the last parser configurations the algorithm is a plain greedy search the key idea is to take advantage of stack lstms so that the vector representing the state of the parser keeps memory of potentially large scoped syntactic features which are known to be decisive features for semantic role labeling such as the path between the predicate and the candidate role filler head the system is tested on the conll data set english and on the multilingual conll data set the authors compare their system performance to previously reported performances showing their system does well compared to the systems but less compared to more recent proposals cf bottom of table they emphasized though that the proposed system does not require any hand craft features and is fast due to the simple greedy algorithm the paper is well written and describes a substantial amount of work building on the recently popular lstms applied to the henderson et al algorithm which appears now to have been somewhat visionary i have reservations concerning the choice of the simple greedy algorithm it renders results not comparable to some of the cited works it would not have been too much additional work nor space to provide for instance beam searched performance more detailed comments questions section a comment on the presence of both a and c a links would help understanding better the target task of the paper a summary of the differences between the set of transitions used in this work and that of henderson et al should be provided in its current form it is difficult to tell what is directly reused from henderson et al and what is new slightly modified section why do you need representations concatenating the word predicate and its disambiguated sense this seems redundant since the disambiguated sense are specific to a predicate section the organization if the sections is confusing concerning multilinguality conll focused on english and conll shared task extended it to a few other languages,4.0
66.json,this paper performs an overdue circling back to the problem of joint semantic and syntactic dependency parsing applying the recent insights from neural network models joint models are one of the most promising things about the success of transition based neural network parsers there are two contributions here first the authors present a new transition system that seems better than the hendersen system it is based on the other contribution is to show that the neural network succeeds on this problem where linear models had previously struggled the authors attribute this success to the ability of the neural network to automatically learn which features to extract however i think there another advantage to the neural network here that might be worth mentioning in a linear model you need to learn a weight for each feature class pair this means that if you jointly learn two problems you have to learn many more parameters the neural network is much more economical in this respect i suspect the transition system would work just as well with a variety of other neural network models e g the global beam search model of andor there are many other orthogonal improvements that could be made i expect extensions to the authors method to produce state of the art results it would be nice to see an attempt to derive a dynamic oracle for this transition system even if it only in an appendix or in follow up work at first glance it seems similar to the arc eager oracle the m s action excludes all semantic arcs between the word at the start of the buffer and the words on the semantic stack and the m d action excludes all semantic arcs between the word at the top of the stack and the words in the buffer the l and r actions seem to each exclude the reverse arc and no other,5.0
165.json,this paper proposes a method for discovering correspondences between languages based on mdl the author model correspondences between words sharing the same meaning in a number of slavic languages they develop codes for rules that match substrings in two or more languages and formulate an mdl objective that balances the description of the model and the data given the model the model is trained with em and tested on a set of slavic languages the results are shown by several distance measures a phylogenetic tree and example of found correspondences the motivation and formulation of the approach makes sense mdl seems like a reasonable tool to attack the problem and the motivation for employing em is presented nicely i must admit though that some of the derivations were not entirely clear to me the authors point out the resemblance of the mdl objective to bayesian inference and one thinks of the application of bayesian inference in biological phylogenetic inference e g using the mrbayes tool an empirical comparison here could be insightful related work lacking comparison to methods for borrowing and cognate detection or other computational methods for historical linguistics for example the studies by alexandre bouchard cote tandy warnow luay nakhleh and andrew kitchen some may not have available tools to apply in the given dataset but one can mention list and moran there are also relevant tools for biological phylogeny inference that can be applied paup mrbayes etc approach and methodology alignment procedure the memory runtime bottleneck appears to be a major drawback allowing the comparison of only languages at most as long as multiple languages are involved and phylogenetic trees it would be interesting to see more languages i am curious what ideas the authors have for dealing with this issue phylogenetic tree using neighbor joining for creating phylogenetic trees is known to have disadvantages like having to specify the root manually how about more sophisticated methods do you run em until convergence or have some other stopping criterion data two datasets are mixed one of cognates and one not necessarily the swadesh lists have you considered how this might impact the results the data is in orthographic form which might hide many correspondences this is especially apparent in languages with different scripts therefore the learned rules might indicate change of script more than real linguistic correspondences this seems like a shortcoming that could be avoided by working on the level of phonetic transcriptions unclear points what is the optimal unigram for symbol usages in all rules line the merging done in the maximization step was not entirely clear to me minor issue focus in on focus on line refs johann mattis list steven moran an open source toolkit for quantitative historical linguistics proceedings of the st annual meeting of the association for computational linguistics system demonstrations pages â sofia bulgaria association for computational linguistics http www aclweb org anthology p andrew kitchen christopher ehret shiferaw assefa and connie j mulligan bayesian phylogenetic analysis of semitic languages identifies an early bronze age origin of semitic in the near east,3.0
132.json,a combination of wordvec and lda could be potentially interesting the main problem with the current paper is that the technical details are incomprehensible section needs a complete rewrite so that a reader familiar with wordvec and lda could relatively easily get a high level picture of how the models are being combined the current presentation does not achieve that more detailed comments the third paragraph of the introduction makes no sense to me requires deriving a new approximation approximation of what why is it time consuming to develop prototypes why is it easier to evaluate features why use the same word vectors for pivot and target unlike in wordvec what is the motivation for that decision what does it mean to separate words from a marginal distribution what is co adaptation if we only included structure up to this point what kind of structure it similarity its footnote breaks anonymity there does not appear to be any evaluation the days when it was ok to just give some example clusters are long gone in nlp figure looks like it might be a quantitative evaluation but it only described in the overly long caption the statement in the conclusion that the model solves word analogies is overstating what was shown which was just a few cherry picked examples of king queen etc sort the chang ref has the conference journal name as advances in you would like me to guess the venue,2.0
132.json,this paper proposes a neural styled topic model extending the objective of wordvec to also learn document embeddings which it then constrains through sparsification hence mimicking the output of a topic model i really liked the model that the authors proposed and found the examples presented by the authors to be highly promising what was really missing from the paper however was any empirical evaluation of the model evaluation entirely falls back on tables of examples without any indication of how representative the examples are or any attempt to directly compare with standard or neural topic models without empirical evaluation it is impossible to get a sense of the true worth of the model making it very hard to accept the paper some ideas of how the authors could have achieved this use the topic representation of each document in a supervised document categorisation setup to compare against a topic model with the same topic cardinality i e as an indirect evaluation of the quality of the representation or through direct evaluation over a dataset with document similarity annotations based on pairwise comparison over topic vectors it fantastic that you are releasing code but you have compromised anonymity in publishing the github link in the submitted version of the paper strictly speaking this is sufficient for the paper to be rejected outright but i leave that up to the pcs other issues how did you select the examples in figures presenting a subset of the actual topics etc potentially reeks of cherry picking in section you discuss the possibility of calculating word representations for topics based on pairwise comparison with each word in the vocabulary but this is going to be an extremely expensive process for a reasonable vocab size and number of topics is this really feasible you say that you identify tokens using spacy in section how you extract noun chunks but not any other chunk type similarly to the section or something else given that you go on to say that you use wordvec pre trained embeddings which include only small numbers of multiword terms it was not clear what you were doing here how does your model deal with oov terms yes in the experiments you report in the paper you appear to train the model over the entire document collection so it perhaps is not an immediate problem but there will be contexts where you want to apply the trained model to novel documents in which case the updating of the wordvec token embeddings is going to mean that any non updated oov relative to the training collection wordvec embeddings are not going to be directly comparable to the tuned embeddings the finding that topics worked best over the newsgroups corpus was not surprising given its composition possibly another very simple form of evaluation here could have been based on some information theoretic comparison relative to the true document labels where again you would have been able to perform a direct comparison with lda etc a couple of other neural topic models that you meed to compare yourself with are cao ziqiang sujian li yang liu wenjie li and heng ji a novel neural topic model and its supervised extension in aaai pp nguyen dat quoc richard billingsley lan du and mark johnson improving topic models with latent feature word representations transactions of the association for computational linguistics shamanta debakar sheikh motahar naim parang saraf naren ramakrishnan and m shahriar hossain concurrent inference of topic models and distributed vector representations in machine learning and knowledge discovery in databases pp springer international publishing low level things line it similarity its similarity line what does it mean for the topic basis to be affected and the are is awkward here in the caption of figure the examples should perhaps be terms rather than words the reference formatting is all over the place e g advances in advances in neural roder et al is missing the conference name etc,2.0
11.json,the authors present a new version of the coreference task tailored to wikipedia the task is to identify the coreference chain specifically corresponding to the entity that the wikipedia article is about the authors annotate documents with all coreference chains of which roughly of the mentions refer to the main concept of the article they then describe some simple baselines and a basic classifier which outperforms these moreover they integrate their classifier into the stanford rule based coreference system and see substantial benefit over all state of the art systems on wikipedia i think this paper proposes an interesting twist on coreference that makes good sense from an information extraction perspective has the potential to somewhat revitalize and shake up coreference research and might bridge the gap in an interesting way between coreference literature and entity linking literature i am sometimes unimpressed by papers that dredge up a new task that standard systems perform poorly on and then propose a tweak so that their system does better however in this case the actual task itself is quite motivating to me and rather than the authors fishing for a new domain to run things in it really does feel like hey wait these standard systems perform poorly in a setting that actually pretty important the task main concept resolution is an intriguing task from an ie perspective i can imagine many times where documents revolve primarily around a particular entity biographical documents dossiers or briefings about a person or event clinical records etc and where the information we care about extracting is specific to that entity the standard coreference task has always had the issue of large numbers of mentions that would seemingly be pretty irrelevant for most ie problems like generic mentions and this task is unquestionably composed of mentions that actually do matter from a methodology standpoint the notion of a main concept provides a bit of a discourse anchor that is useful for coreference but there appears to still be substantial overhead to improve beyond the baselines particularly on non pronominal mentions doing coreference directly on wikipedia also opens the doors for more interesting use of knowledge which the authors illustrate here so i think this domain is likely to be an interesting testbed for ideas which would improve coreference overall but which in the general setting would be more difficult to get robust improvements with and which would be dwarfed by the amount of work dealing with other aspects of the problem moreover unlike past work which has carved off a slice of coreference e g the winograd schema work this paper makes a big impact on the metrics of the overall coreference problem on a domain wikipedia that many in the acl community are pretty interested in the techniques overall the techniques are not the strong point of this paper though they do seem to be effective the features seem pretty sensible but it seems like additional conjunctions of these may help and it unclear whether the authors did any experimentation in this vein the authors should also state earlier in the work that their primary mc resolution system is a binary classifier this is not explicitly stated early enough and the model is left undefined throughout the description of featurization minor details organization i would perhaps introduce the dataset immediately after related works i e have it be the new section so that concrete results can be given in baselines further motivating approach when section refers to dcoref and scoref you should cite the stanford papers or make it clear that it the stanford coreference system many will be unfamiliar with the dcoref scoref names the use of the term candidate list was unclear especially in the following we leverage the hyperlink structure of the article in order to enrich the list of mentions with shallow semantic attributes for each link found within the article under consideration we look through the candidate list for all mentions that match the surface string of the link please make it clear that the candidate list is the set of mentions in the article that are possible candidates for being coreferent with the mc i think most readers will understand that this module is supposed to import semantic information from the link structure of wikipedia e g if a mention is hyperlinked to an article that is female in freebase that mention is female so try to keep the terminology clear section says we consider the union of wcr mentions and all mentions predicted by the method described in raghunathan et al however section implies that these are the same i am missing where additional wcr mentions would be extracted,5.0
86.json,no details are provided on the methods used in this paper to produce the results due to issues of non disclosure restrictions if the reader does not know the learning algorithm or the training data or other resources made use of in the approach then there is nothing in the paper to help with the reader own sentiment analysis methods which is why we share research this is not a research paper hence does not belong in this conference perhaps a submission to a demo session somewhere would be a good idea even with a demo paper however you would need to share more details about the methods used than you do here,1.0
12.json,i reviewed this paper earlier when it was an acl short paper draft at that point it had a flaw in the experiment setup which is now corrected since back then i suggested i would be willing to accept the draft for another acl event provided that the flaw is corrected i now see no obstacles in doing so another reviewer did point out that the setup of the paper is somewhat artificial if we focus on real low resource languages relating to the costs of finding vs paying the annotators i believe this should be exposed in the writeup not to oversell the method there are relevant lines of work in annotation projection for extremely low resource languages e g johannsen et al acl and agic et al acl it would be nice to reflect on those in the related work discussion for completeness in summary i think this is a nice contribution and i vote accept it should be indicated whether the data is made available i evaluate those parts in good faith now presuming public availability of research,4.0
91.json,this paper applies the idea of translation model pruning to neural mt the authors explore three simple threshold and histogram pruning schemes two of which are applied separately to each weight class while the third is applied to the entire model the authors also show that retraining the models produces performance equal to the full model even when of the weights are pruned an extensive analysis explains the superiority of the class blind pruning scheme as well as the performance boost through retraining while the main idea of the paper is simple it seems quite useful for memory restricted applications of nmt i particularly liked the analysis section which gives further insight into the model components that are usually treated like black boxes while these insights are interesting by themselves the paper main motivation is model compression this argument would be stronger if the paper included some numbers on actual memory consumption of the compressed model in comparison to the uncompressed model some minor remarks there is a substantial amount of work on pruning translation models in phrase based smt which could be referenced in related work e g johnson j martin j foster g and kuhn r improving translation quality by discarding most of the phrasetable emnlp or zens r stanton d and peng x a systematic comparison of phrase table pruning techniques emnlp it took me a while to understand figure i would find it more informative to add an additional barplot under figure showing highest discarded weight magnitude by class this would also allow a comparison across all pruning methods,4.0
18.json,the paper presents the first broad coverage semantic parsers for ucca one specific approach to graph based semantic representations unlike conll semantic dependency graphs ucca graphs can contain nonterminal nodes which do not represent words in the string unlike amrs ucca graphs are grounded which the authors take to mean that the text tokens appear as nodes in the semantic representation the authors present a number of parsing methods including a transition based parser that directly constructs ucca parses and evaluate them given that ucca and ucca annotated data exist it seems reasonable to develop a semantic parser for ucca however the introduction and background section hit a wrong note to my ear in that they seem to argue that ucca is the only graph based semantic representation sr formalism that makes sense to be studied this does not work for me and also seems unnecessary a good ucca parser could be a nice contribution by itself i do not entirely agree with the three criteria for semantic representation formalisms the authors lay out in the introduction for instance it is not clear to me that nonterminal nodes contribute any expressive capacity sure it can be inconvenient to have to decide which word is the head of a coordinated structure but exactly what information is it that could only be represented with a nonterminal and not e g with more informative edge labels also the question of discontinuity does not even arise in srs that are not grounded the advantages of grounded representations over amr style ones did not become clear to me i also think that the word grounded has been used for enough different concepts in semantics in the past ten years and would encourage the authors to find a different one anchored lexicalized thus i feel that the entire introductory part of the paper should be phrased and argued much more carefully the parser itself seems fine although i did not check the details however i did not find the evaluation results very impressive on the primary edges even a straightforward maltparser outperforms the bsp parser presented here and the f scores on the remote edges which a dependency tree parser like malt cannot compute directly are not very high either furthermore the conversion of dependency graphs to dependency trees has been studied quite a bit under the name tree approximations in the context of the conll and shared tasks on semantic dependency parsing albeit without nonterminal nodes several authors have proposed methods for reconstructing the edges that were deleted in the graph to tree conversion for instance agic et al semantic dependency graph parsing using tree approximations discuss the issues involved in this reconstruction in detail by incorporating such methods it is likely that the f score of the maltparser and the lstm based maltparser could be improved further and the strength of the bsp parser becomes even less clear to me,2.0
137.json,general comments the paper reports experiments on predicting the level of compositionality of compounds in english the dataset used is a previously existing set of compounds whose compositionality was ranked from to by a non specified number of judges the general form of each experiment is to compute a cosine similarity between the vector of the compound treated as one token and a composition of the vectors of the components evaluation is performed using a spearman correlation between the cosine similarity and the human judgments the experiments vary for the vectors used neural embeddings versus syntactic context count vectors and for the latter case whether plain or aligned vectors should be used for the dependent component of the compound the alignment tries to capture a shift from the dependent to the head alignment were proposed in a previous suppressed reference the results indicate that syntactic context count vectors outperform embeddings and the use of aligned alone performs less well than non modified vectors and a highly tuned combination of aligned and unaligned vectors provides a slight improvement regarding the form of the paper i found the introduction quite well written but other parts like section are difficult to read although the underlying notions are not very complicated rephrasing with running examples could help regarding the substance i have several concerns the innovation with respect to reddy et al seems to be the use of the aligned vectors but they have been published in a previous suppressed reference by the authors the dataset is small and not enough described in particular ranges of frequences are quite likely to impact the results since the improvements using aligned vectors are marginal over a small dataset in which it is unclear how the choice of the compounds was performed i find that the findings in the paper are quite fragile more detailed comments questions section i do not understand the need for the new name packed anchored tree it seems to me a plain extraction of the paths between two lexical items in a dependency tree namely a plain extension of what is traditionally done in syntactic distributional representations of words which typically as far as lin use paths of length one or length with collapsed prepositions further why is it called a tree what are elementary apts section table did not you forget to mention that you discard features of order more than and that why for instance nmod overline nsubj dobj does not appear in leftmost bottom cell of table or does it have to do with the elimination of some incompatible types you mention for which an example should be provided i did not find it very clear section since the reddy et al dataset is central to your work it seems necessary to explain how the compounds were selected what are the frequency ranges of the compounds the components etc there is a lot of chance that results vary depending on the frequency ranges how many judgments were provided for a given compound are there many compounds with same final compositionality score is not it a problem when ranking them to compute the spearman correlation apparently you use constituent for a component of the n n sequence i would suggest component as constituent also has the sense of phrase syntagm the intuition that if a constituent is used literally within a phrase then it is highly likely that the compound and the constituent share co occurrences note the intuition is certainly true if the constituent is the head of the phrase otherwise much less true e g spelling bee does not have the distribution of spelling section note that the elementary representation for the constituent of a compound phrase will not contain any of the contextual features associated with the compound phrase token unless they occurred with the constituent in some other context please provide a running example in order to help the reader follow which object you are talking about does compound phrase token refer to the merged components of the compound section i guess that elementary apts are a triplet target word w dependency path r other word w i find the name confusing clarify whether shifted pmi refer to pmi as defined in equation removing features which tend to go with lots of things low positive pmi means that these phrases appear to have been observed in a very small num ber of highly informative contexts do these phrases co refer with things here the whole sentence seems contradictory please clarify in general we would expect there to be little overlap between apts which have not been prop erly aligned what does not properly aligned means you mean not aligned at all i do not understand paragraph to why should the potential overlap be considerable in the particular case of the nmod relation between the two components paragraph to is quite puzzling why does the whole paper make use of higher order dependency features and then suddenly at the critical point of actually measuring the crucial metric of similarity between composed and observed phrasal vectors you use first order features only note is supposed to provide an answer but i do not understand the explanation of why the nd order paths in the composed representations are not reliable please clarify section smoothing the ppmi calculation with a value of î generally has a small positive effect does not seem so obvious from table what are the optimal values for h and q in equation and they are important in order to estimate how much of hybridity provides the slight gains with respect to the unaligned results it seems that in table results correspond to using the add combination it could help to have this in the legend also could not you provide the results from the wordvec vectors for the compound phrases i do not understand the intuition behind the freq baseline why would a frequent compound tend to be compositional this suggests maybe a bias in the dataset,3.0
176.json,this paper proposes the new to my knowledge step of proposing to treat a number of sentence pair scoring tasks e g answer set scoring rte paraphrasing among others as instances of a more general task of understanding semantic relations between two sentences furthermore they investigate the potential of learning generally applicable neural network models for the family of tasks i find this to be an exciting proposal that worthy of both presentation at conll and further discussion and investigation the main problem i have with the paper is that it in fact feels unfinished it should be accepted for publication only with the proviso that a number of updates will be made for the final version the first results table needs to be completed given the large number of individual results the written discussion of results is terribly short much more interpretation and discussion of the results is sorely needed the abstract promises presentation of a new more challenging dataset which the paper does not seem to deliver this incongruity needs to be resolved the results vary quite a bit across different tasks could some investigation be made into how and why the models fail for some of the tasks and how and why they succeed for others even if no solid answer is found it would be interesting to hear the authors position regarding whether this is a question of modeling or rather dissimilarity between the tasks does it really work to group them into a unified whole please include example instances of the various datasets used including both prototypical sentence pairs and pairs which pose problems for classification the ubu rnn transfer learning model is recommended for new tasks but is this because of the nature of the data is it a more general task or rather the size of the dataset how can we determine an answer to that question despite the unpolished nature of the paper though it an exciting approach that could generate much interesting discussion and i would be happy to see it published in a more finished form i do recognize that this view may not be shared by other reviewers some minor points about language weigh and weighed are consistently used in contexts that rather require weight and weighted there are several misspellings of sentence as sentene what is interpunction one instance of world overlap instead of word overlap,4.0
151.json,the authors proposed an unsupervised algorithm for universal dependencies that does not require training the tagging is based on pagerank for the words and a small amount of hard coded rules the article is well written very detailed and the intuition behind all prior information being added to the model is explained clearly i think that the contribution is substantial to the field of unsupervised parsing and the possibilities for future work presented by the authors give rise to additional research,4.0
13.json,this paper models event linking using cnns given event mentions the authors generate vector representations based on word embeddings passed through a cnn and followed by max pooling they also concatenate the resulting representations with several word embeddings around the mention together with certain pairwise features they produce a vector of similarities using a single layer neural network and compute a coreference score the model is tested on an ace dataset and an expanded version with performance comparable to previous feature rich systems the main contribution of the paper in my opinion is in developing a neural approach for entity linking that combines word embeddings with several linguistic features it is interesting to find out that just using the word embeddings is not sufficient for good performance fortunately the linguistic features used are limited and do not require manually crafted external resources experimental setting it appears that gold trigger words are used rather than predicted ones the authors make an argument why this is reasonable although i still would have liked to see performance with predicted triggers this is especially problematic as one of the competitor systems used predicted triggers so the comparison is not fair the fact that different papers use different train test splits is worrisome i would encourage the authors to stick to previous splits as much as possible unclear points the numbers indicating that cross sentential information is needed are convincing however the last statement in the second paragraph lines was not clear to me embeddings for positions are said to be generaties in a way similar to word embeddings how exactly are they randomly initialized are they lexicalized it is not clear to me why a relative position next to one word should have the same embedding as a relative position next to a different word how exactly are left vs right neighbors used to create the representation lines does this only affect the max pooling operation the word embeddings of one word before and one word after the trigger words are appended to it this seems a bit arbitrary why one word before and after and not some other choice it is not clear how the event mention representation ve line is used in the following sections only v sent lex appear to be used not ve how are pairwise features used in section most features are binary so i assume they are encoded as a binary vector but what about the distance feature for example and are these kept fixed during training other issues and suggestions can the approach be applied to entity coreference resolution as well this would allow comparing with more previous work and popular datasets like ontonotes the use of a square function as nonlinearity is interesting is it novel do you think it has applicability in other tasks datasets one dataset is publicly available but results are also presented with ace which is not do you have plans to release it it would help other researchers compare new methods at least it would have been good to see a comparison to the feature rich systems also on this dataset results some of the numbers reported in the results are quite close significance testing would help substantiating the comparisons related work among the work on entity coreference resolution one might mention the neural network approach by wiseman et al minor issues line that is redundant one of the baselines is referred to as same type in table but same event in the text line refs learning anaphoricity and antecedent ranking features for coreference resolution sam wiseman alexander m rush jason weston and stuart m shieber acl,4.0
683.json,the authors mention that they are not aiming to have sota results however that an ensemble of resnets has lower performance than some of single network results indicates that further experimentation preferably on larger datasets is necessary the literature review could at least mention some existing works such as wide resnets,4.0
683.json,the paper under consideration proposes a set of procedures for incrementally expanding a residual network by adding layers via a boosting criterion the main barrier to publication is the weak empirical validation the tasks considered are quite small scale in and mnist with a convolutional net is basically an uninteresting test by this point the paper does not compare to the literature and cifar results fail to improve upon rather simple single network published baselines springenberg et al for example obtains without data augmentation and i am pretty sure there a simple resnet result somewhere that outshines these too the cifar results are a little bit interesting as they are better than i am used to seeing i have not done a recent literature crawl and this is unsurprising you would expect ensembles to do well when there a dearth of labeled training data and here there are only a few hundred per label but then it typical on both cifar and cifar to use simple data augmentation schemes which are not employed here and these and other forms of regularization are a simpler alternative to a complicated iterative augmentation scheme like this it would be easier to sell this method either as an option for scarce labeled datasets where data augmentation is non trivial but then for most image related applications random crops and reflections are easy and valid but that would necessitate different benchmarks and comparison against simpler methods like said data augmentation dropout especially due to the ensemble interpretation and so on,3.0
379.json,authors describe implementation of tensorflow fold which allows one to run various computations without modifying computation graph they achieve this by creating a generic scheduler as a tensorflow computation graph which can accept graph description as input and execute it they show clear benefits to this approach for tasks where computation changes for each datapoint such as the case with treernn in the experiments they compare against having static batch same graph structure repeated many times and batch size the reason my score is and not higher is because they do not provide comparison to the main alternative of their method someone could create a new tensorflow graph for each dynamic batch in other words instead of using their graph as the scheduling algorithm one could explicitly create each non uniform batch as a tensorflow graph and run that using standard tensorflow,7.0
379.json,the paper presents a novel strategy to deal with dynamic computation graphs they arise when the computation is dynamically influenced by the input data such as in lstms the authors propose an unrolling strategy over the operations done at every step which allows a new kind of batching of inputs the presented idea is novel and the results clearly indicate the potential of the approach for the sake of clarity of the presentation i would drop parts of section a combinator library for neural networks which presents technical details that are in general interesting but do not help the understanding of the core idea of the paper the presented experimental results on the stanford sentiment treebank are in my opinion not supporting the claim of the paper which is towards speed than a little bit confusing it is important to point out that even though the presented ensemble variant sets a new state of the art on both subtasks p this is not due to the framework not even due to the model comp lines and of tab but probably and this can only be speculated about due to the ensemble averaging i would appreciate a clearer argumentation in this respect update on jan th after the authors update for their newest revision i increase my rating to due to the again improved now very clear argumentation,8.0
396.json,the paper presents an interesting framework for image generation which stitches the foreground and background to form an image this is obviously a reasonable approach there is clearly a foreground object however real world images are often quite complicated which may contain multiple layers of composition instead of a simple foreground background layer how would the proposed method deal with such situations overall this is a reasonable work that approaches an important problem from a new angle yet i think sizable efforts remain needed to make it a generic methodology,6.0
396.json,the authors propose a method that generates naturally looking images by first generating the background and then conditioned on the previous layer one or multiple foreground objects additionally they add a image transformer layer that allows the model to more easily model different appearances i would like to see some discussion about the choice of foreground mask rather than just predicting foreground directly for mnist for example the foreground seems completely irrelevant for cub and cifar of course the fg adds the texture and color while the masks ensures a crisp boundary is the mask a binary mask or a alpha blending mask i find the fact that the model learns to decompose images this nicely and learns to produce crisp foreground masks w o too much spurious elements though there are some in cifar pretty fascinating the proposed evaluation metric makes sense and seems reasonable however afaict theoretically it would be possible to get a high score even though the gan produces images not recognizable to humans but only to the classifier network that produces pg e g if the generator encodes the class in some subtle way though this should not happen given the training with an adversarial network fig shows indeed nicely that the decomposition is much nicer when spatial transformers are used however it also seems to indicate that the foreground prediction and the foreground mask are largely redundant for the final results the niceness of the decomposition appears to be largely irrelevant furthermore the transformation layer seems to have a small effect judging from the transformed masked foreground objects they are mainly scaled down what is the rd th column in fig it is not clear if the final composed images are really as bad as advertised regarding the eval experiment using amt it is not clear why it is better to provide the users with l minimized nn matches rather than random pairs i assume that tab adversarial divergence for real images was not actually evaluated it would be interesting to see how close to multiple differently initialized networks actually are also please mention how the confidences std where generated i e different training sets initialisations eval sets and how many runs,7.0
545.json,thank you for an interesting read the ideas presented have a good basis of being true but the experiments are rather too simple it would be interesting to see more empirical evidence pros the approach seems to decrease the training time which is of prime importance in deep learning although that comes at a price of slightly more complex model there is a grounded theory for sum product functions which is basis for the compositional architecture described in the paper theoretically any semiring and kernel could be used for the model which decreases need for handcrafting the structure of the model which is a big problem in existing convolutional neural networks cons the experiments are on very simple dataset norb although it is great to understand a model dynamics on a simpler dataset some analysis on complex datasets are important to act as empirical evidence the compositional kernel approach is compared to convolutional neural networks hence it is only fair to compare said results on large datasets such as imagenet minor section claims that ckms model symmetries of objects it felt that ample justification was not provided for this claim,6.0
512.json,this paper provides a principled framework for nonparametrically learning activation functions in deep neural networks a theoretical justification for authors choice of nonparametric activation functions is given theoretical results are satisfactory but i particularly like the experimental setup where their methods are tested on image recognition datasets and achieve up to a relative increase in test performance compared to the baseline well written paper and novel theoretical techniques the intuition behind the proof of theorem can be given in a little bit more clear way in the main body of the paper but the appendix clarifies everything,7.0
512.json,summary the paper introduces a parametric class for non linearities used in neural networks the paper suggests two stage optimization to learn the weights of the network and the non linearity weights significance the paper introduces a nice idea and present nice experimental results however i find the theoretical analysis not very informative and distractive from the main central idea of the paper a more thorough experimentation with the idea using different basis and comparing it to wider networks equivalent to the number of cosine basis used in the leaned one would help more supporting results in the paper comments are the weights of the non linearity learned shared across all units in all layers or each unit has it is own non linearity if all weights are tied across units and layers one question that would be interesting to study if there is an optimal non linearity how different is the non linearity learned if the hidden units are normalized or un normalized in other words how does the non linearity change if you use or do not use batch normalization does normalization affect the conclusion that polynomial basis fail,6.0
768.json,this paper proposes to learn groups of orthogonal features in a convnet by penalizing correlation among features in each group the technique is applied in the setting of image classification with privileged information in the form of foreground segmentation masks where the model is trained to learn orthogonal groups of foreground and background features using the correlation penalty and an additional background suppression term pros proposes a group wise model diversity loss term which is novel to my knowledge the use of foreground segmentation masks to improve image classification is also novel the method is evaluated on two standard and relatively large scale vision datasets imagenet and pascal voc cons the evaluation is lacking there should be a baseline that leaves out the background suppression term so readers know how much that term is contributing to the performance vs the group orthogonal term the use of the background suppression term is also confusing to me it seems redundant as the group orthogonality term should already serve to suppress the use of background features by the foreground feature extractor it would be nice to see the results with incomplete privileged information on the full imagenet dataset rather than just of it with the privileged information included for the of images where it s available this would verify that the method and use of segmentation masks remains useful even in the regime of more labeled classification data the presentation overall is a bit confusing and difficult to follow for me for example section is titled a unified architecture gocnn yet it is not an overview of the method as a whole but a list of specific implementation details even the very first sentence minor calling eq a regression loss and writing x rather than just x is not necessary and makes understanding more difficult i ve never seen a norm regularization term written this way or described as a regression to minor in fig i think the fg and bg suppression labels are swapped e g the suppress foreground mask has s in the fg and s in the bg which would suppress the bg not the fg an additional question why are the results in table with privileged information different from those in table are these not the same setting the ideas presented in this paper are novel and show some promise but are currently not sufficiently ablated for readers to understand what aspects of the method are important besides additional experiments the paper could also use some reorganization and revision for clarity edit after considering the latest revisions particularly the full imagenet evaluation results reported in table demonstrating that the background segmentation privileged information is beneficial even with the full labeled imagenet dataset i have upgraded my rating from to i will reiterate a very minor point about figure though i still think the and labels in the top part of the figures should be swapped to match the other labels e g the topmost path in figure a with the text suppress foreground currently has in the background and in the foreground when one would want the reverse of this to suppress the foreground,6.0
338.json,thank you for an interesting angle on highway and residual networks this paper shows a new angle to how and what kind of representations are learnt at each layer in the aforementioned models due to residual information being provided at a periodic number of steps each of the layers preserve feature identity which prevents lesioning unlike convolutional neural nets pros the iterative unrolling view was extremely simple and intuitive which was supported by theoretical results and reasonable assumptions figure gave a clear visualization for the iterative unrolling view cons even though the perspective is interesting few empirical results were shown to support the argument the major experiments are image classification and language models trained on mutations of character aware neural language models figure and could be combined and enlarged to show the effects of batch normalization,7.0
338.json,the paper describes an alternative view on hierarchical feature representations in deep neural networks the viewpoint of refining representations is well motivated and is in agreement with the success of recent model structures like resnets pros good motivation for the effectiveness of resnets and highway networks convincing analysis and evaluation cons the effect of this finding of the interpretation of batch normalization is only captured briefly but seems to be significant explanation of findings in zeiler fergus using uie viewpoint missing remarks missing word in line that it is valid,8.0
338.json,this paper provides a new perspective to understanding the resnet and highway net the new perspective assumes that the blocks inside the networks with residual or skip connection are groups of successive layers with the same hidden size which performs to iteratively refine their estimates of the same feature instead of generate new representations under this perspective some contradictories with the traditional representation view induced by resnet and highway network and other paper can be well explained the pros of the paper are a novel perspective to understand the recent progress of neural network is proposed the paper provides a quantitatively experimentals to compare resnet and highway net and shows contradict results with several claims from previous work the authors also give discussions and explanations about the contradictories which provides a good insight of the disadvantages and advantages between these two kind of networks the main cons of the paper is that the experiments are not sufficient for example since the main contribution of the paper is to propose the unrolled iterative estimation and the stage of figure seems not follow the assumption of unrolled iterative estimation and the authors says we note that stage four with three blocks appears to be underestimating the representation values indicating a probable weak link in the architecture thus it would be much better to do experiments to show that under some condition the performance of stage can follow the assumption moreover the paper should provide more experiments to show the evidence of unrolled iterative estimation not comparing resnet with highway net the lack of experiments on this point is the main concern from myself,6.0
504.json,the paper tries to present a first step towards solving the difficult problem of learning from limited number of demonstrations the paper tries to present contributions towards this effort unsupervised segmentation of videos to identify intermediate steps in a process define reward function based on feature selection for each sub task pros the paper is a first attempt to solve a very challenging problem where a robot is taught real world tasks with very few visual demonstrations and without further retraining the method is well motivated and tries to transfer the priors learned from object classification task through deep network features to address the problem of limited training examples as demonstrated in fig the reward functions could be more interpretable and correlate with transitions between subtasks breaking a video into subtasks helps a video demonstration based method achieve comparable performance with a method which requires full instrumentation for complex real world tasks like door opening cons unsupervised video segmentation can serve as a good starting point to identify subtasks however there are multiple prior works in this domain which need to be referenced and compared with particularly video shot detection and shot segmentation works try to identify abrupt change in video to break it into visually diverse shots these methods could be easily augmented with cnn features note that there are multiple papers in this domain eg refer to survey in yuan et al trans on circuits and systems for video tech the authors claim that they did not find it necessary to identify commonalities across demonstrations this limits the scope of the problem drastically and requires the demonstrations to follow very specific set of constraints again it is to be noted that there is past literature video co segmentation eg tang et al eccv which uses these commonalities to perform unsupervised video segmentation the unsupervised temporal video segmentation approach in the paper is only compared to a very simple random baseline for a few sample videos however given the large amount of literature in this domain it is difficult to judge the novelty and significance of the proposed approach from these experiments the authors hypothesize that sparse independent features exists which can discriminate a wide range of unseen inputs and encode this intuition through the feature selection strategy again the validity of the hypothesis is not experimentally well demonstrated for instance comparison to a simple linear classifier for subtasks would have been useful overall the paper presents a simple approach based on the idea that recognizing sub goals in an unsupervised fashion would help in learning from few visual demonstrations this is well motivated as a first step towards a difficult task however the methods and claims presented in the paper need to be analyzed and compared with better baselines,4.0
504.json,this paper proposes a novel method to learn vision feature as intermediate rewards to guide the robot training in the real world since there are only a few sequences of human demonstrations the paper first segments the sequences into fragments so that the features are roughly invariant on the corresponding fragments across sequences then clusters and finds most discriminative features on those fragments and uses them as the reward function the features are from pre trained deep models the idea is simple and seems quite effective in picking the right reward functions fig is a good comparison although it could be better with error bars however some baselines are not strong in particular vision related baselines for example the random reward simply outputs true or false in tbl seems quite arbitrary and may not serve as a good baseline but its performance is still not that bad surprisingly a better baseline would be to use random simpler feature extraction on the image e g binning features and simply picking the most frequent ones which might not be as discriminative as the proposed feature i wonder whether a simpler vision based approach would lead to a similarly performed reward function if so then these delicate steps segment etc altogether,6.0
504.json,the paper explores a simple approach to learning reward functions for reinforcement learning from visual observations of expert trajectories for cases were only little training data is available to obtain descriptive rewards even under such challenging conditions the method re uses a pre trained neural network as feature extractor this is similar to a large body of work on task transfer with neural nets in the area of computer vision and represents the reward function as a weighted distance to features for automatically extracted key frames of the provided expert trajectories the paper is well written and explains all involved concepts clearly while also embedding the presented approach in the literature on inverse reinforcement learning irl the resulting algorithm is appealing due to its simplicity and could prove useful for many real world robotic applications i have three main issues with the paper in its current form if these can be addressed i believe the paper would be significantly strengthened although the recursive splitting approach for extracting the key frames seems reasonable and the feature selection is well motivated i am missing two baselines in the experiments what happens if the feature selection is disabled and the distance between all features is used will this immediately break the procedure if not what is the trade off here an even simpler baseline than what is proposed in the paper would be the following procedure simply use all frames of the recorded trajectories calculate the distance to them in feature space and weights them according to their time as in the approach proposed in the paper how well would that work i understand the desire to combine the extracted reward function with a simple rl method but believe the used simple controller could potentially introduce a significant bias in the experiments since it requires initialization from an expert trajectory as a direct consequence of this initialization the rl procedure is already started close to a good solution and the extracted reward function is potentially only queried in a small region around what was observed in the initial set of images perhaps with the exception of the human demonstrations without an additional experiment it is thus unclear how well the presented approach will work in combination with other rl methods for training the controller i understand that the low number of available images excludes training a deep neural net directly for the task at hand but one has to wonder how other baselines would do what happens if one uses a random projection of the images to form a feature vector how well would a distance measure using raw images e g l norm of image differences or a distance measure based on the first principal components work it seems that occlusions etc would exclude them from working well but without empirical evidence it is hard to confirm this minor issues page make use of ideas about imitation reads a bit awkwardly page we use the inception network pre trained imagenet pre trained for imagenet classification page the definition of the transition function for the stochastic case seems broken page efficient enough to evaluate a bit strangely written sentence additional comments rather than real issues the paper is mainly of empirical nature little actual learning is performed to obtain the reward function and no theoretical advances are needed this is not necessarily bad but makes the empirical evaluation all the more important while i liked the clear exposition the approach in the end boils down to computing quadratic distances to features of pre extracted key frames it is nice that you make a connection to standard irl approaches in section but one could argue that this derivation is not strictly necessary,6.0
441.json,tldr the authors present variable computation in recurrent neural networks vcrnn vcrnn is similar in nature to adaptive computation time graves et al imagine a vanilla rnn at each timestep only a subset i e variable computation of the state is updated experimental results are not convincing there is limited comparison to other cited work and basic lstm baseline gating mechanism at each timestep vcrnn generates a mt vector which can be seen as a gating mechanism based off this mt vector a d first d first as in literally the first d rnn states subset of the vanilla rnn state is gated to be updated or not extra hyperparams epsilon and bar m are needed authors did not give us a value or explain how this was selected or how sensitive and critical these hyperparms are this mechanism while novel feels a bit clunky and awkward it does not feel well principled that only the d first states get updated rather than a generalized solution where any subset of the state can be updated a short section in the text comparing to the soft gating mechanisms of grus lstms multiplicative rnns wu et al would be nice as well variable computation one of the arguments made is that their vcrnn model can save computation versus vanilla rnns while this may be technically true in practice this is probably not the case the size of the rnns they compare to do not saturate any modern gpu cores in theory computation might be saved but in practice there will probably be no difference in wallclock time the authors also did not report any wallclock numbers which makes this argument hard to sell evaluation this reviewer wished there was more citations to other work for comparison and a stronger baseline than just a vanilla rnn first lstms are very simple and quite standard nowadays there is a lack of comparison to any basic stacked lstm architecture in all the experiments the ptb bpc numbers are quite discouraging as well compared to state of the art the vcrnn does not beat the basic vanilla rnn baseline the authors also only cite compare to a basic rnn architecture however there has been many contributions since a basic rnn architecture that performs vastly better please see chung et al table chung et al also experimented w ptb bpc and they cite and compare to a large number of other important contributions one cool experiment the authors did is graph the per character computation of vcrnn i e see figure it shows after a space word boundary we use more computation cool however this makes me wonder what a gru lstm does as well what is the magnitude of the of the change in the state vector after a space in gru lstm i suspect them to do something similar minor please add equations numbers to the paper hard to refer to in a review and discussion references chung et al hierarchical multiscale recurrent neural networks in graves et al adaptive computation time for recurrent neural networks in wu et al on multiplicative integration with recurrent neural networks in,4.0
441.json,this is high novelty work and an enjoyable read my concerns about the paper more or less mirror my pre review questions i certainly agree that the learned variable computation mechanism is obviously doing something interesting the empirical results really need to be grounded with respect to the state of the art and lstms are still an elephant in the room note that i do not consider beating lstms grus or any method in particular as a prerequisite for acceptance but the comparison nevertheless should be made in pre review responses the authors brought up that lstms perform more computation per timestep than elman networks and while that is true this is an axis along which they can be compared this factor controlled for at least in expectation by varying the number of lstm cells etc a brief discussion of the proposed gating mechanism in light of the currently popular ones would strengthen the presentation in light of my concerns being addressed i am modifying my review to a with the understanding that the manuscript will be amended to include the new comparisons posted as a comment,7.0
441.json,this paper describes a simple but clever method for allowing variable amounts of computation at each time step in rnns the new architecture seems to outperform vanilla rnns on various sequence modelling tasks visualizations of the assignment of computational resources over time support the hypothesis that the model is able to learn to assign more computations whenever longer longer term dependencies need to be taken into account the proposed model is evaluated on a multitude of tasks and its ability to outperform similar architectures seems consistent some of the tasks allow for an interesting analysis of the amount of computation the model requests at each time step it s very interesting to see how the model seems to use more resources at the start of each word or ascii character i also like the investigation of the effect of imposing a pattern of computational budget assignment which uses prior knowledge about the task the superior performance of the architecture is impressive but i m not yet convinced that the baseline models had an equal number of hyperparameters to tune i ll come back to this point in the next paragraph because it s mainly a clarity issue the abstract claims that the model is computationally more efficient than regular rnns there are no wall time measurements supporting this claim while the model is theoretically able to save computations the points made by the paper are clearly more conceptual and about the ability of the model to choose how to allocate its resources this makes the paper interesting enough by itself but the claims of computational gains are misleading without actual results to back them up i also find it unfortunate that it s not clear from the text how the hyperparameter bar m was chosen whether it was chosen randomly or set using a hyperparameter search on held out data influences the fairness of a comparison with rnns which did not have a similar type of hyperparameter for controlling regularization like for example dropout or weight noise even if regularization of rnns is a bit tricky i don t consider this a very serious flaw because i m impressed enough by the fact that the new architecture achieves roughly similar performance while learning to allocate resources but i do think that details of this type are too important to be absent from the text even if the superior performance is due to this extra regularization controlling parameter it can actually be seen as a useful part of the architecture but it would be nice to know how sensitive the model is to its precise value to my knowledge the proposed architecture is novel the way the amount of computation is determined is unlike other methods for variable computation i have seen and quite inventive originality is one of this paper s strongest points it s currently hard to predict whether this method for variable computation will be used a lot in practice given that this also depends on how feasible it is to obtain actual computational gains at the hardware level that said the architecture may turn out to be useful for learning long term dependencies i also think that the interpretability of the value mt is a nice property of the method and that it s visualizations are very interesting it might shed some more light into what makes certain tasks difficult for rnns pros original clever idea nice interesting visualizations interesting experiments cons some experimental details are not clear i m not convinced of the strength of the baseline the paper shouldn t claim actual computational savings without reporting wall clock times edit i am very positively impressed by the way the authors ended up addressing the biggest concerns i had about the paper and raised my score adding an lstm baseline and results with a gru version of the model significantly improves the empirical quality of the paper on top of that the authors addressed my question about some experimental detail i found important and promised to change the wording of the paper to remove confusion about whether the computational savings are conceptual or in actual wall time i think it fine that they are conceptual only as long as this is clear from the paper and abstract i want to make clear to the ac that since the changes to the paper are currently still promises my new score should be assumed to apply to an updated version of the paper in which the aforementioned concerns have indeed been addressed edit since i did not know that the difference with the sota for some of these tasks was so large i had to lower my score again after learning about this i still think it a good paper but with these results i cannot say that it stands out,7.0
695.json,summary in this paper the authors introduce noiseout a way to reduce parameters by pruning neurons from a network they do this by identifying pairs of neurons produce the most correlated outputs and replacing the pair by one neuron and then appropriately adjusting weights this technique relies on neurons having high correlations however so they introduce an additional output neuron a noise output which results in the network trying to predict the mean of the noise distribution as this is a constant it increases correlation between neurons experiments test this out on mnist and svhn comments this is an interesting suggestion on how to prune neurons but more experiments on larger datasets are probably need to be convincing that this is an approach that is guaranteed to work well equation seems to be very straightforwards it seems like that for larger datasets more noise outputs might have to be added to ensure higher correlations is there a downside to this in terms of the overall accuracy the paper is presented clearly and was definitely interesting to read so i encourage the authors to continue this line of work,5.0
695.json,this paper proposes and tests two ideas a method of pruning networks by identifying highly correlated neuron pairs pruning one of the pair and then modifying downstream weights to compensate for the removal which works well if the removed neurons were highly correlated a method dubbed noiseout for increasing neuron correlation by adding auxiliary noise target outputs to the network during training the first idea is fairly straightforward and it is not clear if it has been tried before it does seem to work the second idea is of unclear value and seems to this reviewer that it may merely add a regularizing effect comments in this direction in fig right the constant and gaussian treatments seem to produce the same effect in both networks right and the binomial effect seems the same as nonoise if this is true can we conclude that the noiseout targets are simply serving to regularize the network that is to reduce its capacity slightly to show whether this effect is true one would need to compare to other methods of reducing the network capacity for example by reducing the number of neurons by applying l regularization of various values or by applying dropout of various strengths fig makes an attempt at this direction but critically misses several comparison treatments pruned without any regularization pruned with only l and pruned with only dropout have these experiments been run can their results be included and used to produce plots like fig and fig without these comparisons it seems impossible to conclude that noiseout does anything but provide similar regularization to dropout or l the combined ideas do produce a considerable reduction in parameters but sadly the experiments and exposition are somewhat too lacking to really understand what is going on with a little more work the paper could be quite interesting but as is it should probably not be accepted additional comments section states in all of these experiments the only stop criteria is the accuracy decay of the model we set the threshold for this criteria to match the original accuracy therefore all the compressed network have the same accuracy as the original network is this accuracy the train accuracy or test accuracy if train then test accuracy needs to be shown how much test performance is lost when pruning if test then this would typically be referred to as cheating and so the choice needs to be very clearly stated and then defended lowercase rho is used to indicate correlation but this is never actually specified which is confusing for just state once that it indicates correlation how do these results compare to other pruning methods no numerical comparison is attempted,5.0
695.json,the paper proposes to prune a neural network by removing neurons whose operation is highly correlated with other neurons the idea is nice and somewhat novel most pruning methods concentrate on removal of individual weights however i have not done a through research on this topic however the experimental and theoretical justification of this method need to be improved before publication experiments the authors do not report accuracy degradation while pruning in the tables laconically stating that the networks did not degrade this is not convincing the only details are given in figure however this figure disagrees with table in the table the number of parameters ranges from k k while the figure pictures the range k k unless more details are provided simply claiming that a network can remove neurons with no number on the degradation of accuracy is not convincing theory the proofs do not match the experimental conditions and make unreasonable assumptions the proofs show that in the absence of biases a network with a constant output will have two correlated neurons that generate the output offset however this is exactly why networks have biases and does not explain why noise injection helps the proof suggests that all should be fine with deterministic auxiliary neuron my interpretation is that the noisy output injects gradient noise see e g the concurrent iclr submission,3.0
380.json,the authors present a method for changing the objective of generative adversarial networks such that the discriminator accurately recovers density information about the underlying data distribution in the course of deriving the changed objective they prove that stability of the discriminator is not guaranteed in the standard gan setup but can be recovered via an additional entropy regularization term the paper is clearly written including the theoretical derivation the derivation of the additional regularization term seems valid and is well explained the experiments also empirically seem to support the claim that the proposed changed objective results in a better discriminator there are only a few issues with the paper in its current form the presentation albeit fairly clear in the details following the initial exposition in and the beginning of fails to accurately convey the difference between the energy based view of training gans and the standard gan as a result it took me several passes through the paper to understand why the results do not hold for a standard gan i think it would be clearer if you state the connections up front in perhaps without the additional f gan perspective and perhaps add some additional explanation as to how c is implemented right there or in the experiments you may want to just add these details in the appendix see also comment below the proposed procedure will by construction only result in an improved generator and unless i misunderstand something does not result in improved stability of gan training you also do not make such a claim but an uninformed reader might get this wrong impression especially since you mention improved performance compared to salimans et al in the inception score experiment it might be worth while mentioning this early in the paper the experiments although well designed mainly convey qualitative results with the exception of the table in the appendix for the toy datasets i know that evaluating gans is in itself not an easy task but i wonder whether additional more quantitative experiments could be performed to evaluate the discriminator performance for example one could evaluate how well the final discriminator does separate real from fake examples how robust its classification is to injected noise e g how classification accuracy changes for noised training data further one might wonder whether the last layer features learned by a discriminator using the changed objective are better suited for use in auxiliary tasks e g classifying objects into categories main complaint it is completely unclear what the generator and discriminators look like for the experiments you mention that code will be available soon but i feel like a short description at least of the form of the energy used should also appear in the paper somewhere perhaps in the appendix,7.0
380.json,the submission explores several alternatives to provide the generator function in generative adversarial training with additional gradient information the exposition starts by describing a general formulation about how this additional gradient information termed k pgen could be added to the generative adversarial training objective function equation next the authors prove that the shape of the optimal discriminator does indeed depend on the added gradient information proposition which is unsurprising finally the authors propose three particular alternatives to construct k pgen the negative entropy of the generator distribution the l norm of the generator distribution and a constant function which resembles the ebgan objective of zhao et al the exposition moves then to an experimental evaluation of the method which sets k pgen to be the approximate entropy of the generator distribution at this point my intuition is that the objective function under study is the vanilla gan objective plus a regularization term that encourages diversity high entropy in the generator distribution the hope of the authors is that this regularization will transform the discriminator into an estimate of the energy landscape of the data distribution the experimental evaluation proceeds by showing the contour plots of the obtained generator distribution for a d problem studying the generation diversity in mnist digits and showing some samples for cifar and celeba the d problem results are convincing since one can clearly observe that the discriminator scores translate into unnormalized values of the density function the mnist results offer good intuition also the more prototypical digits are assigned larger scores unnormalized densities by the discriminator and the less prototypical digits are assigned smaller scores the sample experiments from section are less convincing since no samples from baseline models are provided for comparison to this end i would recommend the authors to clarify three aspects first we have seen that entropy regularization leads to a discriminator that estimates the energy landscape of the data distribution but how does this regularization reshape the generator function it would be nice to see the mean mnist digit according to the generator and some other statistics if possible second how do the samples produced by the proposed methods compare visually speaking to the state of the art third what are the shortcomings of this method versus vanilla gan too much computational overhead what are the qualitative and quantitative differences between the two entropy estimators proposed in the manuscript overall a clearly written paper i vote for acceptance as an open question to the authors what breakthroughs should we pursue to derive a gan objective where the discriminator is an estimate of the data density function after training,8.0
553.json,for more than a decade near data processing has been a key requirement for large scale linear learning platforms as the time to load the data exceeds the learning time and this has justified the introduction of approaches such as spark deep learning usually deals with the data that can be contained in a single machine and the bottleneck is often the cpu gpu bus or the gpu gpu bus so a method that overcomes this bottleneck could be relevant unfortunately this work is still very preliminary and limited to linear training algorithms so of little interest yet to iclr readership i would recommend publication to a conference where it can reach the large scale linear ml audience first such as icml this paper is clear and well written in the present form and would probably mostly need a proper benchmark on a large scale linear task obviously when the authors have convincing dnn learning simulations they are welcome to target iclr but can the flash memory fpga handle it for experiments the choice of mnist is somewhat bizarre this task is small and performance is notoriously terrible when using linear approaches the authors do not even report it,4.0
416.json,much existing deep learning literature focuses on likelihood based models however maximum entropy approaches are an equally valid modelling scenario where information is given in terms of constraints rather than data that there is limited work in flexible maximum entropy neural models is surprising but is due to the fact that optimizing a maximum entropy model requires a establishing the effect of the constraints on some distribution and formulating the entropy of that complex distribution there is no unbiased estimator of entropy from samples alone and so an explicit model for the density is needed this challenge limits approaches the authors have identified that invertible neural models provide a powerful class of models for solving the maximum entropy network problem and this paper goes on to establish this approach the contributions of this paper are a recognising that because normalising flows provide an explicit model for the density they can be used to provide unbiased estimators for the entropy b that the resulting lagrangian can be implemented as a relaxation of a augmented lagrangian c establishing the practical issues in doing the augmented lagrangian optimization as far as the reviewer is aware this work is novel this approach is natural and sensible and is demonstrated on an number of models where clear evaluation can be done enough experiments have been done to establish this is an appropriate method though not that it is entirely necessary it would be good to have an example where the benefits of the flexible flow transformation were much clearer further discussion of the computational and scaling aspects would be valuable i am guessing this approach is probably appropriate for model learning but less appropriate for inferential settings where a known model is then conditioned on particular instance based constraints some discussion of appropriate use cases would be good the issue of match to the theory via the regularity conditions has been brought up but it is clear that this can be described well and exceeds most of the theoretical discussions that occur regarding the numerical methods in other papers in this field quality good sound paper providing a novel basis for flexible maximum entropy models clarity good originality refreshing significance significant in model development terms whether it will be an oft used method is not clear at this stage minor issues please label all equations others might wish to refer to them even if you don t top of page algorithm algorithm the update for c to overcome stability appears slightly opaque and is mildly worrying i assume there are still residual stability issues can you comment on why this solves all the problems the issue of the support of p is glossed over a little is the support in an additional condition on the support of p if so that seems hard to encode and indeed does not turn up in i guess for a gaussian p and invertible unbounded transformations if the support happens to be r d then this is trivial but for more general settings this seems to be an issue that you have not dealt indeed in your dirichlet example you explicitly map to the required support but for more complex constraints this may be non trivial to do with invertible models with known jacobian it would be nice to include this in the more general treatment rather than just relegating it to the specific example overall i am very pleased to see someone tackling this question with a very natural approach,9.0
416.json,the authors propose a new approach for estimating maximum entropy distributions subject to expectation constraints their approach is based on using normalizing flow networks to non linearly transform samples from a tractable density function using invertible transformations this allows access to the density of the resulting distribution the parameters of the normalizing flow network are learned by maximizing a stochastic estimate of the entropy obtained by sampling and evaluating the log density on the obtained samples this stochastic optimization problem includes constraints on expectations with respect to samples from the normalizing flow network these constraints are approximated in practice by sampling and are therefore stochastic the optimization problem is solved by using the augmented lagrangian method the proposed method is validated on a toy problem with a dirichlet distribution and on a financial problem involving the estimation of price changes from option price data quality the paper seems to be technically sound my only concern would the the approach followed to apply the augmented lagrangian method when the objective and the constraints are stochastic the authors propose their own solution to this problem based on a hypothesis test but i think it is likely that this has already been addressed before in the literature it would be good if the authors could comment on this the experiments performed show that the proposed approach can outperform gibbs sampling from the exact optimal distribution or at least be equivalent with the advantage of having a closed form solution for the density i am concern about the difficulty of he problems considered the dirichlet distributions are relatively smooth and the distribution in the financial problem is one dimensional in this case you can use numerical methods to compute the normalization constant and plot the exact density they seem to be very easy and do not show how the method would perform in more challenging settings high dimensions more complicated non linear constraints etc clarity the paper is clearly written and easy to follow originality the proposed method is not very original since it is based on applying an existing technique normalizing flow networks to a specific problem that of finding a maximum entropy distribution the methodological contributions are almost non existing one could only mention the combination of the normalizing flow networks with the augmented lagrangian method significance the results seem to be significant in the sense that the authors are able to find densities of maximum entropy distributions something which did not seem to be possible before however it is not clearly how useful this can be in practice the problem that they address with real world data financial data could have been solved as well by using dimensional quadrature the authors should consider more challenging problems which have a clear practical interest minor comments more details should be given about how the plot in the bottom right of figure has been obtained a dirichlet whose kl to the true p is small what do you mean by this can you give more details on how you choose that dirichlet i changed updated my review score after having a look at the last version of the paper submitted by the authors which includes new experiments,6.0
601.json,paper summary this paper presents a new comprehension dataset called newsqa dataset containing question answer pairs from over news articles from cnn the dataset is collected through a four stage process article filtering question collection answer collection and answer validation examples from the dataset are divided into different types based on answer types and reasoning required to answer questions human and machine performances on newsqa are reported and compared with squad paper strengths i agree that models can benefit from diverse set of datasets this dataset is collected from news articles hence might pose different sets of problems from current popular datasets such as squad the proposed dataset is sufficiently large for data hungry deep learning models to train the inclusion of questions with null answers is a nice property to have a good amount of thought has gone into formulating the four stage data collection process the proposed barb model is performing as good as a published state of the art model while being much faster paper weaknesses human evaluation is weak two near native english speakers performance on examples each can hardly be a representative of the complete dataset also what is the model performance on these examples not that it is necessary for this paper but to clearly demonstrate that this dataset is harder than squad the authors should either calculate the human performance the same way as squad or calculate human performances on both newsqa and squad in some other consistent manner on large enough subsets which are good representatives of the complete datasets dataset from other communities such as vqa dataset antol et al iccv also use the same method as squad to compute human performance section says that of questions have answers agreed upon by atleast workers why is this number inconsistent with the of questions which have answers without agreement after validation last line in section is the same article shown to multiple questioners if yes is it ensured that the questioners asking questions about the same article are not asking the same similar questions authors mention that they keep the same hyperparameters as squad what are the accuracies if the hyperparameters are tuned using a validation set from newsqa examples which are labeled for reasoning types do not seem enough to represent the complete dataset also what is the model performance on these examples which model performance has been shown in figure are the two students graduate undergraduate students or researchers test set seems to be very small suggestion answer validation step is nice but maybe the dataset can be released in versions one with all the answers collected in rd stage without the validation step and one in the current format with the validation step preliminary evaluation the proposed dataset is a large scale machine comprehension dataset collected from news articles which in my suggestion is diverse enough from existing datasets that state of the art models can definitely benefit from it with a better human evaluation i think this paper will make a good poster,6.0
601.json,summary the paper proposes a novel machine comprehension dataset called newsqa the dataset consists of over question answer pairs based on over news articles from cnn the paper analyzes the different types of answers and the different types of reasoning required to answer questions in the dataset the paper evaluates human performance and the performance of two baselines on the dataset and compares them with the performance on squad dataset strengths the paper presents a large scale dataset for machine comprehension the question collection method seems reasonable to collect exploratory questions having an answer validation step is desirable the paper proposes a novel computationally more efficient implementation of the match lstm model weaknesses the human evaluation presented in the paper is not satisfactory because the human performance is reported on a very small subset questions so it seems unlikely that these questions will provide a reliable measure of the human performance on the entire dataset which consists of thousands of questions newsqa dataset is very similar to squad dataset in terms of the size of the dataset the type of dataset natural language questions posed by crowdworkers answers comprising of spans of text from related paragraphs the paper presents two empirical ways to show that newsqa is more challenging than squad the gap between human and machine performance in newsqa is larger than that in squad however since the human performance numbers are reported on very small subset these trends might not carry over when human performance is computed on all of the dataset the sentence level accuracy on squad is higher than that in newsqa however as the paper mentions the differences in accuracies could likely be due to different lengths of documents in the two datasets so even this measure does not truly reflect that squad is less challenging than newsqa so it is not clear if newsqa is truly more challenging than squad authors mention that barb is computationally more efficient and faster compared to match lstm however the paper does not report how much faster barb is compared to match lstm on page under boundary pointing paragraph the paper should clarify what s in ns refers to review summary while the dataset collection method seems interesting and promising i would be more convinced after i see the following human performance on all or significant percentage of the dataset an empirical study that fairly shows that newsqa is more challenging or better in some other way than squad,6.0
744.json,this paper proposes a network called gated residual networks layer design that adds gating to shortcut connections with a scalar to regulate the gate the authors claim that this approach will improve the training residual networks it seems the authors could get competitive performance on cifar to state of art models with only wide res nets wide gated resnet requires much more parameters than densenet and other res net variants for obtaining a little improvement over dense net more importantly the authors state that they obtained the best results on cifar and cifar but the updated version of densenet huang et al b has new results for a version called densenet bc which outperforms all of the results that authors reported for cifar and for cifar with m parameters densenet bc still outperforms with m parameters which is much less that m the res net variants papers with state of art results report result for image net therefore the empirical results need also the image net to demonstrate that improvement claimed is achieved the proposed trick adopts highway neural networks and residual networks with an intuitive motivation it is not sufficiently novel and the empirical results do not prove sufficient effectiveness of this incremental approach,5.0
744.json,this paper proposes to learn a single scalar gating parameter instead of a full gating tensor in highway networks the claim is that such gating is easier to learn and allows a network to flexibly utilize computation the basic idea of the paper is simple and is clearly presented it is a natural simplification of highway networks to allow easily shutting off layers while keeping number of additional parameters low however in this regard the paper leaves out a few key points firstly it does not mention that the gates in highway networks are data dependent which is potentially more powerful than learning a fixed gate for all units and independent of data secondly it does not do a fair comparison with highway networks to show that this simpler formulation is indeed easier to learn did the authors try their original design of u g k f x g k x where f x is a plain layer instead of a residual layer based on the arguments made in the paper this should work fine why was not it tested if it does not work are the arguments incorrect or incomplete for the mnist experiments since the hyperparameters are fixed the plots are misleading if any dependence on hyperparameters exists for the different models this experiment appears to be based on srivastava et al if it is indeed designed to test optimization at aggressive depths then apart from doing a hyperparameter search the authors should not use regularization such as dropout or batch norm which do not appear in the theoretical arguments for the architecture for cifar experiments the obtained improvements compared to the baseline wide resnets are very small and therefore it is important to report the standard deviations or all results in both cases it not clear that the differences are significant some questions regarding g was g always relu does not this have potential problems with g k becoming and never recovering does this also mean that for the wide resnet in fig most residual blocks are zeroed out since k,5.0
528.json,the authors talk about design choice recommendations for performing program induction via gradient descent basically advocating reasonable programming language practice immutable data higher order language constructs etc as mentioned in the comments i feel fairly strongly that this is a marginal at best contribution beyond terpret an already published system with extensive experimentation and theoretical grounding to be clear i think the terpret paper deserves a large amount of attention it is truly inspiring this paper contradicts one of the key findings in the original paper but does not provide convincing evidence that gradient based evaluators for terpret are superior or even frankly appropriate for program induction this is uncomfortable for me and makes me wonder why gradient based methods were not more carefully vetted in the first place or why more extensive comparisons to already implemented alternatives were not included in this paper my opinion if we want to give the original terpret paper more attention which i think it deserves then this paper is above threshold on the other hand it basically unreadable actually contradicts its mother paper in not well defended ways and is irreproducible without the same so i think unfortunately it below threshold,5.0
528.json,the paper discusses a range of modelling choices for designing differentiable programming languages authors propose recommendations that are then tested on a set of algorithmic tasks for lists such as length of the list return k th element from the list etc the solutions are learnt from input output example pairs for training for test the main difference between this work and differentiable architectures like ntm neural gpu nram etc is the fact that here the authors aim at automatically producing code that solves the given task my main concern are experiments it would be nice to see a comparison to some of the neural networks mentioned in related work also it would be useful to see how this model is doing on typical problems used by mentioned neural architectures problems such as sorting merging adding i am wondering how this is going to generalize to other types of programs that can not be solved with prefix loop suffix structure it is also concerning that although the tasks are simple the structure of the solution is very restricted and model is using extensions doing most of the work the proposed model still fails to find solutions example a l model that has loop fails to solve list length task in of the runs pro generates code rather than black box neural architecture nice that it can learn from very few examples cons weak results works only for very simple tasks missing comparison to neural architectures,4.0
528.json,the paper proposes a set of recommendations for the design of differentiable programming languages based on what made gradient descent more successful in experiments i must say i m no expert in program induction while i understand there is value in exploring what the paper set out to explore making program learning easier i did not find the paper too engaging first everything is built on top of terpret which isn t yet publicly available also most of the discussion is very detailed on the programming language side and less so on the learning side it is conceivable that it would be best received on a programming language conference a comparison with alternatives not generating code would be valuable in my opinion to motivate for the overall setup pros useful well executed novel study cons low on learning specific contributions more into domain related constraints not sure a great fit to iclr,5.0
528.json,this paper presents small but important modifications which can be made to differentiable programs to improve learning on them overall these modifications seem to substantially improve convergence of the optimization problems involved in learning programs by gradient descent that said the set of programs which can be learned is still small and unlikely to be directly useful,6.0
656.json,the paper investigates a hybrid network consisting of a scattering network followed by a convolutional network by using scattering layers the number of parameters is reduced and the first layers are guaranteed to be stable to deformations experiments show that the hybrid network achieves reasonable performance and outperforms the network in network architecture in the small data regime i have often heard researchers ask why it is necessary to re learn low level features of convolutional networks every time they are trained in theory using fixed features could save parameters and training time as far as i am aware this paper is the first to investigate this question in my view the results show that using scattering features in the bottom layers does not work as well as learned cnn features this is not completely obvious a priori and so the results are interesting but i disagree with the framing that the hybrid network is superior in terms of generalization for the low data regime the hybrid network sometimes gives better accuracy than nin but this is quite an old architecture and its capacity has not been tuned to the dataset size for the full dataset the hybrid network is clearly outperformed by fully learned models if i understood correctly the authors have not simply compared identical architectures with and without scattering as the first layers which further complicates drawing a conclusion the authors claim the hybrid network has the theoretical advantage of stability however only the first layers of a hybrid network will be stable while the learned ones can still create instability furthermore if potentially unstable deep networks outperform stable scattering nets and partially stable hybrid nets we have to question the importance of stability as defined in the theory of scattering networks in conclusion i think the paper investigates a relevant question but i am not convinced that the hybrid network really generalizes better than standard deep nets faster computation at test time could be useful e g in low power and mobile devices but this aspect is not really fleshed out in the paper minor comments section learni,5.0
656.json,thanks a lot for your detailed response and clarifications the paper proposes to use a scattering transform as the lower layers of a deep network this fixed representation enjoys good geometric properties local invariance to deformations and can be thought as a form of regularization or prior the top layers of the network are trained to perform a given supervised task this is the final model can be thought as plugging a standard deep convolutional network on top of the scattering transform evaluation on cifar and shows that the proposed approach achieves performance competitive with high performing baselines i find the paper very interesting the idea of cascading these representations seems very natural thing to try to the best of my knowledge this is the first work that combines predefined and generic representations with modern cnn architectures achieving competitive performance to high performing approaches while the state of the art resnets and variants achieves significantly higher performances i believe that this work strongly delivers it point the paper convincingly shows that lower level invariances can be obtained from analytic representations scattering transform simplifying the training process using less parameters and allowing for faster evaluation the of the hybrid approach become crucial in the low data regime the author argues that with the scattering initialisation instabilities cannot occur in the first layers contrary as the operator is non expansive this naturally suggests that the model is more robust to adversarial examples it would be extremely interesting to present an empirical evaluation of this task what is the practical impact can this hybrid network be fooled with adversarial if this is the case it would render the use of scattering initialization very attractive,7.0
713.json,this paper presents a new non linear function for cnn and deep neural networks the new non linearity reports some gains on most datasets of interest and can be used in production networks with minimal increase in computation,7.0
713.json,authors present a parameterized variant of elu and show that the proposed function helps to deal with vanishing gradients in deep networks in a way better than existing non linearities they present both a theoretical analysis and practical validation for presented approach interesting observations on statistics of the pelu parameters are reported perhaps explanation for the observed evolution of parameters can help better understand the non linearity it is hard to evaluate the experimental validation presented given the difference in number of parameters compared to other approaches,6.0
343.json,this paper proposes an approach to character language modeling clms based on developing a domain specific language to represent clms the experiments show mixed performance versus neural clm approaches to modeling linux kernel data and wikipedia text however the proposed dsl models are slightly more compact and fast to query as compared with neural clms the proposed approach is difficult to understand overall and perhaps is aimed towards the sub community already working on this sort of approach but lacks sufficient explanation for the iclr audience critically the paper glosses over the major issues of demonstrating the proposed dsl is a valid probabilistic model and how training is performed to fit the model to data there is clearly not a gradient based training approach used finally the experiments feel incomplete without showing samples drawn from the generative model or analyzing the learned model to determine what it has learned overall i feel this paper does not describe the approach in enough depth for readers to understand or re implement it almost all of the model section is devoted to exposition of the dsl without specifying how probabilities are computed using this model and how training is performed how are probabilities actually encoded the dsl description seems to have only discrete decisions rather than probabilities training is perhaps covered in previous papers but there needs to be some discussion of how it works here section does not do enough to explain how training works or how any measure of optimality is achieved given this model is quite a different hypothesis space from neural models or n grams looking and samples drawn from the model seems critical the current experiments show it can score utterances relatively well but it would be very interesting if the model can sample more structured samples than neural approaches for example long range syntax constraints like brackets,5.0
343.json,the authors propose a method for language modeling by first generating a program from a dsl then learning the count based parameters of that program pros include the proposed method is innovative and highly different from standard lstm based approaches of late the model should also be much quicker to apply at query time strong empirical results are obtained on modeling code though there is some gap between the synthesis method and neural methods on the hutter task a detailed description of the language syntax is provided cons suggestions the synthesis procedure using mcmc is left very vague even though being able to make this procedure efficient is one of the key questions the work builds on work from the pl literature surely the related work could also be expanded and this work better put in context more compact convincing examples of human interpretability would be helpful other comments training time evaluation in table should give basic information such as whether training was done on gpu cpu cpu specs etc,8.0
640.json,this paper discusses multi sense embedddings and proposes learning those by using aligned text across languages further the paper suggests that adding more languages helps improve word sense disambiguation as some ambiguities can be carried across language pairs while this idea in itself is not new the authors propose a particular setup for learning multi sense embeddings by exploiting multilingual data broadly this is fine but unfortunately the paper then falls short in a number of ways for one the model section is unnecessarily convoluted for what is a nice idea that could be described in a far more concise fashion next and more importantly comparison with other work is lacking to such an extent that it is impossible to evaluate the merits of the proposed model in an objective fashion this paper could be a lot stronger if the learned embeddings were evaluated in downstream tasks and evaluated against other published methods in the current version there is too little of this leaving us with mostly relative results between model variants and t sne plots that do not really add anything to the story,4.0
640.json,this work aims to address representation of multi sense words by exploiting multilingual context experiments on word sense induction and word similarity in context show that the proposed solution improves over the baseline from a computational linguistics perspective the fact that languages less similar to english help more is intriguing i see following problem with this work the paper is hard to follow and hard to see what is new compared to the baseline model a paragraph of discussion should clearly compare and contrast with that work the proposed model is a slight variation of the previous work thus the experimental setup should be designed in a way so that we compare which part helps improvement and how much thus mono has not been exposed the same training data and we can not be sure that the proposed model is better because mono does not observe the data or lacks the computational power i suggest following baseline turning multilingual data to monolingual one using the alignment then train the baseline model on this pseudo monolingual data the paper provides good benchmarks for intrinsic evaluation but the message could be conveyed more strongly if we see improvement in a downstream task,4.0
705.json,this paper is a follow up on the nips paper unsupervised learning of spoken language with visual context and does exactly what that paper proposes in its future work section to perform acoustic segmentation and clustering effectively learning a lexicon of word like units using the embeddings that their system learns the analysis is very interesting and i really like where the authors are going with this my main concern is novelty it feels like this work is a rather trivial follow up on an existing model which is fine but then the analysis should be more satisfying currently it feels like the authors are just illustrating some of the things that the nips model with some minor improvements learns for a more interesting analysis i would have liked things like a comparison of different segmentation approaches both in audio and in images i e suppose we have access to the perfect segmentation in both modalities what happens it would also be interesting to look at what is learned with the grounded representation and evaluate e g on multi modal semantics tasks apart from that the paper is well written and i really like this research direction it is very important to analyze what models learn and this is a good example of the types of questions one should ask i am afraid however that the model is not novel enough nor the questions deep enough to make this paper better than borderline for iclr,6.0
705.json,this work proposes a joint classification of images and audio captions for the task of word like discovery of acoustic units that correlate to semantically visual objects the general this is a very interesting direction of research as it allows for a richer representation of data regularizing visual signal with audio and visa versa this allows for training of visual models from video etc a major concern is the amount of novelty between this work and the author previous publication at nips the authors claim a more sophisticated architecture and indeed show an improvement in recall however the improvements are marginal and the added complexity to the architecture is a bit ad hoc clustering and grouping in section is hacky instead of gridding the image the authors could actually use an object detector ssd yolo fasterrcnn etc to estimate accurate object proposals rather than using k means a spectral clustering approach would alleviate the gaussian assumption of the distributions in assigning visual hypotheses with acoustic segments some form of bi partite matching should be used overall i really like this direction of research and encourage the authors to continue developing algorithms that can train from such multimodal datasets however the work is not quite novel enough from nips,5.0
705.json,contributions this paper introduces a method for learning semantic word like units jointly from audio and visual data the authors use a multimodal neural network architecture which accepts both image and audio as spectrograms inputs joint training allows one to embed both image and spoken language captions into a shared representation space audio visual groundings are generated by measuring affinity between image patches and audio clips this allows the model to relate specific visual regions to specific audio segments experiments cover image search audio to image and annotation image to audio tasks and acoustic word discovery novelty significance as correctly mentioned in section the computer vision and natural language communities have studied multimodal learning for use in image captioning and retrieval with regards to multimodal learning this paper offers incremental advancements since it primarily uses a novel combination of input modalities audio and images however bidirectional image audio retrieval has already been explored by the authors in prior work harwath et al nips apart from minor differences in data and cnn architecture the training procedure in this submission is identical to this prior work the novelty in this submission is therefore the procedure for using the trained model for associating image regions with audio subsequences the methods employed for this association are relatively straightforward combination of standard techniques with limited novelty the trained model is used to compute alignment scores between densely sampled image regions and audio subsequences from these alignment scores a number of heuristics are applied to associate clusters of image regions with clusters of audio subsequences missing citation there is a lot of work in this area spanning computer vision natural language and speech recognition one key missing reference ngiam et al multimodal deep learning icml positive points using more data and an improved cnn architecture this paper improves on prior work for bidirectional image audio retrieval the presented method performs efficient acoustic pattern discovery the audio visual grounding combined with the image and acoustic cluster analysis is successful at discovering audio visual cluster pairs negative points limited novelty especially compared with harwath et al nips although it gives good results the clustering method has limited novelty and feels heuristic the proposed method includes many hyperparameters patch size acoustic duration vad threshold iou threshold number of k means clusters etc and there is no discussion of how these were set or the sensitivity of the method to these choices,5.0
586.json,the authors investigate the neural gpu model introduced by kaiser and sutskever in section they claim its performance is due to the o n number of steps it can perform for each example in the subsequent section they highlight the importance of curriculum training and empirically show that larger models generalize better in section they construct examples that reveal failure modes in the last section they compare the performance given different input formats the paper is well written it contains an exhaustive set of experiments which provide insight into the details of training the neural gpu model it pushes the boundary of algorithms that can be learned further on the other hand the paper seems to lack a coherent message it also fails to provide any insight into the how and why of the observations made i e why curriculum training is essential and why certain failure modes exist the introduction contains several statements which should be qualified or explained further as far as i am aware statistical learning theory does not guarantee that empirical risk minimization is consistent when the number of parameters is larger than the number of examples the generalization performance depends on the vc dimension of the function space instead furthermore the suggested link between adversarial examples and learning algorithms is tenuous and references or a further explanation should be provided for the contentious statement that deep neural networks are able to match the performance of any parallel machine learning algorithm the authors argue that the neural gpu performs o n steps on each example which allows it to learn algorithms with super linear complexity such as multiplication this analysis seems to overlook the parallel nature of the neural gpu architecture both addition and multiplication have o log n time complexity when parallelism is used cf a carry lookahead adder and a wallace tree respectively in section the authors show that their larger models generalize better which they argue is not self evident however since both training and test error decrease it is likely that the smaller models are underfitting in which case it is not counter intuitive at all that a larger model would have better generalization error it is interesting to see that progressively decreasing the number of terms and increasing the radix of the number system works well as a learning curriculum although it would be nice to have a stronger intuitive or theoretical justification for the latter the final section claims that neural gpus are cellular automata further justification for this statement would be useful since cellular automata are discrete models and the equivalence between both models is in no way obvious the relationship between global operations and changing the input format is circuitous in conclusion the paper provides some useful insights into the neural gpu model but does not introduce original extensions to the model and does not explain any fundamental limitations several statements require stronger substantiation pro well written exhaustive set of experiments learning algorithms with decimal representation available source code cons no coherent hypothesis premise advanced two or three bold statements without explanation or references some unclarity in experimental details limited novelty and originality factor typos add minus in chance of carrying k digits is k section remove are from the larger models with filters are achieve section add a in such model doesn t generalize section,4.0
586.json,the paper investigates on better training strategies for the neural gpu models as well as studies the limitations of the model pros well written many investigations available source code cons misleading title there is no extension to the neural gpu model just to its training strategies no comparisons to similar architectures e g grid lstm ntm adaptive computation time more experiments on other tasks would be nice it is only tested on some toy tasks no positive results only negative results to really understand the negative results it would be good to know what is missing to make it work this has not been studied further some details remain unclear or missing e g if gradient noise was used in all experiments or the length of sequences e g in figure misleading number of ntm computation steps you write o n but it is actually variable after the results from the paper the limitations still remain unclear because it is not clear exactly why the model fails despite showing some examples which make it fail it was not studied in more detail why it failed for those examples and how you could fix the problem,5.0
569.json,this paper introduces an attention based recurrent network that learns to compare images by attending iteratively back and forth between a pair of images experiments show state of the art results on omniglot though a large part of the performance gain comes from when extracted convolutional features are used as input the paper is significantly improved from the original submission and reflects changes based on pre review questions however while there was an attempt made to include more qualitative results e g fig it is still relatively weak and could benefit from more examples and analysis also why is the attention in fig always attending over the full character although it is zooming in shouldn t it attend to relevant parts of the character attending to the full character on a solid background seems a trivial solution where it is then unclear where the large performance gains are coming from while the paper is much more polished now it is still lacking in details in some respects e g details of the convolutional feature extractor used that gives large performance gain,4.0
569.json,this paper presents an attention based recurrent approach to one shot learning it reports quite strong experimental results surpassing human performance hbpl on the omniglot dataset which is somewhat surprising because it seems to make use of very standard neural network machinery the authors also note that other have helped verify the results did soumith chintala reproduce the results and do provide source code after reading this paper i am left a little perplexed as to where the big performance improvements are coming from as it seems to share a lot of the same components of previous work if the author could report result from a broader suite of experiments like in previous work e g matching networks it would much more convincing an ablation study would also help with understanding why this model does so well,5.0
617.json,this paper describe an implementation of delayed synchronize sgd method for multi gpu deep ne training comments the described manual implementation of delayed synchronization and state protection is helpful however such dependency been implemented by a dependency scheduler without doing threading manually the overlap of computation and communication is a known technique implemented in existing solutions such as tensorflow as described in chen et al and mxnet the claimed contribution of this point is somewhat limited the convergence accuracy is only reported for the beginning iterations and only on alexnet it would be more helpful to include convergence curve till the end for all compared networks in summary this is paper implements a variant of delayed syncsgd approach i find the novelty of the system somewhat limited due to comment the experiments should have been improved to demonstrate the advantage of proposed approach,5.0
617.json,the authors present methods to speed up gradient descent by leveraging asynchronicity in a layer wise manner while they obtain up to x speedup compared to synchronous training their baseline is weak more importantly they dismiss parameter server based methods which are becoming standard and so effectively just do not compare to the current state of the art they also do not present wall time measurements with these flaws the paper is not ready for iclr acceptance,3.0
617.json,this paper is relatively difficult to parse much of the exposition of the proposed algorithm could be better presented using pseudo code describing the compute flow or a diagram describing exactly how the updates take place as it stands i am not sure i understand everything i would also have liked to see exactly described what the various labels in fig correspond to sgd task wise comm did you mean layer wise there are a couple of major issues with the evaluation first no comparison is reported against baseline async methods such as using a parameter server second using alexnet as a benchmark is not informative at all alexnet looks very different from any sota image recognition model and in particular it has many fewer layers which is especially relevant to the discussion in it also uses lots of fully connected layers which affect the compute communication ratios in ways that are not relevant to most interesting architectures today,3.0
494.json,use of ml in itp is an interesting direction of research authors consider the problem of predicting whether a given statement would be useful in a proof of a conjecture or not this is posed as a binary classification task and authors propose a dataset and some deep learning based baselines i am not an expert on itp or theorem proving so i will present a review from more of a ml perspective i feel one of the goals of the paper should be to present the problem to a ml audience in a way that is easy for them to grasp while most of the paper is well written there are some sections that are not clear especially section terms such as lcf ocaml top level debruijn indices have been used without explaining or any references these terms might be trivial in itp literature but were hard for me to follow section describes how the data was splits into train and test set one thing which is unclear is can the examples in the train and test set be statements about the same conjecture or are they always statements about different conjectures it also unclear how the deep learning models are applied let s consider the leftmost architecture in figure each character is embedded into d vector and processed until the global max pooling layer does this layer take a max along each feature and across all characters in the input my another concern is only deep learning methods are presented as baselines it would be great to compare with standard nlp techniques such as bag of words followed by svm i am sure these would be outperformed by neural networks but the numbers would give a sense of how easy hard the current problem setup is did the authors look at the success and failure cases of the algorithm are there any insights that can be drawn from such analysis that can inform design of future models overall i think the research direction of using ml for theorem proving is an interesting one however i also feel the paper is quite opaque many parts of how the data is constructed is unclear atleast to someone with little knowledge in itps if authors can revise the text to make it clearer it would be great the baseline models seem to perform quite well however there are no insights into what kind of ability the models are lacking authors mention that they are unable to perform logical reasoning but that s a very vague statement some examples of mistakes might help make the message clearer further since i am not well versed with the itp literature it s not possible for me to judge how valuable is this dataset from the references it seems like it s drawn from a set of benchmark conjectures proofs used in the itp community so its possibly a good dataset my current rating is a weak reject but if the authors address my concerns i would change to an accept,6.0
494.json,the authors present a dataset extraction method dataset and first interesting results for machine learning supported higher order logic theorem proving the experimental results are impressively good for a first baseline and with an accuracy higher than in relevance classification a lot better than chance and encourage future research in this direction the paper is well written in terms of presentation and argumentation and leaves little room for criticism the related work seems to be well covered though i have to note that i am not an expert for automated theorem proving,8.0
549.json,the paper introduces an efficient variant of sparse coding and uses it as a building block in cnns for image classification the coding method incorporates both the input signal reconstruction objective as well as top down information from a class label the proposed block is evaluated against the recently proposed crelu activation block positives the proposed method seems technically sound and it introduces a new way to efficiently train a cnn layer wise by combining reconstruction and discriminative objectives negatives the performance gain in terms of classification accuracy over the previous state of the art is not clear using only one dataset cifar the proposed method performs slightly better than the crelu baseline but the improvement is quite small in the test set the paper can be strengthened if the authors can demonstrate that the proposed method can be generally applicable to various cnn architectures and datasets with clear and consistent performance gains over strong cnn baselines without such results the practical significance of this work seems unclear,5.0
549.json,first i would like to thank the authors for their answers and clarifications i find the presentation of the multi stage version of the model much clearer now pros the paper states a sparse coding problem using cosine loss which allows to solve the problem in a single pass the energy based formulation allows bi directional coding that incorporates top down and bottom up information in the feature extraction process cons the cost of running the evaluation could be large in the multi class setting rendering the approach less attractive and the computational cost comparable to recurrent architectures while the model is competitive and improves over the baseline the paper would be more convincing with other comparisons see text the experimental evaluation is limited a single database and a single baseline the motivation of the sparse coding scheme is to perform inference in a feed forward manner this property does not hold in the multi stage setting thus optimization would be required as clarified by the authors having an efficient way of performing a bi directional coding scheme is very interesting as the authors clarified this could not necessarily be the case as the model needs to be evaluated many times for performing a classification maybe an interesting combination would be to run the model without any class specific bias and evaluation only the top k predictions with the energy based setting having said this it would be good to include a discussion if not direct comparisons of the trade offs of using a model as the one proposed by cao et al eg computational costs performance using the bidirectional coding only on the top layers seems reasonable one can get a good low level representation in a class agnostic way this however could be studied in more detail for instance showing empirically the trade offs if i understand correctly now only one setting is being reported finally the authors mention that one benefit of using the architecture derived from the proposed coding method is the spherical normalization scheme which can lead to smoother optimization dynamics does the baseline or model use batch normalization if not seems relevant to test minor comments i find figure d confusing i would not plot this setting as it does not lead to a function as the authors state in the text,6.0
725.json,strengths interesting to explore the connection between relu dnn and simplified sfnn small task mnist is used to demonstrate the usefulness of the proposed training methods experimentally the proposed multi stage training methods are simple to implement despite lacking theoretical rigor weaknesses no results are reported on real tasks with large training set not clear exploration on the scalability of the learning methods when training data becomes larger when the hidden layers become stochastic the model shares uncertainty representation with deep bayes networks or deep generative models deep discriminative and generative models for pattern recognition book chapter in pattern recognition and computer vision november download pdf such connections should be discussed especially wrt the use of uncertainty representation to benefit pattern recognition i e supervised learning via bayes rule and to benefit the use of domain knowledge such as explaining away would like to see connections with variational autoencoder models and training which is also stochastic with hidden layers,5.0
725.json,this paper builds connections between dnn simplified stochastic neural network sfnn and sfnn and proposes to use dnn as the initialization model for simplified sfnn the authors evaluated their model on several small tasks with positive results the connection between different models is interesting i think the connection between sigmoid dnn and simplified sfnn is the same as mean field approximation that has been known for decades however the connection between relu dnn and simplified sfnn is novel my main concern is whether the proposed approach is useful when attacking real tasks with large training set for tasks with small training set i can see that stochastic units would help generalize well,6.0
660.json,the paper introduced an extension of adam optimizer that automatically adjust learning rate by comparing the subsequent values of the cost function during training the authors empirically demonstrated the benefit of the eve optimizer on cifar convnets logistic regression and rnn problems i have the following concerns about the paper the proposed method is variant to arbitrary shifts and scaling to the cost function a more fair comparison with other baseline methods would be using additional exponential decay learning scheduling between the lower and upper threshold of dt i suspect dt just shrinks as an exponential decay from figure three additional hyper parameters k k beta overall i think the method has its fundamental flew and the paper offers very limited novelty there is no theoretical justification on the modification and it would be good for the authors to discuss the potential failure mode of the proposed method furthermore it is hard for me to follow section the writing quality and clarity of the method section can be further improved,5.0
660.json,the paper demonstrates a semi automatic learning rate schedule for the adam optimizer called eve originality is somehow limited but the method appears to have a positive effect on neural network training the paper is well written and illustrations are appropriate pros probably a more sophisticated scheduling technique than a simple decay term reasonable results on the cifar dataset although with comparably small neural network cons effect of momentum term would be of interest the adam reference does not point to the conference publications but only to arxiv comparison to adam not entirely conclusive,6.0
772.json,the paper conducts a detailed evaluation of different cnn architectures applied to image retrieval the authors focus on testing various architectural choices but do not propose or compare to end to end learning frameworks technically the contribution is clear particularly with the promised clarifications on how multiple scales are handled in the representation however i am still not entirely clear whether there would be a difference in the multi scale settting for full and cropped queries while the paper focuses on comparing different baseline architectures for cnn based image retrieval several recent papers have proposed to learn end to end representations specific for this task with very good result see for instance the recent work by gordo et al end to end learning of deep visual representations for image retrieval the authors clarify that their work is orthogonal to papers such as gordo et al as they assess instead the performance of networks pre trained from image classification in fact they also indicate that image retrieval is more difficult than image classification this is because it is performed by using features originally trained for classification i can partially accept this argument however given the results in recent papers it is clear than end to end training is far superior in practice and it is not clear the analysis developed by the authors in this work would transfer or be useful for that case as well,6.0
772.json,authors investigate how to use pretrained cnns for retrieval and perform an extensive evaluation of the influence of various parameters for detailed comments on everything see the questions i posted earlier the summary is here i do not think we learn much from this paper we already knew that we should use the last conv layer we knew we should use pca with whitening we knew we should use original size images authors say tolias did not do this as they resized the images but they did this exactly for the same reason as authors did not evaluate on holidays the images are too big so they basically used as large as possible image sizes which is what this paper effectively suggests as well etc this paper essentially concatenates methods that people have already used and performs some more parameter tweaking to achieve the state of the art while the tweaking is actually performed on the test set of some of the tests the setting of the state of the art results is quite misleading as it does not really come from the good choice of parameters but mainly due to the usage of the deeper vgg network furthermore i do not think it sufficient to just try one network and claim these are the best practices for using cnns for instance retrieval what about resnet what about inception i do not know how to apply any of these conclusions for those networks and would these conclusions even hold for them furthermore the parameter tweaking was done on oxford i really can not tell what conclusions would we get if we tuned on ukb for example so a more appropriate paper title would be what are the best parameter values for vgg on oxford paris benchmarks i do not think this is sufficiently novel nor interesting for the community,3.0
322.json,this paper proposes a nonparametric neural network model which automatically learns the size of the model during the training process the key idea is to randomly add zero units and use sparse regularizer to automatically null out the weights that are irrelevant the idea sounds to be a random search approach over discrete space with the help of sparse regularization to eliminate useless units this is an important problem and the paper gives interesting results my main comments are listed below what is the additional computation complexity of the algorithm the decomposition of each fan in weights into a parallel component and an orthogonal component and the transformation into radial angular coordinates may require a lot of extra computation time the authors may need to discuss the extra amount of operations relative to the parametric neural network furthermore it would be useful to show some running time experiments it is observed that nonparametric networks return small networks on the convex dataset so that it is inferior to parametric networks any insight on this,7.0
322.json,i agree with reviewer on the interesting part of the paper the idea of removing or adding units is definitely an interesting direction that will make a model grow or shrink along the lines required by the problem and the data not the user prior knowledge the authors offer an interesting theoretical result that proves that under fan out or fan in regularization the optimum of the error function is achieved for finite number of parameters so the net does not grow indefinitely until it over fits perfectly the data that reminds me of more traditional approaches such as lasso or elastic net in which the regularization produces sparse weights i would have like more intuition to be given for this theorem it is a nice result somewhat expected at last for me it is intuitive and i would have liked such intuition to be given some space in the paper for example less discussion of prior work that is nice too but not as important as discussing and studying the main result of the paper could make more room for addressing the theoretical results please also see below point for some suggestions i have a few other comments to make an interesting experiment would be to show that a model such as yours where the nodes neurons are added or removed automatically can outperform a net with the same number of nodes at the end after complete learning in which the size and number of nodes per layer are fixed from the start this would prove the efficiency of the idea this is where your method is interesting do you save nodes that are not needed and replace them with nodes that are needed do you optimize performance vs memory i understand that experiments along this line are given in figure with mixed results the figure i must say is not very clear but it is possible to interpret under careful inspection in some the non parametric nets are doing better and others are doing worse than the parametric ones even in such case i could see the usefulness of the method as it helps discovering the structure what i do not fully understand is why they can do better sometimes than the end net which could be trained from scratch why is the nonparametric version of learning better than the parametric version when the final net is known in advance could you give more insight can you better discuss the meaning and implications of theorem i feel this theorem is just put there with no proper discussion beyond the proofs from the appendix what is the key insight of the theorem what does it say in plain english to me the conclusion seems almost natural and obvious is there some powerful insight as i have mentioned previously i feel this theoretical result deserves more space with even more experiments to back it up for example can regularizer parameter lambda be predicted given the data is there a property in the data that can help guessing the right lambda my feeling is that lambda is the key factor for determining the final net structure is this true how much does the structure of the final net depend on the initialization do you get different nets if you start from different random weights how different are they what happens when fan in and fan out regularizers are combined do you still have the same theoretical result i have a few additional questions why do you say that adding zero units changes the regularizer value for example does l norm change if you add zero values zero units are defined as having either the fan in or the fan out weights being zero i think that what you meant is that both fan in and fan out weights are zero otherwise you cannot remove the unit and keep the same output f this should be clarified better i think i changed my rating to while hoping that the authors will address my comments above,7.0
637.json,this paper proposes a process to mine rules from vector space representations learned from kbs using nonnegative rescal the paper is nicely written but its motivations are unclear what is the underlying motivation to mine rules from embedding spaces if it is for better performance on link prediction then the paper does not show this the experiments do not compare frm against the performance of the original vector space model if it is for a better interpretability and debugging of the representations learned by vector space models then there should have more elements on this in the paper other remarks the fact that the performance of the methods in figure and are not compared to any baseline is problematic the scalability of the rule miner is a big drawback that should be addressed figure does not do a good job at convincing that rule based systems should be used for prediction or interpretation the learned rules are bad for both cases,3.0
637.json,the paper presents a nice idea of directly finding rules such as brother father uncle in knowledge bases by directly searching in embedding space the idea is to interpret the successive application of relationships as the multiplication of the relation dependent matrices in non negative rescal the experimental section provides an evaluation of the rules that are found by the algorithm nonetheless the work seems only at its first stages for now and many questions are left open while the approach to find rules seems very general the reason why it should work is unclear what properties of the embedding space or of the initial algorithm are required for this approach to find meaningful rules can we apply the same principles to other algorithms than non negative rescal there is no real evaluation in terms of link prediction how can we use these rules in conjunction with the original algorithm to improve link prediction what performance gains can be expected can these rules find links that would not be found be the original algorithm in the first place scaling for now the number of parameters of the rule miner is relationships max path length how does this method scale on standard benchmarks such as fbk where there is more than a of relationships,4.0
508.json,the paper proposed a method mainly for graph classification the proposal is to decompose graphs objects into hierarchies of small graphs followed by generating vector embeddings and aggregation using deep networks the approach is reasonable and intuitive however experiments do not show superiority of their approach the proposed method outperforms yanardag et al and niepert et al on social networks graphs but are quite inferior to niepert et al on bio informatics datasets the authors did not report acccuracy for yanardag et al which on similar bio ddatasets for example nci is significantly better than achieved by the proposed method the authors claim that their method is tailored for social networks graph more is not supported by good arguments what models of graphs is this method more suitable,5.0
508.json,the paper contributes to recent work investigating how neural networks can be used on graph structured data as far as i can tell the proposed approach is the following construct a hierarchical set of objects within the graph each object consists of multiple parts from the set of objects in the level below there are potentially different ways a part can be part of an object the different pi labels which i would maybe call membership types in the experiments the objects at the bottom level are vertices at the next level they are radius just a vertex and radius neighborhoods around each vertex and the membership types here are either root or element depending on whether a vertex is the center of the neighborhood or a neighbor at the top level there is one object consisting of all of these neighborhoods with membership types of radius neighborhood is not this still just a vertex or radius neighborhood every object has a representation each vertex representation is a one hot encoding of its degree to construct an object representation at the next level the following scheme is employed a for each object sum the representation of all of its parts having the same membership type b concatenate the sums obtained from different membership types c pass this vector through a multi layer neural net i have provided this summary mainly because the description in the paper itself is somewhat hard to follow and relevant details are scattered throughout the text so i would like to verify that my understanding is correct some additional questions i have that were not clear from the text how many layers and hidden units were used what are the dimensionalities of the representations used at each layer how is final classification performed what is the motivation for the chosen ego graph representation the proposed approach is interesting and novel the compression technique appears effective and the results seem compelling however the clarity and structure of the writing is quite poor it took me a while to figure out what was going on the initial description is provided without any illustrative examples and it required jumping around the paper to figure for example how the pi labels are actually used important details around network architecture are not provided and very little in the way of motivation is given for many of the choices made were other choices of decomposition object part structures investigated given the generality of the shift aggregate extract formulation what motivated the choice of ego graphs why one hot degrees for the initial attributes overall i think the paper contains a useful contribution on a technical level but the presentation needs to be significantly cleaned up before i can recommend acceptance,5.0
334.json,the paper presented an extension to the current visual attention model that learns a deformable sampling lattice comparing to the fixed sampling lattice from previous works the proposed method shows different sampling strategy can emerge depending on the visual classification tasks the authors empirically demonstrated the learnt sampling lattice outperforms the fixed strategies more interestingly when the attention mechanism is constrained to be translation only the proposed model learns a sampling lattice resembles the retina found in the primate retina pros the paper is generally well organized and written the qualitative analysis in the experimental section is very comprehensive cons the paper could benefit substantially from additional experiments on different datasets it is not clear from the tables the proposed learnt sampling lattice offer any computation benefit when comparing to a fixed sampling strategy with zooming capability e g the one used in draw model overall i really like the paper i think the experimental section can be improved by additional experiments and more quantitative analysis with other baselines because the current revision of the paper only shows experiments on digit dataset with black background it is hard to generalize the finding or even to verify the claims in the paper e g linear relationship between eccentricity and sampling interval leads to the primate retina from the results on a single dataset,5.0
461.json,this paper presents a model for semi supervised learning by encouraging feature invariance to stochastic perturbations of the network and or inputs two models are described one where an invariance term is applied between different instantiations of the model input a single training step and a second where invariance is applied to features for the same input point across training steps via a cumulative exponential averaging of the features these models evaluated using cifar and svhn finding decent gains of similar amounts in each case an additional application is also explored at the end showing some tolerance to corrupted labels as well the authors also discuss recent work by sajjadi al that is very similar in spirit which i think helps corroborate the findings here my largest critique is it would have been nice to see applications on larger datasets as well cifar and svhn are fairly small test cases though adequate for demonstration of the idea for cases of unlabelled data especially it would be good to see tests with on the order of m data samples with k k labeled as this is a common case when labels are missing on a similar note data augmentations are restricted to only translations and for cifar horizontal flips while standard as the paper notes more augmentations would have been interesting to see particularly since the model is designed explicitly to take advantage of random sampling some more details might also pop up such as the one the paper mentions about handling horizontal flips in different ways between the two model variants rather than restrict the system to a particular set of augmentations i think it would be interesting to push it further and see how its performance behaves over a larger array of augmentations and even fewer numbers of labels overall this seems like a simple approach that is getting decent results though i would have liked to see more and larger experiments to get a better sense for its performance characteristics smaller comment the paper mentions dark knowledge a couple times in explaining results e g bottom of p this is ok for a motivation but in analyzing the results i think it may be possible to have something more concrete for instance the consistency term encourages feature invariance to the stochastic sampling more strongly than would a classification loss alone,7.0
461.json,this work explores taking advantage of the stochasticity of neural network outputs under randomized augmentation and regularization techniques to provide targets for unlabeled data in a semi supervised setting this is accomplished by either applying stochastic augmentation and regularization on a single image multiple times per epoch and encouraging the outputs to be similar π model or by keeping a weighted average of past epoch outputs and penalizing deviations of current network outputs from this running mean temporal ensembling the core argument is that these approaches produce ensemble predictions which are likely more accurate than the current network and are thus good targets for unlabeled data both approaches seem to work quite well on semi supervised tasks and some results show that they are almost unbelievably robust to label noise the paper is clearly written and provides sufficient details to reproduce these results in addition to providing a public code base the core idea of the paper is quite interesting and seems to result in higher semi supervised accuracy than prior work i also found the attention to and discussion of the effect of different choices of data augmentation to be useful i am a little surprised that a standard supervised network can achieve accuracy on svhn given random training labels this would only give correctly labeled data by chance unaltered i suppose the other would not provide a consistent training signal such that it is possible but it does seem quite unintuitive i tried to look through the github for this experiment but it does not seem to be included as for the resistance of π model and temporal ensembling to this label noise i find that somewhat more believable given the large weights placed on the consistency constraint for this task the authors should really include discussion of w t in the main paper especially because the tremendous difference in wmax in the incorrect label tolerance experiment x for π model and x for temporal ensembling from the standard setting could the authors comment towards the scalability for larger problems for imagenet you would need to store around gigs for the temporal ensembling method or spend x as long training with π model can the authors discuss sensitivity of this approach to the amount and location of dropout layers in the architecture preliminary rating i think this is a very interesting paper with quality results and clear presentation minor note nd paragraph of page one without neither without either,9.0
461.json,this paper presents a semi supervised technique for self ensembling where the model uses a consensus prediction computed from previous epochs as a target to regress to in addition to the usual supervised learning loss this has connections to the dark knowledge idea ladder networks work is shown in this paper to be a promising technique for scenarios with few labeled examples but not only the paper presents two versions of the idea one which is computationally expensive and high variance in that it needs two passes through the same example at a given step and a temporal ensembling method that is stabler cheaper computationally but more memory hungry and requires an extra hyper parameter my thoughts on this work are mostly positive the drawbacks that i see are that the temporal ensembling work requires potentially a lot of memory and non trivial infrastructure book keeping for imagenet sized experiments i am quite confused by the figure section experiments about tolerance to noisy labels it s very incredible to me that by making of the labels random one can still train a classifier that is either accurate or accurate depending on whether or not temporal ensembling was used i don t see how that can happen basically minor stuff please bold the best in category results in your tables i think it would be nice to talk about the ramp up of w t in the main paper the authors should consider putting the state of the art results for the fully supervised case in their tables instead of just their own i am confused as to why the authors chose not to use more svhn examples the stated reason that it d be too easy seems a bit contrived if they used all examples it would also make it easy to compare to previous work,8.0
524.json,tdlr the authors present a regularization method wherein they add noise to some representation space the paper mainly applies the technique w sequence autoencoders dai et al without the usage of attention i e only using the context vector experimental results show improvement from author baseline on some toy tasks augmentation the augmentation process is simple enough take the seqseq context vector and add noise interpolate extrapolate to it section this reviewer is very curious whether this process will also work in non seqseq applications this reviewer would have liked to see comparison with dropout on the context vector experiments since the authors are experimenting w seqseq architectures its a little bit disappointing they did not compare it w machine translation mt where there are many published papers to compare to the authors did compare their method on several toy datasets that are less commonly used in dl literature and mnist cifar the authors show improvement over their own baselines on several toy datasets the improvement on mnist cifar over the author baseline seems marginal at best the author also did not cite compare to the baseline published by dai et al for cifar here they have a much better lstm baseline of for cifar which beats the author baseline of and the author method of the experiments would be much more convincing if they did it on seqseq mt on say en fr or en de there is almost no excuse why the experiments was not run on the mt task given this is the first application of seqseq was born from even if not mt then at least the sentiment analysis tasks imdb rotten tomatoes of the dai et al paper which this paper is so heavily based on for the sequence autoencoder references something is wrong w your references latex setting seems like a lot of the conference journal names are omitted additionally you should update many cites to use the conference journal name rather than just arxiv listen attend and spell should be listen attend and spell a neural network for large vocabulary conversational speech recognition icassp if citing icassp paper above should also cite bahandau paper end to end attention based large vocabulary speech recognition which was published in parallel also in icassp adam a method for stochastic optimization iclr auto encoding variational bayes iclr addressing the rare word problem in neural machine translation acl pixel recurrent neural networks icml a neural conversational model icml workshop,4.0
748.json,the system described works comparably to bi directional lstm baseline for nmt and cnn are naturally parallelizable key ideas include the use of two stacked cnn one for each of encoding and decoding for translation with res connections and position embeddings the use of cnn for translation has been attempted previously as described by the authors but presumably it is the authors combination of various architectural choices attention position embeddings etc that make the present system competitive with rnn whereas earlier attempts were not they describe system sensitivity to some of these choices e g experiments to choose appropriate number of layers in each of the cnn the experimental results are well reported in detail one or two figures would definitely be required to help clarify the architecture this paper is less about new ways of learning representations than about the combination of choices made over the set of existing techniques in order to get the good results that they do on the reported nmt tasks in this respect while i am fairly confident that the paper represents good work in machine learning i am not quite as confident about its fit for this particular conference,7.0
748.json,the paper reports a very clear and easy to understand result that a convolutional network can be used instead of the recurrent encoder for neural machine translation apart from the known architectural elements such as convolution pooling residual connections position embeddings the paper features one unexpected architectural twist two stacks of convolutions one for computing alignment and another for computing the representations the empirical evidence that this was necessary is provided however the question of why it is necessary remains open the experimental evaluation is very extensive and leaves no doubt that the proposed approach works well the convnet based model was faster at evaluation but it is not very clear what is the main speed up factor it s however hard to argue against the fact that the speed advantage of convnets is likely to increase if a more parallel implementation is considered my main concern is whether or not the paper is appropriate for iclr because the contribution is quite incremental and rather application specific acl emnlp and other nlp conferences would be a better venue i think,6.0
318.json,the main contribution of this paper seems to be an introduction of a set of differential graph transformations which will allow you to learn graph graph classification tasks using gradient descent this maps naturally to a task of learning a cellular automaton represented as sequence of graphs in that task the graph of nodes grows at each iteration with nodes pointing to neighbors and special nodes representing the values proposed architecture allows one to learn this sequence of graphs although in the experiment this task rule was far from solved this idea is combined with ideas from previous papers ggs nn to allow the model to produce textual output rather than graph output and use graphs as intermediate representation which allows it to beat state of the art on babi tasks,7.0
318.json,this paper proposes learning on the fly to represent a dialog as a graph which acts as the memory and is first demonstrated on the babi tasks graph learning is part of the inference process though there is long term representation learning to learn graph transformation parameters and the encoding of sentences as input to the graph this seems to be the first implementation of a differentiable memory as graph it is much more complex than previous approaches like memory networks without significant gain in performance in babi tasks but it is still very preliminary work and the representation of memory as a graph seems much more powerful than a stack clarity is a major issue but from an initial version that was constructive and better read by a computer than a human the author proposed a hugely improved later version this original technically accurate within what i understood and thought provoking paper is worth publishing the preliminary results do not tell us yet if the highly complex graph based differentiable memory has more learning or generalization capacity than other approaches the performance on the babi task is comparable to the best memory networks but still worse than more traditional rule induction see,9.0
436.json,the paper presents an end to end neural network model for the problem of designing natural language interfaces for database queries the proposed approach uses only weak supervision signals to learn the parameters of the model unlike in traditional approaches where the problem is solved by semantically parsing a natural language query into logical forms and executing those logical forms over the given data base the proposed approach trains a neural network in an end to end manner which goes directly from the natural language query to the final answer obtained by processing the data base this is achieved by formulating a collection of operations to be performed over the data base as continuous operations the distributions over which is learnt using the now standard soft attention mechanisms the model is validated on the smallish wikitablequestions dataset where the authors show that a single model performs worse than the approach which uses the traditional semantic parsing technique however an ensemble of models trained in a variety of ways results in comparable performance to the state of the art i feel that the paper proposes an interesting solution to the hard problem of learning natural language interfaces for data bases the model is an extension of the previously proposed models of neelakantan the experimental section is rather weak though the authors only show their model work on a single smallish dataset would love to see more ablation studies of their model and comparison against fancier version of memnns i do not buy their initial response to not testing against memory networks i do have a few objections though the details of the model are rather convoluted and the section is not very clearly written in particular with the absence of the accompanying code the model will be super hard to replicate i wish the authors do a better job in explaining the details as to how exactly the discrete operations are modeled what is the role of the row selector the scalar answer and the lookup answer etc the authors do a full attention over the entire database do they think this approach would scale when the data bases are huge millions of rows wish they experimented with larger datasets as well,7.0
436.json,this paper proposes a weakly supervised end to end neural network model for solving a challenging natural language understanding task as an extension of the neural programmer this work aims at overcoming the ambiguities imposed by natural language by predefining a set of operations the model is able to learn the interface between the language reasoning and answer composition using backpropagation on the wikitablequestions dataset it is able to achieve a slightly better performance than the traditional semantic parser methods overall this is a very interesting and promising work as it involves a lot of real world challenges about natural language understanding the intuitions and design of the model are very clear but the complication makes the paper a bit difficult to read which means the model is also difficult to be reimplemented i would expect to see more details about model ablation and it would help us figure out the prominent parts of the model design,6.0
436.json,this paper proposes a weakly supervised end to end neural network model to learn a natural language interface for tables the neural programmer is applied to the wikitablequestions a natural language qa dataset and achieves reasonable accuracy an ensemble further boosts the performance by combining components built with different configurations and achieves comparable performance as the traditional natural language semantic parser baseline dropout and weight decay seem to play a significant role it will be interesting to see more error analysis and the major reason for the still low accuracy compared to many other nlp tasks what is the headroom and oracle number with the current approach,6.0
573.json,pros the general idea behind the paper seems pretty novel and potentially quite cool the specific technical implementation seems pretty reasonable and well thought through the general types of the tasks that they try out their approach on spans a wide and interesting spectrum of cognition abilities the writing is pretty clear i basically felt like i could replicate much of what they did from their paper descriptions cons the evaluation of the success of these ideas as compared to other possible approaches or as compared to human performance on similar tasks is extremely cursory the specific tasks that they try are quite simple i really do not know whether their approach is better than a bunch of simpler things on these tasks taking these two cons together it feels like the authors basically get the implementation done and working somewhat and then just wrote up the paper i know how it feels to be under a deadline without a complete set of results if the authors had used their approach to solve an obviously hard problem that previously was completely unsolved even the type of cursory evaluation level chosen here would have been fine or if they had done a very thorough evaluation of a bunch of standard models on each task and humans too ideally and compared their model to those results that would have been great but given the complexity of their methods and the fact that the tasks are either not well known benchmarks or very challenging as such it really hard to tell how much of an advance is made here but it does seem like a potentially fruitful research direction,6.0
420.json,this paper explores a variety of memory augmented architectures key key value key predict value and additionally simpler near memory less rnn architectures using an attention model that has access to the various decompositions is an interesting idea and one worth future explorations potentially in different tasks where this type of model could excel even more the results over the wikipedia corpus are interesting and feature a wide variety of different model types this is where the models suggested in the paper are strongest the same models run over the cbt dataset show a comparable but less convincing demonstration of the variations between the models the authors also released their wikipedia corpus already having inspected it i consider it a positive and interesting contribution i still believe that if a model was found that could better handle longer term dependencies it would do better on this wikipedia dataset but at least within the realm of what as an example the first article in train txt is about a person named george abbot yet abbot is not mentioned again until the next sentence tokens later and then the next abbot is tokens from there most gaps between occurrences of abbot are dozens of timesteps performing an analysis based upon easily accessed information such as when the same token reappears again or average sentence length may be useful as an approximation for the length that an attention window may prefer this is a well explained paper that raises interesting questions regarding the spans used in existing language modeling approaches and serves as a potential springboard for future directions,7.0
420.json,the paper presents an investigation of various neural language models designed to query context information from their recent history using an attention mechanism the authors propose to separate the attended vectors into key value and prediction parts the results suggest that this helps performance the authors also found that a simple model which which concatenates recent activation vectors performs at a similar level as the more complicated attention based models the experimental methodology seems sound in general i do have some issues with the way the dimensionality of the vectors involved in the attention mechanism is chosen while it s good that the hidden layer sizes are adapted to ensure similar numbers of trainable parameters for all the models this doesn t control for the fact that key value prediction vectors of a higher dimensionality may simply work better regardless of whether their dimensions are dedicated to one particular task or used together this separation clearly saves parameters but there could also be benefits of having some overlap of information assuming that vectors that lead to similar predictions may also be required in similar contexts for example some tasks may also require more dimensions than others and the explicit separation prevents the model from discovering and exploiting this while memory augmented rnns and rnns with attention mechanisms are not new some of these architectures had not yet been applied to language modeling similarly and as acknowledged by the authors the strategy of separating key and value functionality has been proposed before but not in the context of natural language modeling i m not sure about the novelty of the proposed n gram rnn because i recall seeing similar architectures before but i understand that novelty was not the point of that architecture as it mainly serves as a proof of the lack of ability of the more complicated architectures to do better in that sense i do consider it an inventive baseline that could be used in future work to test the ability of other models that claim to exploit long term dependencies the exact computation of the representation ht was initially not that clear to me the terms hidden and output can be ambiguous at times but besides this the paper is quite clear and generally well written the results in this paper are important because they show that learning long term dependencies is not a solved problem by any means the authors provide a very nice comparison to prior results and the fact that their n gram rnn is often at least competitive with far more complicated approaches is a clear indication that some of those methods may not capture as much context information as previously thought the success of the separation of key value prediction functionality in attention based system is also noteworthy although i think this is something that needs to be investigated more thoroughly i e with more control for hyperparameter choices pros impressive and also interesting results good comparison with earlier work the n gram rnn is an interesting baseline cons the relation between the attention mechanism type and the number of hidden units weakens the claim that the key value prediction separation is the reason for the increase in performance somewhat the model descriptions are not entirely clear i would have liked to have seen what happens when the attention is applied to a much larger context size,7.0
709.json,in this paper the authors propose to pretrain the encoder decoder of seqseq models on a large amount of unlabeled data using a lm objective they obtain improvements using this technique on machine translation and abstractive summarization while the effectiveness of pretraining seqseq models has been known among researchers and explored in a few papers e g zoph et al dai and le i believe this is the first paper to pretrain using a lm for both the encoder decoder the technique is simple but the gains are large e g bleu on nmt in addition the authors perform extensive ablation studies to analyze where the performance is coming from hence i think this paper should be accepted,7.0
709.json,strengths a method is proposed in this paper to initialize the encoder and decoder of the seqseq model using the trained weights of language models with no parallel data after such pretraining all weights are jointly fine tuned with parallel labeled data with an additional language modeling loss it is shown that pretraining accelerates training and improves generalization of seqseq models the main value of the proposed method is to leverage separate source and target corpora contrasting the common methods of using large amounts of parallel training corpora weaknesses the objective function shown in the middle of pg is highly empirical not directly linked to how non parallel data helps to improve the final prediction results the paper should compare with and discuss the objective function based on expectation of cross entropy which is directly linked to improving prediction results as proposed in arxiv chen et al unsupervised learning of predictors from unpaired input output samples the pre training procedure proposed in this paper is also closely connected with the dnn pretraining method presented in dahl et al comparisons should be made in the paper highlighting why the proposed one is conceptually superior if the authors believe so,5.0
532.json,paper is easy to follow idea is pretty clear and makes sense experimental results are hard to judge it would be nice to have other baselines for faster training convergence the question is how well tuned sgd is i did not see any mentioning of learning rate schedule also it would be important to test this on other data sets success with filtering training data could be task dependent,7.0
532.json,this work proposes to augment normal gradient descent algorithms with a data filter that acts as a curriculum teacher by selecting which examples the trained target network should see to learn optimally such a filter is learned simultaneously to the target network and trained via reinforcement learning algorithms receiving rewards based on the state of training with respect to some pseudo validation set stylistic comment please use the more common style of author year rather than author year when the author is not referred to or used in the sentence e g and its variants such as adagrad duchi et al should be such as adagrad duchi et al and proposed in andrychowicz et al should remain so i think the paragraph containing what we need to do is after seeing the mini batch dt of m training instances we dynamically determine which instances in dt are used for training and which are filtered should be clarified what is seeing that is you should mention explicitly that you do the forward pass first then compute features from that and then decide for which examples to perform the backwards pass there are a few choices in this work which i do not understand why wait until the end of the episode to update your reinforce policy algorithm but train your actor critic at each step algorithm you say reinforce has high variance which is true but does not mean it cannot be trained at each step unless you have some experiments that suggest otherwise and if so they should be included or mentionned in the paper similarly why not train reinforce with the same reward as your actor critic model and vice versa you claim several times that a limitation of reinforce is that you need to wait for the episode to be over but considering your data is i i d you can make your episode be anything from a single training step one dt to the whole multi epoch training procedure i have a few qualms with the experimental setting is figure obtained from a single i e one per setup experiment from different initial weights if so there is no proper way of knowing whether results are chance or not this is a serious concern for me with most state of the art work using optimization methods such as adam and rmsprop is it surprising that they were not experimented with it is not clear what the learning rates are how fast should the rl part adapt to the sl part its not clear that this was experimented with at all the environment i e the target network being trained is not stationnary at all it would have been interesting to measure how much the policy changes as a function of time figure could both be the result of the policy adapting or of the policy remaining fixed and the features changing which could indicate a failure of the policy to adapt in fact it is not really adressed in the paper that the environment is non stationary given the current setup the distribution of features will change as the target network progresses this has an impact on optimization how is the pseudo validation data target to the policy chosen it should be a subset of the training data the second paragraph of section suggests something of the sort but then your algorithms suggest that the same data is used to train both the policies and the networks so i am unsure of which is what overall the idea is novel and interesting the paper is well written for the most part but the methodology has some flaws clearer explanations and either more justification of the experimental choices or more experiments are needed to make this paper complete unless the authors convince me otherwise i think it would be worth waiting for more experiments and submitting a very strong paper rather than presenting this potentially powerful idea with weak results,6.0
476.json,description this paper describes experiments testing whether deep convolutional networks can be replaced with shallow networks with the same number of parameters without loss of accuracy the experiments are performed on he cifar dataset where deep convolutional teacher networks are used to train shallow student networks using l regression on logit outputs the results show that similar accuracy on the same parameter budget can be only obtained when multiple layers of convolution are used strong points the experiments are carefully done with thorough selection of hyperparameters the paper shows interesting results that go partially against conclusions from the previous work in this area ba and caruana the paper is well and clearly written weak points cifar is still somewhat toy dataset with only classes it would be interesting to see some results on a more challenging problem such as imagenet would the results for a large number of classes be similar originality this is mainly an experimental paper but the question it asks is interesting and worth investigation the experimental results are solid and provide new insights quality the experiments are well done clarity the paper is well written and clear significance the results go against some of the conclusions from previous work so should be published and discussed overall experimental paper with interesting results well written solid experiments,7.0
476.json,this paper aims to investigate the question if shallow non convolutional networks can be as affective as deep convolutional ones for image classification given that both architectures use the same number of parameters to this end the authors conducted a series of experiments on the cifar dataset they find that there is a significant performance gap between the two approaches in favour of deep cnns the experiments are well designed and involve a distillation training approach and the results are presented in a comprehensive manner they also observe as others have before that student models can be shallower than the teacher model from which they are trained for comparable performance my take on these results is that they suggest that using deep conv nets is more effective since this model class encodes a form of a prori or domain knowledge that images exhibit a certain degree of translation invariance in the way they should be processed for high level recognition tasks the results are therefore perhaps not quite surprising but not completely obvious either an interesting point on which the authors comment only very briefly is that among the non convolutional architectures the ones using or hidden layers outperform those with or hidden layers do you have an interpretation hypothesis of why this is the case it would be interesting to discuss the point a bit more in the paper it was not quite clear to me why were the experiments were limited to use m parameters at most none of the experiments in figure seem to be saturated although the performance gap between cnn and mlp is large i think it would be worthwhile to push the experiment further for the final version of the paper the authors state in the last paragraph that they expect shallow nets to be relatively worse in an imagenet classification experiment could the authors argue why they think this to be the case one could argue that the much larger training dataset size could compensate for shallow and or non convolutional choices of the architecture since mlps are universal function approximators one could understand architecture choices as expressions of certain priors over the function space and in a large data regimes such priors could be expected to be of lesser importance this issue could for example be examined on imagenet when varying the amount of training data also the much higher resolution of imagenet images might have a non trivial impact on the cnn mlp comparison as compared to the results established on the cifar dataset experiments on a second data set would also help to corroborate the findings demonstrating to what extent such findings are variable across datasets,7.0
499.json,although the trainable parameters might be reduced significantly unfortunately the training and recognition speech cannot be reduced in this way unfortunately as the results show the authors could not get better results with less parameters however the proposed structure with even more number of parameters shows significant gain e g in lm the paper should be reorganized and shortened it is sometimes difficult to follow and sometimes inconsistent e g the weights of the feedforward network depend only on an embedding vector see also my previous comments on linear bottlenecks whereas in recurrent network the generated weights also depend on the input observation or its hidden representation could the authors provide the num of trainable parameters for table probably presenting less results could also improve the readability only marginal accept due to the writing style,8.0
499.json,this paper proposes an interesting new method for training neural networks i e a hypernetwork is used to generate the model parameters of the main network the authors demonstrated that the total number of model parameters could be smaller while achieving competitive results on the image classification task in particular the hyperlstm with non shared weights can achieve excellent results compared to conventional lstm and its variants on a couple of lm talks which is very inspiring pros this work demonstrates that it is possible to generate the neural network model parameters using another network that can achieve competitive results by a few relative large scale experiments the idea itself is very inspiring and the experiments are very solid cons the paper would be much stronger if it was more focused in particular it is unclear what is the key advantage of this hypernetwork approach it is argued that in the paper that can achieve competitive results using smaller number of trainable model parameters however in the running time the computational complexity is the same as the standard main network for static networks such as convnet and the computational cost is even larger for dynamic networks such as lstms the improvements of hyperlstms over conventional lstm and its variants seem mainly come from increasing the number of model parameters minor question the convnet and lstm used in the experiments do not have a large softmax layer for most of the word level tasks for either lm or mt the softmax layer could be more than k is it going to be challenging for the hypernetwork generate large number of weights for that case and is it going to slowing the training down significantly,7.0
708.json,paper summary this work proposes a new algorithm to generate k adversarial images by modifying a small fraction of the image pixels and without requiring access to the classification network weight review summary the topic of adversarial images generation is of both practical and theoretical interest this work proposes a new approach to the problem however the paper suffers from multiple issues it is too verbose spending long time on experiments of limited interest disorganized detailed description of the main algorithm in sections and yet a key piece is added in the experimental section and more importantly the resulting experiments are of limited interest to the reader and the main conclusions are left unclear this looks like an interesting line of work that has yet to materialize in a good document it would need significant re writing to be in good shape for iclr pros interesting topic black box setup is most relevant multiple experiments shows that with flipping only of pixels adversarial images can be created cons too long yet key details are not well addressed some of the experiments are of little interest main experiments lack key measures or additional baselines limited technical novelty quality the method description and experimental setup leave to be desired clarity the text is verbose somewhat formal and mostly clear but could be improved by being more concise originality i am not aware of another work doing this exact same type of experiments however the approach and results are not very surprising significance the work is incremental the issues in the experiments limit potential impact of this paper specific comments i would suggest to start by making the paper shorter reducing the text length will force to make the argumentation and descriptions more direct and select only the important experiments section seems flawed if the modified single pixel can have values far outside of the lb ub range then this test sample is clearly outside of the training distribution and thus it is not surprising that the classifier misbehaves this would be true for most classifiers e g decision forests or non linear svms these results would be interesting only if the modified pixel is clamped to the range lb ub lb ub is never specified is it how does p compares to lb ub to be of any use p should be reported in proportion to lb ub the modification is done after normalization is this realistic alg why not clamping to lb ub section implementing algorithm locsearchadv the text is unclear on how p is adjusted new variables are added this is confusion section what happens if p is not adjusted what happens if a simple greedy random search is used e g try times a set of random pixels with value section ptb is computed over all pixels including the ones not modified why is that thus locsearchadv ptb value is not directly comparable to fgsm since it intermingles with ptbpixels e g in many cases far less average perturbation claim section there is no discussion on the average number of model evaluations this would be equivalent to the number of requests made to a system that one would try to fool this number is important to claim the effectiveness of such black box attacks right now the text only mentions the upper bound of network evaluations how does the number of network evaluations changes when adjusting or not adjusting p during the optimization top k is claimed as a main point of the paper yet only one experiment is provided please develop more or tune down the claims why is fgsm not effective for batch normalized networks has this been reported before are there other already published techniques that are effective for this scenario comparing to more methods would be interesting if there is little to note from section results what should be concluded from section that is possible to obtain good results by modifying only few pixels what about selecting the top n largest modified pixels from fgsm would these be enough please develop more the baselines and the specific conclusions of interest minor comments the is an abuse of footnotes most of them should be inserted in the main text i would suggest to repeat twice or thrice the meaning of the main variables used e g p r lb ub table should be figures last line of first paragraph of section is uninformative very tiny small,4.0
708.json,the paper presents a method for generating adversarial input images for a convolutional neural network given only black box access ability to obtain outputs for chosen inputs but no access to the network parameters however the notion of adversarial example is somewhat weakened in this setting it is k misclassification ensuring the true label is not a top k output instead of misclassification to any desired target label a similar black box setting is examined in papernot et al c there black box access is used to train a substitute for the network which is then attacked here black box access in instead exploited via local search the input is perturbed the resulting change in output scores is examined and perturbations that push the scores towards k misclassification are kept a major concern with regard to novelty is that this greedy local search procedure is analogous to gradient descent a numeric approximation observe change in output for corresponding change in input is used instead of backpropagation since one does not have access to the network parameters as such the greedy local search algorithm itself to which the paper devotes a large amount of discussion is not surprising and the paper is fairly incremental in terms of technical novelty,4.0
421.json,this paper proposes a novel and interesting way to tackle the difficulties of performing inference atop hsmm the idea of using an embedded bi rnn to approximate the posterior is a reasonable and clever idea that being said i think two aspects may need further improvement an explanation as to why a bi rnn can provide more accurate approximations than other modeling choices e g structured mean field that uses a sequential model to formulate the variational distribution is needed i think it would make the paper stronger if the authors can explain in an intuitive way why this modeling choice is better than some other natural choices in addition to empirical verification the real world datasets seem to be quite small e g less than sequences experimental results reported on larger datasets may also strengthen the paper,7.0
421.json,putting the score for now will post the full review tomorrow,7.0
437.json,the paper introduces gac a gpu based implementation of the ac algorithm which was originally designed for multi core cpus the main innovation is the introduction of a system of queues the queues are used for batching data for prediction and training in order to achieve high gpu occupancy the system is compared to the authors own implementation of ac as well as to published reference scores the paper introduces a very natural architecture for implementing ac on gpus batching requests for predictions and learning steps for multiple actors to maximize gpu occupancy seems like the right thing to do assuming that latency is not an issue the automatic performance tuning strategy is also really nice to see i appreciate the response showing that the throughput of gac is higher than what is reported in the original ac paper what is still missing is a demonstration that the learning speed data efficiency is in the right ballpark figure of your paper is comparing scores under very different evaluation protocols these numbers are just not comparable the most convincing way to show that the learning speed is comparable would be time vs score plots or data vs score plots that show similar or improved speed to ac for example this open source implementation seems to match the performance on breakout,5.0
437.json,this paper introduce a variant of ac model where while agents run on multiple cores on cpu the model computations which is the computationally intensive part is passed to the gpu and they perform various analysis to show the gained speedup thanks the authors for the replying to the questions and adjusting the paper to make it more clear it an interesting modification the the original algorithm and section does a through analysis of gpu utilization on different configurations the main weakness of the paper is lack of more extensive experiments in more atari domains and non atari domains also multiple plots for multiple runs for observing the instabilities stability is a very important issue in rl and also the most successful algorithms should be able to achieve good results in various domains i do understand the computational resource limitation especially in academia if in fact this work was done outside nvidia,7.0
572.json,comments this contrasts to adversarial attacks on classifiers where any inspection of the inputs will reveal the original bytes the adversary supplied which often have telltale noise is this really true if it were the case would not it imply that training against adversarial examples should easily make a classifier robust to adversarial examples if they all have a telltale noise pros the question of whether adversarial examples exist in generative models and indeed how the definition of adversarial example carries over is an interesting one finding that a certain type of generative model does not have adversarial examples would be a really significant result finding that generative models have adversarial examples would also be a worth negative result the adversarial examples in figures and seem convincing though they seem much more overt and noisy than the adversarial examples on mnist shown in szegedy is this because it actually harder to find adversarial examples in these types of generative models issues paper is significantly over length at pages the beginning of the paper should more clearly motivate its purpose paper has generative models in the title but as far as i can tell the whole paper is concerned with autoencoder type models this is kind of annoying because if someone wanted to consider adversarial attacks on say autoregressive models they might be unreasonably burdened by having to explain how they are distinct from a paper called adversarial examples for generative models i think that the introduction contains too much background information it could be tightened,6.0
572.json,this paper considers different methods of producing adversarial examples for generative models such as vae and vaegan specifically three methods are considered classification based adversaries which uses a classifier on top of the hidden code vae loss which directly uses the vae loss and the latent attack which finds adversarial perturbation in the input so as to match the latent representation of a target input i think the problem that this paper considers is potentially useful and interesting to the community to the best of my knowledge this is the first paper that considers adversarial examples for generative models as i pointed out in my pre review comments there is also a concurrent work of adversarial images for variational autoencoders that essentially proposes the same latent attack idea of this paper with both l distance and kl divergence novelty originality i did not find the ideas of this paper very original all the proposed three attacks are well known and standard methods that here are applied to a new problem and this paper does not develop novel algorithms for attacking specifically generative models however i still find it interesting to see how these standard methods compare in this new problem domain the clarity and presentation of the paper is very unsatisfying the first version of the paper proposes the classification based adversaries and reports only negative results in the second set of revisions the core idea of the paper changes and almost an entirely new paper with a new co author is submitted and the idea of latent attack is proposed which works much better than the classification based adversaries however the authors try to keep around the materials of the first version which results in a page long paper with different claims and unrelated set of experiments in our attempts to be thorough we have had a hard time keeping the length down is not a valid excuse in short the paper is investigating an interesting problem and apply and compare standard adversarial methods to this domain but the novelty and the presentation of the paper is limited,5.0
572.json,after the rebuttal the paper contains an interesting set of results mainly produced after the initial submission but novelty is limited and presentation is suboptimal for me now the biggest problem now is that the title and the content do not correspond the authors clearly attack deterministic encoder decoder models as described in which are not at all the same as generative models even though many generative models make use of this architecture a small experiment with sampling is interesting but does not change the overall focus of the paper this inconsistency in not acceptable the whole issue could be resolved for example by simply replacing generative models by encoder decoder networks in the title then i would tend towards recommending acceptance initial review the paper describes three approaches to generating adversarial examples for deep encoder decoder generative networks trained as vae or vae gan and shows a comparative analysis of these while the phenomenon of adversarial examples in discriminative models is widely known and relatively well studied i am not aware of previous work on adversarial examples for generative networks so this work is novel there is a concurrent work by tabacof et al which should be cited though the paper has significantly improved since the initial submission still i have a number of remarks on presentation and experimental evaluation i am in the borderline mode and may change my rating during the discussion phase detailed comments the paper is pages long significantly over the recommended page limit of pages reviewers have to read multiple papers multiple versions of each it is a lot of work large portions of the paper should be shortened and or moved to the appendix it is job of the authors to make the paper concise and readable in our attempts to be thorough we have had a hard time keeping the length down is a bad excuse it may be hard but has to be done i intentionally avoided term generative model above because it is not obvious to me if the attacks described by the authors indeed attack generative models to clarify the authors train encoder decoders as generative models vae or vae gan but then remove all stochasticity sampling and prior on the latent variables that is they treat the models as deterministic encoders decoders it is not a big surprise that a deterministic deep network can be easily tricked it would be much more interesting to see if the probabilistic aspect of generative models makes them more robust to such attacks am i missing something i would like the authors to clarify their view on this and adjust the claims in the paper if necessary the paper is motivated by possible attacks on a data channel which uses a generative network for compressing information description of the attack scenario in does not look convincing to me it takes a huge amount of space and i do not think it adds much to the paper first experiments on natural images are necessary to judge if the proposed attack could succeed in a realistic scenario and second i am not aware of any existing practical applications of vaes to image compression attacking jpeg would be much more practical experiments are limited to mnist and in the latest version svhn which is very nice while no good generative models of general natural images exist it is common to evaluate generative models on datasets of faces so this would be another very natural domain for testing the proposed approach smaller remarks usage of oracle in does not look appropriate oracle typically has access to part of ground truth which is not the case here as far as i understand beginning of section all three methods work for any generative architecture that relies on a learned latent representation z are technically applicable to would be more correct than work for confidentally,5.0
319.json,the paper proposes a new way of transferring knowledge i like the idea of transferring attention maps instead of activations however the experiments don t show a big improvement compared with knowledge distillation alone and i think more experiments are required in imagenet section i would consider updating the score if the authors extend the last section,6.0
319.json,the paper presented a modified knowledge distillation framework that minimizes the difference of the sum of statistics across the a feature map between the teacher and the student network the authors empirically demonstrated the proposed methods outperform the fitnet style distillation baseline pros the author evaluated the proposed methods on various computer vision dataset the paper is in general well written cons the method seems to be limited to the convolutional architecture the attention terminology is misleading in the paper the proposed method really just try to distill the summed squared or other statistics e g summed lp norm of activations in a hidden feature map the gradient based attention transfer seems out of place the proposed gradient based methods are never compared directly to nor are used jointly with the attention based transfer it seems like a parallel idea added to the paper that does not seem to add much value it is also not clear how the induced norms in eq is computed q is a matrix in mathbb r h times w whose induced norm is its largest singular value it seems computationally expensive to compute such cost function is it possible the authors really mean the frobenius norm overall the proposed distillation method works well in practice but the paper has some organization issues and unclear notation,6.0
319.json,this paper proposes to investigate attention transfers between a teacher and a student network attention transfer is performed by minimising the l distance between the teacher student attention maps at different layers in addition to minimising the classification loss and optionally a knowledge distillation term authors define several activation based attentions sum of absolute feature values raise at the power p or max of values raised at the power p they also propose a gradient based attention derivative of the loss w r t inputs they evaluate their approaches on several datasets cifar cub scene imagenet showing that attention transfers does help improving the student network test performance however the student networks performs worst than the teacher even with attention few remarks questions in section authors claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map while figure is compelling it would be nice to have quantitative results showing that as well how did you choose the hyperparameter values it would be nice to see what is the impact of beta it would be nice to report teacher train and validation loss in figure b from the experiments it is not clear what at the pros cons of the different attention maps at does not lead to better result than the teacher however the student networks have less parameters it would be interesting to characterise the corresponding speed up if you keep the same architecture between the student and the teacher is there any benefit to the attention transfer in summary pros clearly written and well motivated consistent improvement of the student with attention compared to the student alone cons students have worst performances than the teacher models it is not clear which attention to use in which case somewhat incremental novelty relatively to fitnet,6.0
525.json,summary this paper proposes an algorithm to learn the structure of continuous spns in a single pass through the data basically by growing the spn when two variables are correlated note i am not an expert on spns and can not really judge how impressive the presented results are due to lack of familiarity with the datsets pro this looks like possibly impactful work proposing a simple and elegant algorithm for learning spn structure single pass rather than just using random structure which has been done in other work in the online settings con the paper is heavily updated between submission deadline and submission of reviews the paper reads like a rush job sloppily written at least the first version comparison to literature is severely lacking eg several automated structure learning techniques have been proposed followed by citations but no discussion of any of them which one is most related which ideas carry over from the offline setting to this online setting etc also since this work presents both joint structure parameter learning comparison to the online parameter learning papers cited would be appreciated specifically since these prior approaches seem to be more principled with bayesian moment matching in jaini for example i do not know enough about spns and the datasets to properly judge how strong the results are but they seem to be a bit underwhelming on the large datasets wrt random remaining questions after the paper updates table random structure as baseline ok but how were the parameters here learned your simple running average or with more advanced methods table you are presenting positive average log likelihood values this should be an average of log p values what am i missing here i recommend reject mostly because this paper should have been finished and polished at submission time not at review deadline time,4.0
362.json,this papers adds to the literature on learning optimizers algorithms that has gained popularity recently the authors choose to use the framework of guided policy search at the meta level to train the optimizers they also opt to train on random objectives and assess transfer to a few simple tasks as pointed below this is a useful addition however the argument of using rl vs gradients at the meta level that appears below is not clear or convincing i urge the authors to run an experiment comparing the two approaches and to present comparative results this is a very important question and the scalability of this approach could very well hinge on this fact indeed demonstrating both scaling to large domains and transfer to those domains is the key challenge in this domain in summary the idea is a good one but the experiments are weak,6.0
362.json,the current version of the paper is improved w r t the original arxiv version from june while the results are exactly the same the text does not oversell them as much as before you may also consider to avoid words like mantra etc i believe that my criticism given in my comment from dec about randomly generated task is valid and you answer is not,7.0
677.json,this paper proposes an unsupervised graph embedding learning method based on random walk and skip thought model they show promising results compared to several competitors on four chemical compound datasets strength the idea of learning the graph embedding by applying skip thought model to random walk sequences is interesting the paper is well organized weakness as the current datasets are small e g the average number of nodes per graph is around it would be great to explore larger graph datasets to further investigate the method comparisons with recent work like line and nodevec are missing you can compare them easily by applying the same aggregation strategy to their node embeddings detailed questions the description about how to split the random walk sequence into sub sequences is missing also the line lmin nk lmax in section is a mistake can you provide the standard deviations of the fold cross validation in table i m curious about how stable the algorithm is,5.0
677.json,this paper studies the graph embedding problem by using the encoder decoder method the experimental study on real network data sets show the features extracted by the proposed model is good for classification strong points of this paper the idea of using the methods from natural language processing to graph mining is quite interesting the organization of the paper is clear weak points of this paper comparisons with state of art methods graph kernels is missing the problem is not well motivated are there any application of this what is the different from the graph kernel methods the comparison with graph kernel is missing need more experiment to demonstrate the power of their feature extraction methods clustering search prediction etc presentation of the paper is weak there are lots of typos and unclear statements the author mentioned about the graph kernel things but in the experiment they did not compare them also only compare the classification accuracy by using the proposed method is not enough,5.0
677.json,authors take the skip graph architecture kiros and apply it to classifying labeled graphs molecular graphs they do it by creating many sentences by walking the graph randomly and asking the model to predict previous part and next part from the middle part activations of the decoder part of this model on a walk generated from a new graph are used as features for a binary classifier use to predict whether the molecule has anti cancer properties paper is well written except that evaluation section is missing details of how the embedding is used for actual classification ie what classifier is used unfortunately i am not familiar with the dataset and how hard it is to achieve the results they demonstrate that would be the important factor to weight on the papers acceptance,6.0
677.json,the paper presents a method to learn graph embeddings in a unsupervised way using random walks it is well written and the execution appears quite accurate the area of learning whole graph representations does not seem to be very well explored in general and the proposed approach enjoys having very few competitors in a nutshell the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip thought criterion being not an expert in biology i can not comment whether or not this makes sense but the gains reported in table are quite significant an anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered while this is arguably a different goal one natural baseline would be to pool these representations using mean or max pooling it would very interesting to do such a comparison especially given that the considered approach heavily relies on pooling see figure c to sum up i think it is a nice paper and with more baselines i would be ready to further increase the numerical score,7.0
335.json,this paper presents an information theoretic framework for unsupervised learning the framework relies on infomax principle whose goal is to maximize the mutual information between input and output the authors propose a two step algorithm for learning in this setting first by leveraging an asymptotic approximation to the mutual information the global objective is decoupled into two subgoals whose solutions can be expressed in closed form next these serve as the initial guess for the global solution and are refined by the gradient descent algorithm while the story of the paper and the derivations seem sound the clarity and presentation of the material could improve for example instead of listing step by step derivation of each equation it would be nice to first give a high level presentation of the result and maybe explain briefly the derivation strategy the very detailed aspects of derivations which could obscure the underlying message of the result could perhaps be postponed to later sections or even moved to an appendix a few questions that the authors may want to clarify page last paragraph from above we know that maximizing i x r will result in maximizing i y r and i x y u while i see the former holds due to equality in the latter is related via a bound in due to the possible gap between i x r and i x y u can your claim that maximizing of the former indeed maximizes the latter be true paragraph above section it is stated that dropout used to prevent overfitting may in fact be regarded as an attempt to reduce the rank of the weight matrix no further tip is provided why this should be the case could you elaborate on that at the end of page we will discuss how to get optimal solution of c for two specific cases if i understand correctly you actually are not guaranteed to get the optimal solution of c in either case and the best you can guarantee is reaching a local optimum this is due to the nonconvexity of the constraint quadratic equality if optimality cannot be guaranteed please correct the wording accordingly,8.0
335.json,this paper proposes a hierarchical infomax method my comments are as follows first of all this paper is pages without appendix and too long as a conference proceeding therefore it is not easy for readers to follow the paper the authors should make this paper as compact as possible while maintaining the important message one of the main contribution in this paper is to find a good initialization point by maximizing i x r however it is unclear why maximizing i x breve y is good for maximizing i x r because proposition shows that i x breve y is an upper bound of i x r when it is difficult to directly maximize a function people often maximize some tractable lower bound of it minor comments if is approximation of approx should be used why k instead of n in eq in eq h x should disappear can you divide section into subsections,5.0
765.json,this paper introduces an additional reward predicting head to an existing nn architecture for video frame prediction in atari game playing scenarios the authors show that this model can successfully predict both reward and next frames pros paper is well written and easy to follow model is clear to understand cons the model is incrementally different than the baseline the authors state that their purpose is to establish a pre condition which they achieve but this makes the paper quite limited in scope this paper reads like the start of a really good long paper or a good short paper following through on the future work proposed by the authors would make a great paper as it stands the paper is a bit thin on new contributions,4.0
765.json,the paper extends a recently proposed video frame prediction method with reward prediction in order to learn the unknown system dynamics and reward structure of an environment the method is tested on several atari games and is able to predict the reward quite well within a range of about steps the paper is very well written focussed and is quite clear about its contribution to the literature the experiments and methods are sound however the results are not really surprising given that the system state and the reward are linked deterministically in atari games in other words we can always decode the reward from a network that successfully encodes future system states in its latent representation the contribution of the paper is therefore minor the paper would be much stronger if the authors could include experiments on the two future work directions they suggest in the conclusions augmenting training with artificial samples and adding monte carlo tree search the suggestions might decrease the number of real world training samples and increase performance both of which would be very interesting and impactful,4.0
765.json,the topic of the paper model based rl with a learned model is important and timely the paper is well written i feel that the presented results are too incremental augmenting the frame prediction network with another head that predicts the reward is a very sensible thing to do however neither the methodology not the results are novel surprising given that the original method of oh et al already learns to successfully increment score counters in predicted frames in many games i m very much looking forward to seeing the results of applying the learned joint model of frames and rewards to model based rl as proposed by the authors,4.0
509.json,this paper presents an approach to make a programming language forth interpreter differentiable such that it can learn the implementation of high level instruction from provided examples the paper is well written and the research is well motivated overall i find this paper is interesting and pleasure to read however the experiments only serve as proof of concept a more detailed empirical studies can strength the paper comments to my knowledge the proposed approach is novel and nicely bridge programming by example and sketches by programmers the proposed approach borrow some ideas from probabilistic programming and neural turing machine but it is significantly different from these methods it also presents optimisations of the interpreter to speed up the training it would be interesting to present results on different types of programming problems and see how complex of low level code can be generated,7.0
509.json,this paper presents an approach to do structured program induction based on program sketches in forth a simple stack based language they turn the overall too open problem of program induction into a slot filling problem with a differentiable forth interpreter for which one can backprop through the slots as they are random variables the point of having sketches partial programs is that one can learn more complex programs than starting from scratch with no prior information the loss that they optimize end to end through the program flow is a l rmse of the program memory at targeted non masked adresses and the desired output they show that they can learn addition and bubble sort both with a permute way sketch and with a compare way sketch the idea of making a language fully differentiable to write partial programs sketches and have them completed was previously explored in the probabilistic programming community and more recently with terpret i think that using forth a very simple stack based language as the sketch definition language is interesting in itself as it is between machine code neural turing machine stack rnn neural ram approaches and higher level languages church terpret problog section and figure could be made clearer explain the color code explain the parallel between d and the input list the experimental section is quite sparse even for learning to sort there is only one experimental setting train on length and test on length and e g no study of the length at which the generalization breaks it seems that it possibly does not no study of the relative runtime improvement w r t the training set in size and length of input sequences there are no baselines not even at least exhaustive search one of the neural approaches would be a plus to compare to similarly the addition experiment section is very shortly described and there are no baselines either whereas this is a staple of neural approaches to program induction does the presented sketch when trained on single digit addition examples successfully learns the addition and generalises to longer sequences mean that it generalizes to three digits or more overall the paper is very interesting but it seems to me like the experiments do not support the claims nor the usefulness enough,5.0
636.json,the main observation made in the paper is that the use of dropout increases the variance of neurons correcting for this increase in variance in the parameter initialization and in the test time statistics of batch normalization improves performance as is shown reasonably convincingly in the experiments this observation is important as it applies to many of the models used in the literature it not extremely novel it been observed in the literature before that our simple dropout approximations at test time do not achieve the accuracy obtained by full monte carlo dropout the paper could use more experimental validation specifically i am guessing the correction for dropout variance at test time is not only specific to batch normalization standard dropout in networks without batch normalization corrects only for the mean at test time by dividing activations by one minus the dropout probability this work suggests it would be beneficial to also correct for the variance has this been tested how does the dropout variance correction compare to using monte carlo dropout at test time i e just averaging over a large number of random dropout masks,7.0
374.json,this paper proposes a new gating mechanism to combine word and character representations the proposed model sets a new state of the art on the cbt dataset the new gating mechanism also improves over scalar gates without linguistic features on squad and a twitter classification task intuitively the vector based gate working better than the scalar gate is unsurprising as it is more similar to lstm and gru gates the real contribution of the paper for me is that using features such as pos tags and ner help learn better gates the visualization in figure and examples in table effectively confirm the utility of these features very nice in sum while the proposed gate is nothing technically groundbreaking the paper presents a very focused contribution that i think will be useful to the nlp community thus i hope it is accepted,7.0
374.json,i think the problem here is well motivated the approach is insightful and intuitive and the results are convincing of the approach although lacking in variety of applications i like the fact that the authors use pos and ner in terms of an intermediate signal for the decision also they compare against a sufficient range of baselines to show the effectiveness of the proposed model i am also convinced by the authors answers to my question i think there is sufficient evidence provided in the results to show the effectiveness of the inductive bias introduced by the fine grained gating model,6.0
661.json,the paper proposes a model that aims at learning to label nodes of graph in a semi supervised setting the idea of the model is based on the use of the graph structure to regularize the representations learned at the node levels experimental results are provided on different tasks the underlying idea of this paper graph regularization has been already explored in different papers e g learning latent representations of nodes for classifying in heterogeneous social networks jacob et al weston et al where a real graph structure is used instead of a built one the experiments lack of strong comparisons with other graph models e g iterative classification learning from labeled and unlabeled data on a directed graph so the novelty of the paper and the experimental protocol are not strong enough to accpet the paper pros learning over graph is an important topic cons many existing approaches have already exploited the same types of ideas resulting in very close models lack of comparison w r t existing models,3.0
548.json,summary this paper proposes a regularizer that is claimed to help escaping from the saddle points the method is inspired from physics such that thinking of the optimization process is moving a positively charged particle would over the error surface which would be pushed away from saddle points due to the saddle point being positively changed as well authors of the paper show results over several different datasets overview of the review pros the idea is very interesting the diverse set of results on different datasets cons the justification is not strong enough the paper is not well written experiments are not convincing enough criticisms i liked the idea and the intuitions coming from the paper however i think this paper is not written well there are some variables introduced in the paper and not explained good enough for example in the authors start to talk about p without introducing and defining it properly the only other place it appears before is equation the equations need some work as well some work is needed in terms of improving the flow of the paper e g introducing all the variables properly before using them equation appears without a proper explanation and justification it is necessary to explain it what it means properly since i think this is one of the most important equation in this paper more analysis on what it means in terms of optimization point of view would also be appreciated phi is not a parameter it is a function which has its own hyper parameter alpha it would be interesting to report validation or test results on a few tasks as well since this method introduced as an additional cost function its effect on the validation test results would be interesting as well the authors should discuss more on how they choose the hyper parameters of their models the figure and does not add too much to the paper and they are very difficult to understand or draw any conclusions from there are lots of figures under without any labels of captions some of them are really small and difficult to understand since the labels on the figures appear very small and somewhat unreadable a small question do you also backpropagate through tilde mw i t,5.0
548.json,this paper proposes a novel method for accelerating optimization near saddle points the basic idea is to repel the current parameter vector from a running average of recent parameter values this method is shown to optimize faster than a variety of other methods in a variety of datasets and architectures on the surface the proposed method seems extremely close to momentum it would be very valuable to think of a clear diagram illustrating how it differs from momentum and why it might be better near a saddle point the illustration of better convergence on the toy saddle example is not what i mean here optimization speed comparisons are always difficult due to the many details and hyper parameters involved so seeing it work faster in one specific application is not as useful as a conceptual diagram which shows a critical case where cpn will behave differently from and clearly qualitatively better than momentum another way of getting at the relationship to momentum would be to try to find a form for rt f that yields the exact momentum update you could then compare this with the rt f used in cpn the overly general notation phi w w etc should be dropped eqn is enough the theoretical results eqn and thm should be removed they are irrelevant until the joint density can be specified experimentally it would be valuable to standardize the results to allow comparison to other methods for instance recreating figure of dauphin et al but engaging the cpn method rather than sfn would clearly demonstrate that cpn can escape something that momentum cannot i think the idea here is potentially very valuable but needs more rigorous comparison and a clear relation to momentum and other work,4.0
495.json,summary this paper contributes to the description and comparison of the representational power of deep vs shallow neural networks with relu and threshold units the main contribution of the paper is to show that approximating a strongly convex differentiable function is possible with much less units when using a network with one more hidden layer pros the paper presents an interesting combination of tools and arrives at a nice result on the exponential superiority of depth cons the main result appears to address only strongly convex univariate functions specific comments thanks for the comments on l still it would be a good idea to clarify this point as far as possible in the main part also i would suggest to advertise the main result more prominently i still have not read the revision and maybe you have already addressed some of these points there the problem statement is close to that from montufar pascanu cho bengio nips which specifically arrives at exponential gaps between deep and shallow relu networks albeit from a different angle i would suggest to include that paper it in the overview in lemma there is an i that should be x in theorem tilde f is missing the x theorem the lower bound always increases with l in theorem bf x in d,7.0
616.json,the paper describes a network architecture for inverse problems in computer vision example inverse problems considered are image inpainting computing intrinsic image decomposition and foreground background separation the architecture is composed of i a generator that produces target latent output such as foreground background regions ii renderer that composes that latent output back to the image that can be compared with the input to measure reconstruction error and iii adversarial prior that ensures the target output latent image respects a certain image statistics strong points the proposed architecture with memory database is interesting and appears to be novel weak points experimental results are only proof of concept in toy set ups and do not clearly demonstrate benefits of the proposed architecture it is unclear whether the memory retrieval engine that retrieves images based on l distance on pixel values is going generalize to other more realistic scenarios clarity the clarity of explanation can be also improved see below detailed evaluation originality the novelty of this work lies in the iii adversarial prior that places an adversarial loss between the generated latent output and a single image retrieved from a large unlabelled database of target output examples called memory the adversarial prior has a convolutional form matching local image statistics rather than the entire image the particular form of network architecture with the memory based fully convolutional adversarial loss appears to be novel and potentially interesting motivation for the architecture the weakest point of the proposed architecture is the memory retrieval engine r section where images are retrieved from the memory by measuring l distance on pixel intensities while this maybe ok for simple problems considered in this work it is unclear how this can generalize to other more complicated datasets and problems this should be better discussed better justified and ideally results in some more realistic set up shown see below quality experiments results are shown for inpainting of mnist digits intrinsic image decomposition on the mit intrinsic image database and figure ground layer extraction on the synthesized dataset of d chairs rendered onto background from real photographs the experimental validation of the model is not very strong and proof of concept only all the experiments are performed in simplified toy set ups the mnist digit inpainting is far from current state of the art on image inpainting in real photographs see e g pathak et al the foreground background separation is done on only synthetically generated test data even for intrinsic image demposition problem there is now relatively large scale dataset of bell et al see the citation below while this is probably ok for the iclr paper it diminishes the significance of the work is this model going to be useful in a real settings one possibility to address this would be to focus on one of the problems and show results on a challenging state of the art data it would be great to see the benefits of the memory database s bell k bala and n snavely intrinsic images in the wild acm transactions on graphics clarity the clarity of the writing can be improved i found some of the terminology of the paper specially the imagination and memory confusing from figure it is not clear how the memories for the given input image are obtained which also took me some time to understand to help understand the proposed architecture it would be useful to draw an illustration of what is happening in the feature space similar in spirit e g to figure in,6.0
587.json,one of the main idea of this paper is to replace pooling layers with convolutions of stride and retraining the model authors merge this into a new layer and brand it as a new type of layer this is very misleading and adding noise to the field and using strided convolutions rather than pooling is not actually novel e g,4.0
587.json,this paper proposes to reduce model size and evaluation time of deep cnn models on mobile devices by converting multiple layers into single layer and then retraining the converted model the paper showed that the computation time can be reduced by x to x with only accuracy loss on a specific model reducing model sizes and speeding up model evaluation are important in many applications i have several concerns there are many techniques that can reduce model sizes for example it has been shown by several groups that using the teacher student approach people can achieve the same and sometimes even better accuracy than the teacher big model using a much smaller model however this paper does not compare any one of them the technique proposed in this paper is limited in its applicability since it designed specifically for the models discussed in the paper replacing several layers with single layer is a relatively standard procedure for example the mean variance normalization layer and batch normalization layer can all be absorbed without retraining or losing accuracy btw the dnn low rank approximation technique was first proposed in speech recognition e g xue j li j and gong y august restructuring of deep neural network acoustic models with singular value decomposition in interspeech pp,4.0
587.json,this paper looks at the idea of fusing multiple layers typically a convolution and a lrn or pooling layer into a single convolution via retraining of just that layer and shows that simpler faster models can be constructed that way at minimal loss in accuracy this idea is fine several issues the paper introduces the concept of a would eeprebirth layer and for a while it seems like it going to be some new architecture mid way we discover that it just a convolution it actually a different kind of convolution depending on whether one fuses serial or parallel pooling layers i understand the desire to give a name to the technique but in this case naming the layer itself when it actually multiple things non of which are new architecturally confuses the argument a lot there are ways to perform this kind of operator fusion without retraining and some deep learning framework such as theano and the upcoming tensorflow xla implement them it would have been nice to have a baseline that implements it especially since most of the additional energy cost from non fused operators comes from the extra intermediate memory writes that operator fusion removes batchnorm can be folded into convolution layers without retraining by scaling the weights were they folded into the baseline figures reported in table at the time of writing the authors have not provided the details that would make this research reproducible in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments retraining how much time epochs does the retraining take did you consider using any form of distillation interesting set of experiments this paper needs a lot of improvements to be suitable for publication open sourcing having the implementation be open source always enhances the usefulness of such paper not a requirement obviously,4.0
568.json,this paper proposes a new model for sentence classification pros some interesting architecture choices in the network cons no evaluation of the architecture choices an ablation study is critical here to understand what is important and what is not no evaluation on standard datasets on the only pre existing dataset evaluated on a simple tfidf svm method is state of the art so results are unconvincing,4.0
568.json,this paper proposes a new neural network model for sentence representation this new model is inspired by the success of residual network in computer vision and some observation of word morphology in natural language processing although this paper shows that this new model could give the best results on several datasets it lacks a strong evidence intuition motivation to support the network architecture to be specific i was confused by the contribution of this paper character aware word embedding or residual network or both the claim of using residual network in section seems pretty thin since it ignores some fundamental difference between image representation and sentence representation even though the results show that adding residual network could help i was still not be convinced is there any explanation about what is captured in the residual component from the perspective of sentence modeling this paper combines several components in the classification framework including character aware model for word embedding residual network and attention weight in type feature i would like to see the contribution from each of them to the final performance while in table i only saw one of them is it possible to add more results on the ablation test in equation what is the meaning of i in gi the citation format is impropriate,4.0
354.json,this work develops a method to quickly produce an ensemble of deep networks that outperform a single network trained for an equivalent amount of time the basis of this approach is to use a cyclic learning rate to quickly settle the model into a local minima and saving a model snapshot at this time before quickly raising the learning rate to escape towards a different minima well of attraction the resulting snapshots can be collected throughout a single training run and achieve reasonable performance compared to baselines and have some of the gains of traditional ensembles at a much lower cost this paper is well written has clear and informative figures tables and provides convincing results across a broad range of models and datasets i especially liked the analysis in section the publicly available code to ensure reproducibility is also greatly appreciated i would like to see more discussion of the accuracy and variability of each snapshot and further comparison with true ensembles preliminary rating this is an interesting work with convincing experiments and clear writing minor note why is the axis for lambda from to in figure where lambda is naturally between and,9.0
591.json,the paper proposes a new criterion sample importance to study the impact of samples during the training of deep neural networks this criterion is not clearly defined the term phi t i j is never defined only phi ti is defined despite the unclear definition it is understood that sample importance is the squared l norm of the gradient for a sample i and at time t strangely scaled by the squared learning rate the learning rate should have nothing to do with the importance of a sample in this context the paper presents experiments on the well known mnist and cifar datasets with correspondingly appropriate network architectures and choice of hyper parameters and initialisations the size of the hidden layers is a bit small for mnist and very small for cifar this could explain the very poor performance in figure error on cifar the study of the evolution of sample importance during training depending on layers seems to lead to trivial conclusions the overall sample importance is different under different epochs yes the norm of the gradient is expected to vary output layer always has the largest average sample importance per parameter and its contribution reaches the maximum in the early training stage and then drops yes since the gradient flows backwards the gradient is expected to be stronger for the output layer and it is expected to become more diffuse as it propagates to lower layers which are not stable as learning progresses one would expect the output layer to have progressively smaller gradients the norm of the gradient depends on the scaling of the variables the question of figure is absurd is sample importance the same as negative log likelihood of a sample of course not the results are very bad on cifar which discredits the applicability of those results on mnist performance is not readable figure error rate should only be presented between and or despite these important issues there are others the paper manages to raises some interesting things the so called easy samples and hard samples do seem to correspond although the study is very preliminary in this regard to what would intuitively be considered easy the most representative canonical samples and hard edge cases samples also the experiments are very well presented,2.0
591.json,this paper examines the so called sample importance of each sample of a training data set and its effect to the overall learning process the paper shows empirical results that shows different training cases induces bigger gradients at different stages of learning and different layers the paper shows some interesting results contrary to the common curriculum learning ideas of using easy training samples first however it is unclear how one should define easy training cases in addition the experiments demonstrating ordering either nll or si is worse than mixed or random batch construction to be insightful possible improvements it would be nice to factor out the magnitudes of the gradients to the contribution of sample importance higher gradient as a function of a particular weight vector can be affected weight initialization thereby introducing noise to the model it would also be interesting if improvements based on sample importance could be made to the batch selection algorithm to beat the baseline of random batch selection overall this paper is a good paper with various experiments examining how various samples in sgd influences the various aspect of training,7.0
591.json,paper summary the authors introduce the notion of sample importance meant to measure the influence of a particular training example on the training of a deep neural network this quantity is closely related to the squared l norm of the gradient where the summation is performed over i parameters of a given layer or ii across all parameters summing this quantity across time gives the overall importance used to tease apart easy from hard examples from this quantity the authors illustrate the impact of easy hard example during training and their impact on layer depth detailed review i have several objections to this paper first and foremost i am not convinced of the sample importance as a meaningful metric as previously mentioned the magnitude of gradients will change significantly during learning and i am not sure what conclusions one can draw from sumt gi t vs sumt gj t for example gradients tend to have higher norms early in training than at convergence in which case weighting each gradient equally seems problematic i tried illustrating the above with a small thought experiment during the question period if the learning rate were too high training may not even converge in which case sample importance would be ill defined having a measure which depends on the learning rate seems problematic to me as does the use of the l norm the input fisher norm mathbb e frac partial log p partial x for a given time step may be better suited as it speaks directly to the sensitivity of the classifier to the input x and is insensitive to changes in the mean gradient norm but again summing fisher norms across time may not be meaningful the experimental analysis also seems problematic the authors claim from fig that output layers are primarily learnt in the early stage of training however this is definitely not the case for cifar and is debatable for mnist sample importance remains high for all layers during training despite a small spike early on the output layer fig lower middle and fig also seems to highlight an issue with the si measure the si is dominated by the input layer which has the most parameters and can thus more readily impact the gradient norm different model architectures may have yielded different conclusions had the authors managed to use the si to craft a better curriculum this would have given significant weight to the measure unfortunately these results are negative pros extensive experiments cons sample importance is a heuristic not entirely well justified si yields limited insight into training of neural nets si does not inform curriculum learning,3.0
712.json,the authors propose a recurrent variational neural network approach to modelling volatility in financial time series this model consists of an application of chung et al s vrnn model to volatility forecasting wherein a variational autoencoder vae structure is repeated at each time step of the series the paper is well written and easy to follow although this reviewer suggests applying a spelling checking since the paper contains a number of harmless typos the paper s main technical contribution is to stack two levels of recurrence one for the latent process and one for the observables this appears to be a novel if minor contribution the larger contribution is methodological in areas of time series modelling that are both of great practical importance and have hitherto been dominated by rigid functional forms the demonstration of the applicability and usefulness of general purpose non linear models for volatility forecasting would be extremely impactful i have a few comments and reservations with the paper although not mentioned explicitly the authors framework are couched in terms of carrying out one timestep ahead forecasts of volatility however many applications of volatility models for instance for derivative pricing require longer horizon forecasts it would be interesting to discuss how this model could be extended to forecast at longer horizons in section there s a mention that a garch is conditionally deterministic this is true only when forecasting time step in the future at longer horizons the garch volatility forecast is not deterministic i was initially unhappy with the limitations of the experimental validation limited to comparison with a baseline garch model however the authors provided more comparisons in the revision which adds to the quality of the results although the models compared against cannot be considered state of the art it would be well advised to look into r packages such as stochvol and fgarch to get implementations of a variety of models that can serve as useful baselines and provide convincing evidence that the modelled volatility is indeed substantially better than approaches currently entertained by the finance literature in section more details should be given on the network e g number of hidden units as well as the embedding dimension de section in section more details should be given on the data generating process for the synthetic data experiments some results in the appendix are very puzzling around jumps in the price series which are places where the volatility should spike the model reacts instead by huge drops in the volatility figure b and c respectively around time steps and this should be explained and discussed all in all i think that the paper provides a nice contribution to the art of volatility modelling in spite of some flaws it provides a starting point for the broader impact of neural time series processing in the financial community,6.0
529.json,this paper suggests combining lstms trained on a large midi corpus with a handcrafted reward function that helps to fine tune the model in a musically meaningful way the idea to use hand crafted rewards in such a way is great and seems promising for practical scenarios where a musician would like to design a set of rules rather than a set of melodies even though some choices made along the way seem rather ad hoc and simplistic from a music theoretical perspective the results sound like an improvement upon the note rnn baseline but we also do not know how cherry picked these results are i am not convinced that this approach will scale to much more complicated reward functions necessary to compose real music maybe lstms are the wrong approach altogether if they have so much trouble learning to produce pleasant melodies from such a relatively big corpus of data are not there any alternative differentiable models that are more suitable what about dilated convolution based approaches what i do not like about the paper is that the short melodies are referenced as compositions while being very far from meaningful music they are not even polyphonic after all i think it would be great if such papers would be written with the help or feedback of people that have real musical training and are more critical towards these details what i like about the paper is that the authors make an effort to understand what is going on table is interesting for instance however figure should have included real melody excerpts with the same sound synthesis sample setup besides that more discussion on the shortcomings of the presented method should be added in summary i do like the paper and idea and i can imagine that such rl based fine tuning approaches will indeed be useful for musicians even though the novelty might be limited the paper serves as a documentation on how to achieve solid results in practice,6.0
529.json,the authors propose a solution for the task of synthesizing melodies the authors claim that the language model type approaches with lstms generate melodies with certain shortcomings they tend to lack long range structure to repeat notes etc to solve this problem the authors suggest that the model could be first trained as a pure lm style lstm and then trained with reinforcement learning to optimize an objective which includes some non differentiable music theory related constraints the reinforcement learning methodology is appropriate but straightforward and closely resembles previous work for text modeling and dialogue generation by itself the methodology does not offer a new technique to me the paper contribution then comes down to the novelty utility impact of the application the authors clearly put substantial of effort into crafting the rules and user study and that is commendable on the other hand music itself is dealt with somewhat naively while the user study reflects hard work it seems premature the semi plausible piano melodies here are only music in the way that lstm shakespeare passes as poetry so it analogous to conducting a user study comparing lstm shakespeare to n gram shakespeare i would caution the author against the uncritical motivation that a problem has previously been studied research contains abundant dead ends not to say this is necessarily one and the burden to motivate research should not be forgotten this is especially true when the application is the primary thrust of a paper generally the authors should be careful about describing this model as composing by analogy to a shakespeare lstm the language model is not really composing english prose the relationship between constructing a statistical sequence model and creating art an activity that involves communication grounded in real world semantics should not be overstated i appreciate the authors efforts to respond to some criticisms of the problem setup and encourage them to anticipate these arguments in the paper and to better motivate the work in the future if the main contribution is the application the methods have been used elsewhere then the motivation is of central importance i also appreciate their contention that the field benefits from multiple datasets and not simply relying on language modeling further they are correct in asserting that midi can capture all the information in a score not merely gameboy music and that for some musics e g european classical the score is of central importance however the authors may overstate the role of a score in jazz music overall for me the application while fun does not add enough to the impact of the paper and the methodology while appropriate does not stand on its own update thanks for your modifications and arguments i have revised my scores to add a point,5.0
483.json,the authors formulate a recurrent deep neural network to predict human fixation locations in videos as a mixture of gaussians they train the model using maximum likelihood with actual fixation data apart from evaluating how good the model performs at predicting fixations they combine the saliency predictions with the cd features for action recognition quality i am missing a more thorough evaluation of the fixation prediction performance the center bias performance in table differs significantly from the on in table all the state of the art models reported in table have a performance worse than the center bias performance reported in table is there really no other model better than the center bias additionally i am missing details on how central bias and human performance are modelled is human performance cross validated you claim that your results are very close to human performance the difference is only this difference is actually larger than the difference between central bias and your model reported in table apart from this it is dangerous to compare auc performance differences due to e g saturation issues clarity the explanation for table is a bit confusing also it is not clear why the conv and the fc models differ in how the saliency map is used at least one should also evaluate the conv model when multiplying the input with the saliency map to see how much of the difference comes from the different ways to use the saliency map and how much from the different features other issues you cite kümmerer et al as a model which learns indirectly rather than from explicit information of where humans look however the their model has been trained on fixation data using maximum likelihood apart from these issues i think the paper make a very interesting contribution to spatio temporal fixation prediction if the evaluation issues given above are sorted out i will happily improve my rating,7.0
483.json,this work proposes to a spatiotemporal saliency network that is able to mimic human fixation patterns thus helping to prune irrelevant information from the video and improve action recognition the work is interesting and has shown state of the art results on predicting human attention on action videos it has also shown promise for helping action clip classification the paper would benefit from a discussion on the role of context in attention for instance if context is important and people give attention to context why is it not incorporated automatically in your model one weak point is the action recognition section where the comparison between the two and seems unfair the attention weighted feature maps in fact reduce the classification performance and only improve performance when doubling the feature and associated model complexity by concatenating the weighted maps with the original features is there a way to combine the context and attention without concatenation the rational for concatenating the features extracted from the original clip and the features extracted from the saliency weighted clip seems to contradict the initial hypothesis that eliminating or down weighting pixels that are not important will improve performance the authors should also mention the current state of the art results in table for comparison other comments abstract typo mixed with irrelevant time consistency in videos expands the temporal domain from few frames to seconds these two points are not clear probably need a re write contributions the model can be trained without having to engineer spatiotemporal features you would need to collect training data from humans though section the number of fixation points is controlled to be fixed for each frame how is this done in practice we freeze the layers of the cd network to values pretrained by tran etal what happens when you allow gradients to flow back to the cd layers is it not better to allow the features to be best tuned for the final task the precise way in which the features are concatenated needs to be clarified in section minor typo we added them trained central bias,6.0
483.json,this paper proposes a new method for estimating visual attention in videos the input clip is first processed by a convnet in particular cd to extract visual features the visual features are then passed to lstm the hidden state at each time step in lstm is used to generate the parameters in a gaussian mixture model finally the visual attention map is generated from the gaussian mixture model overall the idea in this paper is reasonable and the paper is well written rnn lstm has been used in lots of vision problem where the outputs are discrete sequences there has not been much work on using rnn lstm for problems where the output is continuous like in this paper the experimental results have demonstrated the effectiveness of the proposed approach in particular it outperforms other state of the art on the saliency prediction task on the hollywood datasets it also shows improvement over baselines e g cd svm on the action recognition task my only gripe of this paper is that this paper is missing some important baseline comparisons in particular it does not seem to show how the recurrent part help the overall performance although table shows rmdn outperforms other state of the art it might be due to the fact that it uses strong cd features while other methods in table use traditional handcrafted features since saliency prediction is essentially a dense image labeling problem similar to semantic segmentation for dense image labeling there has been lots of methods proposed in the past two years e g fully convolution neural network fcn or deconvnet a straightforward baseline is to simply take fcn and apply it on each frame if the proposed method still outperforms this baseline we can know that the recurrent part really helps,6.0
600.json,this paper proposed the group sparse auto encoder for feature extraction the author then stack the group sparse auto encoders on top of cnns to extract better question sentence representation for qa tasks pros group sparse auto encoder seems new to me extensive experiments on qa tasks cons the idea is somewhat incremental writing need to be improved lack of ablation studies to show the effectiveness of the proposed approach moreover i am not convinced by the author answer regarding the baseline a separate training stages of cnn sgl for comparison is fine the purpose is to validate and analyze why the proposed sga is preferred rather than group lasso e g joint training could improve or the proposed group sparse regularization outperforms l norm etc however we can not see it from the current experiments,5.0
600.json,this paper propose to classify questions by leveraging corresponding answers the proposed method uses group sparse autoencoders to model question groups the proposed method offers improved accuracy over baselines but the baseline used is a little stale would be interesting to see how it compares to more recent cnn and rnn based methods it would also be interesting to see the contribution of each components for example how much gsa contributed to the improvement,6.0
315.json,interesting paper definitely provides value to the community by discussing why large batch gradient descent does not work too well,8.0
315.json,the paper is an empirical study to justify that sgd with smaller batch sizes converges to flatter minima flatter minima have better generalization ability pros and cons although there is little novelty in the paper i think the work is of great value in shedding light into some interesting questions around generalization of deep networks significance i think such results may have impact on both theory and practice respectively by suggesting what assumptions are legitimate for real scenarios for building new theories or be used heuristically to develop new algorithms with generalization by smart manipulation of mini batch sizes comments earlier i had some concern about the correctness of a claim made by the authors which is resolved now they had claimed their proposed sharpness criterion is scale invariance they took care of it by removing this claim in the revised version,10.0
552.json,this paper discusses recurrent networks with an update rule of the form h t rx r h t where rx is an embedding of the input x into the space of orthogonal or unitary matrices and r is a shared orthogonal or unitary matrix while this is an interesting model it is by no means a new model the idea of using matrices to represent input objects and multiplication to update state is often used in the embedding knowledge bases or embedding logic literature e g using matrices to model symbolic relationships by ilya sutskever and geoffrey hinton or holographic embeddings of knowledge graphs by maximillian nickel et al i do not think the experiments or analysis in this work add much to our understanding of it in particular the experiments are especially weak consisting only of a very simplified version of the copy task which is already very much a toy i know several people who have played with this model in the setting of language modeling and as the other reviewer notes the inability of the model to forget is an actual annoyance i think it is incumbent on the authors to show how this model can be really useful on a nontrivial task as it is we should not accept this paper some questions is there any reason to use the shared r instead of absorbing it into all the rx can you find any nice ways of using the fact that the model is linear in h or linear in rx,4.0
552.json,this is a nice proposal and could lead to more efficient training of recurrent nets i would really love to see a bit more experimental evidence i asked a few questions already but did not get any answer so far here are a few other questions concerns i have is the resulting model still a universal approximator providing large enough hidden dimensions and number of layers more generally can one compare the expressiveness of the model with the equivalent model without the orthogonal matrices with the same number of parameters for instance the experiments are a bit disappointing as the number of distinct input output sequences were in fact very small and as noted by the authr training becomes unstable i did not understand what success meant in this case the authors point that the experiment section need to be expanded but as far as i can tell they still have not unfortunately,5.0
694.json,the authors present a well thought out and constructed system for performing lipreading the primary novelty is the end to end nature of the system for lipreading with the sentence level prediction also differentiating this with prior work the described neural network architecture contains convolutional and recurrent layers with a ctc sequence loss at the end and beam search decoding with an lm is done to obtain best results performance is evaluated on the grid dataset with some saliency map and confusion matrix analysis provided as well overall the work seems of high quality and clearly written with detailed explanations the final results and analysis appear good as well one gripe is that that the novelty lies in the choice of application domain as opposed to the methods lack of word level comparisons also makes it difficult to determine the importance of using sentence level information vs choices in model architecture decoding and finally the grid dataset itself appears limited with the grammar and use of a n gram dictionary clearly the system is well engineered and final results impress though it unclear how much broader insight the results yield,6.0
694.json,proven again that end to end training with deep networks gives large gains over traditional hybrid systems with hand crafted features the results are very nice for the small vocabulary grammar task defined by the grid corpus the engineering here is clearly very good will be interesting to see the performance on large vocabulary lm tasks comparison to human lip reading performance for conversational speech will be very interesting here traditional av asr systems which apply weighted audio visual posterior fusion reduce to pure lip reading when all the weight is on the visual there are many curves showing performance of this channel in low audio snr conditions for both grammar and lm tasks traditional hybrid approaches to av asr are also sentence level sequence trained with fmpe mpe mmi etc objectives see old references so we cannot say here that this is the first sentence level objective for lipreading model analogous to saying there was no sequence training in hybrid lvcsr asr systems before ctc,4.0
381.json,authors propose a strategy for pruning weights with the eventual goal of reducing gflop computations the pruning strategy is well motivated using the taylor expansion of the neural network function with respect to the feature activations the obtained strategy removes feature maps that have both a small activation and a small gradient eqn a ideally the gradient of the output with respect to the activation functions should be at the optimal but as a result of stochastic gradient evaluations this would practically never be zero small variance in the gradient across mini batches indicates that irrespective of input data the specific network parameter is unlikely to change intuitively these are parameters that are closer to convergence parameters weights that are close to convergence and also result in a small activation are intuitively good candidates for pruning this is essentially what eqn conveys and is likely to be reason why just removing weights that result in small activations is not as good of a pruning strategy as shown by results in the paper there are two kind of differences in weights that are removed by activation v s taylor expansion weights with high activations but very low gradients will be removed by taylor expansion but not by activation alone weights with low activation but high gradients will be removed by activation criterion but not by taylor expansion it will be interesting to analyze which of or contribute more to the differences in weights that are removed by the taylor expansion v s activation criterion intuitively it seems that weight that satisfy are important because they are converged and contribute significantly to network activation it is possible that a modified criterion eqn lambda feature activation where lambda needs to be found by cross validation may lead to even better results at the cost of more parameter tuning b another interesting comparison is with the with the optimal damage framework where the first order gradients are assumed to be zero and pruning is performed using the second order information also discussed by authors in the appendix critically only the diagonal of the hessian is computed there is no comparison with optimal damage as authors claim it is memory and computation inefficient back of envelope calculations suggest that this would result only in increase in memory and computation during pruning but no loss in efficiency during testing therefore from a standpoint of deployment i do not think this missing comparison is justified c the eventual goal of the authors is to reduce gflops some recent papers have proposed using lower precision computation for this a comparison in gflops with lower precision v s pruning would be a great while both these approaches are complementary and it is expected that combining both of them can lead to superior performance than either of the two it is unclear when we are operating in the low precision regime how much pruning can be performed any analysis on this tradeoff would be great but not necessary d on finetuning authors report results of alexnet and vgg on two different datasets flowers and birds respectively why is this the case it would be great to see the results of both the networks on both the datasets e authors report there is only a small drop in performance after pruning suppose the network was originally trained with n iterations and then m finetuning iterations were performed during pruning this means that pruned networks were trained for n m iterations the correct comparison in accuracies would be if we the original network was also trained for n m iterations in figure does the performance at parameters reports accuracy after n m iterations or after n iterations overall i think the paper is technically and empirically sound it proposes a new strategy for pruning based on taylor expansion feature normalization to reduce parameter tuning efforts iterative finetuning however i would like to see some comparisons mentioned in my comments above if those comparisons are made i would change my ratings to an accept,7.0
440.json,this paper introduces an approach for model based control of stochastic dynamical systems with policy search based on learning the stochastic dynamics of the underlying system with a bayesian deep neural network bnn that allows some of its inputs to be stochastic and a policy optimization method based on simulated rollouts from the learned dynamics bnn training is carried out using alpha divergence minimization the specific form of which was introduced in previous work by the authors validation and comparison of the approach is undertaken on a simulated domain as well as real world scenarios the paper is tightly written and easy to follow its approach to fitting bayesian neural networks with alpha divergence is interesting and appears novel in this context the resulting application to model based control appears to have significant practical impact particularly in light of the explainability that a system model can bring to specific decisions made by the policy as such i think that the paper brings a valuable contribution to the literature that said i have a few questions and suggestions in section it should be explained how the random zn input is used by the neural network is it just concatenated to the other inputs and used as is or is there a special treatment moreover much case is made for the need to have stochastic inputs but only a scalar input seems to be provided throughout is this enough how computationally difficult would providing stochastic inputs of higher dimensionality be how important is the normality assumption in zn how is the variance gamma established it is mentioned that the hidden layers of the neural network are made of rectifiers but no further utilization of this fact is made in the paper is this assumption somehow important in the optimization of the alpha divergence beyond what we know about rectifiers to mitigate the vanishing gradient problem equation denominator mathbf y should be mathbf y section it would be helpful to have an overview or discussion of the computational complexity of training bnns to understand whether and when they can practicably be used between eq and a citation to the statement of the time embedding theorem would be helpful as well as an indication of how the embedding dimension should be chosen figure the subplots should have the letters by which they are referenced in the text on p in section it is not clear if the gas turbine data is publicly available and if so where in addition more details should be provided such as the dimensionality of the variables et nt and at perhaps the comparisons with gaussian processes should include variants that support stochastic inputs such as girard et al to provide some of the same modelling capabilities as what s made use of here at least this strand of work should be mentioned in section references girard a rasmussen c e quiñonero candela j murray smith r gaussian process priors with uncertain inputs application to multiple step ahead time series forecasting advances in neural information processing systems,7.0
440.json,this paper considers the problem of model based policy search the authors consider the use of bayesian neural networks to learn a model of the environment and advocate for the alpha divergence minimization rather than the more usual variational bayes the ability of alpha divergence to capture bi modality however comes at a price and most of the paper is devoted to finding tractable approximations the authors therefore use the approach of hernandez lobato et al as proxy to the alpha divergence the environment system dynamics is clearly defined as a well as the policy parametrization section and would constitute a useful reference point for other researchers simulated roll outs using the learned model then provide samples of the expected return since a model of the environment is available stochastic gradient descent can be performed in the usual way without policy gradient estimators via automatic differentiation tools the experiments demonstrate that alpha divergence is capable of capturing multi model structure which competing methods variational bayes and gp would otherwise struggle with the proposed approach also compares favorably in a real world batch setting the paper is well written technically rich and combines many recent tools into a coherent algorithm however the repeated use of approximations to original quantities seems to somehow defeat the benefits of the original problem formulation the scalability and computational effectiveness of this approach is also questionable and i am uncertain if many problem would warrant such complexity in their solution as with other bayesian methods the proposed approach would probably shine in low samples regime and in this case might be preferable to other methods in the same class vb gp,7.0
339.json,the authors present a simple method to affix a cache to neural language models which provides in effect a copying mechanism from recently used words unlike much related work in neural networks with copying mechanisms this mechanism need not be trained with long term backpropagation which makes it efficient and scalable to much larger cache sizes they demonstrate good improvements on language modeling by adding this cache to rnn baselines the main contribution of this paper is the observation that simply using the hidden states hi as keys for words xi and ht as the query vector naturally gives a lookup mechanism that works fine without tuning by backprop this is a simple observation and might already exist as folk knowledge among some people but it has nice implications for scalability and the experiments are convincing the basic idea of repurposing locally learned representations for large scale attention where backprop would normally be prohibitively expensive is an interesting one and could probably be used to improve other types of memory networks my main criticism of this work is its simplicity and incrementality when compared to previously existing literature as a simple modification of existing nlp models but with good empirical success simplicity and practicality it is probably more suitable for an nlp specific conference however i think that approaches that distill recent work into a simple efficient applicable form should be rewarded and that this tool will be useful to a large enough portion of the iclr community to recommend its publication,7.0
339.json,this paper proposes a simple extension to a neural network language model by adding a cache component the model stores,5.0
513.json,paper summary this paper evaluates the ability of two unsupervised learning models to learn a generalizable physical intuition governing the stability of a tower of blocks the two models are a model that predicts the final state of the tower given the initial state and a model that predicts the sequence of states of this tower over time given the initial state generalizability is evaluated by training a model on towers made of a certain number of blocks but testing on towers made of a different number of blocks strengths this paper explores an interesting way to evaluate representations in terms of their generalizability to out of domain data as opposed to more standard methods which use train and test data drawn from the same distribution experiments show that the predictions of deep unsupervised learning models on such out of domain data do seem to help even though the models were not trained explicitly to help in this way weaknesses based on fig it seems that the models trained on blocks cd cld generalize to and blocks however it is plausible that these models only pay attention to the bottom blocks of the or block towers in order to determine their stability this would work correctly a significant fraction of the time therefore the models might actually be overfitting to block towers and not really generalizing the physics of these blocks is this a possibility i think more careful controls are needed to make the claim that the features actually generalize for example test the block model on a block test set but only make the th or th block unstable if the model still works well then we could argue that it is actually generalizing the experimental analysis seems somewhat preliminary and can be improved in particular it would help to see visualizations of what the final state looks like for models trained on blocks but test on and vice versa that would help understand if the generalization is really working the discriminative objective gives some indication of this but might obfuscate some aspects of physical realism that we would really want to test in figure and it is not mentioned whether these models are being tested on the same number of blocks they were trained for it seems that the task of the predicting the final state is really a binary task whether or not to remove the blocks and replace them with gray background the places where the blocks land in case of a fall is probably quite hard to predict even for a human because small perturbations can have a big impact on the final state it seems that in order to get a generalizable physics model it could help to have a high frame rate sequence prediction task currently the video is subsampled to only time steps quality a more detailed analysis and careful choices of testing conditions can increase the quality of this paper and strengthen the conclusions that can be drawn from this work clarity the paper is well written and easy to follow originality the particular setting explored in this paper is novel significance this paper provides a valuable addition to the growing work on transferability generalizability as an evaluation method for unsupervised learning however more detailed experiments and analysis are needed to make this paper significant enough for an iclr paper minor comments and suggestions the acronym ipe is used without mentioning its expansion anywhere in the text there seems to be a strong dependence on data augmentation but given that this is a synthetic dataset it is not clear why more data was not generated in the first place table it might be better to draw this as a x grid rows corresponding to the models and columns corresponding to the test sets mentioning the train set is redundant since it is already captured in the model name that might make it easier to read overall this is an excellent direction to work and preliminary results look great however more controls and detailed analysis are needed to make strong conclusions from these experiments,5.0
513.json,summary this paper trains models to predict whether block towers will fall down or not it shows that an additional model of how blocks fall down predicting a sequence of frames via unsupervised learning helps the original supervised task to generalize better this work constructs a synthetic dataset of block towers containing to blocks places in more or less precarious positions it includes both labels the tower falls or not and video frame sequences of the tower evolution according to a physics engine three kinds of models are trained the first s simply takes an image of a tower starting state and predicts whether it will fall or not the other two types cd and cld take both the start state and the final state of the tower after it has or has not fallen and predict whether it has fallen or not they only differ in how the final state is provided one model convdeconv cd predicts the final frame using only the start frame and the other convlstmdeconv predicts a series of intermediate frames before coming to the final frame both cd and cld are unsupervised each model is trained on towers of a particular heigh and tested on towers with an unseen height when the height of the train towers is the same as the test tower height all models perform roughly the same with in a few percentage points however when the test height is greater than the train height it is extremely helpful to explicitly model the final state of the block tower before deciding whether it has fallen or not via cd and cld models pros there are very clear large gains in accuracy from adding an unsupervised final frame predictor because the generalization problem is also particularly clear train and test with different numbers of blocks this makes for a very nice toy example where unsupervised learning provides a clear benefit the writing is clear cons my one major concern is a lack of more detailed analysis the paper establishes a base result but does not explore the idea to the extent to which i think an iclr paper should two general directions for potential analysis follow is this a limitation of the particular way the block towers are rendered the lstm model could be limited by the sub sampling strategy it looks like the sampling may be too coarse from the provided examples for the two towers in figure that fall they have fallen after only or time steps how quickly do most towers fall what happens if the lstm is trained at a higher frame rate what is the frame by frame video prediction accuracy of the lstm is that quantity meaningful how much does performance improve if the lstm is provided ground truth for only the first k frames why is generalization to different block heights limited is it limited by model capacity or architecture design what would happen if the s type models were made wider deeper with the cd cld fall predictor capacity fixed is it limited by the precise task specification what would happen if networks were trained with towers of multiple heights apparently this experiment is in the works i appreciate that one experiment in this direction was provided is it limited by training procedure what if the cd cld models were trained in an end to end manner what if the double frame fall predictor were trained with ground truth final frames instead of generated final frames minor concerns it may be asking too much to re implement zhang et al and physnet for the newly proposed dataset but it would help the paper to have baselines which are directly comparable to the proposed results i do not think this is a major concern because the point of the paper is about the role of unsupervised learning rather than creating the best fall prediction network the auxiliary experiment provided is motivated as follows one solution could be to train these models to predict how many blocks have fallen instead of a binary stability label is there a clear intuition for why this might make the task easier will the dataset or code to generate it be released overall evaluation the writing presentation and experiments are clear and of high enough quality for iclr however the experiments provide limited analysis past the main result see comments above the idea is a clear extension of ideas behind unsupervised learning video prediction and recent results in intuitive physics from lerer et al and zhang et al so there is only moderate novelty however these results would provide a valuable addition to the literation especially if more analysis was provided,5.0
513.json,paper summary the paper proposes to learn a predictive model aka predict the next video frames given an input image and uses the prediction from this model to improve a supervised classifier the effectiveness of the approach is illustrated on a tower stability dataset review summary this work seems rather preliminary in terms of experimentation and using forward modeling as pretraining has already been proposed and applied to video and text classification tasks discussion on related work is insufficient the end task choice will there be motion might not be the best to advocate for unsupervised training detailed review this work seems rather preliminary there is no comparison with alternative semi supervised strategies any approach that consider the next frames as latent variables or privileged information can be considered also i am not sure if the supervised stability prediction model is actually needed once the next frame is predicted basically the task can be reduced to predict whether there will be motion in the video following the current frame or not for instance comparing the first frame and last prediction or the density of gray in the top part of the video might work just as well also training a model to predict the presence of motion from the unsupervised data only would probably do very well i would suggest to stir away from task where the label can be inferred trivially from the unsupervised data meaning that unlabeled videos can be considered labeled frames in that case the related work section misses a discussion on previous work on learning unsupervised features from video through predictive models dimensionality reduction for helping classification of still images or videos fathi et al mabahi et al srivastava et al more recently wang and gupta have obtained excellent imagenet results from features pre trained on unlabeled videos vondrick et al have shown that generative models of video can help initialize models for video classification tasks also in the field of text classification pre training of classifier with a language model is a form predictive modeling e g dai le i would also suggest to report test results on the dataset from lerrer et al i understand that you need your own videos to pre train the predictive model but stability prediction only require still images overall i feel the experimental section is too preliminary it would be better to focus on a task where solving the unsupervised task does not necessarily imply that the supervised task is trivially solved or conversely that a simple rule can turn the unlabeled data into label data reference fathi alireza and greg mori action recognition by learning mid level motion features computer vision and pattern recognition cvpr ieee conference on ieee mobahi hossein ronan collobert and jason weston deep learning from temporal coherence in video proceedings of the th annual international conference on machine learning acm srivastava nitish elman mansimov and ruslan salakhutdinov unsupervised learning of video representations using lstms corr abs a dai q v le semi supervised sequence learning nips unsupervised learning of visual representations using videos x wang a gupta iccv generating videos with scene dynamics c vondrick h pirsiavash a torralba nips,3.0
456.json,the work introduces a new regularization for learning domain invariant representations with neural networks the regularization aims at matching the higher order central moments of the hidden activations of the nns of the source and target domain the authors compared the proposed method vs mmd and two state of art nn domain adaptation algorithms on the amazon review and office datasets and showed comparable performance the idea proposed is simple and straightforward and the empirical results suggest that it is quite effective the biggest limitation i can see with the proposed method is the assumption that the hidden activations are independently distributed for example this assumption will clearly be violated for the hidden activations of convolutional layers where neighboring activations are dependent i guess this is why the authors start with the output of dense layers for the image dataset do the authors have insight on if it is beneficial to start adaptation from lower level if so do the authors have insight on how to relax the assumption in these scenarios if mmd has an advantage as it does not make this assumption figure does not seems to clearly support the boost of performance shown in table the only class where the new regularization brings the source and target domain closer seem to be the mouse class pointed by the authors is the performance improvement only coming from this single class,6.0
456.json,this paper proposed a new metric central moment discrepancy cmd for matching two distributions with applications to domain adaptation compared to a more well known variant mmd cmd has the benefit of not over penalizing the mean and therefore can focus more on the shape of distribution around the center in terms of discriminative power the ability to tell two distributions apart mmd and cmd should be equivalent but in practice i can understand that cmd may be better as mmd tries to match the raw moments which may over penalize data that are not zero centered in the paper cmd is used only up to kth order and not all the central moments are used but rather only the diagonal entries are considered in the cmd objective i think this is mostly motivated for computation efficiency a natural comparison with mmd therefore can be made by also explicitly include raw moments up to kth order another thing to compare against is to include all moments not just the diagonal terms in the objective this is computationally expensive but can be done for e g st and nd orders since the experiments only compare cmd in the above form with kernelized mmd the claim that explicit moment matching is helpful is not very well supported to make this a solid claim cmd should be compared against mmd with explicit raw moments the claim that the kernel parameter in mmd is hard to tune and cmd does not have such parameters only applies to kernel mmd not explicit mmd for kernel mmd there are also studies on how to set these parameters for example sriperumbudur et al kernel choice and classifiability for rkhs embeddings of probability distributions gretton et al a kernel two sample test and also using multiple kernels li et al which removes the need to tune them tuning the beta directly like done in this paper is usually not the way mmd is tuned at least simple heuristics like dividing x y by dimensionality or mean pairwise distance first should be applied first before trying beta in the way done in this paper overall i think cmd could be better than mmd and could have applications in many domains but it also has the problem of not easily kernelizable you can argue this both ways though the experiments demonstrating that cmd is better could be done more convincinly,7.0
790.json,the submission proposes to modify the typical gan architecture slightly to include encrypt alice and decrypt bob modules as well as a module trying to decrypt the signal without a key eve through repeated transmission of signals the adversarial game is intended to converge to a system in which alice and bob can communicate securely or at least a designated part of the signal should be secure while a sophisticated eve cannot break their code examples are given on toy data as a proof of concept we implemented alice bob and eve networks that take n bit random plain text and key values and produce n entry floating point ciphertexts for n and both plaintext and key values are uniformly distributed the idea considered here is cute if some but not necessarily all of the signal is meant to be secure the modules can learn to encrypt and decrypt a signal while an adversary is simultaneously learned that tries to break the encryption in this way some of the data can remain unencrypted while the portion that is e g correlated with the encrypted signal will have to be encrypted in order for eve to not be able to predict the encrypted part while this is a nice thought experiment there are significant barriers to this submission having a practical impact gans and from the convergence figures also the objective considered here are quite unstable to optimize the only guarantees of privacy are for an eve that is converged to a very strong adversary stronger than a dedicated attack over time i do not see how one can have any sort of reliable guarantee of the safety of the data transmission from the proposed approach at least the paper does not outline such a guarantee public key encryption systems are readily available computationally feasible and successfully applied almost anywhere the toy examples given in the paper do not at all convince me that this is solving a real world problem at this point perhaps a good example will come up in the near future and this work will be shown to be justified but until such an example is shown the approach is more of an interesting thought experiment,5.0
790.json,the paper deals with an interesting application of adversarial training to encryption it considers the standard scenario of alice eve and bob where a and b aim to exchange messages conditioned on a shared key while eve should be unable to encrypt the message experiments are performed in a simple symmetric bit encryption task and an application on privacy the concepts ideas and previous literature are quite nicely and carefully presented the only major concern i have and i apologize to the authors for not raising this earlier are the experiments in section in particular i do not quite get the scenario the reasoning here seems to be as follows given information a b c d i want to give the public the value of d e g movies watched without releasing information about c e g gender in this scenario eve would need to be able to reconstruct d as good as possible without gaining information about c what is described in section however is that d and d public are both reconstructed by bob but why would bob reconstruct the latter he is not public in particular because he is allowed to reconstruct c which is not tested here also eve only tries to estimate c thus rendering the scenario not different in any way to the scenario considered in section i have two more minor concerns as raised in the pre review eve should actually be stronger then alice and bob in order to be able to compensate for the missing key the authors noted they have been doing these experiments and are going to add the results in any natural encryption case i would expect the length of the key to be much shorter then the length of the message this however could potentially make the scenario much easier for eve although i doubt any of the results will change if the key is long enough i like the creative application of adversarial training to a completely different domain and i believe it could be the starting point of a very interesting direction in cryptographic systems or in privacy applications although it is unclear whether the weak guarantees of neural network based approaches can ever be overcome at the same time the application in the privacy setting leaves me quite confused and the symmetric encryption example is not particularly strong either i would appreciate if the authors could address the major concern i raised above and i will be quite happy to raise the score in case this confusion can be resolved,6.0
544.json,i would definitely love to have this and use it for my research a great tool however the paper lacks detail in particular i feel that it is impossible for someone to reimplement the research mostly because of the lack of detail however replicability is a crucial part of science other publications proposing software e g the tensorflow theano and edward papers come along with open source code this is not the case here and therefore the picture is quite incomplete i am not convinced that iclr is the right venue robotics conferences such as iros and icra might appreciate it much more nevertheless this is just an encouragement to the authors to interact with those communities,5.0
544.json,a differentiable physics engine is indeed a wonderful thing to have the key selling point of the proposed software is its speed however there is no comparison to other physics engines besides describing the engine speed in rather creative units e g model seconds per day the reader has no idea if this is fast or slow todorov engine my simulator of choice computes a dynamics step and its derivatives wrt both states and controls using finite differences in less than ms for a full humanoid model his code is available here mujoco org book programming html saderivative i think this actually faster than the engine described in this paper but i can not be sure because this engine is so limited in what it can collide sphere sphere and sphere plane it would be trivial to build the example models in several other popular engines e g ode bullet and mujoco and simply compare the performance until this comparison is done i consider the paper to be incomplete,5.0
401.json,the paper reads well and the idea is new sadly many details needed for replicating the results such as layer sizes of the cnns learning rates are missing the training of the introspection network could have been described in more detail also i think that a model which is closer to the current state of the art should have been used in the imagenet experiments that would have made the results more convincing due to the novelty of the idea i recommend the paper i would increase the rating if an updated draft addresses the mentioned issues,8.0
401.json,edit updated score see additional comment i quite like the main idea of the paper which is based on the observation in sec that the authors find many predictable patterns in the independent evolution of weights during neural network training it is very encouraging that a simple neural network can be used to speed up training by directly predicting weights however the technical quality of the current paper leaves much to be desired and i encourage the authors to do more rigorous analysis of the approach here are some concrete suggestions the findings in section which motivate the approach should be clearly presented in the paper presently they are stated as anecdotes a central issue with the paper is that the training of the introspection network i is completely glossed over how well did the training work in terms of training validation test losses how well does it need to work in order to be useful for speeding up training these are important questions for anyone interested in this approach an additional important issue is that of baselines would a simple linear quadratic model also work instead of a neural network what about a simple heuristic rule to increase decrease weights i think it important to compare to such baselines to understand the complexity of the weight evolution learned by the neural network i do not think that default tensorflow example hyperparameters should be used as mentioned by authors on openreview there is no scientific basis for using them instead first hyperparameters which produce good results in a reasonable time should be selected as the baseline and then added the benefit of the introspection network to speed up training and reaching a similar result should be shown the authors state in the discussion on openreview that they also tried rnns as the introspection network but it did not work with small state size what does did not work mean in this context did it underfit i find it hard to imagine that a large state size would be required for this task even if it is that does not rule out evaluation due to memory issues because the rnn can be run on the weights in mini batch mode in general i think other baselines are more important than rnn a question about jump points the i is trained on sgd trajectories while using i to speed up training at several jump points if the input weights cross previous jump points then i gets input data from a weight evolution which is not from sgd it has been altered by i this seems problematic but does not seem to affect your experiments i feel that this again highlights the importance of the baselines perhaps i is doing something extremely simple that is not affected by this issue since the main idea is very interesting i will be happy to update my score if the above concerns are addressed,9.0
397.json,the ar prior and its equivalent the inverse ar posterior is one of the more elegant ways to improve the unfortunately poor generative qualities of vae s it is only an incremental but important step incremental because judging by the lack of say cifar pictures of the vlae in its creative regime i e when sampling from prior it will not answer many of the questions hanging over we hope to see the paper accepted in relative terms the paper shines in the landscape of the other papers which are rich on engineering hacks but lacking on theoretical insights some disagreements with the theoretical suppositions in the paper i the vae s posterior converges to the prior faster than we would like because the gradients of the generative error the kl divergence of prior and posterior w r t mu sigma are simple inf differentiable functions and their magnitude far exceeds the magnitude of the resp gradients of the reconstruction error especially when more hairy decoders like pixelcnn are used we always considered this obvious and certainly not worthy of one page of cs mumbo jumbo to explain dumbing down the decoder via variations of dropout or complexifying the sampler as in here or slapping the generative error with a deepmind constant betavae are the natural band aids but seem to fail in the creative regime for real life sets like cifar or more complex ones other conceptual solutions are needed some are discussed in ii the claim near the end of section that the extra coding cost a k a variational error will exist and will not be negligible is a speculation which in our empirical experience at least is incorrect the variational error is quantifiable for the gibbs exponential family of priors posteriors as described in section and as tim salimans knows from his own previous work in the case of cifar for example the variational error is negligible even for simple sampling families like gaussian laplacian etc moreover in hindsight using the closed form for generative error the kl divergence of prior and posterior in the pioneering vae papers was likely a mistake inherited by the unnecessary bayseanism which inspired them beautiful but a mistake nonetheless the combo of generative and variational error should together be approximated by the same naive monte carlo used for the reconstruction error easily follows from equation in i e arithmetic average over observations on the lighter side guys please do not recycle ridiculous terms like optimizationally challenged as in section the english language has recently acquired mentally challenged emotionally challenged etc and now political correctness has sadly found its way to machines,9.0
397.json,this paper introduces the notion of a variational lossy autoencoder where a powerful autoregressive conditional distribution on the inputs x given the latent code z is crippled in a way that forces it to use z in a meaningful way its three main contributions are it gives an interesting information theoretical insight as to why vae type models do not tend to take advantage of their latent representation when the conditional distribution on x given z is powerful enough it shows that this insight can be used to efficiently train vaes with powerful autoregressive conditional distributions such that they make use of the latent code it presents a powerful way to parametrize the prior in the form of an autoregressive flow transformation which is equivalent to using an inverse autoregressive flow transformation on the approximate posterior by itself i think the information theoretical explanation of why vaes do not use their latent code when the conditional distribution on x given z is powerful enough constitutes an excellent addition to our understanding of vae related approaches however the way this intuition is empirically evaluated is a bit weak the crippling method used feels hand crafted and very task dependent and the qualitative evaluation of the lossyness of the learned representation is carried out on three datasets mnist omniglot and caltech silhouettes which feature black and white images with little to no texture figures a and a do show that reconstructions discard low level information as observed in the slight variations in strokes between the input and the reconstruction but such an analysis would have been more compelling with more complex image datasets have the authors tried applying vlae to such datasets i think the caltech silhouettes benchmark should be treated with caution as no comparison is made against other competitive approaches like iaf vae pixelrnn and conv draw this means that vlae significantly outperforms the state of the art in only one of the four settings examined a question which is very relevant to this paper is does a latent representation on top of an autoregressive model help improve the density modeling performance the paper touches this question but very briefly the only setting in which vlae is compared against recent autoregressive approaches shows that it wins against pixelrnn by a small margin the proposal to transform the latent code with an autoregressive flow which is equivalent to parametrizing the approximate posterior with an inverse autoregressive flow transformation is also interesting there is however one important distinction to be made between the two approaches in the former the prior over the latent code can potentially be very complex whereas in the latter the prior is limited to be a simple factorized distribution it is not clear to me that having a very powerful prior is necessarily a good thing from a representation learning point of view oftentimes we are interested in learning a representation of the data distribution which is untangled and composed of roughly independent factors of variation the degree to which this can be achieved using something as simple as a spherical gaussian prior is up for discussion but finding a good balance between the ability of the prior to fit the data and its usefulness as a high level representation certainly warrants some thought i would be interested in hearing the authors opinion on this overall the paper introduces interesting ideas despite the flaws outlined above but weaknesses in the empirical evaluation prevent me from recommending its acceptance update the rating has been revised to a following the authors reply,7.0
723.json,this paper explores the use of open bigrams as a target representation of words for application to handwriting image recognition pros the use of obs is novel and interesting clearly written and explained cons no comparison to previous state of the art only with author generated results more ablation studies needed i e fill in table with rnn rnn rnn etc etc it is not clear where the performance is coming from as it seems that it is single character modelling and word endings that are actually beneficial while the use of open bigrams is novel there are works which use bag of bigrams and ngrams as models which are not really compared to or explored e g,5.0
723.json,this paper uses an lstm model to predict what it calls open bigrams bigrams of characters that may or may not have letters inbetween from handwriting data these open bigrams are subsequently used to predict the written word in a decoding step the experiments indicate that the system does slightly better than a baseline model that uses viterbi decoding i have some major concerns about this paper i find the cortical inspired claim troublesome if anything it is psychology cognitive science inspired in the sense that open bigrams appear to help for word recognition touzet et al but the implied cortical characteristics implicitly referred to e g by pointing to analogies between deep neural nets for object recognition and in that case the visual cortex is unfounded is there any direct evidence from neuroscience that open bigrams constitute a wholly separate layer in the cortex for a handwriting recognition task dehaene work is a proposal so you will need to describe more findings in cognitive neurosciences sic research on reading p to substantiate those claims i am further worried by the fact that the authors seem to think that deep neural networks are based on a series of about five pairs of neurons sic layers unless i misunderstand something you are specifically referring to krizhevsky alexnet here which you should probably have cited there i hope you do not mean to imply that all deep neural nets need five layers it is also not true that ten is quite close to the number of layers of an efficient deep nn what network what task etc the model is not clearly explained there is a short paragraph in appendix a that roughly describes the setup but this does not include e g the objective function or answer why the network output is only considered each two consecutive time steps rather than at each time step or so it seems this is probably because the paper argues that it is focused on the decoder p rather than on the whole problem i find this problematic because in that case we are effectively measuring how easy it is to reconstruct a word from its open bigrams which has very little to do with handwriting recognition it could have been evaluated on any text corpus in fact as the example on page shows handwriting is not necessary to illustrate the open bigram hypothesis which leads me to wonder why these particular tasks were chosen if we are only interested in the decoding mechanism the comparison is not really fair the viterbi decoder only has access to unigrams as far as i can tell the only model that does better than that baseline has access to a lot more information and does not do that much better did the viterbi model have access to the word boundary information at one point rather confusingly called extremities that pushed the open bigram model over the edge in terms of performance why is there no comparison to e g rnn unigram bigram boundary markers the dataset also appears to be biased in favor of the proposed approach longer words only i am not convinced that this paper really shows that open bigrams help i very much like the idea of the paper but i am simply not convinced by its claims minor points there are quite a few typos just a sample independant fig we evaluate an handwritten hand written words an the results their approach include the letter bigrams of a word w is for the two considered database would not it be easy to add how many times a bigram occurs which would improve the decoding process you can just normalize over the full counts instead of the binary occurrence counts the results in table are the same but different precision as the results in table except that edit distance and ser are added this is confusing,4.0
723.json,this submission investigates the usability of cortical inspired distant bigram representations for handwritten word recognition instead of generating neural network based posterior features for character optionally in local context sets posterior for character bigrams of different length are used to represent words the aim here is to investigate the viability of this approach and to compare to the standard approach overall the submission is well written although information is missing w r t to the comparison between the proposed approach and the standard approach see below it would be desirable to see the model complexity of all the different models used here i e the number of parameters used language models are not used here since the different models utilize different levels of context language models can be expected to have a different effect on the different approaches therefore i suggest to include the use of language models into the evaluation for your comparative experiments you use only of the data by choosing longer words only on the other hand it is well known that the shorter words are more prone to result in misrecognitions the question remains if this choice is advantageous for one of the tasks or not corresponding quantitative results should be provided to be able to better evaluate the effect of using this constrained corpus without clarification of this i would not readily agree that the error rates are competitive or better than the standard approach as stated at the end of sec i do see the motivation for introducing open bigrams in an unordered way due to the corresponding evidence from cognitive research however decision theoretically i wonder why the order should be given up if the underlying sequential classification problem clearly is of a monotonous nature it would be interesting to see an experiment where only the use of the order is varied to differentiate the effect of the order from the effect of other aspects of the approach end of page whole language method please explain what is meant by this page define your notation for rnnd x t the number of target for the rnns modeling order unigrams effectively and the rnns modeling order and larger are very much different therefore the precision and recall numbers in table do not seem to be readily comparable between order and orders at least the column for order should be visually separated to highlight this minor comments a spell check is recommended p state of art state of the art p predict character sequence predict a character sequence p top their approach include their approach includes p top an handwritten a handwritten p bottom consituent constituent p top in classical approach in the classical approach p top transformed in a vector transformed into a vector p were build were built references first authors name written wrongly thodore bluche theodore bluche,7.0
666.json,this paper proposes a k shot learning framework that can be used on existing pre trained networks by grouping filters that produce similar activations the grouped filters are learned together to address overfitting when only few training samples are available the idea of the paper is interesting there are some encouraging results but the current version does not seem ready for publication performance the method should be compared with other state of the art k shot learning methods e g matching networks by vinyals et al it not clear how this method compares against them missing explanation experimental setting for k shot learning should be more detailed measure accuracy difference does not look like a good idea for comparing the baseline method and the proposed one just raw accuracies would be fine many grammatical errors and inappropriate formatting of citations such as m et al imagenet alex et al judy et al this reference appears three times in the reference section,4.0
666.json,this paper proposes a regularization technique for k shot learning based on orthogonal grouping of units in a neural network the units within a group are forced to be maximally similar at the same time the units from different groups are encouraged to be orthogonal while i like the motivation of the approach the empirical analysis provided in the paper doesn t look particularly convincing my main concerns are the following the method is sensitive to the values of alpha and beta and a poor choice of those hyperparameters can lead to a quite drastic drop in performance comparing the minor gains one gets when alpha and beta are set properly it seems strange that the best performance is obtained when the group size ratio is from the figures in the paper it follows that usually one has more orthogonal groups in a filter bank i have an impression that the empirical evidence doesn t align well with the motivation of the proposed approach the paper contains a significant amount of typos and incorrectly formatted references there are also several places in the manuscript that i found hard to understand due to unusual phrasing i would like to thank the authors for answering addressing my pre review questions i would be grateful if the authors could provide more clarifications of the following question i m not sure if modifying theta map alone would result in any learning at all do i understand correctly that theta map is only used to define groups if so then i don t see how the proposed method can be used in the purely unsupervised regime question i was not referring to the fixed clustering based on the filter of the pre trained network one can perform that clustering at every step of the k shot learning process i m not sure i understand why the authors visualize grouping of filters while in the actual algorithm they group activations overall the paper is quite interesting but needs a stronger empirical justification of the approach as well as a better presentation of the material,4.0
774.json,this paper proposes a variety of techniques for visualizing learned generative models focussing specifically on vae and gan models this paper is somewhat challenging to assess since it does not propose a new algorithm model application etc on the one hand these techniques will be highly relevant to the generative modeling community and i think this paper deserves a wide audience the techniques proposed are simple well explained and of immediate use to those working on generative models however i am not sure the paper is appropriate for an iclr conference track as it does not provide any greater theoretical insights into sampling generative models and there are no comparisons quantitative evaluations of the techniques proposed overall i am very much on the fence since i think the techniques are useful and this paper should be read by those interested in generating modeling i would be willing to increase my core if the author could present a case for why iclr is an appropriate venue for this work,5.0
774.json,this paper proposed a set of different things under the name of sampling generative models focusing on analyzing the learned latent space and synthesizing desirable output images with certain properties for gans this paper does not have one single clear message or idea but rather proposed a set of techniques that seem to produce visually good looking results while this paper has some interesting ideas it also has a number of problems the spherical interpolation idea is interesting but after a second thought this does not make much sense the proposed slerp interpolation equation page implicitly assumes that the two points q and q lie on the same sphere in which case the parameter theta is the angle corresponding to the great arc connecting the two points on the sphere however the latent space of a gan no matter trained with a uniform distribution or a gaussian distribution is not a distribution on a sphere and many points have different distances to the origin the author justification for this comes from the well known fact that in high dimensional space even with a uniform distribution most points lie on a thin shell in the unit cube this is true because in high dimensional space the outer shell takes up most of the volume in space and the inner part takes only a very small fraction of the space in terms of volume this does not mean the density of data in the outer shell is greater than the inner part though in a uniform distribution the data density should be equal everywhere a point on the outer shell is not more likely than a point in the inner part under a gaussian model the data density is on the other hand higher in the center and much lower on the out side if we have a good model of data then sampling the most likely points from the model should give us plausible looking samples in this sense spherical interpolation should do no better than the normally used linear interpolation from the questions and answers it seems that the author does not recognize this distinction the results shown in this paper seem to indicate that spherical interpolation is better visually but it is rather hard to make any concrete conclusions from three pairs of examples if this is really the case then there must be something else wrong about our understanding of the learned model aside from these the j diagram and the nearest neighbor latent space traversal both seems to be good ways to explore the latent space of a learned model the attribute vector section on transforming images to new ones with desired attributes is also interesting and it provides a few new ways to make the gan latent space more interpretable overall i feel most of the techniques proposed in this paper are nice visualization tools the contributions however are mostly on the design of the visualizations and not much on the technical and model side the spherical interpolation provides the only mathematical equation in the paper yet the correctness of the technique is arguable for the visualization tools there are also no quantitative evaluation maybe these results are more art than science,5.0
774.json,in this paper the authors propose various techniques to sample visualizations from generative models with high dimensional latent spaces like vaes and gans for example the authors highlight the well known but often not sufficiently appreciated fact that the probability mass of high dimensional gaussian distributions concentrates near a thin hyper shell with a certain radius they therefore propose to use spherical interpolations great arcs instead of the commonly used linear interpolations in a similar spirit they propose a visualisation for analogies and techniques to reinforce structure in vae latent spaces i find it hard to give clear recommendation for this paper on the one hand i enjoyed reading it and i might want use some of the proposals e g spherical interpolations j diagrams in future work of mine on the other hand it s obvious that this paper is not a typical machine learning paper it does not propose a new model or training method or provide theoretical empirical insight and it does not have the scientific quality and depth i ve seen in many other iclr submissions but it does more than just describing useful tricks and all things considered i think this paper deserves a wider audience but i am not convinced that iclr is the right venue,6.0
324.json,this paper prunes entire groups of filters in cnn so that they reduce computational cost and at the same time do not result in sparse connectivity this result is important to speed up and compress neural networks while being able to use standard fully connected linear algebra routines the results are a improvements in resnet like and imagenet which may be also achieved with better design of networks new networks should have been also compared but this we know it is time consuming a good paper with some useful results,7.0
324.json,this paper proposes a simple method for pruning filters in two types of architecture to decrease the time for execution pros impressively retains accuracy on popular models on imagenet and cifar cons there is no justification for for low l or l norm being a good selection criteria there are two easy critical missing baselines of randomly pruning filters pruning filters with low activation pattern norms on training set there is no direct comparison to the multitude of other pruning and speedup methods while flops are reported it is not clear what empirical speedup this method gives which is what people interested in these methods care about wall clock speedup is trivial to report so the lack of wall clock speedup is suspect,6.0
631.json,please provide an evaluation of the quality clarity originality and significance of this work including a list of its pros and cons paper summary this work proposes to use rnns inside a convolutional network architecture as a complementary mechanism to propagate spatial information across the image promising results on classification and semantic labeling are reported review summary the text is clear the idea well describe the experiments seem well constructed and do not overclaim overall it is not a earth shattering paper but a good piece of incremental science pros clear description well built experiments simple yet effective idea no overclaiming detailed comparison with related work architectures cons idea somewhat incremental e g can be seen as derivative from bell results are good but do not improve over state of the art quality the ideas are sound experiments well built and analysed clarity easy to read and mostly clear but some relevant details left out see comments below originality minor this is a different combination of ideas well known significance seems like a good step forward in our quest to learn good practices to build neural networks for task x here semantic labelling and classification specific comments section we introduction more nonlinearities through the convolutional layers and convolutional layers are linear operators section why exactly rnn cannot have pooling operators i do not see what would impede it section into the computational block which block seems like a typo please rephrase figure b and c not present please fix figure or references to it maybe add a short description of gru in the appendix for completeness section last sentence not sure what is meant the convolutions relu and pooling in resnet do provide non linearities between layers too please clarify section and appendix a how is the learning rate increased and decreased manually this is an important detail that should be made explicit is the learning rate schedule the same in all experiments of each table if there is a human in the loop what is the variance in results between two human schedulers section last sentence we certainly have a strong baseline the pascal voc for competition reports miou as best known results so no is not certainly strong please tune down the statement section modules modules the results ignore any mention of increased memory usage or computation cost this is not a small detail please add a discussion on the topic section adding multi scale spatial adding spatial there is nothing inherently multi in the rnn section furthermoe furthermore appendix c redundant with figure,7.0
631.json,the paper proposes a method of integrating recurrent layers within larger potentially pre trained convolutional networks the objective is to combine the feature extraction abilities of cnns with the ability of rnns to gather global context information the authors validate their idea on two tasks image classification on cifar and semantic segmentation on pascal voc on the positive side the paper is clear and well written apart from some occasional typos the proposed idea is simple and could be adopted by other works and can be deployed as a beneficial perturbation of existing systems which is practically important if one wants to increase the performance of a system without retraining it from scratch the evaluation is also systematic providing a clear ablation study on the negative side the novelty of the work is relatively limited while the validation is lacking a bit regarding novelty the idea of combining a recurrent layer with a cnn something practically very similar was proposed in bell et al there are a few technical differences e g cascading versus applying in parallel the recurrent layers but in my understanding these are minor changes the idea of initializing the recurrent network with the cnn is reasonable but is at the level of improving one wrong choice in the original work of bell rather than really proposing something novel this contribution we use rnns within layers is repeatedly mentioned in the paper including intro conclusion but in my understanding was part of bell et al modulo minor changes regarding the evaluation experiments on cifar are interesting but only as proof of concept furthermore as noted in my early question wide residual networks sergey zagoruyko nikos komodakis bmvc report better results on cifar error while not using any recurrent layers rather using instead a wide vgg type resnet variant so the authors answer wide residual networks use the depth of the network to spread the receptive field across the entire image densenet huang et al similarly uses depth thus there is no need for recurrence within layers to capture contextual information in contrast we show that a shallow cnn where the receptive field would be limited can capture contextual information within the whole image if a l rnn is used so we agree that wrn do not need recurrence and can still do better the point of my question has practically been whether using a recurrent layer is really necessary i can understand the answer as being yes if you want to keep your network shallow i do not necessarily see why one would want to keep one network shallow probably an evaluation on imagenet would bring some more insight about the merit of this layer regarding semantic segmentation one of my questions has been is the boost you are obtaining due to something special to the recurrent layer or is simply because one is adding extra parameters on top of a pre trained network i admit i may have missed some details of your experimental evaluation the answer was for pascal segmentation we add the l rnn into a pre trained network this adds recurrence parameters and again show that this boosts performance more so than adding the same number of parameters as extra cnn layers as it is able to model long range dependences i could not find one such experiment in the paper more so than adding the same number of parameters as extra cnn layers i understand that you have x connections for the recurrence it would be interesting to see what you get by spreading them over non recurrent residual layers clearly this is not going to be my criterion for rejection acceptance since one can easily make it fail but i was mostly asking for some sanity check furthermore it is a bit misleading to put in table fcn s and fcns lrnn since this gives the impression that the lrnn gives a boost by in practice the fcns prefix of fcns lrnn is that of the authors and not of long et al as indicated in table s original is quite worse than s here another thing that is not clear to me is where the boost comes from in table the authors mention that when inserting the l rnn after pool and pool in fcn s the l rnn is able to learn contextual information over a much larger range than the receptive field of pure local convolutions this is potentially true but i do not see why this was not also the case for fcn s this is more a property of the recurrence rather than the factor right a few additional points it seems like fig b and figc never made it into the pdf figure is unstructured and throws some boxes to the reader i would be surprised if anyone is able to get some information out of this why not have a table appendix a this is very mysterious did you try other learning rate schedules e g polynomial what is the performance if you apply a standard training schedule e g step appendix c maps is maps are,6.0
631.json,this paper proposes a cascade of paired left right up down d rnns as a module in cnns in order to quickly add global context information to features without the need for stacking many convolutional layers experimental results are presented on image classification and semantic segmentation tasks pros the paper is very clear and easy to read enough details are given that the paper can likely be reproduced with or without source code using d rnns inside cnns is a topic that deserves more experimental exploration than what exists in the literature cons elaborated on below contributions relative to e g bell et al are minor disappointed in the actual use of the proposed l rnn module versus how it sold in the intro classification experiments are not convincing the introduction states w r t bell et al more substantial differences are two fold first we treat the l rnn module as a general block that can be inserted into any layer of a modern architecture such as into a residual module second we show section that the l rnn can be formulated to be inserted into a pre trained fcn by initializing with zero recurrence matrices and that the entire network can then be fine tuned end to end i felt positive about these contributions after reading the intro but then much less so after reading the experimental sections based on the first contribution general block that can be inserted into any layer i strongly expected to see the l rnn block integrated throughout the cnn starting from near the input however the architectures for classification and segmentation only place the module towards the very end of the network while not exactly the same as bell et al there are many technical details that differ it is close the paper does not compare to the design from bell et al is there any advantage to the proposed design or is it a variation that performs similarly what happens if l rnn is integrated earlier in the network as suggested by the introduction the second difference is a bit more solid but still does not rise to a ubstantive difference in my view note that bell et al also integrate d rnns into an imagenet pretrained vgg model i do however think that the method of integration proposed in this paper zero initialization may be more elegant and does not require two stage training by first freezing the lower layers and then later unfreezing them i am generally skeptical of the utility of classification experiments on cifar when presented in isolation e g no results on imagenet too the issue is that cifar is not interesting as a task unto itself and methods that work well on cifar do not necessarily generalize to other tasks imagenet has been useful because thus far it produces features that generalize well to other tasks showing good results on imagenet is much more likely to demonstrate a model that learns generalizable features however that is not even necessarily true and ideally i would like to see that that a model that does well on imagenet in fact transfers its benefit to at least one other ask e g detection one additional issue with the cifar experiments is that i expect to see a direct comparison of models a f with and without l rnn it is hard to understand from the presented results if l rnn actually adds much in sum i have a hard time taking away any valuable information from the cifar experiments minor suggestion figure is hard to read the pixelated rounded corners on the yellow boxes are distracting,5.0
631.json,the authors propose the use of a vertical and horizontal one dimensional rnn denoted as l rnn module to capture long range dependencies and summarize convolutional feature maps l rnn modules are an alternative to deeper or wider networks d rnns dilated atrous convolutional layers and a simple flatten or global pooling layer when applied to the last convolutional layer for classification l rnn modules are faster than d rnns since rows and columns can be processed in parallel are easy to implemented and can be inserted in existing convolutional networks the authors demonstrate improvements for classification and semantic segmentation however further evaluations are required that show for which use cases l rnns are superior to alternatives for summarizing convolutional feature maps i suggest to use a fixed cnn with as certain number of layers and summarize the last feature map by a a flatten layer b global average pooling c a d rnn d and dilated convolutional layers for segmentation the authors should report both the run time and number of parameters for these variants in addition to prediction performances for segmentation the number of dilated convolutional layers should be chosen such that the number of parameters is similar to a single l rnn module the authors compare classification performances only on x cifar images for higher resolution images the benefit of l rnn modules to capture long range dependencies might be more pronounced i therefore suggest evaluating classification performances on one additional dataset with higher resolution images e g imagenet or the cub bird dataset additionally i have the following minor comments the authors use vanilla rnns it might be worth investigating lstms or grus instead for classification the authors summarize hidden states of the final vertical recurrent layer by global max pooling is this different from more common global average pooling or concatenating the final forward and backward recurrent states table is hard to understand since it mingles datasets pascal p and coco c and methods crf post processing i suggest e g using an additional column with crf yes or no i further suggest listing the number of parameters and runtime if possible section does not clearly describe in which order batch normalization is applied in residual blocks figure suggest that the newer bn relu conv order described in he et al is used this should be mentioned in the text finally the text needs to be revised to reach publication level quality specifically i have the following comments equation is the update of a vanilla rnn which should be stated more clearly i suggest to first describe bidirectional rnns to reference grus and lstms and then describe how they are applied here to images figure should also be referenced in the text in section i suggest to describe bell at al more clearly why are they using eight instead of four rnns section starts with a verbose description about transfer learning which can be compressed into a single reference or skipped entirely equation seems to be missing an index i in particular section and contain a lot of clutter and slang which should be avoided page as can be seen we turn to that case next page to the very high value as noted earlier less context to contribute here page in fact far deeper a simple matter of there is much left to investigate,7.0
332.json,this paper proposes a model to learn across different views of objects the key insight is to use a triplet loss that encourages two different views of the same object to be closer than an image of a different object the approach is evaluated on object instance and category retrieval and compared against baseline cnns untrained alexnet and alexnet fine tuned for category classification using fc features with cosine distance furthermore a comparison against human perception on the tenenbaum objects is shown positives leveraging a triplet loss for this problem may have some novelty although it may be somewhat limited given some concurrent work see below the paper is reasonably written negatives the paper is missing relevant references of related work in this space and should compare against an existing approach more details the image purification paper is very related to this work a joint embeddings of shapes and images via cnn image purification hao su yangyan li charles qi noa fish daniel cohen or leonidas guibas siggraph asia there they learn to map cnn features to hand designed light field descriptors of d shapes for view invariant object retrieval if possible it would be good to compare directly against this approach e g the cross view retrieval experiment in table of a it appears that code and data is available online,5.0
332.json,i think learning a deep feature representation that is supervised to group dissimilar views of the same object is interesting the paper is not technically especially novel but that does not bother me at all it does a good job exploring a new form of supervision with a new dataset i am also not bothered that the dataset is synthetic but it would be good to have more experiments with real data as well i think the paper goes too far in linking itself to human vision i would prefer the intro not have as much cognitive science or neuroscience the second to fourth paragraphs of the intro in particular feels like it over stating the contribution of this paper as somehow revealing some truth about human vision really the narrative is much simpler we often want deep feature representations that are viewpoint invariant we supervise a deep network accordingly humans also have some capability to be viewpoint invariant which has been widely studied citations i am skeptical of any claimed connections bigger than that i think should not be based on tree to tree distance comparisons but instead based on the entire matrix of instance to instance similarity assessments why do the lossy conversion to trees first i do not think remarkably is justified in the statement remarkably we found that opnets similarity judgement matches a set of data on human similarity judgement significantly better than alexnet i am not an expert on human vision but from browsing online and from what i have learned before it seems that object persistence frequently relates to the concept of occlusion occlusion is never mentioned in this paper i feel like the use of human vision terms might be misleading or overclaiming,6.0
762.json,this paper aims to characterize the perceptual ability of a neural network under different input conditions this is done by manipulating the input image x in various ways e g downsamplig foveating and training an auto encoder to reconstruct the original full resolution image mse and qualitative results are shown and compared for the different input conditions unfortunately this paper seems to lack focus presenting a set of preliminary inspections with few concrete conclusions for example at the end of sec this result is not surprising given that fov r contains additional information these results suggests that a small number of foveations containing rich details might be all these neural networks need but this hypothesis is left dangling what detailed regions are needed and from where for what sort of tasks secondly it is not clear to me what reconstruction behaviors are caused by a fundamental perception of the input and what are artifacts of the autoencoder and pixelwise l loss a prime example is texture which the autoencoder fails to recover but with a pixelwise loss the network must predict high frequency textures nearly pixel for pixel at training time if this is impossible then it will generate a pixelwise average of the training samples a flat region so then the network inability to reconstruct textures is due to a problem generating them specifically averaging from the training loss not necessarily an issue in perceiving textures a network trained a different way perhaps an adversarial network may infer a texture is there even if it would not be able to generate it in a pixelwise l sense similarly the ability to perform color reconstruction given a color glimpse i think has much to do with disambiguating the color of an object scene if there is an ambiguity the network wo not know which to choose white flower or yellow flower and output an average which is why there are so many sepia tones however in its section on this the paper only measures the reconstruction error for different amounts of color given and does not drill very far into any hypotheses for why this behavior occurs there are some interesting measurements here such as the amount of color needed in the foveation to reconstruct a color image and the discussion on global features which may start to get at a mechanism by which glimpses may propagate to an entire reconstruction but overall it hard to know what to take away from this paper what are larger concrete conclusions that can be garnered from the details and what mechanisms bring them about can these be more thoroughly explored with more focus,4.0
762.json,i like the idea the paper is exploring nevertheless i see some issues with the analysis to get a better understanding of the quality of the results i think at least some state of the art comparisons should be included e g by setting d times d pixel patches too their average and applying a denoising autoencoder if they perform significantly better then this indicates that the presented model is not yet taking all the information from the input image that could be used sct r and fov r are supposed to test how much information can be restored from the fovea alone as opposed to the fovea together with low resolution periphery however there is an additional difference between the two conditions according to the paper in sct r part of the image was set to zero while in fov r it was removed alltogether with only one or two hidden layers i could easily imagine this making a difference on page you compare the performance of fov r error with that of ds d and attribute this to information about the periphery that the autoencoder extracts from the fovea while this might be the case at least part of the reduced error will be due to the fact that the fovea is hopefully perfectly reconstructed to answer the actual question how much additional information about the periphery can be extracted from the fovea you should consider calculating the error only in the periphery i e the part of the image where ds d and fov r got exactly the same input for then any decreased error is only due to the additional fovea information other issues the images in figure a and b in the rows factor factor factor look very blurry there seems some interpolation to be going on although slighly different than the bilinear interpolation this makes it hard to asses how much information is in these images i think it would be much more insightfull to print them with nearest interpolation figure caption too vague maybe add something like footnote often figures appear too early in paper which leads to lots of distance between text and figures,6.0
762.json,this paper is motivated by the ability that human visual system can recognize contents of environment by from critical features and tried to investigate whether neural networks can also have this kind of ability specifically the paper proposed to use auto encoder ae as the network to reconstruct the low fidelity of visual input moreover similar to mnih et al the paper also proposed to use a recurrent fashion to mimic the sequential behavior the human visual system i think the paper is well motivated however there are several concerns the baselines of the paper are too weak nearest neighbor bilinear bicubic and cubic interpolations without any learning procedure are of course performed worse than ae based models the author should compare with the stoa methods such as,5.0
627.json,this paper proposes a multimodal neural machine translation that is based upon previous work using variational methods but attempts to ground semantics with images considering way to improve translation with visual information seems like a sensible thing to do when such data is available as pointed out by a previous reviewer it is not actually correct to do model selection in the way it was done in the paper this makes the gains reported by the authors very marginal in addition as the author also said in their question response it is not clear if the model is really learning to capture useful image semantics as such it is unfortunately hard to conclude that this paper contributes to the direction that originally motivated it,3.0
627.json,the paper proposes an approach to the task of multimodal machine translation namely to the case when an image is available that corresponds to both source and target sentences the idea seems to be to use a latent variable model and condition it on the image in practice from equation and figure one can see that the image is only used during training to do inference that said the approach appears flawed because the image is not really used for translation experimental results are weak if the model selection was done properly that is using the validation set the considered model would only bring meteor and bleu advantage over the baseline in the view of the overall variance of the results these improvements can not be considered significant the qualitative analysis in subsection appears inconclusive and unconvincing overall there are major issues with both the approach and the execution of the paper,4.0
559.json,this paper proposes an improved version of matching networks with better scalability properties with respect to the support set of a few shot classifier instead of considering each support point individually they learn an embedding function that aggregates over items of each class within the support set eq this is combined with episodic few shot training with randomly sampled partitions of the training set classes so that the training and testing scenarios match closely although the idea is quite straightforward and there are a great many prior works on zero shot and few shot learning the proposed technique is novel to my knowledge and achieves state of the art results on several benchmark datasets one addition that i think would improve the paper is a clearer description of the training algorithm perhaps pseudocode in its current form the paper a bit vague about this,6.0
735.json,the paper proposes a nonlinear regularizer for solving ill posed inverse problems the latent variables or causal factors corresponding to the observed data are assumed to lie near a low dimensional subspace in an rkhs induced by a predetermined kernel the proposed regularizer can be seen as an extension of the linear low rank assumption on the latent factors a nuclear norm penalty on the cholesky factor of the kernel matrix is used as a relaxation for the dimensionality of the subspace empirical results are reported on two tasks involving linear inverse problems missing feature imputation and estimating non rigid d structures from a sequence of d orthographic projections and the proposed method is shown to outperform linear low rank regularizer the clarity of the paper has scope for improvement particularly introduction the back and forth b w dimensionality reduction techniques and inverse problems is confusing at times clearly defining the ill posed inverse problem first and then motivating the need for a regularizer which brings dimensionality reduction techniques into the picture may be a more clear flow in my opinion the motivation behind relaxation of rank in eq to nuclear norm in eq is not clear to me in this setting the relaxation does not yield a convex problem over s c eq and also increases the computations algo needs to do full svd of k s every time the authors should discuss pros cons over the alternate approach that fixes the rank of c which can be selected using cross validation in the same way as tau is selected leaving just the first two terms in eq for this simpler objective an interesting question to ask would be are there kernel functions for which it can solved in a scalable manner the proposed alternating optimization approach in the current form is computationally intensive and seems hard to scale to even moderate sized data in every iteration one needs to compute the kernel matrix over s and perform full svd over the kernel matrix algo empirical evaluations are also not extensive i the dataset used for feature imputation is old and non standard ii for structure estimation from motion on cmu dataset the paper only compares with linear low rank regularization iii there is no comment study on the convergence of the alternating procedure algo,4.0
735.json,this paper presents an approach to non linear kernel dimensionality reduction with a trace norm regularizer in the feature space the authors proposed an iterative minimization approach in order to obtain a local optimum of a relaxed problem the paper contains errors and the experimental evaluation is not convincing only old techniques are compared against in very toy datasets the authors claim state of the art however the oil dataset is not a real benchmark and the comparisons are to very old approaches the experimental evaluation should demonstrate robustness to more complex noise and outliers as this was one of the motivations in the introduction the authors do not address the out of sample problem this is a problem of kernel based methods vs lvms and thus should be address here the paper contains errors the last paragraph of section says that this paper proposes a closed form solution to robust kpca this is simply wrong as the proposed approach consists of iteratively solving iterativey a set of closed form updates and levenberg marquard optimizationd this is not any more closed form in the same paragraph and later in the text the authors claim that the proposed approach can be trivially generalized to incorporate other cost functions this is not true as in general there will be no more inner loop closed form updates and the authors will need to solve a much more complex optimization problem the third paragraph of section claims that this paper presents a novel energy minimization framework to solve problems of the general form of eq however this is not what the authors solve at the end they solve a different problem that has been subject to at least two relaxations it is not clear how solving for a local optima of this double relaxed problem is related to the original problem they want to solve the paper says that geiger et al defined non linearities on a latent space of pre defined dimensionality this is wrong this paper discovers the dimensionality of the latent space by means of a regularizer that encourages the singular values to be sparse thus it does not have a fixed dimensionality the latent space is just bounded to be smaller or equal than the dimensionality of the original space it is not clear to me why the author say for lvms such as gplvm that the latent space is learned a priority with clean training data one can use different noise models within the gp framework furthermore the proposed approach assumes gaussian noise see eq which is also the trivial case for gp based lvms it is not clear what the authors mean in the paper by pre training or saying that techniques do not have a training phase kpca is trained via a closed form update but there is still training,4.0
467.json,this paper provides an interesting idea which extends gan by taking into account bidirectional network totally the paper is well written and easy to follow what is contribution of this paper from the theoretical parts the proposed method bigan inherits similar properties in gan the experimental results show that bigan is competitive with other methods a drawback would a non convex optimization problem in bigan this paper is still suitable to be accepted in my opinion,7.0
488.json,the authors propose to apply virtual adversarial training to semi supervised classification it is quite hard to assess the novelty on the algorithmic side at this stage there is a huge available literature on semi supervised learning especially svm related literature but some work were applied to neural networks too unfortunately the authors do not mention it nor relate their approach to it and stick to the adversarial world in terms of novelty on the adversarial side the authors propose to add perturbations at the level of words embeddings rather than the input itself having in mind applications to nlp concerning the experimental section authors focus on text classification methods again comparison with the existing svm related literature is important to assess the viability of the proposed approach for example wang et al report on imbd with a very simple linear svm without transductive setup overall the paper reads well and propose a semi supervised learning algorithm which is shown to work in practice theoretical and experimental comparison with past work is missing,6.0
488.json,this paper applies the idea of the adversarial training and virtual adversarial training to the lstm based model in the text context the paper is in general well written and easy to follow extending the idea of the adversarial training to the text tasks is simple but non trivial overall the paper is worth to publish i only have a minor comment it is also interesting to see how much adversarial training can help in the performance of rnn which is a simpler model and may be easier to analyze,7.0
522.json,the paper proposes a convergence analysis of some two layer nns with relus it is not the first such analysis but maybe it is novel on the assumptions used in the analysis and the focus on relu nonlinearity that is pretty popular in practice the paper is quite hard to read with many english mistakes and typos nevertheless the analysis seems to be generally correct the novelty and the key insights are however not always well motivated or presented and the argument that the work uses realistic assumptions gaussian inputs for example as opposed to other works is quite debatable actually overall the paper looks like a correct analysis work but its form is really suboptimal in terms of writing presentation and the novelty and relevance of the results are not always very clear unfortunately the main results and intuition should be more clearly presented and details could be moved to appendices for example that could only help to improve the visibility and impact of these interesting results,4.0
522.json,this work analyzes the continuous time dynamics of gradient descent when training two layer relu networks one input one output thus only one layer of relu units the work is interesting in the sense that it does not involve some unrealistic assumptions used by previous works with similar goal most importantly this work does not assume independence between input and activations and it does not rely on noise injection which can simplify the analysis nonetheless removing these simplifying assumptions comes at the expense of limiting the analysis to only one layer of nonlinear units discarding the bias term in relu while keeping the input gaussian thus constant input trick cannot be used to simulate the bias term imposing strong assumption on the representation on the input output via bias less relu networks existence of orthonormal bases to represent this relationships having that said as far as i can tell the paper presents original analysis in this new setting which is interesting and valuable for example by exploiting the symmetry in the problem under the assumption i listed above the authors are able to reduce the high dimensional dynamics of the gradient descent to a bivariate dynamics instead of dealing with original size of the parameters such reduction to d allows the author to rigorously analyze the behavior of the dynamics e g convergence to a saddle point in symmetric case or to the optimum in non symmetric case clarification needed first paragraph of page near the end of the paragraph you say initialization can be arbitrarily close to origin but at the beginning of the same paragraph you state initialized randomly with standard deviation of order sqrt d are not these inconsistent some minor comments about the draft in section nd paragraph we assume x is gaussian and thus the network is bias free do you mean zero mean gaussian then standard deviation is spelled standard derivation multiple times in the paper page last paragraph first line corollary should be corollary,8.0
430.json,this paper proposes to learn decomposition of sequences such as words for speech recognition it addresses an important issue and i forsee it being useful for other applications such as machine translation while the approach is novel and well motivated i would very much like to see a comparison against byte pair encoding bpe bpe is a very natural and important baseline i e dynamic vs fixed decomposition the bpe performance should be obtained for various bpe vocab sizes minor points did the learned decompositions correspond to phonetically meaningful units from the example in the appendix it hard to tell if the model is learning phonemes or just most frequent character n grams any thoughts on applications outside of speech recognition if this is shown to be effective in other domains it would be a really strong contribution but this is probably outside the scope for now,8.0
430.json,interesting paper which proposes jointly learning automatic segmentation of words to sub words and their acoustic models although the training handles the word segmentation as hidden variable which depends also on the acoustic representations during the decoding only maximum approximation is used the authors present nice improvements over character based results however they did not compare results with word segmentation which does not assume the dependency on acoustic obviously only text based segmentation would result in two but simpler independent tasks in order to extract such segmentation several publicly open tools are available and should be cited some of those tools can also exploit the unigram probabilities of the words to perform their segmentations it looks that the improvements come from the longer acoustical units longer acoustical constraints which could lead to less confused search pointing towards full word models in another way less tokens are more probable due to less multiplication of probabilities as a thought experiment for an extreme case if all the possible segmentations would be possible mixture of all word fragments characters and full words would the proposed model use word fragments at all wsj is a closed vocabulary task it would be good to show that the sub word model could outperform even a full word model no segmentation your model estimates p zt x z,7.0
430.json,this submission proposes to learn the word decomposition or word to sub word sequence mapping jointly with the attention based sequence to sequence model a particular feature of this approach is that the decomposition is not static instead it also conditions on the acoustic input and the mapping is probabilistic i e one word may map to multiple sub word sequences the authors argue that the dynamic decomposition approach can more naturally reflect the acoustic pattern interestingly the motivation behind this approach is analogous to learning the pronunciation mixture model for hmm based speech recognition where the probabilistic mapping from a word to its pronunciations also conditions on the acoustic input e g i mcgraw i badr and j glass learning lexicons form speech using a pronunciation mixture model in ieee transactions on audio speech and language processing l lu a ghoshal s renals acoustic data driven pronunciation lexicon for large vocabulary speech recognition in proc asru r singh b raj and r stern automatic generation of subword units for speech recognition systems in ieee transactions on speech and audio processing it would be interesting to put this work in the context by linking it to some previous works in the hmm framework overall the paper is well written and it is theoretically convincing the experimental study could be more solid e g it is reasonable to have a word level baseline as the proposed approach lies in between the character level and word level systems the vocabulary size of the wsj si dataset is k at maximum which is not very large for the softmax layer and it is a closed vocabulary task i guess the word level system may be also competitive to the numbers reported in this paper furthermore can you explain what is the computational bottleneck of the proposed approach you downsampled the data by the factor of using an rnn and it still took around days to converge to me it is a bit expensive especially given that you only take one sample when computing the gradient table is a little bit misleading as ctc with language model and seqseq with a language model model from bahdanau et al is much closer to the best number reported in this table while you may only get a very small improvement using a language model finally o days to converge sounds a bit odd to me,7.0
575.json,it is not clear to me at all what this paper is contributing deep cca andrew et al already gives the gradient derivation of the correlation objective with respect to the network outputs which are then back propagated to update the network weights again the paper gives the gradient of the correlation i e the cca objective w r t the network outputs so it is confusing to me when authors say that their differentiable version enables them to back propagate directly through the computation of cca,3.0
575.json,after a second look of the paper i am still confused what the authors are trying to achieve the cca objective is not differentiable in the sense that the sum of singular values trace norm of t is not differentiable it appears to me from the title and section the authors are trying to solve this problem however did the authors simply reformulate the cca objective or change the objective the authors need to be explicit here what is the relationship between the retrieval objective and the cca layer i could imagine different ways of combining them such as combination or bi level optimization and i could not find discussion about this in section for this equations would be helpful even though the cca objective is not differentiable in the above sense it has not caused major problem for training e g in principle we need batch training but empirically using large minibatches works fine the authors need to justify why the original gradient computation is problematic for what the authors are trying to achieve from the authors response to my question it seems they still use svd of t so i am not sure if the proposed method has advantage in computational efficiency in terms of paper organization it is better to describe the retrieval objective earlier than in the experiments and i still encourage the authors to conduct the comparison with contrastive loss that i mentioned in my previous comments,4.0
349.json,this paper proposed an integration of memory network with reinforcement learning the experimental data is simple but the model is very interesting and relatively novel there are some questions about the model how does the model extend to the case with multiple variables in a single sentence if the answer is out of vocabulary how would the model handle it i hope the authors can provide more analysis about the curriculum learning part since it is very important for the rl model training in the training in each iteration how the data samples were selected by random or from simple one depth to multiple depth,6.0
349.json,this paper introduces a nice dataset data generator that creates babi like tasks except where the questioning answering agent is required to clarify the values of some variables in order to succeed i think the baselines the authors use to test the tasks are appropriate i am a bit worried that the tasks may be too easy as the babi tasks have been but still i think locally these will be useful if the generation code is well written and the tasks are extensible they may be useful for some time,7.0
349.json,this paper investigates a set of tasks that augment the basic babi problems in particular some of the people and objects in the scenarios are replaced with unknown variables some of these variables must be known to solve the question thus the agent must learn to query for the values of these variables interestingly one can now measure both the performance of the agent in correctly answering the question and its efficiency in asking for the values of the correct unknown variables and not variables that are unnecessary to answer the question this inferring of unknown variables goes beyond what is required for the vanilla version of the babi tasks which are now more or less solved the paper is well written and the contributions are clear due to the very limited vocabulary and structure of the babi problems in general i think these tasks and variants on them should be viewed more as basic reasoning tasks than natural language understanding i m not convinced by the claim of the paper that this really tests the interaction capabilities of agents while the task is phrased as a kind of interaction i think it s more aptly described by simply inferring important unknown variables which while important is more related to reasoning i m not sure whether the connection of this ability to interaction is more a superficial one that being said it is certainly true that conversational agents will need basic reasoning abilities to converse meaningfully with humans i sympathise with the general goal of the babi tasks which is to test these reasoning abilities in synthetic environments that are just complicated enough but not more to drive the construction of interesting models i am convinced by the authors that their extension to these tasks are interesting and worthy of future investigation and thus i recommend the acceptance of the paper,7.0
426.json,the paper focuses on bilingual word representation learning with the following setting bilingual representation is learnt in an offline manner i e we already have monolingual representations for the source and target language and we are learning a common mapping for these two representations there is no direct word to word alignments available between the source and target language this is a practically useful setting to consider and authors have done a good job of unifying the existing solutions for this problem by providing theoretical justifications even though the authors do not propose a new method for offline bilingual representation learning the paper is significant for the following contributions theory for offline bilingual representation learning inverted softmax using cognate words for languages that share similar scripts showing that this method also works at sentence level to some extent authors have addressed all my pre review questions and i am ok with their response i have few more comments header for table which says word frequency is misleading word frequency could mean that rare words occur in row while i guess authors meant to say that rare words occur in row i see that authors have removed precision and from table is it because of the space constraints or the results have different trend i would like to see these results in the appendix in table what is the difference between row and row is the only difference nn vs inverted softmax or there are other differences please elaborate another suggestion is to try running an additional experiment where one can use both expert dictionary and cognate dictionary comparing all methods in this setting should give more valuable insights about the usefulness of cognate dictionary,8.0
426.json,this paper extends preceding works to create a mapping between the word embedding space of two languages the word embeddings had been independently trained on monolingual data only and various forms of bilingual information is used to learn the mapping this mapping is then used to measure the precision of translations in this paper the authors propose two changes cca and inverted softmax looking at table cca is only better than dina et al in out of cases it en most of the improvements are in fact obtained by the introduction of the inverted softmax normalization overall i wonder which aspect of this paper is really new you mention faruqui dyer already used cca and dimensionality reduction xing et al argued already that mikolov linear matrix should be orthogonal could you make clear in what aspect your work is different from faruqui dyer other the fact that you applied the method to measure translation precision using cognates instead of a bilingual directory is a nice trick please explain how you obtained this list of cognates obviously this only works for languages with the same alphabet for instance greek and russian are excluded also it seems to me that in linguistics the term cognate refers to words which have a common etymological origin they do not necessarily have the same written form e g night nuit noche nacht maybe you should use a different term those words are probably proper names in news texts,6.0
563.json,in this paper the authors extend the f gan by using bregman divergences for density ratio matching the argument against f gan which is a generalization of the regular gan is that the actual objective optimized by the generator during training is different from the theoretically motivated objective due to gradient issues with the theoretically motivated objective in b gans the discriminator is a density ratio estimator r x p x q x and the generator tries to minimize the f divergence between p and q by writing p x r x q x my main problem with this paper is that it is unclear why any of this is useful the connection to density estimation is interesting but any derived conclusions between the two seem questionable for example in previous density estimation literature the pearson divergence is more stable the authors claim that the same holds for gans and try to show this in their experiments unfortunately the experiments section is very confusing with unilluminating figures looking at the graph of density ratios is not particularly illuminating they claim that for the pearson divergence and modified kl divergence the learning did not stop by looking at the graph of density ratios this is completely hand wavey and no further evidence is given to back this claim also why was the normal gan objective not tried in light of this analysis furthermore it seems that despite criticizing normal gans for using a heuristic objective for the generator multiple heuristics objectives and tricks are used to make b gan work i think this paper would be much improved if it was rewritten in a clear fashion as it stands it is difficult to understand the motivation or intuition behind this work,5.0
563.json,this paper proposes b gan which trains a discriminator by estimating density ratio that minimizes bregman divergence the authors also discuss how b gans relate to f gan and the original gan work providing a unifying view through the lens of density ratio estimation note that the unifying view applies only to gan variants which optimize density ratios in general gans which use mmd in the discriminator step do not fit in the b gan framework except for special choices of the kernel i was a bit confused about the dual relationship between f gan and b gan are the conditions on the function f the same in both cases if so what is the difference between f gan and b gan other than the fact that the former has been derived using f divergence and the latter has been derived using bregman divergence one of the original claims was that b gans optimize f divergence directly as opposed to f gan and gan however in practice the authors optimize an approximation to the f divergence the quality of the approximation is not quantified anywhere so b gan does not seem more principled than f gan and gan the experiments left me a bit confused and were not very illuminating on the choice of f overall i liked the connections to the density ratio estimation literature the appendix seems like a scattered collection right now some re writing of the text would significantly improve this paper,6.0
534.json,i just noticed i submitted my review as a pre review question sorry about this here it is again with a few more thoughts added the authors present a great and as far as i can tell accurate and honest overview of the emerging theory about gans from a likelihood ratio estimation divergence minimisation perspective it is well written and a good read and one i would recommend to people who would like to get involved in gans my main problem with this submission is that it is hard as a reviewer to pin down what precisely the novelty is beyond perhaps articulating these views better than other papers have done in the past a sentence from the paper but it has left us unsatisfied since we have not gained the insight needed to choose between them summarises my feeling about this paper this is a nice unifying review type paper that for me lacks a novel insight in summary my assessment is mixed i think this is a great paper i enjoyed reading it i was left a bit disappointed by the lack of novel insight or a singular key new idea which you often expect in conference presentations and this is why i m not highly confident about this as a conference submission and hence my low score i am open to be convinced either way detailed comments i think the authors should probably discuss the connection of eq to kliep kullback leibler importance estimation by shugiyama and colleagues i don t quite see how the part with equation and fit into the flow of the paper by this point the authors have established the view that gans are about estimating likelihood ratios and then using these likelihood ratios to improve the generator these paragraphs read like we also tried to derive another particular formulation for doing this but we failed to do it in a practical way there is a typo in spelling csiszar divergence equation is known to me as least squares importance estimation by kanamori et al a variant of least squares likelihood estimation uses the kernel trick and finds a function from an rkhs that best represents the likelihood ratio between the two distributions in a least squares sense i think it would be interesting to think about how this function is related to the witness function commonly used in mmd and what the properties of this function are compared to the witness function perhaps showing the two things for simple distributions i have stumbled upon the work of sugiyama and collaborators on direct density ratio estimation before and i found that work very insightful generally while some of this work is cited in this paper i felt that the authors could do more to highlight the great work of this group who have made highly significant contributions to density ratio estimation albeit with a different goal in mind on likelihood ratio estimation some methods approximate the likelihood ratio directly such as least squares importance estimation some can be thought of more as approximating the log of this quantity logistic regression denoising autoencoders an unbiased estimate of the ratio will provide a biased estimate of the logarithm and vice versa to me it feels like estimating the log of the ratio directly is more useful and in more generality estimating the convex function of the ratio which is used to define the f divergence seems like a good approach could the authors comment on this i think the hypothesis testing angle is oversold in the paper i m not sure what additional insight is gained by mixing in some hypothesis testing terminology other than using quantities that appear in hypothesis testing as tests statistics his work does not really talk about hypothesis testing nor does it use any tools from the hypothesis testing literature in this sense this paper is in contrast with sutherland et al in review for iclr who do borrow concepts from two sample testing to optimise hyperparameters of the divergence used,6.0
534.json,the paper provides an exposition of multiple ways of learning in implicit generative models of which generative adversarial networks are an example the paper is very clear the exposition is insightful and the presented material is clearly important it is hard to assess novelty of this work as the individual pieces are not novel and yet the exposition of all of them in the same space with clear outline of the connections between them is novel i believe this work is significant it provides a bridge for language and methods used in multiple parts of statistics and machine learning this has the potential to accelerate progress i recommend publishing this paper at iclr even though it is not the typical paper that get published at this conference in that it does not offer empirical validation nor makes a particular claim about relative merits of different methods,8.0
308.json,this paper makes a valuable contribution to provide a more clear understanding of generative adversarial network gan training procedure with the new insight of the training dynamics of gan as well as its variant the authors reveal the reason that why the gradient is either vanishing in original gan or unstable in its variant more importantly they also provide a way to avoid such difficulties by introducing perturbation i believe this paper will inspire more principled research in this direction i am very interested in the perturbation trick to avoid the gradient instability and vanishment in fact this is quite related to dropout trick in where the perturbation can be viewed as bernoulli distribution it will be great if the connection can be discussed besides the theoretical analysis is there any empirical study to justify this trick could you please add some experiments like fig and for the perturbated gan for comparison,8.0
308.json,summary this paper addresses important questions about the difficulties in training generative adversarial networks it discusses consequences of using an asymmetric divergence function and sources of instability in training gans then it proposes an alternative using a smoothening approach pros theory good questions nice answers makes an interesting use of concepts form analysis and differential topology proposes avenues to avoid instability in gans cons a bit too long technical some parts and consequences still need to be further developed which is perfectly fine for future work minor comments section maybe shorten this section a bit e g move all proofs to the appendix section provides a nice intuitive simple solution on page second bullet this also means that pg is smaller than the data distribution in some other x which in turn will make the kl divergence non zero on page for not generating plausibly looking pictures should be for generating not plausibly looking pictures lemma would also hold in more generality theorem seems to be basic analysis in other words a reference could spare the proof in theorem it would be good to remind the reader about p z lemma seems to be basic analysis in other words a reference could spare the proof specify the domain of the random variables relly rely theorem the closed manifolds have boundary or not already in the questions corollary assumptions of theorem i could not find theorem theorem therefore then theorem is a is a the number of the theorems is confusing,7.0
308.json,this is a strong submission regarding one of the most important and recently introduced methods in neural networks generative adversarial networks the authors analyze theoretically the convergence of gans and discuss the stability of gans both are very important to the best of my knowledge this is one of the first theoretical papers about gans and the paper contrary to most of the submissions in the field actually provides deep theoretical insight into this architecture the stability issues regarding gans are extremely important since the first proposed versions of gans architecture were very unstable and did not work well in practice theorems are novel and introduces mathematical techniques are interesting i have some technical questions regarding the proof of theorem but these are pretty minor,10.0
685.json,this paper proposes a model for representing unseen words in a neural language model the proposed model achieves poor results in lm and a slight improvement over a baseline model this work needs a more comprehensive analysis there no comparison with related work trying to address the same problem an intrinsic evaluation and investigation of why how their work should be better are missing to make a bolder claim more investigation should be done with other morphologically rich languages especially for mt in addition to going from en languagex mrlx en or mrlx mrly should be done,2.0
390.json,a well written paper and an interesting construction i thoroughly enjoyed reading it i found the formalism a bit hard to follow without specific examples that is it was not clear to me at first what the specific components in figure a were what constitutes the controller a control the optimizer what was being optimized etc in specific cases algorithm boxes may have been helpful especially in the case of your experiments a description of existing models that fall under your conceptual framework might help as well in practical bayesian optimization of machine learning algorithms snoek larochelle and adams propose optimizing with respect to expected improvement per second to balance computation cost and performance loss it might be interesting to see how this falls into your framework experimental results were presented clearly and well illustrated the usefulness of the metacontroller i am curious to see the results of using more metaexperts,8.0
390.json,pros quality clarity originality significance this paper presents a novel metacontroller optimization system that learns the best action for a one shot learning task but as a framework has the potential for wider application the metacontroller is a model free reinforcement learning agent that selects how many optimization iterations and what function or expert to consult from a fixed set such as an action value or state transition function experimental results are presented from simulation experiments where a spacecraft must fire its thruster once to reach a target location in the presence of between and heavy bodies the metacontroller system has a similar performance loss on the one shot learning task as an iterative standard optimization procedure however by taking into account the computational complexity of running a classical iterative optimization procedure as a second resource loss term the metacontroller is shown to be more efficient moreover the metacontroller agent successfully selects the optimal expert to consult rather than relying on an informed choice by a domain expert model designer the experimental performance is a contribution that merits publication and it also exhibits the use of an interaction network for learning the dynamics of a simulated physical system the dataset that has been developed for this task also has the potential to act as a new baseline for future work on one shot physical control systems the dataset constitutes an ancillary contribution which could positively impact future research in this area cons it not clear how this approach could be applied more broadly to other types of optimization moreover the reinforce gradient estimation method is known to suffer from very high variance yielding poor estimates i am curious what methods were used to ameliorate these problems and if any other performance tricks were necessary to train well content of this type this could form a useful additional appendix a few critiques on the communication of results the formal explication of the paper s content is clear but fig s a and could be improved fig a is missing a clear visual demarcation of what exactly the metacontroller agent is have you considered a plate or bounding box around the corresponding components this would likely speed the uptake of the formal description fig is generally clear but the lack of x axis tick marks on any subplots makes it more challenging than necessary to compare among the experts also the overlap among the points and confidence intervals in the upper left subplot interferes with the quantitative meaning of those symbols perhaps thinner bars of different colors would help here moreover this figure lacks a legend and so the different lines are impossible to compare with each other lastly the second sentence in appendix b is a typo and terminates without completion,8.0
543.json,validity the presented work seems technically valid code for matrix library sushi and dl library sukiyaki are on github including live demos that run in your browser,6.0
543.json,while it is interesting that this can be done and it will be useful for some it does seem like the audience is not really the mainstream iclr audience who will not be afraid to use a conventional ml toolkit there is no new algorithm here nor is there any ui meta design improvement to make it easier for non experts to design and train neural network systems i think there will be relatively little interest at iclr in such a paper that does not really advance the state of the art i have no significant objection to the presentation or methodology of the paper,4.0
406.json,paper addresses systematic discrepancies between simulated and real world policy control domains proposed method contains two ideas training on an ensemble of models in an adversarial fashion to learn policies that are robust to errors and adaptation of the source domain ensemble using data from a real world target domain significance paper addresses and important and significant problem the approach taken in addressing it is also interesting clarity paper is well written but does require domain knowledge to understand my main concerns were well addressed by the rebuttal and corresponding revisions to the paper,7.0
406.json,the paper looks at the problem of transferring a policy learned in a simulator to a target real world system the proposed approach considers using an ensemble of simulated source domains along with adversarial training to learn a robust policy that is able to generalize to several target domains overall the paper tackles an interesting problem and provides a reasonable solution the notion of adversarial training used here does not seem the same as other recent literature e g on gans it would be useful to add more details on a few components as discussed in the question response round i also encourage including the results with alternative policy gradient subroutines even if they don t perform well e g reinforce as well as results with and without the baseline on the value function such results are very useful to other researchers,7.0
514.json,pros new and clear formalism for invariance on signals with known structure good numerical results cons the structure must be specified the set structure dataset is too simple there is a gap between the large and sometimes complex theory introduced and the numerical experiments consequently a new reader could be lost since examples might be missing besides from a personal point of view i think the topic of the paper and its content could be suitable for a big conference as the author improves its content thus if rejected i think you should not consider the workshop option for your paper if you wish to publish it later in a conference because big conferences might consider the workshop papers of iclr as publications that an issue i had to deal with at some points,5.0
781.json,the goal of this paper is to learn a collection of experts that are individually meaningful and that have disjoint responsibilities unlike a standard mixture model they use a different mixture for each dimension d while the results seem promising the paper exposition needs significant improvement comments the paper jumps in with no motivation at all what is the application or even the algorithm or architecture that this is used for this should be addressed at the beginning the subsequent exposition is not very clear there are assertions made with no justification e g the experts only have a small variance for some subset of the variables while the variance of the other variables is large since you re learning both the experts and the weights can this be rephrased in terms of dictionary learning please discuss the relevant related literature the horse data set is quite small with respect to the feature dimension and so the conclusions may not necessarily generalize,6.0
502.json,this paper addresses the issue of how to evaluate automatic dialogue responses this is an important issue because current practice to automatically evaluate e g bleu based on n gram overlap etc is not correlated well with the desired quality i e human annotation the proposed approach is based on the use of an lstm encoding of dialogue context reference response and model response with appropriate scoring with the essence of training one dialogue model to evaluate another model however the proposed solution depends on a reasonably good dialogue model to begin with which is not guaranteed rendering the new metric possibly meaningless,5.0
502.json,overall the paper address an important problem how to evaluate more appropriately automatic dialogue responses given the fact that current practice to automatically evaluate bleu meteor is often insufficient and sometimes misleading the proposed approach using an lstm based encoding of dialogue context reference response and model response s that are then scored in a linearly transformed space while the overall approach is simple it is also quite intuitiv and allows end to end training as the authors rightly argue simplicity is a feature both for interpretation as well as for speed the experimental section reports on quite a range of experiments that seem fine to me and aim to convince the reader about the applicability of the approach as mentioned also by others more insights from the experiments would have been great i mentioned an in depth failure case analysis and i would also suggest to go beyond the current dataset to really show generalizability of the proposed approach in my opinion the paper is somewhat weaker on that front that it should have been overall i like the ideas put forward and the approach seems sensible though and the paper can thus be accepted,7.0
447.json,the paper introduces a simulator and a set of synthetic question answering tasks where interaction with the teacher via asking questions is desired the motivation is that an intelligent agent can improve its performance by asking questions and getting corresponding feedback from users the paper studies this problem in an offline supervised and an online reinforcement learning settings the results show that the models improve by asking questions the idea is novel and is relatively unexplored in the research community the paper serves as a good first step in that direction the paper studies three different types of tasks where the agent can benefit from user feedback the paper is well written and provides a clear and detailed description of the tasks models and experimental settings other comments questions what is the motivation behind using both vanilla memnn and cont memnn is using both resulting in any conclusions which are adding to the paper contributions in the question clarification setting what is the distribution of misspelled words over question entity answer entity relation entity or none of these if most of the misspelled words come from relation entities it might be a much easier problem than it seems the first point on page the performance of testmodelaq is worse than testaq but better than testqa is not true for task from the numbers in tables and what happens if the conversational history is smaller or none figure task why does the accuracy for good student drop when it stops asking questions it already knows the relevant facts so asking questions is not providing any additional information to the good student figure task the poor student is able to achieve almost of the questions correct even without asking questions i would expect this number to be quite low any explanation behind this figure task aq last sentence should have a negative response instead of positive as currently shown preliminary evaluation a good first step in the research direction of learning dialogue agents from unstructured user interaction,7.0
447.json,the goal of this paper is to analyze the behaviour of dialogue agents when they must answer factoid questions but must query an oracle for additional information this can be interpreted as a form of interaction between the dialogue agent and a teacher the problem under investigation is indeed very important the authors create a synthetic environment in which to test their agent the main strength of the paper is that the paper tests many different combinations of environments where either some knowledge is missing and the agent has to query for it or there is some misspelling in the teacher s question and different ways the agent can ask for extra information i am a bit concerned that many of the tasks are too easy e g the aq question paraphrase and i am also concerned that the environment presented is very limited and quite far in terms of richness of linguistic structure from how real humans would interact with chatbots i think the paper would be better positioned as testing the basic reasoning capabilities of agents their ability to do question answering rather than dialogue however i think the ground up approach that starts with simple environments is indeed worthy of analysis and this paper makes an interesting contribution in that direction of course the paper would be much more convincing with human experiments additional notes i think the simulation in the synthetic environment for the first mistake a learner can make during dialogue the learner has problems understanding the surface form of the text of the dialogue partner e g the phrasing of a question is particularly limited since only word misspellings are considered and the models used don t work at the character level which is of course only a tiny fraction of ways an agent can misunderstand the context i would be particularly interested to see some discussion of how the authors plan to scale this up to more realistic settings edit i have updated my score to reflect the addition of the mechanical turk experiments,7.0
693.json,this paper presents a meta learning algorithm which learns to learn generative models from a small set of examples it s similar in structure to the matching networks of vinyals et al and is trained in a meta learning framework where the inputs correspond to datasets results are shown on omniglot in terms of log likelihoods and in terms of generated samples the proposed idea seems reasonable but i m struggling to understand various aspects of the paper the exposition is hard to follow partly because existing methods are described using terminology fairly different from that of the original authors most importantly i can t tell which aspects are meant to be novel since there are only a few sentences devoted to matching networks even though this work builds closely upon them i brought this up in my reviewer question and the paper has not been revised to make this clearer i m also confused about the meta learning setup one natural formulation for meta learning of generative models would be that the inputs consist of small datasets x and the task is to predict the distribution from which x was sampled but this would imply a uniform weighting of data points which is different from the proposed method based on it seems like one additionally has some sort of query q but it s not clear what this represents in terms of experimental validation there aren t any comparisons against prior work this seems necessary since several other methods have already been proposed which are similar in spirit,4.0
693.json,this paper proposes an interesting idea for rapidly adapting generative models in the low data regime the idea is to use similar techniques that are used in one shot learning specifically ideas from matching networks to that end the authors propose the generative matching networks model which is effectively a variational auto encoder that can be conditioned on an input dataset given a query point the model matches the query point to points in the conditioning set using an attention model in an embedding space this is similar to matching networks the results on the omniglot dataset show that this method is successfully able to rapidly adapt to new input distributions given few examples i think that the method is very interesting however the major issue for me with this paper is a lack of clarity i outline more details below but overall i found the paper somewhat difficult to follow there are a lot of details that i feel are scattered throughout and i did not get a sense after reading this paper that i would be able to implement the method and replicate the results my suggestion is to consolidate the major implementation details into a single section and be explicit about the functional form of the different embedding functions and their variants i was a bit disappointed to see that weak supervision in the form of labels had to be used how does the method perform in a completely unsupervised setting this could be an interesting baseline there is a lack of definition of the different functions some basic insight into the functional forms of f g phi sim and r would be nice otherwise it is very unclear to me what s going on section only state of the recurrent controller was used for matching my reading of this section after several passes is that the pseudo input is used in the place of a regular input is this correct otherwise this sentence section needs more clarification i noticed upon further reading in section that there are two versions of the model one in which a pseudo input is used and one in which a pseudo input is not used the conditional version what is the difference in functional form between these that is how do the formulas for the embeddings f and g change between these settings since the result was fully contrastive we did not apply any further binarization what does it mean for a result to be fully contrastive for clarity the figures and table refer to the number of shots but this is never defined i assume this is t here this should be made consistent figure why is the value of t only in this case what does it mean for it to be it is stated earlier that t should go up to i assume shot corresponds to t it also looks like the results continue to improve with an increased number of steps i would like to see the results for and maybe steps as well presumably there will come a point where you get diminishing returns table is the vae a fair baseline you mention that ctest affects pd in the evaluation the fact that the vae does not have an associated ctest implies that the two models are being evaluated with a different metric can the authors clarify this it s important that the comparison is apples to apples mnist is much more common than omniglot for evaluating generative models would it be possible to perform similar experiments on this dataset that way it can be compared with many more models further why are the negative log likelihood values monotonically decreasing in the number of shots that is is there ever a case where increasing the number of shots can hurt things what happens at t as a minor grammatical issue the paper is missing determiners in several sentences at one point the model is referred to as she instead of it on figure should be changed to in figure in the experiments section,5.0
369.json,the paper shows a different approach to a ternary quantization of weights strengths the paper shows performance improvements over existing solutions the idea of learning the quantization instead of using pre defined human made algorithm is nice and very much in the spirit of modern machine learning weaknesses the paper is very incremental the paper is addressed to a very narrow audience the paper very clearly assumes that the reader is familiar with the previous work on the ternary quantization it is what is new in the topic update not really a standalone paper the description of the main algorithm is very concise to say the least and is probably clear to those who read some of the previous work on this narrow subject but is unsuitable for a broader deep learning audience there is no convincing motivation for the work what is presented is an engineering gimmick that would be cool and valuable if it really is used in production but is that really needed for anything are there any practical applications that require this refinement i do not find the motivation it is related to mobile therefore it is cool sufficient this paper is a small step further in a niche research as long as the authors do not provide a sufficient practical motivation for pursuing this particular topic with the next step on a long list of small refinements i do not think it belongs in iclr with a broad and diversified audience also the code was not released is my understanding,3.0
369.json,this paper presents new way for compressing cnn weights in particular this paper uses a new neural network quantization method that compresses network weights to ternary values the group has recently published multiple paper on this topic and this one offers possibly the lowest returns i have seen only a fraction of percentage in imagenet results on alexnet are of very little interest now given the group already showed this kind of older style network can be compressed by large amounts i also would have liked to see this group release code for the compression and also report data on the amount of effort required to compress flops time number of passes required original dataset etc this data is important to decide if a compression is worth the effort,7.0
369.json,this work presents a novel ternary weight quantization approach which quantizes weights to either or one of two layer specific learned values unlike past work these quantized values are separate and learned stochastically alongside all other network parameters this approach achieves impressive quantization results while retaining or surpassing corresponding full precision networks on cifar and imagenet strengths overall well written and algorithm is presented clearly approach appears to work well in the experiments resulting in good compression without loss and sometimes gain of performance i enjoyed the analysis of sparsity and how it changes over the course of training though it is uncertain if any useful conclusion can be drawn from it some points the energy analysis in table assumes dense activations due to the unpredictability of sparse activations can the authors provide average activation sparsity for each network to help verify this assumption even if the assumption does not hold relatively close values for average activation between the networks would make the comparison more convincing in section the authors suggest having a fixed t threshold parameter set at for all layers allows for varying sparsity owed to the relative magnitude of different layer weights with respect to the maximum in section paragraph this is further developed by suggesting additional sparsity can be achieved by allowing each layer a different values of t how are these values set does this multiple threshold style network appear in any of the tables or figures can it be added the authors claim ii quantized weights play the role of learning rate multipliers during back propagation as a benefit of using trained quantization factors why is this a benefit figure and table captions are not very descriptive preliminary rating i think this is an interesting paper with convincing results but is somewhat lacking in novelty minor notes table lists flops rather than energy for the full precision model why section peeding up figure reference error last line,7.0
369.json,this paper presents a ternary quantization method for convolutional neural networks all weights are represented by ternary values multiplied by two scaling coefficients both ternary weights and the scaling coefficients are updated using back propagation this is useful for cnn model compression experiments on alexnet show that the proposed method is superior ternary weight networks twn and dorefa net this work has the following strengths and weaknesses strengths good results are shown on cifar dataset massive energy saving of the ternary weights comparing to bit weights it is well written and easy to understand weaknesses it seems that this work is an incremental improvement on the existing works the main difference from binary weight networks bwn proposed in xnor net is using ternary weights instead of binary weights while ternary weights have been used by many previous works both bwn and the proposed method in this paper learn the scaling factors during training comparing to ternary weight networks twn the main difference is that two independent quantization factors are used for positive and negative weights while twn utilizes the same scaling factor for all weights in the experiment the authors did not process the first conv layer and the last fully connected layer the results of processing all layers should be given for fair comparison in the experiment comparison with bwn is not reported in the top and top error of alexnet on imagenet of bwn is and which is comparable with the method proposed in this paper and however the bwn only uses binary weights and all layers are binarized including the first conv layer and the last fully connected layer for the baseline method of full precision alexnet with bn the reported accuracy seems to be too low top error commonly using batch normalization can boost the accuracy while the reported accuracy are much lower than alexnet without batch normalization on the other hand the error rates of pre trained model of alexnet with bn reported by the official matconvnet are and the proposed method should be evaluated on the original alexnet whose accuracy is publicly available for almost all deep learning frameworks like caffe moreover more experiments should be added on imagenet like vgg s vgg googlenet or resnet in previous methods such as xnor net and twn most of the bit multiply operation can be replaced by addition by using binary or ternary weights however the proposed method in this paper utilizes independent scaling factors for positive and negative weights thus it seems that the multiply operation can not be replaced by addition references mohammad r vicente o joseph r ali f xnor net imagenet classification using binary convolutional neural networks eccv,3.0
369.json,this paper studies in depth the idea of quantizing down convolutional layers to bits with a different positive and negative per layer scale it goes on to provide an exhaustive analysis of performance essentially no loss on real benchmarks this paper is remarkably mnist free the relevance of this paper is that it likely provides a lower bound on quantization approaches that do not sacrifice any performance and hence can plausibly become the approach of choice for resource constrained inference and might suggest new hardware designs to take advantage of the proposed structure furthermore the paper provides power measurements which is really the main metric that anyone working seriously in that space cares about nit i do not see measurements for the full precision baseline i would have loved to see a sota result on imagenet and a result on a strong lstm baseline to be fully convinced i would have also liked to see discussion of the wall time to result using this training procedure,8.0
555.json,this paper aims at attacking the problem of preselecting deep learning model structures for new domains it reported a series of experiments on various small tasks and feed forward dnns it claims that some ranking algorithm can be learned based on these results to guide the selection of model structures for new domains although the goal is interesting i found their conclusion is neither convincing nor useful in practice for several reasons they only explored really simple networks feed forward dnns while this significantly limited the search space it also limited the value of the experiments in fact the best model architecture is highly task domain dependent and the type of model dnn vs cnn vs lstm is often much more important than size of the network itself their experiments were conduced with some important hyper parameters e g learning rate schedule fixed however it is well known that learning rate often is the most important hyper parameter during training without adjusting these important hyper parameters the conclusion on the best model architecture is not convincing their experiments seem to indicate that the training data difference is not important however this is unlikely to be true as you would definitely want to use larger models total number of parameters when your training set is magnitude larger i e log datasize can be an important feature this is likely because they did not run experiments on large datasets in addition i think the title of the paper does not accurately reflect what the paper is about and should be modified also this paper cited sainath et al as the work that leads to breakthrough in speech recognition however the breakthrough in asr happened much earlier the first paper with all three key components was published in yu d deng l and dahl g december roles of pre training and fine tuning in context dependent dbn hmms for real world speech recognition in proc nips workshop on deep learning and unsupervised feature learning and the more detailed paper was published in dahl g e yu d deng l and acero a context dependent pre trained deep neural networks for large vocabulary speech recognition ieee transactions on audio speech and language processing pp as a conclusion this paper presented some very preliminary result although it interesting it not ready for publishing,3.0
410.json,the paper address the problem of detecting if an example is misclassified or out of distribution this is an very important topic and the study provides a good baseline although it misses strong novel methods for the task the study contributes to the community,6.0
410.json,the authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out of domain they contrast the performance of the proposed method with directly using the softmax output probabilities and not their statistics as a measure of confidence it would be great if the authors elaborate on the idea of ignoring the logit of the blank symbol it would be interesting to see the performance of the proposed methods in more confusable settings ie in cases where the out of domain examples are more similar to the in domain examples e g in the case of speech recognition this might correspond to using a different language speech with an asr system trained in a particular language here the acoustic characteristics of the speech signals from two different languages might be more similar as compared to the noisy and clean speech signals from the same language in section the description of the auxiliary decoder setup might benefit from more detail there has been recent work on performance monitoring and accuracy prediction in the area of speech recognition some of this work is listed below ogawa tetsuji et al delta m measure for accuracy prediction and its application to multi stream based unsupervised adaptation proceedings of icassp hermansky hynek et al towards machines that know when they do not know proceedings of icassp variani ehsan et al multi stream recognition of noisy speech with performance monitoring interspeech,6.0
607.json,the authors propose a hierarchical attention model for video captioning they introduce a model composed of three parts the temporal modeler tem that takes as input the video sequence and outputs a sequential representation of the video to the ham the hierarchical attention memory mechanism ham implements a soft attention mechanism over the sequential video representation and finally a decoder that generates a caption related to the second series of questions above it seems as though the authors have chosen to refer to their use of an lstm or equivalent rnn as the output of the bahdanau et al attention mechanism as a hierarchical memory mechanism i am actually sympathetic to this terminology in the sense that the recent popularity of memory based models seems to neglect the memory implicit in the lstm state vector but that said this seems to seriously misrepresent the significance fo the contribution of this paper i appreciate the ablation study presented in table not enough researchers bother with this kind of analysis but it does show that the value of the contributions is not actually clear in particular the case for the tem is quite weak regarding the quantitative evaluation presented in table the authors are carving out a fairly specific set of features to describe the set of fair comparators from the literature given the variability of the models and alternate training datasets that are in use i would find it more compelling if the authors just set about trying to achieve the best results they can if that includes the fine tuning of the frame model so be it the value of this work is as an application paper so the discovery and incorporation of elements that can significantly improve performance would seems warranted overall at this point i do not see a sufficient contribution to warrant publication in iclr,4.0
607.json,this paper addresses video captioning with a tem ham architecture where a ham module attends over attended outputs of the tem module when generating the description this gives a kind of level attention the model is evaluated on the charades and msvd datasets quality clarify i found this paper to be poorly written and relatively hard to understand as far as i can tell the tem module of section is a straight forward attention frame encoder of bahdanau et al or xu et al the decoder of section is a standard lstm with log likelihood the ham module of section is the novel module but is not very well described it looks to be an attention lstm where the attention is over the tem lstm outputs but the attention weights are additionally conditioned on the decoder state there are a lot of small problems with the description such as notational discrepancy in using textbf in equations and then not using it in the text also i spent a long time trying to understand what fm is the authors say in order to let the network remember what has been attended before and the temporal structure of a video we propose fm to memorize the previous attention and encoded version of an input video with language model using fm not only enables the network to memorize previous attention and frames but also to learn multi layer attention over an input video and corresponding language where one fm is bold and the other fm is not due to words such as we propose fm assumed this was some kind of a novel technical contribution i could not find any details about but it is specified later in section at the end that fm is in fact just an lstm it not clear why this piece of information is in section which discusses the decoder the paper is sloppy in other parts for example in table some numbers have significant digit and some have the semantics of the horizontal line in table are not explained in text experimental results the ablation study shows mixed results when adding tem and ham to the model looking at meteor which was shown to have the highest correlation to humans in the coco paper compared to the other evaluation criteria adding tem ham improves the model from to it is not clear how significant this improvement is especially given that the test set is only videos i have doubts over this result in table the meteor score of pan et al a is higher vs but this discrepancy is not addressed in text this is surprising because the authors explicitly claim state of the art results originality significance the paper introduces an additional layer of attention over a more standard sequence to sequence setup which is argued to alleviate the burden on the lstm memory this is moderately novel but i do not believe that the experimental results make it sufficiently clear that it is also worth doing if the paper made the standard model somehow simpler instead of more complex i would be more inclined to judge it favorably minor in response to the author comment not sure what causes to think of rbm we do not model any part of our architecture using rbm we would be appreciated if you please elaborate more about your confusion about figure so we can address it accordingly i created a diagram to hopefully make this more clear,4.0
312.json,this paper explores an important part of our field that of automating architecture search while the technique is currently computationally intensive this trade off will likely become better in the near future as technology continues to improve the paper covers both standard vision and text tasks and tackle many benchmark datasets showing there are gains to be made by exploring beyond the standard rnn and cnn search space while one would always want to see the technique applied to more datasets this is already far more sufficient to show the technique is not only competitive with human architectural intuition but may even surpass it this also suggests an approach to tailor the architecture to specific datasets without resulting in hand engineering at each stage this is a well written paper on an interesting topic with strong results i recommend it be accepted,9.0
312.json,this paper presents search for optimal neural net architectures based on actor critic framework the method treats dnn as a variable length sequence and uses rl to find the target architecture which acts as an actor the node selection is an action in the rl context and evaluation error of the outcome architecture corresponds to reward a auto regressive two layer lstm is used as a controller and critic the method is evaluated on two different problems and each compared with number of other human created architectures this is very exciting paper hand selecting architectures is difficult and it is hard to know how far from optimal results the hand designed networks are the presented method is novel the authors do an excellent job of describing it in detail with all the improvements that needed to be done the tested data represents well the capability of the method it is very interesting to see the differences between the generated architectures and human generated ones the paper is written very clearly and is very accessible the coverage and contrast with the related literature is done well it would be interesting to see the data about the time needed for training and correlation between time resources needed to train and the quality of the model it would also be interesting to see how human bootstrapped models perform and involve overall an excellent and interesting paper,9.0
742.json,this paper presents a theoretical and empirical approach to the problem of understanding the expressivity of deep networks random networks deep networks with random gaussian weights hard tanh or relu activation are studied according to several criterions number of neutron transitions activation patterns dichotomies and trajectory length there does not seem to be a solid justification for why the newly introduced measures of expressivity really measure expressivity for instance the trajectory length seems a very discutable measure of expressivity the only justification given for why it should be a good measure of expressivity is proportionality with other measures of expressivity in the specific case of random networks the paper is too obscure and too long the work may have some interesting ideas but it does not seem to be properly replaced in context some findings seem trivial detailed comments p much of the work examining achievable functions relies on unrealistic architectural assumptions such as layers being exponentially wide i don t think so in deep belief networks are compact universal approximators by leroux et al proof is given that deep but narrow feed forward neural networks with sigmoidal units can represent any boolean expression i e a neural network with n layers of n units with n the number of input neutron comparing architectures in such a fashion limits the generality of the conclusions to my knowledge much of the previous work has focused on mathematical proof and has led to very general conclusions on the representative power of deep networks one example being leroux et al again it is much harder to generalise the approach you propose based on random networks which are not used in practice we study a family of networks arising in practice the behaviour of networks after random initialisation these networks arise in practice as an intermediate step that is not used to perform computations this means that the representative power of such intermediate networks is a priori irrelevant you would need to justify why it is not results on random networks provide natural baselines to compare trained networks with random networks are not natural for the study of expressivity of deep networks it is not clear how the representative power of random networks what kind of random networks seems an important question here is linked to the representative power of i of the whole class of networks or ii the class of networks after training those two classes of networks are the ones we would a priori care about and you would need to justify why the study of random networks helps in understanding either i or ii p as fw is a random neural network it would suggest that points far enough away from each other would have independent signs i e a direct proportionality between the length of z n t and the number of times it crosses the decision boundary as you say it seems that proportionality of the two measures depends on the network being random this seems to invalidate generalisation to other networks i e if the networks are not random one would assume that path lengths are not proportional p the expressivity w r t remaining depth seems a trivial concerns completely equivalent to the expressivity w r t depth this makes the remark in figure that the number of achievable dichotomies only depends only on the number of layers above the layer swept seem trivial p in figure a network width of for mnist seems much too small accordingly performance is very poor and it is difficult to generalise the results to relevant situations,3.0
742.json,summary this paper studies the expressive power of deep neural networks under various related measures of expressivity it discusses how these measures relate to the trajectory length which is shown to depend exponentially on the depth of the network in expectation at least experimentally at an intuitive level or theoretically under certain assumptions the paper also emphasises the importance of the weights in the earlier layers of the network as these have a larger influence on the represented classes of functions and demonstrates this in an experimental setting pros the paper further advances on topics related to the expressive power of feedforward neural networks with piecewise linear activation functions in particular elaborating on the relations between various points of view cons the paper further advances and elaborates on interesting topics but to my appraisal it does not contribute significantly new aspects to the discussion comments the paper is a bit long especially the appendix and seems to have been written a bit in a rush overall the main points are presented clearly but the results and conclusions could be clearer about the assumptions experimental vs theoretical nature the connection to previous works could also be clearer on page one finds the statement furthermore architectures are often compared via hardcoded weight values a specific function that can be represented efficiently by one architecture is shown to only be inefficiently approximated by another this is partially true but it neglects important parts of the discussion conducted in the cited papers in particular the paper montufar pascanu cho bengio discusses not one hard coded function but classes of functions with a given number of linear regions that paper shows that deep networks generically produce functions with at least a given number of linear regions while shallow networks never do generically meaning that after fixing the number of parameters any function represented by the network for parameter values form an open positive measure neighbourhood belongs to the class of functions which have at least a certain number of linear regions in particular such statements can be directly interpreted in terms of networks with random weights one of the measures for expressivity discussed in the present paper is the number of dichotomies in statistical learning theory this notion is used to define the vc dimension in that context a high value is associated with a high statistical complexity meaning that picking a good hypothesis requires more data on page one finds the statement we discover and prove the underlying reason for this all three measures are directly proportional to a fourth quantity trajectory length the expected trajectory length increasing exponentially with depth can be interpreted as the increase or decrease in the scale by a composition of the form a a x which scales the inputs by a d such a scaling by itself certainly is not an underlying cause for an increase in the number of dichotomies or activation patterns or transitions here it seems that at least the assumptions on the considered types of trajectories also play an important role this is probably related to another observation from page if the variance of the bias is comparatively too large then we no longer see exponential growth other specific comments in theorem here it would be good to be more specific about random neural network i e fixed connectivity structure with random weights and also about the kind of one dimensional trajectory i e finite in length closed differentiable almost everywhere etc the notation g geq o f used in the theorem reads literally as g geq leq k f for some k for large enough arguments it could also be read as g being not smaller than some function that is bounded above by f which holds for instance whenever g geq for expressing asymptotic lower bounds one can use the notation omega see,6.0
742.json,summary of the paper authors study in this paper quantities related to the expressivity of neural networks the analysis is done for a random network authors define the trajectory length of a one dimensional trajectory as the length of the trajectory as the points in a m dimensional space are embedded by layers of the network they provide growth factors as function of hidden units k and number of layers d the growth factor is exponential in the number of layers authors relates this trajectory length to authors quantities transitions activation patterns and dichotomies as a consequence of this study authors suggest that training only earlier layers in the network leads higher accuracy then just training later layers experiments are presented on mnist and cifar clarity the paper is a little hard to follow since the motivations are not clear in the introduction and the definitions across the paper are not clear novelty studying the trajectory length as function of transforming the data by a multilayer network is new and interesting idea the relation to transition numbers is in term of the growth factor and not as a quantity to quantity relationship hence it is hard to understand what are the implications significance the geometry of the input set of dimension m shows up only weakly in the activation patterns analysis the trajectory study should tell us how the network organizes the input set as observed in the experiments the network becomes contractive selective as we train the network it would be interesting to study those phenomenas using this trajectory length as a measure for disentangling nuisance factors such as invariances etc in the supervised setting the network need not to be contractive every where so it needs to be selective to the class label a theoretical study of the selectivity and contraction using the trajectory length would be more appealing detailed comments theorem as raised by reviewer one the definition of a one dimensional input trajectory is missing what does theorem tells us about the design and the architecture to use in neural networks as promised in the introduction is not clear the connection to transitions in theorem is rather weak theorem in the proof of theorem it not clear what is meant by t and t notations are confusing the expectation is taken with respect to which weight is it w d or w d and w d i understand you do not want to overload notation but maybe e d can help keeping track i do not see how the recursion is applied if t and t in it have different definitions seems t d for you is a random variable and t d is fixed are you fixing wd and then looking at w d as random in the same proof the recursion is for d your analysis is for w in r k times k you do not not study the w in mathbb r k times m in this case you can not assume assume that z should d be analyzed alone to know how it scales with m theorem in main text is the proof missing or theorem in the main text is theorem in the appendix figures and the trajectory length reduction in the training is not that just the network becoming contractive to enable mapping the training points to the labels see for instance on contraction in deep networks,5.0
715.json,this paper proposes a simple randomized algorithm for selecting which weights in a convnet to prune in order to reduce theoretical flops when evaluating a deep neural network the paper provides a nice taxonomy or pruning granularity from coarse layer wise to fine intra kernel the pruning strategy is empirically driven and uses a validation set to select the best model from n randomly pruned models makes claims in the intro about this being one shot and near optimal that cannot be supported it is n shot in the sense that n networks are generated and tested and there is no evidence or theory that the found solution is near optimal pros nice taxonomy of pruning levels comparison to the recent weight sum pruning method cons experimental evaluation does not touch upon recent models resnets and large scale datasets imagenet paper is somewhat hard to follow feature map pruning can obviously accelerate computation without specialized sparse implementations of convolution but this is not the case for finer grained sparsity since this paper considers fine grained sparsity it should provide some evidence that introducing that sparsity can yield performance improvements another experimental downside is that the paper does not evaluate the impact of filter pruning on transfer learning for example there is not much direct interest in the tasks of mnist cifar or even imagenet instead a main interest in both academia and industry is the value of the learned representation for transferring to other tasks one might expect pruning to harm transfer learning it possible that the while the main task has about the same performance transfer learning is strongly hurt this paper has missed an opportunity to explore that direction in summary the proposed method is simple which is good but the experimental evaluation is somewhat incomplete and does not cover recent models and larger scale datasets,5.0
345.json,the authors propose a method to compress neural networks by retraining them while putting a mixture of gaussians prior on the weights with learned means and variances which then can be used to compress the neural network by first setting all weights to the mean of their infered mixture component resulting in a possible loss of precision and storing the network in a format which saves only the fixture index and exploits the sparseness of the weights that was enforced in training quality of course it is a serious drawback that the method does not seem to work on vgg which would render the method unusable for production as it is right now maybe this can be improved i guess alexnet takes too long to process too otherwise this might be a very valuable addition in figure i am noticing two things on the left there is a large number of points with improved accuracy which is not the case for lenet caffe is there any intuition for why that the case additionally regarding the spearmint optimization do they authors have found any clues about which hyperparameter settings worked well this might be helpful for other people trying to apply this method i really like figure in it latest version clarity especially section on mdl is written very well and gives a nice theoretic introduction sections and are very short but seem to contain most relevant information it might be helpful to have at least some more details about the used models in the paper maybe the number of layers and the number of parameters in the authors claim even though most variances seem to be reasonable small there are some that are large from figure this is very hard to assess especially as the vertical histogram essentially shows only the zero component it might be helpful to have either a log histogram or separate histograms for each componenent what are the large points in figure as opposed to the smaller ones they seem to have a very good compression accuracy loss ratio is that it some other points are listed below originality while there has been some work on compressing neural networks by using a reduced number of bits to store the parameters and exploiting sparsity structure i like the idea to directly learn the quantization by means of a gaussian mixture prior in retraining which seems to be more principled than other approaches significance the method achievs state of the art performance on the two shown examples on mnist however these networks are far from the deep networks used in state of the art models this obviously is a drawback for the practical usability of the methods and therefor it significance if the method could be made to work on more state of the art networks like vgg or resnet i would consider this a contribution of high significance minor issues page there seems to be a space in front of the first author name page in this scenario pi may be fixed missing backslash in tex page two wrong blanks in the number of components tau page in experiences with vgg in experiments page figure c figure,7.0
596.json,this paper proposes a method for link prediction on knowledge bases the method contains main innovations an iterative inference process that allows the model to refine its predictions and a shared memory component thanks to these elements the model introduced in the paper achieved remarkable results on two benchmarks the paper is fairly written the model is interesting and the experimental results are strikingly good still i only rate for a weak accept for the following reasons the main problem with this paper is that there is little explanation of how and why the two new elements aforementioned are leading to such better results for instance what are the performance without the shared memory and when its size is grown how does the performance is impacted when one varies tmax from to which the chosen value for the experiments i assume this gives an indications of how often the termination gate works it would also be interesting to give the proportion of examples for which the inference is terminated before hitting tmax what is the proportion of examples for which the prediction changed along several inference iterations a value of lambda set to section seems to indicate a low temperature for the softmax is the attention finally attending mostly at a single cell how do the softmax activations change with the type of relationships the entity type fbk and wn are quite old overused benchmarks now it would be interesting to test on larger conditions,6.0
579.json,updated review the authors did an admirable job of responding to and incorporating reviewer feedback in particular they put a lot of effort into additional experiments even incorporating a new and much stronger baseline the convnet lstm baseline requested by multiple reviewers i still have two lingering concerns previously stated that each model architecture hidden units etc should be tuned independently and that a pure time series forecasting baselines without the trend preprocessing should be tried i am going to bump up my score from a clear rejection to a borderline this paper is concerned with time series prediction problems for which the prediction targets include the slope and duration of upcoming local trends this setting is of great interest in several real world problem settings e g financial markets where decisions e g buy or sell are often driven by local changes and trends the primary challenge in these problems is distinguishing true changes and trends i e a downturn in share price from noise the authors tackle this with an interesting hybrid architecture trenet with four parts preprocessing to extract trends an lstm that accepts those trends as inputs to ostensibly capture long term dependencies a convnet that accepts a local window of raw data as its input at each time step and a higher feature fusion i e dense layer to combine the lstm and convnet outputs on three univariate time series data sets the trenet outperforms the competing baselines including those based on its constituent parts lstm trend inputs cnn strengths a very interesting problem setting that can plausibly be argued to differ from other sequential modeling problems in deep learning e g video classification this is a nice example of fairly thoughtful task driven machine learning accepting the author assumptions as true for the moment the proposed architecture seems intuitive and well designed weaknesses although this is an interesting problem setting decisions driven by trends and changes the authors did not make a strong argument for why they formulated the machine learning task as they did trend targets are not provided from on high by data oracle but extracted from raw data using a deterministic algorithm thus one could just easily formulate this as plain time series forecasting problem in which we forecast the next steps and then apply the trend extractor to convert those predictions into a trend if the forecasts are accurate so will be the extracted trends the proposed architecture while interesting is not justified in particular the choice to feed the extracted trends and raw data into separate lstm and convnet layers that are only combined at the end by a shallow mlp an equally straightforward but more intuitive choice would have been to feed the output of the convnet into the lstm perhaps augmented by the trend input without a solid rationale this unconventional choice comes across as arbitrary following up on that point the raw convnet lstm and raw convnet trends lstm architectures are natural baselines for experiments the paper presupposes rather than argues the value of the extracted trends and durations as inputs it is not unreasonable to think that with enough training data a sufficiently powerful convnet lstm architecture should be able to learn to detect these trends in raw data if they are predictive following up on that point two other obvious baselines that were omitted raw lstm and raw convnet trends mlp basically the authors propose a complex architecture without demonstrating the value of each part trend extraction lstm convnet mlp the baselines are unnecessarily weak one thing i am uncertain about in general the validity of the practice of using the same lstm and convnet architectures in both the baselines and the trenet this sounds like an apples to apples comparison but in the world of hyperparameter tuning it could in fact disadvantage either it seems like a more thorough approach would be to optimize each architecture independently regarding related work and baselines i think it is fair to limit the scope of in depth analysis and experiments to a set of reasonable representative baselines at least in a conference paper submitted to a deep learning conference that said the authors ignored a large body of work on financial time series modeling using probabilistic models and related techniques this is another way to frame the above separate trends from noise problem treat the observations as noisy one semi recent example j hernandez lobato j lloyds and d hernandez lobato gaussian process conditional copulas with applications to financial time series nips i appreciate this research direction in general but at the moment i believe that the work described in this manuscript is not suitable for inclusion at iclr my policy for interactive review is to keep an open mind and willingness to change my score but a large revision is unlikely i would encourage the authors to instead use their time and energy and reviewer feedback in order to prepare for a future conference deadline e g icml,6.0
579.json,revision of the review the authors did a commendable job of including additional references and baseline experiments this paper presents a hybrid architecture for time series prediction focusing on the slope and duration of linear trends the architecture consists of combining a d convnet for local time series and an lstm for time series of trend descriptors the convnet and lstm features are combined into an mlp for predicting either the slope or the duration of the next trend in a d time series the method is evaluated on small datasets summary this paper while relative well written and presenting an interesting approach has several methodology flaws that should be handled by new experiments pros the idea of extracting upward or downward trends from time series although these should ideally be learned not rely on an ad hoc technique given that this is a submission for iclr methodology in section what do you mean by predicting either the duration hat lt or slope hat st of the trend predictions are valid only if those two predictions are done jointly the two losses should be combined during training in the entire paper the trend slope and duration need to be predicted jointly predicting a time series without specifying the horizon of the prediction is meaningless if the duration of the trends is short the time series could go up or down alternatively if the duration of the trend is long the slope might be close to zero predictions at specific horizons are needed in general time series prediction for such applications as trading and load forecasting is pointless if no decision is made a trading strategy would be radically different for short term and noisy oscillations or from long term stable upward or downward trend an actual evaluation in terms of trading profit loss should be added for each of the baselines including the naïve baselines as mentioned earlier in the pre review questions an important baseline is missing feeding the local time series to the convnet and connecting the convnet directly to the lstm without ad hoc trend extraction the convnet lstm architecture would need an analysis of the convnet filters and trend prediction representation trend prediction segmentation by the convnet could be an extra supervised loss the detailed analysis of the trend extraction technique is missing in section the svm baselines have local trend and local time series vectors concatenated why isn t the same approach used for lstm baselines as a multivariate input and why the convnet operates only on local an important naïve baseline is missing next local trend slope and duration previous local trend slope and duration missing references the related work section is very partial and omits important work in hybrid convnet lstm architectures in particular vinyals oriol toshev alexander bengio samy and erhan dumitru show and tell a neural image caption generator corr abs donahue jeff hendricks lisa anne guadarrama sergio rohrbach marcus venugopalan subhashini saenko kate and darrell trevor long term recurrent convolutional networks for visual recognition and description corr abs karpathy andrej toderici george shetty sanketh leung thomas sukthankar rahul and fei fei li large scale video classification with convolutional neural networks in cvpr the organization of the paper needs improvement section does not explain the selection of the maximal tolerable variance in each trend segment the appendix should be moved to the core part of the paper section is unnecessarily long and gives well known details and equations about convnets and lstms the only variation from standard algorithm descriptions is that lk sk are concatenated the feature fusion layer can be expressed by a simple mlp on the concatenation of r t l and c l t details could be moved to the appendix additional questions in section how many datapoints are there in each dataset listing only the number of local trends is uninformative typos p top duration and slop,5.0
646.json,the qa model is not novel very similar to the existing model the iqa model is very confusing if it needs human interactive in the training process how could it be practical to ask human to join the training in each iteration it sounds impractical if the human interactive questions are predefined then it is not interactive at all since it is not based on the current state of model output,5.0
646.json,this work describes a two stage encoding of stories in babi like setups where a gru is used to encode a sentence word by word conditioned on a sentence level gru and the sentence level gru keeps track of a sentence level encoding each is used modifying the babi tasks so it is necessary to ask a question to correctly solve the problem i am not convinced by the papers results the new architecture does not do significantly better than dmn and in my view is similar to dmn what problem with dmn does your architecture solve there are now several papers doing the second thing for example dialog based language learning by weston and learning end to end goal oriented dialog by bordes and weston and i think doing it more carefully and in more compelling ways in the current work the correct answer to the question seems given independent of the what the agent asks so any model that can output unknown and then input the extra response has an advantage essentially all of the architectures that are used to solve babi can be modified to do this indeed the enc dec accuracies in appendix a show that this sort of module can be appended to any other model all of the standard models can be trained to output questions as a sequence of words furthermore i suspect you could generate the questions in the authors setting just by enumerating all the questions that occur in training and taking a softmax over them instead of generating word by word,4.0
353.json,all in all this is a nice paper i think the model is quite clever attempting to get the best of latent variable models and auto regressive models the implementation and specific architecture choices as discussed in the pre review also seem reasonable on the experimental side i would have liked to see something more than nll measurements and samples maybe show this is useful for other tasks such as classification though i do not think this is a huge leap forward this is certainly a nice paper and i recoemmend acceptance,7.0
703.json,the authors present tartan a derivative of the previously published dnn accelerator architecture dadiannao the key difference is that tartan s compute units are bit serial and unroll mac operation over several cycles this enables the units to better exploit any reduction in precision of the input activations for improvement in performance and energy efficiency comments i second the earlier review requesting the authors to be present more details on the methodology used for estimating energy numbers for tartan it is claimed that tartan gives only a improvement in energy efficiency however i suspect that this small improvement is clearly within the margin of error ij energy estimation tartan is a derivative of dadiannao and it heavily relies the overall architecture of dadiannao the only novel aspect of this contribution is the introduction of the bit serial compute unit which unfortunately turns out to incur a severe area overhead of nearly x over dadiannao compute units nonetheless the idea of bit serial computation is certainly quite interesting i am of the opinion that it would be better appreciated and perhaps be even more relevant in a circuit design architecture focused venue,5.0
703.json,summary the paper describes how the dadiannao dadn dnn accelerator can be improved by employing bit serial arithmetic they replace the bit parallel multipliers in dadn with multipliers that accept the weights in parallel but the activations serially serial x parallel multipliers they increase the number of units keeping the total number of adders constant this enables them to tailor the time and energy consumed to the number of bits used to represent activations they show how their configuration can be used to process both fully connected and convolutional layers of dnns strengths using variable precision for each layer of the network is useful but was previously reported in judd good evaluation including synthesis but not place and route of the units also this evaluation is identical to that in judd b weaknesses the idea of combining bit serial arithmetic with the dadn architecture is a small one the authors have already published almost everything that is in this paper at micro in judd b the increment here is the analysis of the architecture on fully connected layers everything else is in the previous publication the energy gains are small because the additional flip flop energy of shifting the activations in almost offsets the energy saved on reducing the precision of the arithmetic the authors don t compare to more conventional approaches to variable precision using bit parallel arithmetic units but data gating the lsbs so that only the relevant portion of the arithmetic units toggle this would not provide any speedup but would likely provide better energy gains than the bit serial x bit parallel approach overall the tartan and stripes architectures are interesting but the incremental contribution of this paper adding support for fully connected layers over the three previous publications on this topic and in particular judd b is very small this idea is worth one good paper not four,5.0
703.json,this seems like a reasonable study though it not my area of expertise i found no fault with the work or presentation but did not follow the details or know the comparable literature there seem to be real gains to be had through this technique though they are only in terms of efficiency in hardware not changing accuracy on a task the tasks chosen alexnet vgg seem reasonable the results are in simulation rather than in actual hardware the topic seems a little specialized for iclr since it does not describe any new advances in learning or representations albeit that the cfp includes hardware i think the appeal among attendees will be rather limited please learn to use parenthetical references correctly as is your references make reading harder,6.0
703.json,i do not feel very qualified to review this paper i studied digital logic back in university that was it i think the work deserves a reviewer with far more sophisticated background in this area it certainly seems useful my advice is also to submit it another venue,4.0
703.json,this paper proposed a hardware accelerator for dnn it utilized the fact that dnn are very tolerant to low precision inference and outperforms a state of the art bit parallel accelerator by x without any loss in accuracy while it is x more energy efficient trt requires no network retraining it achieved super linear scales of performance with area the first concern is that this paper does not seem very well suited to iclr the circuit diagrams makes it more interesting for the hardware or circuit design community the second concern is the take away for machine learning community seeing from the response the take away is using low precision to make inference cheaper this is not novel enough in last year iclr there were at least papers discussing using low precision to make dnn more efficient these ideas have also been explored in the authors previous papers,4.0
754.json,this paper presents an improved neural language models designed for selected long term dependency i e to predict more accurately the next identifier for the dynamic programming language such as python the improvements are obtained by replacing the fixed widow attention with a pointer network in which the memory only consists of context representation of the previous k identifies introduced for the entire history a conventional neural lstm based language model is combined with such a sparse pointer network with a controller which linearly combines the prediction of both components using a dynamic weights decided by the input hidden state and the context representations at the time stamp such a model avoids the the need of large window size of the attention to predict next identifier which usually requires a long term dependency in the programming language this is partly validated by the python codebase which is another contribution of this paper experiments in the paper while the paper still misses some critical information that i would like to see including how the sparse pointer network performance chances with different size of k and how computationally efficient it is for both training and inference time compared to lstm w attention of various window size and ablation experiments about how much and contribute respectively it might be of interest to the iclr community to see it accepted,6.0
754.json,this paper takes a standard auto regressive model of source code and augments it with a fixed attention policy that tracks the use of certain token types like identifiers additionally they release a python open source dataset as expected this augmentation the fixed attention policy improves the perplexity of the model it seems important to dig a bit deeper into these results and show the contribution of different token types to the achieve perplexity this is alluded to in the text but a more thorough comparison would be welcome the idea of an attention policy that takes advantage of expert knowledge is a nice contribution but perhaps if limited novelty for example the maddison and tarlow paper which the authors cite has scoping rules that track previously used identifiers in scope,5.0
304.json,this paper argues that being able to handle recursion is very important for neural programming architectures that handling recursion allows for strong generalization to out of domain test cases and learning from smaller amounts of training data most of the paper is a riff on the reed de freitas paper on neural programmer interpreters from iclr which learns from program traces this paper trains npi models on traces that have recursive calls the authors show how to verify correctness by evaluating the learned program on only a small set of base cases and reduction rules and impressively show that the npi architecture is able to perfectly infer bubblesort and the tower of hanoi problems what i like is that the idea is super simple and as the authors even mention the only change is to the execution traces that the training pipeline gets to see i m actually not sure what the right take away is does this mean that we have effectively solved the neural programming problem when the execution traces are available and was the problem too easy to begin with for example a larger input domain as one of the reviewers also mentions is mnist digits and we can imagine a problem where the npi must infer how to sort mnist digits from highest to lowest in this setting having execution traces would effectively decouple the problem of recognizing the digits from that of inferring the program logic and so the problem would be no harder than learning to recognize mnist digits and learning to bubble sort from symbols what is a problem where we have access to execution traces but cannot infer it using the proposed method,8.0
304.json,this is a very interesting and fairly easy to read paper the authors present a small yet nifty approach to make neural programming interpreters significantly more powerful by allowing recursion npi generalizes better from fewer execution traces it an interesting example of how a small but non trivial extension can make a machine learning method significantly more practical i also appreciate that the same notation was used in this paper and the original deepmind paper as a non expert on this topic it was easy to read the original paper in tandem my one point of critique is that the generalization proves are a bit vague for the numerical examples in the paper you can iterate over all possible execution paths until the next recursive call however how would this approach generalize a continuous input space e g the d car example in the original paper it seems that a prove of generalization will still be intractable in the continuous case are you planning on releasing the source code,8.0
538.json,the authors propose a new model to learn symbolic expression representations they do a reasonably extensive evaluation with similar approaches and motivate their approach well as expressed in the preliminary questions i think the authors could improve the motivation for their subexpforce loss at the top of page the authors mention that they compare to two layer mlp w o residual connections i think having a direct comparison between a model with and w o the subexpforce loss would be helpful too and should be included i e keep the residual connections and normalization my main concern is the evaluation score it appears to be precision on a per query basis i believe a more standard metric precision recall or roc would be more informative in particular the chosen metric is expected to perform better when the equivalence classes are larger since this is not taken into account in the denominator but the likelihood of a random expression matching the query increases,7.0
538.json,the goal of this paper is to learn vector representation of boolean and polynomial expressions such that equivalent expressions have similar representations the model proposed in the paper is based on recursive neural network as introduced by socher et al given the syntactic parse tree of a formula either boolean or polynomial the representation for a node is obtained by applying a mlp on the representation of the children this process is applied recursively to obtain the representation of the full expression contrary to socher et al this paper proposes to use more than one layer this is especially important to capture xor operation which is not surprising at all the paper also introduces a reconstruction error called subexpforce so that the expression of children can be recovered from the expression of the parent if i understood correctly the model is trained using a classification loss where the label of a given expression corresponds to its equivalence class the method is then evaluated on randomly generated data and compared to baselines such as tf idf gru rnn or standard recursive neural network while i do agree with the authors that learning good representation for symbolic expressions and to capture compositionality is an important task i am not entirely convinced by the experimental setting proposed in this paper indeed as stated in the paper the task of deciding if two boolean expressions are equivalent is np hard and i do not understand if the model can do better than implicitly computing the truth table of expressions while sometimes a bit hard to follow the paper is technically sound in particular the proposed model is well adapted to the problem and outperforms the baselines pros the model is relatively simple and sound using a classification loss over equivalence classes should be compared with using similarity cons not convinced by the setting i do not believe that you can really do better than the truth table for boolean expr or computing the value of the polynomial expression for randomly chosen points in n some part of the paper are a bit hard to follow e g justification of the subexpforce discussion of why softmax does not work etc comparison between classification loss and similarity loss is missing,5.0
538.json,this work proposes to compute embeddings of symbolic expressions e g boolean expressions or polynomials such that semantically equivalent expressions are near each other in the embedded space the proposed model uses recursive neural networks where the architecture is made to match that of the parse tree of a given symbolic expression to train the model parameters the authors create a dataset of expressions where semantic equivalence relationships are known and minimize a loss function so that equivalent expressions are closer to each other than non equivalent expressions via a max margin loss function the authors also use a subexpression forcing mechanism which if i understand it correctly encourages the embeddings to respect some kind of compositionality results are shown on a few symbolic expression datasets created by the authors and the proposed method is demonstrated to outperform baselines pretty convincingly i especially like the pca visualization where the action of negating an expression is shown to correspond roughly to negating the embedding in its vector space it is a lot like the man woman queen king type embeddings that we see in the wordvec and glove style papers the weakest part of the paper is probably that the setting seems somewhat contrived i can t really think of a real setting where it is easy to have a training set of known semantic equivalences but still more worth it to use a neural network to do predictions the authors have also punted on dealing with variable names assuming that distinct variables refer to different entities in the domain this is understandable as variable names add a whole new layer of complexity on an already difficult problem but also seems high limiting for example the proposed methods would not be useable in an equation search engine unless we were able to accurately canonicalize variable names in some way other miscellaneous points regarding problem hardness i believe that the problem of determining if two expressions are equivalent is actually undecidable see the word problem for thue systems related to this i was not able to figure out how the authors determine ground truth equivalence in their training sets they say that expressions are simplified into a canonical form and grouped but this seems to not be possible in general so one question is is it possible that equivalent expressions in the training data would have been mapped to different canonical forms would it have been easier possible to construct and compare truth tables the combine operation uses what the authors describe as a residual like connection looking at the equations the reason why this is not actually a residual connection is because of the weight matrix that is multiplied by the lower level l features a true residual connection would have passed the features through unchanged identity connection and would have also been better at fighting gradient explosion so is there a reason why this was used rather than an identity connection in table the first tf idf entry a c a c seems equivalent to a c a c vertical spacing between figure caption and body of text is very small and looks like the caption continues into the body of the text,6.0
493.json,the paper analyses the misclassification error of discriminators and highlights the fact that while uniform probability prior of the classes makes sense early in the optimization the distribution deviates from this prior significantly as the parameters move away from the initial values consequently the optimized upper bound log loss gets looser as a fix an optimization procedure based on recomputing the bound is proposed the paper is well written while the main observation made in this paper is a well known fact it is presented in a clear and refreshing way that may make it useful to a wide audience at this venue i would like to draw the author attention to the close connections of this framework with curriculum learning more on this can be found in which is a relevant reference that should be cited a discussion on this could enrich the quality of the paper there is a large body of work on directly optimizing task losses and the references therein these should also be discussed and related particularly to section optimizing the roc curve training highly multiclass classifiers gupta et al direct loss minimization for structured prediction mcallester et al generalization bounds and consistency for latent structural probit and ramp loss mcallester and keshet final comment i believe the material presented in this paper is of interest to a wide audience at iclr the problem studied is interesting and the proposed approach is sound i recommend to accept the paper and increase my score from to,8.0
493.json,the paper proposes an alternative to conditional max log likelihood for training discriminative classifiers the argument is that the conditional log likelihood is an upper bound of the bayes error which becomes lousy during training the paper then proposes better bounds computed and optimized in an iterative algorithm extensions of this idea are developed for regularized losses and a weak form of policy learning tests are performed on different datasets an interesting aspect of the contribution is to revisit a well accepted methodology for training classifiers the idea looks fine and some of the results seem to validate it this is however still a preliminary work and one would like to see the ideas pushed further globally the paper lacks coherence and depth the part on policy learning is not well connected to the rest of the paper and the link with rl is not motivated in the two examples roc optimization and uncertainties the experimental part needs a rewriting e g i did not find a legend for identifying the different curves in the figures which makes difficult to appreciate the results,4.0
610.json,this paper performs a series of experiments to systematically evaluate the robustness of several defense methods including rad aec and its improved version etc it provides interesting observations overall rad and distillation have the best performances but none of the methods can really resist the additional attack from cg or adam since it is an experimental paper my main concern is about its clarity see the comments below for details pros this paper provides a good comparison of the performances for the selected methods section the additional attack is a interesting investigation although the final result about the defense methods is negative its results are still inspiring overall this paper provides interesting and inspiring experimental results about the selected methods cons there are several other methods in the literature that are missing from the paper for example the defense methods and the attack methods in the papers although a long list of experimental results are provided in the paper many details are skipped for example details of the experiments that generate the results in table without further explanations and analyses about the experimental results the contribution of the paper seems limited this paper proposed an improved version of the aec algorithm but its experimental results seems not promising minor comments page equation is also non convex so the non convexity of equation should not be the motivation of equation,5.0
610.json,the paper compares several defense mechanisms against adversarial attacks retraining two kinds of autoencoders and distillation with the conclusion that the retraining methodology proposed by li et al works best of those approaches the paper documents a series of experiments on making models robust against adversarial examples the methods proposed here are not all too original rad was proposed by li et al distillation was proposed in goodfellow et al explaining and harnessing adversarial examples stacked autoencoders were proposed by szegedy et al intriguing properties of neural networks the most original part of the paper is the improved version of autoencoders proposed in this paper the paper establishes experimental evidence that the rad framework provides the best defense mechanism against adversarial attacks which makes the introduction of the improved autoencoder mechanism less appealing although the paper establishes interesting measurement points and therefore it has the potential for being cited as a reference its relative lack of originality decreases its significance,5.0
755.json,i think the write up can be improved the results of the paper also might be somewhat misleading the behavior for when weights are is not revealing of how the model works in general i think the work also underestimates the effect of the nonlinearities on the learning dynamics of the model,4.0
305.json,two things i would like to see specifics about the jpeg and jpeg implementations used and how they were configured one major weakness i see in many papers is they do not include specific encoders and configuration used in comparisons without knowing this it hard to know if the comparison was done with a suitably strong jpeg implementation that was properly configured for example the comparison to jpeg is unfortunately not that interesting since that codec does not have widespread usage and likely never will a better comparison would be with webp performance or even better both very nice results is a software implementation of this available to play with,7.0
305.json,this is the most convincing paper on image compression with deep neural networks that i have read so far the paper is very well written the use of the rate distortion theory in the objective fits smoothly in the framework the paper is compared to a reasonable baseline jpeg as opposed to previous papers only considering jpeg i would expect this paper to have a very good impact yes please include results on lena barbara baboon sorry not gibbons along with state of the art references with more classical methods such as the one i mentioned in my questions i think it is important to clearly state how nn compare to best previous methods from the submitted version i still do not know how both categories of methods are positioned,9.0
305.json,this paper extends an approach to rate distortion optimization to deep encoders and decoders and from a simple entropy encoding scheme to adaptive entropy coding in addition the paper discusses the approach s relationship to variational autoencoders given that the approach to rate distortion optimization has already been published the novelty of this submission is arguably not very high correct me if i missed a new trick in some ways this paper even represents a step backward since earlier work optimized for a perceptual metric where here mse is used however the results are a visible improvement over jpeg and i don t know of any other learned encoding which has been shown to achieve this level of performance the paper is very well written equation appears to be wrong and i believe the partition function should depend on gs y theta this would mean that the approach is not equivalent to a vae for non euclidean metrics what was the reason for optimizing mse rather than a perceptual metric as in previous work given the author s backgrounds it is surprising that even the evaluation was only performed in terms of psnr what is the contribution of adaptive entropy coding versus the effect of deeper encoders and decoders this seems like an important piece of information so it would be interesting to see the performance without adaptation as in the previous paper more detail on the adaptive coder and its effects should be provided and i will be happy to give a higher score when the authors do,8.0
581.json,this paper has no machine learning algorithmic contribution it just uses the the same combination of lstm and bivariate mixture density network as graves and the detailed explanation in the appendix even misses one key essential point how are the gaussian parameters obtained as a transformation of the output of the lstm there are also no numerical evaluation suggesting that the algorithm is some form of improvement over the state of the art so i do not think such a paper is appropriate for a conference like iclr the part describing the handwriting tasks and the data transformation is well written and interesting to read it could be valuable work for a conference more focused on handwriting recognition but i am no expert in the field,3.0
581.json,the paper presents a method for sequence generation with a known method applied to feature extracted from another existing method the paper is heavily oriented towards to chosen technologies and lacks in literature on sequence generation in principle rich literature on motion prediction for various applications could be relevant here recent models exist for sequence prediction from primed inputs for various applications e g for skeleton data these models learn complex motion w o any pre processing evaluation is a big concern there is no quantitative evaluation there is no comparision with other methods i still wonder whether the intermediate representation developed by plamondon et al is useful in this context of a fully trained sequence generation model and whether the model could pick up the necessary transformations itself this should be evaluated details there are several typos and word omissions which can be found by carefully rereading the paper at the beginning of section it is still unclear what the application is prediction of dynamic parameters what for section should give a better motivation of the work concerning the following paragraph while such methods are superior for handwriting analysis and biometric purposes we opt for a less precise method berio leymarie that is less sensitive to sampling quality and is aimed at generating virtual target sequences that remain perceptually similar to the original trace this method has not been explained a paper should be self contained the authors mentioned that the vv model is conditioned on but not enough details are given generally speaking more efforts could be made to make the paper more self contained,3.0
581.json,this paper takes a model based on that of graves and retrofits it with a representation derived from the work of plamondon part of the goal of deep learning has been to avoid the use of hand crafted features and have the network learn from raw feature representations so this paper is somewhat against the grain the paper relies on some qualitative examples as demonstration of the system and does not seem to provide a strong motivation for there being any progress here the paper does not provide true text conditional handwriting synthesis as shown in graves original work be more consistent about your bibliography e g variants of plamondon own name use of et al in the bibliography etc,3.0
647.json,unfortunately even after reading the authors response to my pre review question i feel this paper in its current form lacks sufficient novelty to be accepted to iclr fundamentally the paper suggests that traditional iterative algorithms for specific class of problems ill posed image inverse problems can be replaced by discriminatively trained recurrent networks as r also notes un rolled networks for iterative inference are not new they have been used to replace crf type inference and also to solve image inverse problems my refs therefore i would argue that the fundamental idea proposed by the paper is not new it is just that the paper seeks to formalize it as an approach for inverse problems although there is nothing specific about the analysis that ties it to inverse problems the paper only shows that the rim can express gradient descent over prior likelihood objective i also did not find the claims about benefits over prior approaches very compelling the comment about parameter sharing works both ways it is possible that untying the parameters leads to better performance over a fewer number of iterations and given that the training set is synthetically generated learning a larger number of parameters does not seem to be an issue also i would argue that sharing the parameters is the obvious approach and the prior methods choose to not tie the parameters to get better accuracy the same holds for being able to handle different noise levels scale sizes a single model can always be trained to handle multiple forms of degradation its just that its likely to do better when it trained for specific degradation model level but more importantly there is no evidence in the current set of experiments that shows that this is a property of the rim architecture moreover this claim goes against one of the motivations of the paper of not training a single prior for different observation models but to train the entire inference architecture end to end it is possible that the proposed method does offer practical benefits beyond prior work but these benefits do not come from the idea of simply unrolling iterations which is not novel i would strongly recommend that the authors consider a significant re write of the paper with a detailed discussion of prior work mentioned in the comments that highlights with experiments the specific aspects of their recurrent architecture that enables better recovery for inverse problems i would also suggest that to claim the mantle of olving inverse problems the paper consider a broader set of inverse tasks in painting deconvolution different noise models and possibly working with multiple observations like for hdr,4.0
702.json,this paper presents two models for extractive document summarization the classifier architecture and the selector architecture these two models basically use either classification or ranking in a sequential order to pick the candidate sentences for summarization experiments in this paper show the results are either better or close to the sota technical comments in equation there is a position relevant component call positional importance i am wondering how important this component is is it possible to show the performance without this component especially for the discussion on impact of document structure when the model is trained on the shuffled order but tested on the original order a similar question about equation is the content richness component really necessary since the score function already has salience part which could measure how important of hj with respect to the whole document for the dynamic summary representation in equation why not use the same updating equation for both training and test procedures during test time the model actually knows the decisions that have been made so far by the decoder in this way the model will be more consistent during training and test i think section is the most interesting part of this paper and it is also convincing on the difference between the two architectures it is a little disappointing that the decoding algorithm used in this paper is too simple in a minimal case both of them could use beam search and the results could be better,6.0
702.json,this paper presents two rnn architectures for extractive document summarization the first one classifier takes into account the order in which sentences appear in the original document whereas the second one selector chooses sentences in an arbitrary order for each architecture the concatenated rnn hidden state from a sentence forward and backward pass is used as features to compute a score that captures content richness salience positional importance and redundancy both models are trained in a supervised manner so the authors used pseudo ground truth generation to create training data from abstractive summaries experiments show that the classifier model performs better and it achieves near state of the art performance for some evaluation metrics the proposed model is in general an extension of cheng and lapata unfortunately the performance is only slightly better or sometimes even worse the authors mentioned that one key difference how they transform abstractive summaries to become gold labels for the supervised method however in the experiment results the authors described that one potential reason their models do not consistently outperform the extractive model of cheng lapata is that the unsupervised greedy approximation may generate noisier ground truth labels than cheng lapata is there a reason to construct the training data similar to cheng lapata if that turns out to be a better method in order for the proposed models to be convincing they need to outperform this baseline that very similar to the proposed methods more consistently since the main contribution is improved neural architectures for extractive document summarization,4.0
578.json,this paper empirically studies the invariance equivariance and equivalence properties of representations learned by convolutional networks under various kinds of data augmentation additional loss terms are presented which can make a representation more invariant or equivariant the idea of measuring invariance equivariance and equivalence of representations is not new lenc vedaldi the authors are the first to systematically study the effect of data augmentation on these properties but it is unclear in what way the results are surprising interesting or useful it is not really surprising that data augmentation increases invariance or that training with the same augmentation leads to more similar representations than training with different augmentations regarding the presented method to increase invariance and equivariance while it could be that a representation will generalize better if it is invariant or equivariant it is not clear why one would want to increase in equivariance if it does not indeed lead to improvements in performance the paper presents no evidence that training for increased invariance equivariance leads to substantial improvements in performance combined with the fact that the loss eq would substantially increase the computational burden i don t think this technique will be very useful minor comments r nxn should be r n times n in eq equivaraince in argmax is not properly formatted i think data augmentation was already considered essential before krizhevsky et al not really correct to attribute this to them about the claim this is related to the idea of whether cnns collapse invariance or linearize equivariance view manifolds of d objects the idea that equivariance means that the manifold orbit is linearized is incorrect a linear representation mg can create nonlinear manifolds a simple example is given by a rotation matrix in d clearly linear generating a nonlinear manifold the circle equivariance in eq should be called non equivariance if the value is low the representation is equivariant while if it is high it is non equivariant eq also uses the paradigm that uses the word paradigm in a strange manner in the definition of x ij should one of the gj be inverted otherwise it seems like the transformation is applied twice instead of being undone,4.0
578.json,this work presents an empirical study of the influence of different types of data augmentation on the performance of cnns it also proposes to incorporate additional loss functions to encourage approximate invariance or equivariance and shows there are some benefits the paper reads well and the objectives are clear the study of invariances in cnns is a very important topic and advances in this area are greatly appreciated the paper splits itself in two very different parts the empirical study of equivariances in existing cnns and the proposal of equivariance objectives however taken separately each of these two parts could be better executed on the empirical study its breath is relatively limited and it hard to draw any far reaching conclusions from it only one network is studied at least one other architecture would have made for better generalization only one layer fc is studied this presents issues as the top layer is the most invariant at least one convolutional layer possibly more should have been considered the reliance on the scanned text dataset does not help however the imagenet results are definitely very encouraging it is nice to see how performance degrades with the degree of transformations and the authors do interpret the results but it would be better to see more analysis there is only a limited set of conclusions that can be drawn from evaluating networks with jittered data if the authors could propose some other interesting ways to assess the invariance and equivariance they would potentially draw more insightful conclusions from it on the proposed loss function only a very quick treatment of it is given section half a page it does not differ too much from known invariance equivariance objectives studied in the literature previously e g decoste and scholkopf training invariant support vector machines machine learning i am not sure that dividing the paper into these two different contributions is the best approach they both feel a bit incomplete and a full treatment of only one of them would make for an overall better paper,5.0
651.json,approaches like adaptive dropout also have the binary mask as a function of input to a neuron very similar to the proposed approach it is not clear even from the new draft how the proposed approach differs to adaptive dropout in terms of functionality the experimental validation is also not extensive since comparison to sota is not included,5.0
714.json,this paper implements the method of jonschkowski brock to learn a low dimensional state representation represented as the last layer of a neural network the experiments apply the method for learning a one dimensional state representation of a simulated robot s head position from synthetic images learning state representations is an active and useful area of research for learning representations in interactive domains such as robotics however there seems to be no novelty in the method over jonschkowki brock the primary contribution is the experimental evaluation performed on one task where the paper evaluates the correlation between the learned state representation and the ideal state representation for the task which is the robot s head position as acknowledged by the authors the experiments are very preliminary only showing one simple task with a one dimensional learned representation and a two dimensional discrete action space to make the experiments compelling there need to be comparisons to prior methods such as lange et al watter et al nips and finn et al icra which also learn state representations from raw images pca on the images would also be a useful comparison especially for simple tasks without these comparisons it is impossible to evaluate the effectiveness of the method lastly as mentioned in the pre review questions the related work should include a discussion of other state representation learning methods such as watter et al nips finn et al icra and van hoof et al iros in summary this paper lacks novelty and significance as the paper implements an existing method and demonstrates results on only one simple task without comparisons the results are impossible to interpret more challenging tasks and experimental comparisons would significantly improve the paper additionally this paper does not introduce any novel contributions to state representation learning for solving challenges in this domain one pro is that the paper is generally written clearly,3.0
714.json,the paper proposes to use the representation learning approach of jonschkowski brock with a deep network as function approximator the general task and approach are interesting but contribution of this work is limited and experimental evaluation is absolutely unsatisfactory so the paper cannot be accepted for publications the approach is tested on a simple synthetic task with very small training and test sets and very little variation in the data the authors admitted themselves that the results are preliminary the proposed method is not compared with existing approaches or simple hand crafted baselines it is impossible to judge if the proposed method is useful and or performs well compared to existing approaches this makes the paper unfit for publication with proper experiments and if the method works in interesting realistic scenarios this could become a good paper,3.0
344.json,the paper presents a learning algorithm for micromanagement of battle scenarios in real time strategy games it focuses on a complex sub problem of the full rts problem the assumptions and restrictions made greedy mdp distance based action encoding etc are clear and make sense for this problem the main contribution of this paper is the zero order optimization algorithm and how it is used for structured exploration this is a nice new application of zero order optimization meets deep learning for rl quite well motivated using similar arguments as dpg the results show clear wins over vanilla q learning and reinforce which is not hard to believe although rts is a very interesting and challenging domain certainly worthy as a domain of focused research it would have been nice to see results on other domains mainly because it seems that this algorithm could be more generally applicable than just rts games also evaluation on such a complex domain makes it difficult to predict what other kinds of domains would benefit from this zero order approach maybe the authors could add some text to clarify motivate this there are a few seemingly arbitrary choices that are justified only by it worked in practice for example using only the sign of w psi theta s k a k again later also we neglected the argmax operation that chooses the actions i suppose this and dividing by t could keep things nicely within or close to it might make sense to try truncating normalizing w psi it seems that much information must be lost when only taking the sign also lines such as we did not extensively experiment with the structure of the network but we found the maxpooling and tanh nonlinearity to be particularly important and claiming the importance of adagrad over rmsprop without elaboration or providing any details feels somewhat unsatisfactory and leaves the reader wondering why e g could these only be true in the rts setup in this paper the presentation of the paper can be improved as some ideas are presented without any context making it unnecessarily confusing for example when defining f tilde s c at the top of page the w vector is not explained at all so the reader is left wondering where it comes from or what its use is this is explained later of course but one sentence on its role here would help contextualize its purpose maybe refer later to the section where it is described fully also page because we neglected that a single u is sampled for an entire episode actually no you did mention this in the text above and it clear from the pseudo code too perturbated perturbed after response period no rebuttal entered therefore review remains unchanged,7.0
344.json,this is a very interesting and timely paper with multiple contributions it proposes a setup for dealing with combinatorial perception and action spaces that generalizes to an arbitrary number of units and opponent units it establishes some deep rl baseline results on a collection of starcraft subdomains it proposes a new algorithm that is a hybrid between black box optimization reinforce and which facilitates consistent exploration as mentioned in an earlier comment i don t see why the gradient of the average cumulative reward is a reasonable choice as compared to just the average reward this over weights late rewards at the expense of early ones so the updates are not matching the measured objective the authors state that they did not observe a large difference in preliminary experiments so if that is the case then why not choose the correct objective dpq is characterized incorrectly despite its name it does not collect traces by following deterministic policies instead it follows a stochastic behavior policy and learns off policy about the deterministic policy please revise this gradient free optimization is also characterized incorrectly it only scales to few parameters recent work has shown that this can be overcome e g the torcs paper by koutnik et al this also suggests that your preliminary experiments with direct exploration in the parameter space may not have followed best practices in neuroevolution did you try out some of the recent variants of neat for example which have been applied to similar domains in the past on the specific results i m wondering about the dqn transfer from mv to mv obtaining the best win rate of in transfer despite only reaching the worst on the training domain is this a typo or how can you explain that,7.0
344.json,this work introduces some starcraft micro management tasks controlling individual units during a battle these tasks are difficult for recent deeprl methods due to high dimensional variable action spaces the action space is the task of each unit the number of units may vary in such large action spaces simple exploration strategies such as epsilon greedy perform poorly they introduce a novel algorithm zo to tackle this problem this algorithm combines ideas from policy gradient deep networks trained with backpropagation for state embedding and gradient free optimization the algorithm is well explained and is compared to some existing baselines due to the gradient free optimization providing for much better structured exploration it performs far better this is a well written paper and a novel algorithm which is applied to a very relevant problem after the success of deeprl approaches at learning in large state spaces such as visual environment there is significant interest in applying rl to more structured state and action spaces the tasks introduced here are interesting environments for these sorts of problems it would be helpful if the authors were able to share the source code specifications for their tasks to allow other groups to compare against this work i found section the details of the raw inputs and feature encodings somewhat difficult to understand in addition to clarifying the authors might wish to consider whether they could provide the source code to their algorithm or at least the encoder to allow careful comparisons by other work although discussed there is no baseline comparison with valued based approaches with attempt to do better exploration by modeling uncertainty such as bootstrapped dqn it would useful to understand how such approaches which also promise better exploration compare it would also be interesting to discuss whether action embedding models such as energy based approaches e g,8.0
485.json,summary in this paper the authors look at the ability of neural networks to represent low dimensional manifolds efficiently e g embed them into a lower dimensional euclidian space they define a class of manifolds monotonic chains affine spaces that intersect with hyperplanes separating monotonic intervals of spaces and give a construction to embed such a chain with a neural network with one hidden layer they also give a bound on the number of parameters required to do so and examine what happens when the manifold is noisy experiments involve looking at embedding synthetic data from a monotonic chain using a distance preservation loss this experiment supports the theoretical bound on number of parameters needed to embed the monotonic chain another experiment varies the elevation and azimuth of of faces which are known to lie on a monotonic chain on a regression loss comments the direction of investigation in the paper looking at what happens to manifolds in a neural network is very compelling and i strongly encourage the authors to continue exploring this direction however the current version of the paper could use some more work the experiments are all with a regression loss and a shallow network and as part of the reason for interest in this question is the very large high dimensional datasets we use now which require a deeper network it seems important to address this case it also seems important to confirm that embedding works well when classification loss is used instead of regression the theory sections could do with being more clearly written i m not as familiar with the literature in this area and while the proof method used is relatively elementary it was difficult to understand what exactly was being proved e g formally stating what could be expected of an embedding that accurately and efficiently preserves a monotonic chain etc,5.0
606.json,a method for training neural networks to mimic abstract data structures is presented the idea of training a network to satisfy an abstract interface is very interesting and promising but empirical support is currently too weak the paper would be significantly strengthened if the method could be shown to be useful in a realistic application or be shown to work better than standard rnn approaches on algorithmic learning tasks the claims about mental representations are not well supported i would remove the references to mind and brain as well as the more philosophical points or write a paper that really emphasizes one of these aspects and supports the claims,4.0
743.json,the authors explore whether the halting time distributions for various algorithms in various settings exhibit universality i e after rescaling to zero mean and unit variance the distribution does not depend on stopping parameter dimensionality and ensemble the idea of the described universality is very interesting however i see several shortcomings in the paper in order to be of practical relevance the actual stopping time might be more relevant than the scaled one the discussion of exponential tailed halting time distributions is a good start but i am not sure how often this might be actually helpful still the findings in the paper might be interesting from a theoretical point of view especially for iclr i think it would have been more interesting to look into comparisons between stochastic gradient descent momentum adam etc on different deep learning architectures over which of those parameters does universality hold how can different initializations influence the halting time distribution i would expect a sensible initialization to cut of part of the right tail of the distribution additionally i found the paper quite hard to read here are some clarity issues abstract even when the input is changed drastically from the abstract i am not sure what input refers to here i introduction where the stopping condition is essentially the time to find the minimum this does not seem to make sense a condition is not a time i guess the authors wanted to say that the stopping condition is that the minimum has been reached i the notions of dimension n epsilon and ensemble e are introduced without any clarification what they are from the later parts of the paper i got some ideas and examples but here it is very hard to understand what these parameters should be just some examples would be already helpful i we use x ell for ell in z dots s where z is a random sample from of training samples this formulation does not make sense either z is a random sample or z s ii it took me a long time to find the meaning of m as this parameter seems to be crucial for universality in this case it would be very helpful to point out more explicitly what it refers to,5.0
743.json,summary for several algorithms previous research has shown that the halting time follows a two parameter distribution the so called universal property investigated by the authors in this work the authors extend the investigation to new algorithms spin glass gradient descent in deep learning an algorithm is considered to satisfy the universality property when the centered scaled halting time fluctuations empirical distribution of halting times depend on the algorithm but do not depend on the target accuracy epsilon an intrinsic measure of dimension n the probability distribution random ensemble this is clear from eq where on the left the empirical halting time distribution depends on epsilon n a e and on the right the approximation only depends on the algorithm the authors argue that empirically the universal property is observed when both algorithms spin glass and deep learning perform well and that it is not observed when they do not perform well a moment based indicator is introduced to assess whether universality is observed review this paper presents several problems page for sufficiently large n and eps eps n the dependence of epsilon on n is troubling page universality is a measure of stability in an algorithm for example halting time for the power method has infinite expectation and hence this type of universality is not present one could use this to conclude that the power method is naive therefore the presence of universality is a desirable feature of a numerical method no an algorithm is naive if there are better ways to answer the problem one could not conclude from a halting time with infinite expectation e g solving a problem extremely quickly of the time and looping forever in of cases or infinite variance that the algorithm is naive moreover the universal property is more restrictive than having a finite halting time expectation even if in many specific cases having a finite halting time expectation is a desirable property showing that the presence of universality is desirable would require a demonstration that the other more restrictive aspects are also desirable also the paragraph only concerns one algorithm why would the conclusions generalise to all numerical methods even if the universality property is arguably desirable i e event if the conclusion of this paragraph is assumed correct the paragraph does not support the given conclusion comparing eq and figures from eq universality means that the centered scaled halting time fluctuations which depend on a epsilon n e can be approximated by a distribution that only depends on a not on epsilon n e but in the experiments only e varies figures the validity of the approximation with varying epsilon or n is never tested the ensembles distributions parameter e on which halting fluctuations should not depend and the algorithm a on which halting fluctuations are allowed to depend are not well defined especially w r t the common use of the words in the optimisation setting we are told that the functional form of the landscape function is part of a in answer to the question of a reviewer but what is part of the functional form what about computations where the landscape has no known functional form black box the conclusion claims that the paper attempts to exhibit cases where one can answer questions in a robust and quantitative way question what are the conditions on the ensembles and the model that lead to such universality the only quantitative way would be to use the moments based indicator however there is only one example of universality not being observed which concerns only one algorithm conjugate gradient and one type of failure when m n this does not demonstrate robustness of the method question what constitutes a good set of hyper parameters for a given algorithm the proposed way to choose would be to test whether universality is observed if it is then the hyper parameters are good if not the hyper parameters are bad the correspondance between bad hyper parameters and observing no universality concerns only one algorithm and one type of failure other algorithms may fail in the universal regime or perform well in the non universal regime the paper does not show how to answer this question in a robust way question how can we go beyond inspection when tuning a system the question is too vague and general and there is probably no robust and quantitative way to answer it at all question how can we infer if an algorithm is a good match to the system at hand the paper fails to demonstrate convincingly that universality is either a good or robust way to approach the very few studied algorithms the suggested generalisation to all systems and algorithms is extremely far fetched question what is the connection between the universal regime and the structure of the landscape same as before the question is extremely vague and cannot be answered in a robust or quantitative way at all the fact that what corresponds to a and what corresponds to e is not clear does not help in the conclusion it is written that the paper validates the claim that universality is present in all or nearly all sensible computation it does not the paper does not properly test whether universality is present only parameter in that should not vary is tested the paper does not properly test whether universality is lost when the computation is no longer sensible only one failure case tested finally the experiments do not apply to all or nearly all computations but only to very few specific algorithms,2.0
411.json,this is an interesting and pleasant paper on superoptimization that extends the problem approached by the stochastic search stoke to a learned stochastic search where the stoke proposals are the output of a neural network which takes some program embedding as an input the authors then use reinforce to learn an mcmc scheme with the objective of minimizing the final program cost the writing is clear and results highlight the efficacy of the method comments questions am i correct in understanding that of the entire stochastic computation graph only the features proposal part is learned the rest is still effectively the stoke mcmc scheme does that imply that the uniform model is effectively stoke and is your baseline this should probably be made explicit did the authors consider learning the features instead of using out of the box features could be difficult given the relatively small amount of data the feature extractor might not generalize in a different context markov chain monte carlo and variational inference bridging the gap by salimans et al suggests considering a mcmc scheme as a stochastic computation graph and optimizing using a variational i e rl criterion the problem is different it uses hmc instead of mcmc but it might be worth citing as a similar approach to meta optimized mcmc algorithms,8.0
411.json,two things i really liked about this paper the whole idea of having a data dependent proposal distribution for mcmc i was not familiar with this although it apparently was previously published i went back the zhu paper was unreadable the jampani paper on informed sampling was good so perhaps this is not a good reason for accepting to iclr the results are quite impressive the rough rule of thumb is that optimization can help you speed up code by the standard mcmc results presented on the paper on randomly generated programs roughly matches this the fact that the proposed algorithm get speedup is quite surprising and worth publishing the argument against accepting this paper is that it does not match the goals of iclr i do not go to iclr to hear about generic machine learning papers we have nips and icml for that instead i go to learn about how to automatically represent data and models now maybe this paper talks about how to represent generated programs so it tangentially lives under the umbrella of iclr but it will compete against more relevant papers in the conference it may just be a poster sending this to a programming language conference may have more eventual impact nonetheless i give this paper an accept because i learned something valuable and the results are very good,7.0
692.json,the authors did not bother responding or fixing any of the pre review comments hence i repeat here please do not make incredibly unscientific statements like this one the working procedure of this model is just like how we human beings read a text and then answer a related question really humans beings have an lstm like model to read a text can you cite an actual neuroscience paper for such a claim the answer is no so please delete such statements from future drafts generally your experiments are about simple classification and the methods you are competing against are simple models like nb svm so i would change the title abstract ad introduction accordingly and not attempt hyperbole like learning to understand in the title lastly your attention level approach seems similar to dynamic memory networks by kumar et al they also have experiments for sentiment and it would be interesting to understand the differences to your model and compare to them other reviewers included further missing related work and fitting this paper into the context of current literature given that no efforts were made to fix the pre review questions and feedback i doubt this will become ready in time for publication,3.0
368.json,review this paper proposes a quantitative evaluation for decoder based generative models that use annealed importance sampling ais to estimate log likelihoods quantitative evaluations are indeed much needed since for some models like generative adversarial networks gans and generative moment matching networks gmmns qualitative evaluation of samples is still frequently used to assess their generative capability even though there exist quantitative evaluations like kernel density estimation kde the authors show how ais is more accurate than kde and how it can be used to perform fine grained comparison between generative models gan gmms and variational autoencoders vae the authors report empirical results comparing two different decoder architectures that were both trained on the continuous mnist dataset using the vae gan and gmmn objectives they also trained an importance weighted autoencoder iwae on binarized mnist and show that in this case the iwae bound underestimates the true log likelihoods by at least nat which is significant for this dataset according to the ais evaluation of the same model pros their evaluation framework is public and is definitely a nice contribution to the community this paper gives some insights about how gan behaves from log likelihood perspective the authors disconfirm the commonly proposed hypothesis that gan are memorizing training data the authors also observed that gans miss important modes of the data distribution cons questions it is not clear for me why sometimes the experiments were done using different number of examples coming from different sources trainset validset testset or simulation generated by the model for instance in table why results were not reported using all examples of the testing set it is not clear why in figure c ais is slower than ais encoder is the number of intermediate distributions the same in both independent chains for ais seems a bit low from what i saw in the literature e g in salakhutdinov murray or desjardins etal they used chains could it be that increasing the number of chains helps tighten the confidence interval reported in table i would have like the authors to give their intuitions as to why gan has a bdmc gap of nats i e order of magnitude compared to the others minor comments table is not referenced in the text and lacks description of what the different columns represent figure a are the reported values represents the average log likelihood of each or total training and validation examples of mnist as described in section figure c i am guessing it is on binarized mnist also why are there fewer points for ais compared to iwae and ais encoder are the bdmc gaps mentioned in section the same as the ones reported in table typo in caption of figure c gmmn but actually showing gmmn according to the graph title and subcaption,7.0
387.json,the paper investigates a simple extension of gatys et al cnn based texture descriptors for image generation similar to gatys et al the method uses as texture descriptor the empirical intra channel correlation matrix of the cnn feature response at some layer of a deep network differently from gatys et al longer range correlations are measured by introducing a shift between the correlated feature responses which translates in a simple modification of the original architecture the idea is simple but has interesting effects on the generated textures and can be extended to transformations other than translation while longer range correlations could be accounted for by considering the response of deeper cnn features in the original method by gatys et al the authors show that modelling them explicitly using shallower features is more effective which is reasonable an important limitation that this work shares with most of its peers is the lack of a principled quantitative evaluation protocol such that judging the effectiveness of the approach remains almost entirely a qualitative affair while this should not be considered a significant drawback of the paper due to the objective difficulty of solving this open issue nevertheless it is somewhat limiting that no principled evaluation method could be devised and implemented the authors suggest that as future work a possible evaluation method could be based on a classification task this is a potentially interesting approach that merits some further investigation,7.0
503.json,the paper introduces gated multimodal units gmus which use multiplicative weights to select the degree to which a hidden unit will consider different modalities in determining its activation the paper also introduces a new dataset multimodal imdb consisting of over k movie summaries with their posters and labeled genres gmus are related to mixture of experts in that different examples will be classified by different parts of the model but rather than routing gating entire examples individual hidden units are gated separately they are related to attention models in that different parts of the input are weighted differently there the emphasis is on gating modalities of input the dataset is a very nice contribution and there are many experiments varying text representation and single modality vs two modality what the paper is lacking is a careful discussion experimentation and analysis in comparison to other multiplicative gate models which is the core intellectual contribution of the paper for example i could imagine that a mixture of experts or attention models or other gated models might perform very well and at the very least provide interesting scientific comparative analysis i encourage the authors to continue the work and submit a revised paper when ready as is i consider the paper to be a good workshop paper but not ready for a major conference,4.0
446.json,this is a parallel work with bigan the idea is using auto encoder to provide extra information for discriminator this approach seems is promising from reported result,7.0
446.json,this paper extends the gan framework to allow for latent variables the observed data set is expanded by drawing latent variables z from a conditional distribution q z x the joint distribution on x z is then modeled using a joint generator model p x z p z p x z both q and p are then trained by trying to fool a discriminator this constitutes a worthwhile extension of gans giving gans the ability to do inference opens up many applications that could previously only be addressed by e g vaes the results are very promising the cifar samples are the best i have seen so far not counting methods that use class labels matching the semi supervised results from salimans et al without feature matching also indicates the proposed method may improve the stability of training gans,8.0
780.json,this paper presents a linear pipeline all reduce approach for parallel neural networks on multiple gpu the paper provides both theoretical analysis and experiments overall the results presented in the paper are interesting but the writing can be improved comments the authors compare their proposed approach with several alternative approaches and demonstrate strong performance of the proposed approaches but it is unclear if the improvement is from the proposed approach or from the implementation the paper is not easy to follow and the writing can be improved in many place aside from typos and missing references specifically the authors should provide more intuitions of the proposed approach in the introduction and in section the proposition and the analysis in section do not suggest the communication cost of linear pipeline is approximately x and log p faster than be and mst respectively as claimed in many places in the paper instead it suggests lp cannot be faster than these methods by x and log p times more specifically eq shows tbroadcasebe tbroadcaselp this does not provide an upper bound of tbroadcaselp and it can be arbitrary worse when comparing with tbroadcasebe from this inequality therefore instead of showing tbroadcasebe tbroadcaselp the authors should state tbroadcasebe tbroadcaselp when n approaches infinity it would be interesting to emphasize more on the differences between designing parallel algorithms on cpu v s on gpu to motivate the paper,5.0
780.json,the primary point made by this paper is that given certain architectural characteristics of multi gpu systems namely the use of bi directional pci e for communication and the integration of two independent dma engines on recent gpu devices providing support for simultaneous independent communications and given the characteristics of the communications patterns required by synchronous sgd trainers for deep neural networks namely that the messages are large dense and have a fixed length it makes sense to design communication collectives such as broadcast reduce and allreduce specifically for the use case of synchronous sgd training on a multi gpu system the paper describes the implementation of these three collectives broadcast reduce and allreduce using a linear pipelining lp scheme on a logical ring topology the paper compares the lp collectives to two alternatives collectives based on a minimal spanning tree mst topology and collectives based on bidirectional exchange be first a theoretical comparison is made using a standard cost model used in the high performance computing community when assumptions based on multi gpu system architecture very low latency for messages and on the communication characteristics of synchronous sgd training very large messages are integrated into the model the paper finds that the lp collectives should be less costly than be collectives by a factor of and less costly than mst collectives by a factor of log p where p is the number of gpus being used second an empirical comparison is performed in which the time required to perform each of the different collectives on a device km system is measured as a function of message size and the time required to perform each of the different collectives with a mb message length is measured as a function of the number of devices in the system these measurements show that the lp based collectives are consistently the fastest third dnn training experiments with alexnet and googlenet are performed on a device system using three different synchronous sgd algorithms with the different implementations of the collectives a total of different algorithms in all measurements of the communication and computation costs show that the lp collectives reduce communication costs without affecting computation costs as expected measurements of the convergence of the training loss as a function of time for the two dnn architectures show that use of the lp collectives leads to faster training while the theory says that the costs of lp collectives should be invariant to the number of devices in a multi gpu system the empirical work shows that in practice this does not hold going from to devices in the tested configuration because in a device system messages must traverse the qpi are there other practical considerations that the authors are aware of that affect the scaling of the lp collectives if so these should be mentioned in the paper in the sentence worringen proposed a pipeline collective model in shared memory environment for cpu data but communications of different mpi processes sharing the same cpu memory bus within the same cpu socket i really can not figure out what the words after but communications of different mpi processes are trying to convey this sentence is not comprehensible please note the latency term is log pα which is the smallest among algorithms in table therefore mst only suits for high frequent short messages the claim that mst collectives are only suitable for high frequency short messages does not follow from the statement that mst collectives have the smallest latency term you also need to consider the way the cost scales with message size the bandwidth term if the mst collectives had a better bandwidth term than the other collectives then they would also be superior for large messages let s take an appropriate block size b to ensure n b α this looks wrong since n b should it be b n α however the parameters are not consistent after several iterations due to the precision issues of float multiplications in gradient update are you sure the inconsistency in weight estimates across devices is due to multiplication i would expect that it would be due to gradients being accumulated in different orders that is because floating point addition is not commutative i recommend replacing the term sub gradients in this paper with partial gradients in the optimization literature the term sub gradient has a very specific meaning that differs from this paper use of the term see,6.0
515.json,the paper presents an application of a tensor factorization to linear models which allows to consider higher order interactions between variables in classification and regression problems and that maintains computational feasibility being linear in the dimension the factorization employed is based on the tt format first proposed by oseledests the authors also propose the adoption of a riemannian optimization scheme to explicit consider the geometry of the tensor manifold and thus speed up convergence the paper in general is well written it presents an interesting application of the tt tensor format for linear models together with an application of riemannian optimization which in my opinion is quite interesting since it has a wide range of possible applications in different algorithms in machine learning on the other side i have some concerns are about the experimental part which i consider not at the level of the rest of the paper for instance in terms of number of experiments on real datasets role of dropout in real datasets comparison with other algorithms on real datasets moreover the authors do not take into account explicitly the problem of the choice of the rank to be used in the experiments in general the experimental section seems a collection of preliminary experiments where different aspects have been tested by not in a organic way i think the paper is close to a weak acceptance weak rejection i do not rate it as a full acceptance paper mainly due to the non satisfactory experiment setting in case of extra experiments confirming the goodness of the approach i believe the paper could have much better scores some minor comments formula obvious comment learning the parameters of the model in can be done as in but also in other ways depending on the approach you are using the fact that the rank is bounded by r before formula is explained in lubich et al after formula why the n projections in total they cost o dr r n it should be o ndr r no since each of the elements of the summation has rank and the cost for each of them is o dr r ttrank z where tt rank z am i wrong section can you explain why the random initialization freezes the convergence this seems interesting but not motivated any guess section you adopt dropout can you comment in particular on the advantages it gives in the context of the exponential machines did you use it on real datasets how do you choose r in you experiments with a validation set in section why you do not have x x among the variables section there is a typo in experiments section we simplicity we binarized i think there a problem with the english language in this sentence section we report that dropout helps this is quite general statement only tested on a synthetic dataset section can you provide more results for this dataset for instance in terms of training and inference time or test wrt other algorithms,5.0
515.json,the paper describes how to use a tensor factorization method called tensor train for modeling the interactions between features for supervised classification tasks tensor train approximates tensors of any dimensions using low rank products of matrices the rank is used as a parameter for controlling the complexity of the approximation experiments are performed on different datasets for binary classification problems the core of the paper consists in demonstrating how the tt formalism developed by one of the authors could be adapted for modeling interactions between features another contribution is a gradient algorithm that exploits the geometrical structure of the factorization these ideas are probably new in machine learning the algorithm itself is of reasonable complexity for the inference and could probably be adapted to large size problems although this is not the case for the experiments here the experimental section is not well structured it is incomplete and could be improved we miss a description of the datasets characteristics the performance on the different datasets are not provided each dataset has been used for illustrating one aspect of the model but you could also provide classification performance and a comparison with baselines for all the experiments the experiments on the uci datasets show optimization performance on the training set you could provide the same curves on test sets to show how the algorithm generalizes the comparison to other approaches section is only performed on artificial data which are designed with interacting features and are not representative of diverse situations the same holds for the role of dropout the comparison on the movielens dataset is incomplete besides all the tests are performed on small size problems overall there are original contributions which could be worth a publication the experiments are incomplete and not conclusive a more detailed comparison with competing methods like factorization machines could also improve the paper,6.0
450.json,i would like first to apologize for the delay summary a framework for two samples statistical test using binary classification is proposed it allows multi dimensional sample testing and an interpretability that other tests lack a theoritical analysis is provided and various empirical tests reported a very interesting approach i have however two main concerns the clarity of the presentation is obscured by too much content it would be more interesting if the presentation could be somewhat self contained you could consider making papers out of this paper seriously you cram a lot of experiments in this paper but the setting of the experiments is not really explained we are supposed to have read jitkrittum et al radford et al yu et al etc all this is okay but reduces your public to a very few for example if i am not mistaken you never explained what scf is despite the fact that its performances are reported as a second point given also that the number of submissions to this conference are exploding i would like to challenge you with the following question why is this work significant to the representation learning community,7.0
450.json,the submission considers the setting of sample testing from the perspective of evaluating a classifier for a classifier between two samples from the same distribution the distribution of the classification accuracy follows a simple form under the null hypothesis as such a straightforward threshold can be derived for any classifier finding a more powerful test then amounts to training a better classifier one may then focus efforts e g on deep neural networks for which statistics such as the mmd may be very difficult to characterize the approach is sound and very general the paper is timely in that deep learning has had huge impacts in classification and other prediction settings but has not had as big an impact on statistical hypothesis testing as kernel methods have the discussion of the relationship to kernel mmd has not always been as realistic as it could have been for example the kernel mmd can also be seen as a classifier based approach so a more fair discussion could be provided also the form of kernel mmd used in the comparisons is a bit contradictory to the discussion as well the linear kernel mmd is used which is less powerful than the quadradic kernel mmd the authors have justified this from the perspective of computation time the kernel mmd is argued against due to its unwieldy distribution under the null but the linear time kernel mmd see also zaremba et al nips has a gaussian distribution under the null arthur gretton comment from dec during the discussion period was very insightful and helpful if these insights and additional experiments comparing the kernel mmd to the classifier threshold on the blobs dataset could be included that would be very helpful for understanding the paper the open review format gives an excellent opportunity to assign proper credit for these experiments and insights by citing the comment,8.0
450.json,paper summary the paper reconsiders the idea of using a binary classifier to do two sample testing the idea is to split the sample into two disjoint training and test sets train a classifier on the training set and use the accuracy on the test set as the test statistic if the accuracy is above chance level one concludes that the two samples are from different distributions i e reject h a theoretical result on an asymptotic approximate test power is provided one implication is that the test is consistent assuming that the classifier is better than coin tossing experiments on toy problems evaluation of gans and causal discovery verify the effectiveness of the test in addition when the classifier is a neural net examining the first linear filter layer allows one to see features which are most activated the result is an interpretable visual indicator of how the two samples differ review summary the paper is well written and easy to follow the idea of using a binary classifier for a two sample testing is not new as made clear in the paper the main contributions are the analysis of the asymptotic test power the use of modern deep nets as the classifier in this context and the empirical studies on various tasks the empirical results are satisfactorily convincing although not much discussion is made on why the method works well in practice overall contributions have a potential to start a new direction of research on model criticisms of generative models as well as visualization of where a model fails i vote for an acceptance major comments questions my main concern is on theorem asymptotic test power and its assumptions but i understand that these can be fixed as discussed below under h the distribution of the test statistic i e sum of classification results follows binomial nte as stated however under h terms in the sum are independent but not identical bernoulli random variable this is because each term depends on a data point zi which can be from either p or q so in the paragraph in sec the random variable nte hat t follows a binomial nte p is not correct essentially p depends on zi it should follow a poisson binomial distribution in the same paragraph for the same reason the alternative distribution of binomial nte p p risk is probably not correct i guess you mention it to use moivre laplace to get the asymptotic normality anyway i see no reason why you would need this statement as the binomial is not required in the proof but only its asymptotic normality a variant of the central limit theorem instead of the moivre laplace theorem for independent non identical variables would still allow you to conclude the asymptotic normality of the poisson binomial with some conditions see for example,7.0
329.json,this paper is well written and well presented this method is using denoise autoencoder to learn an implicit probability distribution helps reduce training difficulty which is neat in my view joint training with an auto encoder is providing extra auxiliary gradient information to improve generator providing auxiliary information may be a methodology to improve gan extra comment please add more discussion with ebgan in next version,7.0
329.json,this paper is about using denoising autoencoders to improve performance in gans in particular the features as determined by the discriminator of images generated by the generator are fed into a denoising ae and we try to have these be reconstructed well i think it an interesting idea to use this extra information namely the feature representations learned by the discriminator it seems very much in the spirit of iclr my main concern though is that i am not wholly convinced on the nature of the improvement this method achieves higher inception scores than other methods in some cases but i have a hard time interpreting these scores and thus a hard time getting excited by the results in particular the authors have not convinced me that the benefits outweigh the required additional sophistication both conceptually and implementation wise speaking of which will code be released one thing i would be curious to know is how hard is it to get this thing to actually work also i view gans as a means to an end while i am not particularly excited about generating realistic images especially in x i am very excited about the future potential of gan based systems so it would have been nice to see these improvements in inception score translate into improvements in a more useful task but this criticism could probably apply to many gan papers and so perhaps is not fair here i do think the idea of exploiting extra information like discriminator features is interesting both inside and outside the context of this paper,6.0
779.json,in this paper the authors present several strategies to select a small subset of target vocabulary to work with per source sentence which results in significant speedup the results are convincing and i think this paper offers practical values to general seqseq approaches to language tasks however there is little novelty in this work the authors further mostly extend the work of mi et al with more vocabulary selection strategies and thorough experiments this paper will fit better in an nlp venue,4.0
779.json,this paper evaluates several strategies to reduce output vocabulary size in order to speed up nmt decoding and training it could be quite useful to practitioners although the main contributions of the paper seem somewhat orthogonal to representation learning and neural networks and i am not sure iclr is the ideal venue for this work do the reported decoding times take into account the vocabulary reduction step aside from machine translation might there be applications to other settings such as language modeling where large vocabulary is also a scalability challenge the proposed methods are helpful because of the difficulties induced by using a word level model but at least in my opinion starting from a character or even lower level abstraction seems to be the obvious solution to the huge vocabulary problem,5.0
542.json,this paper studies the problem of abstract hierarchical multiagent rl with policy sketches high level descriptions of abstract actions the work is related to much previous work in hierarchical rl and adds some new elements by using neural implementations of prior work on hierarchical learning and skill representations sketches are sequences of high level symbolic labels drawn from some fixed vocabulary which initially are devoid of any meaning eventually the sketches get mapped into real policies and enable policy transfer and temporal abstraction learning occurs through a variant of the standard actor critic architecture experiments are provided through a standard game like domain maze minecraft etc the paper as written suffers from two problems one the idea of policy sketches is nice but not sufficiently fleshed out to have any real impact it would have been useful to see this spelled out in the context of abstract smdp models to see what they bring to the table what one gets here is some specialized invocation of this idea in the context of the specific approach proposed here second the experiments are not thorough enough in terms of comparing with all the related work for example ghavamzadeh et al explored the use of maxq like abstractions in the context of mulitagent rl it would be great to get a more detailed comparison to maxq based multiagent rl approaches where the value function is explicitly decomposed,5.0
542.json,the paper proposes a new rl architecture that aims at learning policies from sketches i e sequence of high level operations to execute for solving a particular task the model relies on a hierarchical structure where the sub policy is chosen depending on the current operation to execute in the sketch the learning algorithm is based on an extension of the actor critic model for that particular case and also involves curriculum learning techniques when the task to solve is hard experimental results are provided on different learning problems and compared to baseline methods the paper is well written and very easy to follow i am not really convinced by the impact of such a paper since the problem solved here can be seen as an option learning problem with a richer supervision i e the sequence of option is given it thus corresponds to an easier problem with a limited impact moreover i do not really understand to which concrete application this setting corresponds for example learning from natural langage instructions is clearly more relevant so since the model proposed in this article is not a major contribution and shares many common ideas with existing hierarchical reinforcement learning methods the paper lacks a strong motivation and or concrete application so the paper only has a marginal interest for the rl community pros original problem with well design experiments simple adaptation of the actor critic method to the problem of learning sub policies cons very simple task that can be seen as a simplification of more complex problems like options discovery hierarchical rl or learning from instructions no strong underlying applications that could help to are inforce the interest of the approach,3.0
407.json,this paper studies the problem of transferring solutions of existing tasks to tackle a novel task under the framework of reinforcement learning and identifies two important issues of avoiding negative transfer and being selective transfer the proposed approach is based on a convex combination of existing solutions and the being learned solution to the novel task the non negative weight of each solution implies that the solution of negative effect is ignored and more weights are allocated to more relevant solution in each state this paper derives this so called at learning algorithm for policy transfer and value transfer for reinforce and actor critic algorithms and experiments with synthetic chain world and puddle world simulation and atari game pong this paper presents a novel approach for transfer reinforcement learning the experiments are cleverly designed to demonstrate the ability of the proposed method an important aspect of transfer learning is that the algorithm can automatically figure out if the existing solutions to known tasks are sufficient to solve the novel task so that it can save the time and energy of learning from scratch this issue is not studied in this paper as most of experiments have a learning from scratch solution as base network it will be interesting to see how well the algorithm performs without base network in addition from figure and the proposed algorithm seems to accelerate the learning speed but the overall network seems not better than the solo base network it will be more convincing to show some example that existing solutions are complementary to the base network if ignoring the base network the proposed network can be considered as ensemble reinforcement learning that take advantages of learned agents with different expertise to solve the novel task,7.0
407.json,the paper tackles important problems in multi task reinforcement learning avoid negative transfer and allow finer selective transfer the method is based on soft attention mechanism very general and demonstrated to be applicable in both policy gradient and value iteration methods the introduction of base network allows learning new policy if the prior policies are not directly applicable state dependent sub policy selection allows finer control and can be thought of assigning state space to different sub policies experts the tasks are relatively simplistic but sufficient to demonstrate the benefits one limitation is that the method is simple and the results claims are mostly empirical it would be interesting to see extensions to option based framework stochastic hard attention mechanism sub policy pruning progressive networks in figure the read curve seems to perform worse than the rest in terms of final performance perhaps alternative information to put with figures is the attention mask activation statistics during learning so that we may observe that it learns to turn off adversarial sub policies and rely on newly learned base policy mostly this is also generally good to check to see if any weird co adaptation is happening,7.0
391.json,the paper proposes a method for pruning weights in neural networks during training to obtain sparse solutions the approach is applied to an rnn based system which is trained and evaluated on a speech recognition dataset the results indicate that large savings in test time computations can be obtained without affecting the task performance too much in some cases the method can actually improve the evaluation performance the experiments are done using a state of the art rnn system and the methodology of those experiments seems sound i like that the effect of the pruning is investigated for networks of very large sizes the computational gains are clearly substantial it is a bit unfortunate that all experiments are done using a private dataset even with private training data it would have been nice to see an evaluation on a known test set like the hub for conversational speech it would also have been nice to see a comparison with some other pruning approaches given the similarity of the proposed method to the work by han et al to verify the relative merit of the proposed pruning scheme while single stage training looks more elegant at first sight it may not save much time if more experiments are needed to find good hyperparameter settings for the threshold adaptation scheme finally the dense baseline would have been more convincing if it involved some model compression tricks like training on the soft targets provided by a bigger network overall the paper is easy to read the table and figure captions could be a bit more detailed but they are still clear enough the discussion of potential future speed ups of sparse recurrent neural networks and memory savings is interesting but not specific to the proposed pruning algorithm the paper doesn t motivate the details of the method very well it s not clear to me why the threshold has to ramp up after a certain period time for example if this is based on preliminary findings the paper should mention that sparse neural networks have been the subject of research for a long time and this includes recurrent neural networks e g sparse recurrent weight matrices were standard for echo state networks the proposed method is also very similar to the work by han et al where a threshold is used to prune weights after training followed by a retraining phase of the remaining weights while i think that it is certainly more elegant to replace this three stage procedure with a single training phase the proposed scheme still contains multiple regimes that resemble such a process by first training without pruning followed by pruning at two different rates and finally training without further pruning again the main novelty of the work would be the application of such a scheme to rnns which are typically more tricky to train than feedforward nets improving scalability is an important driving force of the progress in neural network research while i don t think the paper presents much novelty in ideas or scientific insight it does show that weight pruning can be successfully applied to large practical rnn systems without sacrificing much in performance the fact that this is possible with such a simple heuristic is a result worth sharing pros the proposed method is successful at reducing the number of parameters in rnns substantially without sacrificing too much in performance the experiments are done using a state of the art system for a practical application cons the proposed method is very similar to earlier work and barely novel there is no comparison with other pruning methods the data is private and this prevents others from replicating the results jaeger h the echo state approach to analyzing and training recurrent neural networks with an erratum note bonn germany german national research center for information technology gmd technical report han song pool jeff tran john and dally william j learning both weights and connections for efficient neural networks in advances in neural information processing systems,6.0
391.json,summary the paper presents a technique to convert a dense to sparse network for rnns the algorithm will increasingly set more weights to zero during the rnn training phase this provides a rnn model with less storage requirement and higher inference rate pros proposes a pruning method that doesn t need re training and doesn t affect the training phase of rnn the method achieves sparsity and hence less number of parameters cons questions judiciously choosing hyper parameters for different models and different applications wouldn t be cumbersome in equation is q the sparsity of final model is there a formula to know what is sparsity number of parameters and accuracy of final model given a set of hyper parameters before going through training questions answered in table we see a trade off between number of units and sparsity to achieve better number of parameters or accuracy or in table better speed good but where are the results for gru sparse big i mean accuracy must be similar and still get decent compression rate and speed up just like rnn sparse medium compared with rnn dense i can t see much advantage of pruning and getting high speed up if you are sacrificing so much accuracy issue fixed with updated data why sparsity for table and table are different in text average sparsity of but in table is are the models used in table different from table issue fixed,7.0
391.json,updated review jan thanks to the authors for including a comparison to the previously published sparsity method of yu et al the comparison is plausible though it would be clearer if the authors were to state that the best comparison for the results in table is the rnn sparse result in table i have updated my review to reflect my evaluation of the revised paper although i am also leaving the original review in place to preserve the history of the paper this paper has three main contributions it proposes an approach to training sparse rnns in which weights falling below a given threshold are masked to zero and a schedule is used for the threshold in which pruning is only applied after a certain number of iterations have been performed and the threshold increases over the course of training it provides experimental results on a baidu internal task with the deep speech network architecture showing that applying the sparsification to a large model can lead to a final trained model which has better performance and fewer non zero parameters than a dense baseline model it provides results from timing experiments with the cusparse library showing that there is some potential for faster model evaluation with sufficiently sparse models but that the current cusparse implementation may not be optimal pros the paper is mostly clear and easy to understand the paper tackles an important practical problem in deep learning how to successfully deploy models at the lowest possible computational and memory cost cons as a second baseline this paper should compare to distillation approaches e g,6.0
309.json,this paper proposes a way of adding unsupervised auxiliary tasks to a deep rl agent like ac authors propose a bunch of auxiliary control tasks and auxiliary reward tasks and evaluate the agent in labyrinth and atari proposed unreal agent performs significantly better than ac and also learns faster this is definitely a good contribution to the conference however this is not a surprising result since adding additional auxiliary tasks that are relevant to the goal should always help in better and faster feature shaping this paper is a proof of concept for this idea the paper is well written and easy to follow by any reader with deep rl expertise can authors comment about the computational resources needed to train the unreal agent the overall architecture is quite complicated are the authors willing to release the source code for their model after rebuttal no change in the review,7.0
470.json,this paper presents an approach which modifies the variational auto encoder vae framework so as to use stochastic latent dimensionality this is achieved by using an inherently infinite prior the stick breaking process this is coupled with inference tailored to this model specifically the kumaraswamy distribution as an approximate variational posterior the resulting model is named the sb vae which also has a semi supervised extension in similar vein to the original vae paper there a lot of interest in vaes these days many lines of work seek to achieve automatic black box inference in these models for example the authors themselves mention parallel work by blei lab also others towards this direction however there a lot of merit in investigating more bespoke solutions to new models which is what the authors are doing in this paper indeed a useful side effect of providing efficient inference for the sb vae is drawing attention to the use of the kumaraswamy distribution which has not been popular in ml although the paper is in general well structured i found it confusing at parts i think the major source of confusion comes from the fact that the model specification and model inference are discussed in a somehow mixed manner the pre review questions clarified most parts i have two main concerns regarding the methodology and motivation of this paper firstly conditioning the model directly on the stick breaking weights seems a little odd i initially thought that there was some mixture probabilistic model involved but this is not the case to be fair the authors discuss about this issue which became clearer to me after the pre review questions and explain that they are investigating the apparently challenging problem of using a base distribution g the question is whether their relaxation is still useful from the experiments it seems that the method is at least competitive so the answer is yes hopefully an extension will come in the future as the authors mention the second concern is about the motivation of this method it seems that the paper fails to clearly explain in a convincing way why it is beneficial to reformulate the vae as a sb vae i understand that the non parametric property induced by the prior might result in better capacity control however i feel that this advantage and potentially others which are still unclear to me is not sufficiently explained and demonstrated perhaps some comparison with a dropout approach or a more thorough discussion related to dropout would make this clearer overall i found this to be an interesting paper it would be a good fit for iclr,8.0
470.json,summary this is the first work to investigate stick breaking priors and corresponding inference methods for use in vaes the background material is explained clearly as well as the explanation of the priors and posteriors and their dncp forms the paper is really well written in experiments they find that stick breaking priors does not generally improve upon spherically gaussian priors in the completely unsupervised setting when measured w r t log likelihood the fact that they do report this negative result suggests good scientific taste in a semi supervised setting the results are better comments sec there is plenty of previous work with non gaussian p z draw the generative resnet paper in the iaf paper ladder vaes etc sec two comma text flow eq please refer to appendix with the closed form kl divergence the v are sampled via in the posterior the v are sampled via it not clear you are talking about the posterior here instead of the prior the last paragraph of section is great sec density estimation technically you are also doing mass estimation sec is samples is a bit on the low side figure f interesting that k nn works so well on raw pixels,8.0
535.json,the authors apply the image captioning architecture of xu et al to video captioning the model is extended to have attention over multiple layers of the convnet instead of just a single layer experiments on youtubetext m vad and msr vtt show that this works better than only using one of the layers at a time i think this is solid work on the level of a well executed course project or a workshop paper the model makes sense it is adequately described and the experiments show that attending over multiple layers works better than attending over any one layer in isolation unfortunately i do not think there is enough to get excited about here from a technical perspective and it not clear what value the paper brings to the community other aspects of the paper such as including the hard attention component do not seem to add to the paper but take up space if the authors want to contribute a detailed focused exploration of multi level features this could become a more valuable paper but in that case i would expect a much more thorough exploration of the choices and tradeoffs of different schemes without too many spurious aspects such as video features hard attention etc,4.0
535.json,summary this paper proposes a video captioning model based on a d space time convnet cd encoder and a lstm decoder the authors investigate the benefits of using attention mechanisms operating both at the spatio temporal and layer feature abstraction levels contributions well motivated and implemented attention mechanism to handle the different shapes of cd feature maps along space time and feature dimensions convincing quantitative and qualitative experiments on three challenging datasets youtubetext m vad msr vtt showing clearly the benefit of the proposed attention mechanisms interesting comparison of soft vs hard attention showing a slight performance advantage for the simpler soft attention mechanism in this case suggestions for improvement hypercolumns comparison as mentioned during pre review questions it would be interesting to compare to the hypercolumns of,7.0
427.json,the authors of this work propose an interesting approach to visualizing the predictions made by a deep neural network the manuscript is well written is provides good insight into the problem i also appreciate the application to medical images as simply illustrating the point on imagenet is not interesting enough i do have some questions and comments as the authors correctly point out in approximating the conditional probability of a feature xi by the marginal distribution p xi is not realistic they advocate for translation invariance i e the position of the pixel in the image should not affect the probability and suggest that the pixels appearance depends on the small neighborhood around it however it is well known that global context makes an big impact on the semantics of pixels in objects in contexts authors show that a given neighborhood of pixels can take different semantic meanings based on the global context in the image in the context of deep neural networks works such as parsenet also illustrate the importance of global context on the spatial label distribution this does not necessarily invalidate this approach but is a significant limitation it would be great if the authors provided a modification to and empirically verified the change figure shows the distribution over top predictions before and after softmax it is expected that even fairly uniform distributions will transform toward delta functions after softmax normalization is there an additional insight here finally in the authors state that it takes minutes to analyze a single image with goolenet on a gpu why is this so computationally expensive such complexity seems to make the algorithm impractical and analyzing datasets of statistical relevance seems prohibitive,6.0
562.json,this paper proposes to address the mode collapsing problem of gans by training a large set of generators and discriminators pairing them each up with different ones at different times throughout training the idea here is that no one generator discriminator pair can be too locked together since they are all being swapped this idea is nice and is addressing an important issue with gan training however i think the paper is lacking in experimental results in particular the authors need to do more work to motivate the gam metric it is not intuitively obvious to me that the gam metric is a good way of evaluating the generator networks since it relies on the prediction of the discriminator networks which can fixate on artifacts perhaps the authors could explore if the gam metric correlates with inception scores or human evaluations currently the only quantitative evaluation uses this criterion and it really is not clear it a relevant quantity to be measuring related to the above comment the authors need to compare more to other methods why not evaluate inception scores and compare with previous methods similarly generation quality is not compared with previous methods it not obvious that the sample quality is any better with this method and now just repeating questions from pre review section if instead of swapping you were to simply train k gans on k splits of the data or k gans with differing initial conditions but without swapping do you see any improvement in results similarly how about if you train larger capacity models with dropout in g and d since dropout essentially averages many models it would be interesting to see if the effects are the same in figure it appears that the validation costs remain the same as parallelization increase but the training cost goes up and that is why the gap is shrinking does this really imply better generalization in summary interesting paper that addresses an important issue with gan training but compelling results are missing,4.0
348.json,this paper presents a theoretical treatment of transformation groups applied to convnets and presents some empirical results showing more efficient usage of network parameters the basic idea of steerability makes huge sense and seems like a very important idea to develop it is also a very old idea in image processing and goes back to simoncelli freeman adelson as well as perona greenspan and others in the early s this paper approaches it through a formal treatment of group theory but at the end of the day the idea seems pretty simple the feature representation of a transformed image should be equivalent to a transformed feature representation of the original image given that the authors are limiting their analysis to discrete groups for example rotations of and deg the formalities brought in from the group theoretic analysis seem a bit overkill i am not sure what this buys us in the end it seems the real challenge lies in implementing continuous transformations so if the theory could guide us in that direction it would be immensely helpful also the description of the experiments is fairly opaque i would have a hard time replicating what exactly the authors did here in terms of implementing capsules or transformation groups,6.0
348.json,the authors propose a parameterization of cnns that guarantees equivariance wrt a large family of geometric transformations the mathematical analysis is rigorous and the material is very interesting and novel the paper overall reads well there is a real effort to explain the math accessibly though some small improvements could be made the theory is general enough to include continuous transformations although the experiments are restricted to discrete ones while this could be seen as a negative point it is justified by the experiments which show that this set of transformations is powerful enough to yield very good results on cifar another form of intertwiner has been studied recently by lenc vedaldi they have studied equivariance empirically in cnns which offers an orthogonal view in addition to the recent references on scale rotation deep networks suggested below geometric equivariance has been studied extensively in the mentioning at least one work would be appropriate the one that probably comes closest to the proposed method is the work by reisert who studied steerable filters for invariance and equivariance using lie group theory the difference of course is that the focus at the time was on kernel machines rather than cnns but many of the tools and theorems are relatable some of the notation could be simplified to make the formulas easier to grasp on a first read working over a lattice z d is unnecessarily abstract since the inputs are always images z would make much of the later math easier to parse generalization is straightforward so i do not think the results lose anything by it and the authors go back to d latices later anyway it could be more natural to do away with the layer index l which appears throughout the paper and have notation for current next layer instead e g pi and pi k and d instead of k l and kl in any case i leave it up to the authors to decide whether to include these suggestions on notation but i urge them to consider them or other ways to unburden notation a few minor issues some statements would be better supported with an accompanying reference e g explicit formulas exist on page the introduction of intertwiners on page finally there is a tiny mistake in the balduzzi ghifary reference some extra information was included as an author name lenc vedaldi understanding image representations by measuring their equivariance and equivalence reisert group integration techniques in pattern analysis a kernel view,7.0
348.json,this paper essentially presents a new inductive bias in the architecture of convolutional neural networks cnn the mathematical motivations derivations of the proposed architecture are detailed and rigorous the proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional cnns which is particularly useful in small data regimes interesting and novel connections are presented between steerable filters and so called steerable fibers the architecture is strongly inspired by the author s previous work as well as that of capsules hinton the proposed architecture is compared on cifar against state of the art inspired architectures resnets and is shown to be superior particularly in the small data regime the lack of empirical comparison on large scale dataset such as imagenet or coco makes this largely a theoretical contribution i would have also liked to see more empirical evaluation of the equivariance properties it is not intuitively clear exactly why this architecture performs better on cifar as it is not clear that capturing equivariances helps to classify different instances of object categories wouldn t action recognition in videos for example not be a better illustrative dataset,8.0
718.json,the paper reframes feed forward neural networks as a multi agent system it seems to start from the wrong premise that multi layer neural networks were created expressed as full matrix multiplications this ignores the decades long history of development of artificial neural networks inspired by biological neurons which thus started from units with arbitrarily sparse connectivity envisioned as computing in parallel the matrix formulation is primarily a notational convenience note also that when working with sparse matrix operations or convolutions zeros are neither stored not multiplied by besides the change in terminology essentially renaming neurons agents i find the paper brings nothing new and interesting to the table pulling in useful insights from a different communitiy such as multi agent systems would be most welcome but for this to be compelling it would have to be largely unheard of elements in neural net research with clear supporting empirical evidence that they significantly improve accuracy or efficiency this is not achieved in the present paper,1.0
431.json,this paper introduces an analytical performance model to estimate the training and evaluation time of a given network for different software hardware and communication strategies the paper is very clear the authors included many freedoms in the variables while calculating the run time of a network such as the number of workers bandwidth platform and parallelization strategy their results are consistent with the reported results from literature furthermore their code is open source and the live demo is looking good the authors mentioned in their comment that they will allow users to upload customized networks and model splits in the coming releases of the interface then the tool can become very useful it would be interesting to see some newer network architectures with skip connections such as resnet and densenet,7.0
431.json,in paleo the authors propose a simple model of execution of deep neural networks it turns out that even this simple model allows to quite accurately predict the computation time for image recognition networks both in single machine and distributed settings the ability to predict network running time is very useful and the paper shows that even a simple model does it reasonably which is a strength but the tests are only performed on a few networks of very similar type alexnet inception nin and only in a few settings much broader experiments including a variety of models rnns fully connected adversarial etc in a variety of settings different batch sizes layer sizes node placement on devices etc would probably reveal weaknesses of the proposed very simplified model this is why this reviewer considers this paper borderline it a first step but a very basic one and without sufficiently large experimental underpinning more experiments were added so i am updating my score,6.0
466.json,this paper provides some theoretical guarantees for the identity parameterization by showing that arbitrarily deep linear residual networks have no spurious local optima and residual networks with relu activations have universal finite sample expressivity this paper is well written and studied a fundamental problem in deep neural network i am very positive on this paper overall and feel that this result is quite significant by essentially showing the stability of auto encoder given the fact that it is hard to provide concrete theoretical guarantees for deep neural networks one of key questions is how to extent the result in this paper to the more general nonlinear actuation function case minors one line before eq u in r times k,8.0
466.json,paper summary authors investigate identity re parametrization in the linear and the non linear case detailed comments linear residual network the paper shows that for a linear residual network any critical point is a global optimum this problem is non convex it is interesting that this simple re parametrization leads to such a result non linear residual network authors propose a construction that maps the points to their labels via a resnet using an initial random projection followed by a residual block that clusters the data based on their label and a last layer that maps the clusters to the label in eq seems the dimensions are not matching qj in r k and ej in r r please clarify the construction seems fine but what is special about the resnet here in this construction one can do a similar construction if we did not have the identity can you discuss this point in the linear case it is clear from a spectral point of view how the identity is helping the optimization please provide some intuition existence of a network in the residual class that overfits does it give us any intuition on why residual network outperform other architectures what does an existence result of such a network tell us about its representation power a simple linear model under the assumption that points can not be too close can overfit the data and get fast convergence rate see for instance tsybakov noise condition what does the construction tell us about the number of layers clustering the activation independently from the label is an old way to pretrain the network one could use those centroids as weights for the next layer this is also related to nystrom approximation see for instance,5.0
489.json,the authors present a methodology for analyzing sentence embedding techniques by checking how much the embeddings preserve information about sentence length word content and word order they examine several popular embedding methods including autoencoding lstms averaged word vectors and skip thought vectors the experiments are thorough and provide interesting insights into the representational power of common sentence embedding strategies such as the fact that word ordering is surprisingly low entropy conditioned on word content exploring what sort of information is encoded in representation learning methods for nlp is an important and under researched area for example the tide of word embeddings research was mostly stemmed after a thread of careful experimental results showing most embeddings to be essentially equivalent culminating in improving distributional similarity with lessons learned from word embeddings by levy goldberg and dagan as representation learning becomes even more important in nlp this sort of research will be even more important while this paper makes a valuable contribution in setting out and exploring a methodology for evaluating sentence embeddings the evaluations themselves are quite simple and do not necessarily correlate with real world desiderata for sentence embeddings as the authors note in other comments performance on these tasks is not a normative measure of embedding quality for example as the authors note the ability of the averaged vector to encode sentence length is trivially to be expected given the central limit theorem or more accurately concentration inequalities like hoeffding inequality the word order experiments were interesting a relevant citation for this sort of conditional ordering procedure is generating text with recurrent neural networks by sutskever martens and hinton who refer to the conversion of a bag of words into a sentence as debagging although this is just a first step in better understanding of sentence embeddings it is an important one and i recommend this paper for publication,8.0
523.json,synopsis the authors introduce an efficient approximation to the softmax function that speeds up the empirical calculation of the softmax on gpus they leverage the unbalanced distribution of words and specific empirical timings of matrix multiplies on gpus to devise an algorithm that selects an optimal placement of the vocabulary into clusters they show empirical results that show speedups over alternative methods while not losing much accuracy compared to the full softmax thoughts since the goal of this work is to speed up training i am curious why you compare only to the flat level hsm o sqrt v speedup at best and not the deeper binary tree hsm o lgv speedup at best overall the paper is clear easy to understand and well written bar a few notation issues as pointed out by other reviewers it adds an interesting extra tool in the language modeling toolbox the idea is based on several previous works that aim to optimize vocabulary clustering to improve the speed accuracy tradeoff often experienced in practice with hierarchical methods the interesting result here seems to be that this particular clustering objective improves speed what it was designed for while apparently not losing much i t o accuracy what it was not designed for although the authors do not speculate reasons for the latter part at all i suspect it is largely related to the fact that the flat region on the timing graph fig means that the head group vh can actually include a sizeable portion of the most frequent words in the vocabulary at constant cost this reduces the approximation error regions of no support in papprox next previous compared to preal which in turn mitigates the hit in perplexity compared to the full softmax however since the method is intimately related to the speed optimal method proposed by zweig et al albeit without the explicit tailoring towards gpu i feel that a direct comparison is warranted i understand this is underway if the performance and accuracy improvements still hold i will update my rating to a,6.0
523.json,he authors provide an interesting computational complexity driven approach for efficient softmax computation for language modeling based on gpus an adaptive softmax approach is proposed based on a hierarchical model dynamic programming is applied to optimize the structure of the hierarchical approach chosen here w r t computational complexity based on gpus however it remains unclear how robust the specific configuration obtained from dynamic programming is w r t performance perplexity corresponding comparative results with perplexity based clustering would be desirable especially in sec paragraph baselines and table respectively it would be interesting to see a result on hsm ppl cf zweig et al afaik the first successful application of an lstm based language model for large vocabulary was published by sundermeyer et al see below which is missing in the sumary of prior work on the bottom of p mainly the paper is well written and accessible though notation in some cases should be improved see detailed comments below prior work on lstm language modeling sundermeyer et al lstm neural networks for language modeling interspeech pp notation use of g k vs g k b d g k should be clearly defined constant b and d notation should not be reused b is matrix in eq and batch size in sec notation p i j eq and before is kind of misleading as p i j is not the same as p i j minor comments p item list at bottom first item take takes p second paragraph will then contained will then contain p third paragaph to associated to associate sec first paragraph at the time being for the time being below eq most right right most below eq the second term of this equation the second term of the right hand side of this equation p second to last line smaller that the smaller than the p sec itemize first item millions million p last sentence we are the ours is the,7.0
671.json,the paper proposes a new neural architecture called dragnn for the transition based framework a dragnn uses tbrus which are neural units to compute hidden activations for the current state of a transition based system the paper proves that dragnns can cover a wide range of transition based methods in the literature in addition one can easily implement multitask learning systems with dragnns the experimental results shows that using dragnns the authors built near state of the art systems for tasks parsing and summarization the paper contains two major parts dragnn and demonstrations of its usages regarding to the first part the proposed dragnn is a neat tool for building any transition based systems however it is difficult to say whether the dragnn is novel transition based framework is already well defined and there a huge trend in nlp using neural networks to implement transition based systems in my opinion the difference between the stack lstm dyer et al and dragnn is slight of course the dragnn is a powerful architecture but the contribution here should be considered mainly in terms of software engineering in the second part the authors used dragnn to implement new transition based systems for different multi tasks the implementations are neat confirming that dragnn is a powerful architecture especially for multitask learning however we should bear in mind that the solutions employed are already there in the literature thus making difficult to judge the novelty of this part w r t the theme of the conference,6.0
671.json,overall this is a nice paper developing a unifying framework for these newer neural models is a worthwhile endeavor however it unclear if the dragnn framework in its current form is a significant standalone contribution the main idea is straightforward use a transition system to unroll a computation graph when you implement models in this way you can reuse code because modules can be mixed and matched this is nice but in my opinion is just good software engineering not machine learning research moreover there appears to be little incentive to use dragnn as there are no free things benefits that you get by using the framework for example if you write your neuralnet in an automatic differentiation library e g tensorflow or dynet you get gradients for free in the vw framework there are efficiency tricks that the credit assignment compiler provides for you which would be tedious to implement on your own there is also a variety of algorithms for training the model in a principled way i e without exposure bias i do not feel that my question about the limitations of the framework has been satisfactorily addressed let me ask it in a different way can you give me examples of a few models that i can not nicely express in the dragnn framework what if i wanted to implement,5.0
558.json,this paper introduces a new way of extending the count based exploration approach to domains where counts are not readily available the way in which the authors do it is through hash functions experiments are conducted on several domains including control and atari it is nice that the authors confirmed the results of bellemare in that given the right density estimator count based exploration can be effective it is also great the observe that given the right features we can crack games like montezuma revenge to some extend i however have several complaints first by using hashing the authors did not seem to be able to achieve significant improvements over past approaches without feature engineering the authors achieved only a fraction of the performance achieved in bellemare et al on montezuma revenge the proposed approaches in the control domains the authors also does not outperform vime so experimentally it is very hard to justify the approach second hashing although could be effective in the domains that the authors tested on it may not be the best way of estimating densities going forward as the environments get more complicated some learning methods are required for the understanding of the environments instead of blind hashing the authors claim that the advantage of the proposed method over bellemare et al is that one does not have to design density estimators but i would argue that density estimators have become readily available pixelcnn vaes real nvp gans that they can be as easily applied as can hashing training the density estimators is not difficult problem as more,4.0
558.json,the paper proposes a new exploration scheme for reinforcement learning using locality sensitive hashing states to build a table of visit counts which are then used to encourage exploration in the style of mbie eb of strehl and littman several points are appealing about this approach first it is quite simple compared to the current alternatives e g vime density estimation and pseudo counts second the paper presents results across several domains including classic benchmarks continuous control domains and atari games in addition there are results for comparison from several other algorithms dqn variants many of which are quite recent the results indicate that the approach clearly improves over the baseline the results against other exploration algorithms are not as clear more dependent on the individual domain game but i think this is fine as the appeal of the technique is its simplicity third the paper presents results on the sensitivity to the granularity of the abstraction i have only one main complaint which is it seems there was some engineering involved to get this to work and i do not have much confidence in the robustness of the conclusions i am left uncertain as to how the story changes given slight perturbations over hyper parameter values or enabling disabling of certain choices for example how critical was using pixelcnn or tying the weights or noisifying the output in the autoencoder or what happens if you remove the custom additions to bass the granularity results show that the choice of resolution is sensitive and even across games the story is not consistent the authors decide to use state based counts instead of state action based counts deviating from the theory which is odd because the reason to used lsh in the first place is to get closer to what mbie eb would advise via tabular counts there are several explanations as to why state based versus state action based counts perform similarly in atari the authors do not offer any why it seems like the technique could be easily used in dqn as well and many of the variants the authors compare to are dqn based so omitting dqn here again seems strange the authors justify their choice of trpo by saying it ensures safe policy improvement though it is not clear that this is still true when adding these exploration bonuses the case study on montezuma revenge while interesting involves using domain knowledge and so does not really fit well with the rest of the paper so in the end simple and elegant idea to help with exploration tested in many domains though i am not certain which of the many pieces are critical for the story to hold versus just slightly helpful which could hurt the long term impact of the paper after response thank you for the thorough response and again my apologies for the late reply i appreciate the follow up version on the robustness of simhash and state counting vs state action counting the paper addresses an important problem exploration suggesting a simple compared to density estimation counting method via hashing it is a nice alternative approach to the one offered by bellemare et al if discussion among reviewers were possible i would now try to assemble an argument to accept the paper specifically i am not as concerned about beating the state of the art in montezuma as reviewer as the merit of the current paper is one the simplicity of the hashing and on the wide comparison of domains vs the baseline trpo this paper shows that we should not give up on simple hashing there still seems to be a bunch of fiddly bits to get this to work and i am still not confident that these results are easily reproducible nonetheless it is an interesting new contrasting approach to exploration which deserves attention not important for the decision the argument in the rebuttal concerning dqn ac is a bit of a straw man i did not mention anything at all about ac i strictly referred to dqn which is less sensitive to parameter tuning than ac also bellemare main result on montezuma used dqn hence the omission of these techniques applied to dqn still seems a bit strange for the atari experiments the figure s from mnih et al points to instances of asynchronous one step sarsa with varied thread counts of course this will be sensitive to parameters it is both asynchronous online algorithms and the parameter varied is the thread count this is hardly indicative of dqn sensitivity to parameters since dqn is a single threaded b uses experience replay leading to slower policy changes another source of stability dqn uses a target network that changes infrequently perhaps the authors made a mistake in the reference graph in the figure i see no figure in,6.0
763.json,this manuscript proposes an approach for modeling correlated timeseries through a combination of loss functions which depend on neural networks the loss functions correspond to data fit term autoregressive latent state term and a term which captures relations between pairs of timeseries relations have to be given as prior information modeling relational timeseries is a well researched problem however little attention has been given to it in the neural network community perhaps the reason for this is the importance of having uncertainty in the representation the authors correctly identify this need and consider an approach which considers distributions in the state space the formulation is quite straightforward by combining loss functions the model adds to ziat et al in certain aspects which are well motivated but unfortunately implemented in an unconvincing way to start with uncertainty is not treated in a very principled way since the inference in the model is rather naive i would expect employing a vae framework for better uncertainty handling furthermore the gaussian co variance collapses into a variance which is the opposite of what one would want for modelling correlated time series there are approaches which take these correlations into account in the states e g moreover the treatment of uncertainty only allows for linear decoding function f this significantly reduces the power of the model state of the art methods in timeseries modeling have moved beyond this constraint especially in the gaussian process community e g comparing to a few of these methods or at least discussing them would be useful references kingma and welling auto encoding variational bayes arxiv damianou et al variational gaussian process dynamical systems nips mattos et al recurrent gaussian processes iclr frigola bayesian time series learning with gaussian processes university of cambridge phd thesis frigola et al variational gaussian process state space models nips one innovation is that the prior structure of the correlation needs to be given this is a potentially useful and also original structural component however it also constitutes a limitation in some sense since it is unrealistic in many scenarios to have this prior information moreover the particular regularizer that makes similar timeseries to have closeness in the state space seems problematic some timeseries groups might be more similar than others and also the similarity might be of different nature across groups these variations cannot be well captured distilled by a simple indicator variable eij furthermore these variables are in practice taken to be binary by looking at the experiments which would make it even harder to model rich correlations the experiments show that the proposed method works but they are not entirely convincing importantly they do not shed enough light into the different properties of the model w r t its different parts for example the effect and sensitivity of the different regularizers the authors state in a pre review answer that they amended with some more results but i can not see a revision in openreview please let me know if i have missed it from the performance point of view the results are not particularly exciting especially given the fact that it not clear which loss is better making it difficult to use the method in practice it would also be very interesting to report the optimized values of the parameters lambda to get an idea of how the different losses behave timeseries analysis is a very well researched area given the above it not clear to me why one would prefer to use this model over other approaches methodology wise there are no novel components that offer a proven advantage with respect to past methods the uncertainty in the states and the correlation of the time series are the aspects which could add an advantage but are not adequately researched in this paper,4.0
763.json,in absence of authors response the rating is maintained this paper introduces a nonlinear dynamical model for multiple related multivariate time series it models a linear observation model conditioned on the latent variables a linear or nonlinear dynamical model between consecutive latent variables and a similarity constraint between any two time series provided as prior data and non learnable the predictions constraints given by the three components of the model are gaussian because the model predicts both the mean and the variance or covariance matrix inference is forward only the model is evaluated on four datasets and compared to several baselines plain auto regressive models feed forward networks rnn and dynamic factor graphs dfgs which are rnns with forward and backward inference of the latent variables the model which introduces lateral constraints between different time series and which predicts both the mean and covariance seems interesting but presents two limitations first of all the paper should refer to variational auto encoders deep gaussian models which also predict the mean and the variance during inference secondly the datasets are extremely small for example the who contains only times series of time points although the experiments seem to suggest that the proposed model tends to outperform rnns the datasets are very small and the high variance in the results indicates that further experiments with longer time series are required the paper could also easily be extended with more information about the model what is the architecture of the mlp as well as time complexity comparison between the models especially between dfgs and this model minor remark the footnote on page seems to refer to the structural regularization term not to the dynamical term,4.0
626.json,summary this paper looks at the structure of the preimage of a particular activity at a hidden layer of a network it proves that any particular activity has a preimage of a piecewise linear set of subspaces pros formalizing the geometry of the preimages of a particular activity vector would increase our understanding of networks cons analysis seems quite preliminary and no novel theoretical results or clear practical conclusions the main theoretical conclusion seems to be the preimage being this stitch of lower dimensional subspaces would a direct inductive approach have worked e g working backwards from the penultimate layer say this is definitely an interesting direction and it would be great to see more results on it e g how does the depth width etc affect the division of space or what happens during training but it does not seem ready yet,4.0
626.json,i have not read the revised version in detail yet summary this paper studies the preimages of outputs of a feedforward neural network with relus pros the paper presents a neat idea for changes of coordinates at the individual layers cons quite unpolished not enough contributions for a finished paper comments in the first version the paper contains many typos and appears to be still quite unpolished the paper contains nice ideas but in my opinion it does not contribute sufficiently many results for a conference paper i would be happy to recommend for the workshop track irreversibly mixed and several other notions from the present paper are closely related to the concepts discussed in montufar pascanu cho bengio nips i feel that that paper should be cited here and the connections should be discussed in particular that paper also contains a discussion on the local linear maps of relu networks i am curious about the practical considerations when computing the pre images the definition should be rather straight forward really but the implementation computation could be troublesome detailed comments on page can easily be shown to be many to one in general on page for each point x l the parentheses in the superscript are missing after eq the mapping is unique is missing when w and w are linearly independent eq should be a vector above eq collected the weights ai into the vector w and bias b period is missing on page illustrate the preimage for the case of points on the lines respectively please indicate which is which in figure is this a sketch or the actual illustration of a network in the latter case please state the specific value of x and the weights that are depicted also define and explain the arrows precisely what are the arrows in the gray part on page this means that the preimage is just the point x l the points that w maps to x l on page the first display equation there is an index i on the left but not on the right hand side the quantifier in the right hand side is not clear generated by the mapping w i subscript get mapped to this hyperplane to zero remaining remaining from what using e g grassmann cayley algebra how about using elementary linear algebra gives rise to a linear manifold with dimension one lower at each intersection this holds if the hyperplanes are in general position is complete in the input space forms a basis remaining kernel remaining from what kernel here kernel is referring to nullspace or to a matrix of orthonormal basis vectors of the nullspace or to what specifically figure nullspaces of linear maps should pass through the origin from pairwise intersections cap indicated as arrows or the shaded area this description is far from clear typos peieces diminsions netork me,4.0
626.json,i really appreciate the directions the authors are taken and i think something quite interesting can come out of it i hope the authors continue on this path and are able to come up with something quite interesting soon however i feel this paper right now is not quite ready is not clear to me what the results of this work are yet the preimage construction is not obviously at least not to me helpful it feels like the right direction but it did not got to a point where we can use it to identify the underlying mechanism behind our models we know relu models need to split apart and unite different region of the space and i think we can agree that we can construct such mechanism it comes from the fact that relu models are universal approximators though this does not speak to what happens in practice all in all i think this work needs a bit more work yet,4.0
630.json,this paper proposed two incremental ideas to extend the current state of the art summarization work based on seqseq models with attention and copy pointer mechanisms this paper introduces pass reading where the representations from the st pass is used to re wight the contribution of each word to the sequential representation of the nd pass the authors described how such a so called read again process applies to both gru and lstm on the decoder side the authors also use the softmax to choose between generating from decoder vocabulary and copying a source position with a new twist of representing the previous decoded word y t differently this allows the author to explore a smaller decoder vocabulary hence led to faster inference time without losing summarization performance this paper claims the new state of the art on duc but the comparison on gigaword seems to be incomplete missing more recent results after rush etc while the overall work is solid there are also other things missing scientifically for example how much computational costs does the nd pass reading add to the end to end system how does the decoder small vocabulary trick work without nd pass reading on the encoder side for both summarization performance and runtime speed there are other ways to improve the embedding of a sentence how does the nd pass reading compare to recent work from multiple authors on self attention and or lstmn for example cheng et al long short term memory networks for machine reading parikh et al a decomposable attention model for natural language inference,6.0
519.json,i think this build upon previous works in the attempt of doing something similar to batch norm specific for rnns to me the experiments are not yet very convincing i think is not clear this works better than e g layer norm or not significantly so i am not convinced on how significant the speed up is either i can appreciate is faster but it does not feel like order of magnitude faster the theoretical analysis also does not provide any new insights all in all i think is good incremental work but maybe is not yet significant enough for iclr,6.0
688.json,this paper presents iterative power an off policy variation on power a policy gradient algorithm in the reward weighted family i am not familiar enough with this type lower bound scheme to comment on it it looks like the end result is less conservative step sizes in policy parameter space all expectation based algorithms and their kl regularized cousins a la trpo take smallish steps and this might be a sensible way to accelerate them the description of the experiments in section vi is insufficient for reproducibility is the cart moved right supposed to be a positive force is applied to the cart how is negative force applied what is the representation of the state what is the distribution of initial states a linear policy is insufficient for swing up and balance of a cart pole are you only doing balancing what is the noise magnitude of the policy how was it chosen how long were the episodes the footnote at the bottom of page threw me off if you are using newton method where is the discussion of gradients and hessians i thought the argmaxtheta operator was a stand in for an em style step which i how i read eq in the kober paper,3.0
688.json,the paper considers the problem of reinforcement learning where the number of policy updates is required to be low the problem is well motivated and the author provides an interesting modification to the power algorithm along with variational bounds on the value function lemmas which are interesting in themselves they also provide numerical results on the cartpole problem and a problem in online advertising with real data overall this is a strong well written paper my main reservation is whether it is completely appropriate for iclr since the log concavity assumption the model relies on appear to restrict to simpler models where representations will be not in fact be learned other comments there is a general lack of baselines in the numerical experiment section i acknowledge this is somewhat of an unusual setting but even a simple well justified baseline would have been welcome since cartpole is a relatively simple problem and the advertising dataset is presumably private perhaps a way to generate a synthetic advertising dataset would have been interesting i was confused by the control variates as constant scalars are they meant to be constant baselines and if so they appear to be treated as hyperparameters why are they not learned or estimated there is an interesting section on constrained optimization but as it is feels a bit disconnected from the rest of the paper it appears applicable to the problem of online advertising but is not mentioned in the corresponding experimental section also might be worth adding a citation to the literature of constrained mdps which develops similar lagrangian ideas,7.0
688.json,the paper presents an interesting modification to power algorithm that is well motivated the main limitation of this paper is the lack of comparison with other methods and on richer problems the experiments have not given confidence to show its claimed benefits generality and scalability over prior methods giving this confidence doesn t necessarily require running your method on all large scale domains or doing exhaustic hyper parameter search but for example it could go beyond current domains cartpole only optimizes parameters ad targeting task lacks comparison with alternative methods since this method is built on power and closely connected with rwr it is likely there are limits to performance which may become apparent when the method is tried on other domains and with other benchmark methods e g even standard ones like importance sampling based off policy learning is known to suffer in high dimensional or continuous action space limits of rwr power like methods based on their connection with entropy regularized rl,5.0
372.json,a new memory module based on k nn is presented the paper is very well written and the results are convincing omniglot is a good sanity test and the performance is surprisingly good the artificial task shows us that the authors claims hold and highlight the need for better benchmarks in this domain and the translation task eventually makes a very strong point on practical usefulness of the proposed model i am not a specialist in memory networks so i trust the authors to double check if all relevant references have been included another reviewer mentioned associative lstm but besides that i think this is a very nice and useful paper i hope the authors will publish their code,8.0
372.json,the paper proposes a new memory module to be used as an addition to existing neural network models pros clearly written and original idea useful memory module shows nice improvements tested on some big tasks cons no comparisons to other memory modules such as associative lstms etc,7.0
667.json,i read the authors response and maintain my rating this paper introduces an approach for integrating a direct acyclic graph structure of the data into word code embeddings in order to leverage domain knowledge and thus help train an rnn with scarce data it is applied to codes of medical visits each code is part of an ontology which can be represented by a dag where codes correspond to leaf nodes and where different codes may share common ancestors non leaf nodes in the dag instead of embedding merely the leaf nodes one can also embed the non leaf nodes and the embeddings of the code and its ancestors can be combined using a convex sum that convex sum can be seen as an attention mechanism over the representation the attention weights depend on the embeddings and the weights of an mlp meaning that the model can separate learning the code embeddings and the interaction between the codes embedding codes are pretrained using glove then fine tuned the model is properly evaluated on two medical datasets with several variations to isolate the contribution of the dag gram or gram vs rnn or randomdag and of pretraining the embeddings rnn vs rnn gram vs gram both are shown to help achieve the best performance and the evaluation methodology seems thorough the paper is also well written and the case for mlp attention instead of a plain dot product of embeddings was made by the authors my only two comments would be why is there a softmax in equation given that the loss is multivariate cross entropy in the predicted visit several codes could be equal to not a a single class cross entropy what is the embedding dimension m,6.0
667.json,summary this paper presents a method for enriching medical concepts with their parent nodes in an ontology the method employs an attention mechanism over the parent nodes of a medical concept to create a richer representation of the concept itself the rationale of this is that for infrequent medical concepts the attention mechanism will rely more on general concepts higher in the ontology hierarchy while for frequent ones will focus on the specific concept the attention mechanism is trained together with a recurrent neural network and the model accuracy is tested on two tasks the first task aims at prediction the diagnosis categories at each time step while the second task aims at predicting whether or not a heart failure is likely to happen after the t th step results shows that the proposed model works well in condition of data insufficiency overall judgment the proposed model is simple but interesting the ideas presented are worth to expand but there are also some points where the authors could have done better the learning of the representation of concepts in the ontology is a bit naive for example the authors could have used some kind of knowledge base factorization approach to learn the concepts or some graph convolutional approach i do not see why the the very general factorization methods for knowledge bases do not apply in the case of ontology learning i also found strange that the representation of leaves are fine tuned while the inner nodes are not it is a specific reason to do so regarding the presentation the paper is clear and the qualitative evaluation is insightful detailed comments figure please use the same image format with the same resolution,6.0
536.json,summary this paper presents a study of the number of hidden units and training examples needed to learn functions from a particular class this class is defined as those boolean functions with an upper bound on the variability of the outputs pros the paper promotes interesting results from the theoretical computer science community to investigate the efficiency of representation of functions with limited variability in terms of shallow feedforward networks with linear threshold units cons the analysis is limited to shallow networks the analysis is based on piecing together interesting results however without contributing significant innovations the presentation of the main results and conclusions is somewhat obscure as the therein appearing terms constants do not express a clear relation between increased robustness and decreasing number of required hidden units comments in the abstract one reads the universal approximation theorem for neural networks says that any reasonable function is well approximated by a two layer neural network with sigmoid gates but it does not provide good bounds on the number of hidden layer nodes or the weights in page the paper points the reader to a review article it could be a good idea to include also more recent references given the motivation presented in the abstract of the paper it would be a good idea to also comment of works discussing the classes of boolean functions representable by linear threshold networks for instance the paper hyperplane arrangements separating arbitrary vertex classes in n cubes wenzel ay paseman discusses various classes of functions that can be represented by shallow linear threshold networks and provides upper and lower bounds on the number of hidden units needed for representing various types of boolean functions in particular that paper also provides lower bounds on the number of hidden units needed to define a universal approximator it certainly would be a good idea to discuss the results on the learning complexity in terms of measures such as the vc dimension thank you for the explanations regarding the constants so if the noise sensitivity is kept constant larger values of epsilon are associated with a smaller value of delta and of epsilon nonetheless the description in theorem is in terms of poly epsilon delta which still could increase also in lemma reducing the sensitivity at a constant noise increases the bound on k the fact that the descriptions are independent of n seems to be related to the definition of the noise sensitivity as an expectation over all inputs this certainly deserves more discussion one good start could be to discuss examples of functions with an upper bound on the noise sensitivity aside from the linear threshold functions discussed in lemma also reverse statements to lemma would be interesting describing the noise sensitivity of juntas specifically even if only as simple examples on page variables is polynomial in the noise sensitivity parameters should be inverse of minor comments on page proposition should be lemma,5.0
536.json,this work finds a connection between bourgain junta problem the existing results in circuit complexity and the approximation of a boolean function using two layer neural net i think that finding connections between different fields and applying the insights gained is a valid contribution for this reason i recommend acceptance but my current major concern is that this work is only constrained to the domain of boolean hypercube which is far from what is done in practice continuous domain indeed the authors could argue that understanding the former is a first step but if the connection is only suitable for this case and not adaptable to more general scenarios then it probably would have limited interest,6.0
561.json,the paper presents a simple method for constructing a visual hierarchy of imagenet classes based on a cnn trained on discriminate between the classes it investigates two metrics for measuring inter class similarity softmax probability outputs i e the class confusion matrix and l distance between fc features along with three methods for constructing the hierarchy given the distance matrix approximation central point minimal spanning tree and multidimensional scaling of borg groenen there are two claimed contributions constructs a biology evolutionary tree and gives insight into the representations produced by deep networks regarding while the motivation of the work is grounded in biology in practice the method is based only on visual similarity the constructed trees thus can t be expected to reflect the evolutionary hierarchy and in fact there are no quantitative experiments that demonstrate that they do regarding the technical depth of the exploration is not sufficient for iclr i m not sure what we can conclude from the paper beyond the fact that cnns are able to group categories together based on visual similarities and deeper networks are able to do this better than more shallow networks fig in summary this paper is unfortunately not ready for publication at this time,3.0
424.json,the paper shows the relation between stochastically perturbing the parameter of a model at training time and considering a mollified objective function for optimization aside from eqs where i found hard to understand what the weak gradient g exactly represents eq is intuitive and the subsequent section clearly establishes for a given class of mollifiers the equivalence between minimizing the mollified loss and training under gaussian parameter noise the authors then introduce generalized mollifiers to achieve a more sophisticated annealing effect applicable to state of the art neural network architectures e g deep relu nets and lstm recurrent networks the resulting annealing effect can be counterintuitive in section the binomial bernoulli parameter grows from deterministic identity layers to deterministic relu layers meaning that the network goes initially through a phase of adding noise this might effectively have the reverse effect of annealing annealing schemes used in practice seem very engineered e g algorithm that determines how units are activated at a given layer consists of successive steps due to the more conceptual nature of the authors contribution various annealing schemes have been proposed but the application of the mollifying framework is original it could have been useful to reserve a portion of the paper to analyze simpler models with more basic non generalized mollifiers for example i would have liked to see simple cases where the perturbation schemes derived from the mollifier framework would be demonstrably more suitable for optimization than a standard heuristically defined perturbation scheme,6.0
577.json,this paper proposes to use a linear classifier as the probe for the informativeness of the hidden activations from different neural network layers the training of the linear classifier does not affect the training of the neural network the paper is well motivated for investigating how much useful information or how good the representations are for each layer the observations in this paper agrees with existing insights such as fig a too many random layers are harmful fig b training is helpful fig lower layers converge faster than higher layer fig too deep network is hard to train and skip link can remedy this problem however this paper has following problems it is not sufficiently justified why the linear classifier is a good probe it is not crystal clear why good intermediate features need to show high linear classification accuracy more theoretical analysis and or intuition will be helpful this paper does not provide much insight on how to design better networks based on the observations designing a better network is also the best way to justify the usefulness of the analysis overall this paper is tackling an interesting problem but the technique the linear classifier as the probe is not novel and more importantly need to be better justified moreover it is important to show how to design better neural networks using the observations in this paper,4.0
609.json,previous literature uses data derived adjacency matrix a to obtain neighbors to use as foundation of graph convolution they propose extending the set of neighbors by additionally including nodes reachable by i k steps in this graph this introduces an extra tunable parameter k so it needs some justification over the previous k solution in one experiment provided merk using k worked better they do not specify which k that used just that it was big enough for their to be p nodes obtained as neighbors in the second experiment mnist they used k for their experiments which is what previous work coats ng proposed as well a compelling experiment would compare to k and show that using k gives improvement strong enough to justify an extra hyper parameter,3.0
609.json,update i thank the authors for their comments after reading them i decided to increase the rating this paper proposes a variant of the convolution operation suitable for a broad class of graph structures for each node in the graph a set of neighbours is devised by means of random walk the neighbours are ordered by the expected number of visits as a result the graph is transformed into a feature matrix resembling matlab s caffe s imcol output the convolution itself becomes a matrix multiplication although the proposed convolution variant seems reasonable i m not convinced by the empirical evaluation the mnist experiment looks especially suspicious i don t think that this dataset is appropriate for the demonstration purposes in this case in order to make their method applicable to the data the authors remove important structural information relative locations of pixels thus artificially increasing the difficulty of the task at the same time they are comparing their approach with regular cnns and conclude that the former performs poorly and does not even reach an acceptable accuracy for the particular dataset i guess to justify the presence of mnist or similar datasets in the experimental section the authors should modify their method to incorporate additional graph structure e g relative locations of nodes in cases when the relation between nodes cannot be fully described by a similarity matrix i believe in its current form the paper is not yet ready for publication but may be later resubmitted to a workshop or another conference after the concern above is addressed,6.0
609.json,this work proposes a convolutional architecture for any graph like input data where the structure is example dependent or more generally any data where the input dimensions that are related by a similarity matrix if instead each input example is associated with a transition matrix then a random walk algorithm is used generate a similarity matrix developing convolutional or recurrent architectures for graph like data is an important problem because we would like to develop neural networks that can handle inputs such as molecule structures or social networks however i do not think this work contributes anything significant to the work that has already been done in this area the two main proposals i see in this paper are for data associated with a transition matrix this paper proposes that the transition matrix be converted to a similarity matrix this seems obvious for data associated with a similarity matrix the k nearest neighbors of each node are computed and supply the context information for that node this also seems obvious perhaps i have misunderstood the contribution but the presentation also lacks clarity and i cannot recommend this paper for publication specific comments on page an interesting attribute of this convolution as compared to other convolutions on graphs is that it preserves locality while still being applicable over different graphs with different structures this is false the other proposed architectures can be applied to inputs with different structures e g duvenaud et al lusci et al for nn architectures on molecules specifically,3.0
520.json,this paper proposes an extension of pixelcnn method that can be conditioned on text and spatially structured constraints segmentation keypoints it is similar to reed a except the extension is built on top of pixelcnn instead of gan after reading the author comment i realized the argument is not that conditional pixelcnn is much better than conditional gan i think the authors can add more discussions about pros and cons of each model in the paper i agree with the other reviewer that some analysis of training and generation time would be helpful i understand it takes o n instead of o for pixelcnn method to do sampling but is that the main reason that the experiments can only be conducted in low resolution x i also think since there are not quantitative comparisons it makes more sense to show more visualizations than examples overall the generated results look reasonably good and have enough diversity the color mistake is an issue where the author has provided some explanations in the comment i would say the technical novelty is incremental since the extension is straightforward and similar to previous work i lean toward accepting because it is very relevant to iclr community and it provides a good opportunity for future investigation and comparison between different deep image synthesis methods,5.0
520.json,this work focuses on conditional image synthesis in the autoregressive framework based on pixelcnn it trains models that condition on text as well as segmentation masks or keypoints experiments show results for keypoint conditional synthesis on the cub birds and mhp human pose dataset and segmentation conditional synthesis on ms coco objects this extension to keypoint segment conditioning is the primary contribution over existing pixelcnn work qualitative comparison is made to gan approaches for synthesis pros the paper demonstrates additional capabilities for image generation in the autoregressive framework suggesting that it can keep pace with the latest capabilities of gans qualitative comparison in figure suggests that pixelcnn and gan based methods may make different kinds of mistakes with pixelcnn being more robust against introducing artifacts some effort is put forth to establish quantitative evaluation in terms of log likelihoods table cons comparison to other work is difficult and limited to qualitative results the qualitative results can still be somewhat difficult to interpret i believe supplementary material or an appendix with many additional examples could partially alleviate this problem the extension of pixelcnn to conditioning on additional data is fairly straightforward this is a solid engineering contribution but not a surprising new concept,7.0
520.json,first it allows us to assess whether auto regressive models are able to match the gan results of reed et al a does it though because the resolution is so bad and resolution limitations are not addressed until the second to last paragraph of the paper and figure only shows results picked randomly picked to be favorable to pixelcnn that hardly seems conclusive the segmentation masks and keypoints are pretty strong input constraints it hard to tell how much coherent object and scene detail is emerging because the resolution is so low for example the cows in figure look like color blobs basically any color blob that follows an exact cow segmentation mask will look cow like the amount of variation is impressive though how can we assess how much the model is replaying training data figure tries to get at this but i wonder how much each of the red birds for instance is mostly copied from a particular training example i am unsatisfied with the answers to the pre review questions you did not answer my questions the paper would benefit from concrete numbers on training time epochs and testing time you did not say why you can not make high resolution comparisons yes it slower at test time is it prohibitively slow or is it slightly inconvenient there really are not that many comparisons in the paper anyway so it if takes an hour to generate a result that does not seem prohibitive to be clear about my biases i do not think pixelcnn is the right way to do deep image generation texture synthesis methods used these causal neighborhoods with some success but only because there was not a clear way to do the optimization more globally kwatra et al texture optimization for example based synthesis being one of the first alternatives it seems simply incorrect to make hard decisions about what pixel values should be in one part of the image before synthesizing another part of the image another texture synthesis strategy to help fight back against this strict causality was coarse to fine synthesis and i do see some deep image synthesis methods exploring that it seems much more correct to have a deeper network and let all output pixels be conditioned on all other pixels this conditioning will implicitly emerge at intermediate parts of the network that said i could be totally wrong and the advantages stated in the paper could outweigh the disadvantages but this paper does not feel very honest about the disadvantages overall i think the results are somewhat tantalizing especially the ability to generate diverse outputs but the resolution is extremely low especially compared to the richness of the inputs the network gets a lot of hand holding from rich inputs it does at least learn to obey them the deep image synthesis literature is moving very quickly the field needs to move on from proof of concept papers the first to show a particular result is possible to more thorough comparisons this paper has an opportunity to be a more in depth comparison but it not very deep in that regard there is not really an apples to apples comparison between pixelcnn and gan nor is there a conclusion statement about why that is impossible there is not any large scale comparison either qualitative or quantified by user studies about the quality of the results,6.0
465.json,the paper presents an interesting and very detailed study of targeted and non targeted adversarial examples in cnns i m on the fence about this paper but am leaning towards acceptance such detailed empirical explorations are difficult and time consuming to construct yet can serve as important stepping stones for future work i see the length of the paper as a strength since it allows for a very in depth look into the effectiveness and transferability of different kinds of adversarial examples there are however some concerns while the length of the paper is a strength in my mind the key contributions should be made much more clear as evidenced by my comment earlier i got confused at some point between the ensemble non ensemble method and about the contribution of the clarifai evaluation and what i should be focusing on where i d strongly suggest a radical revision which more clearly focuses the story first we demonstrate that non targeted attacks are easy while targeted attacks are hard evidenced by a key experiment comparing the two we refer to appendix or later sections for the extensive exploration of e g current section thus we propose an ensemble method that is able to handle targeted attacks much better evidenced by experiments focusing on the comparison between ensemble and non ensemble method both in a controlled setting and on clarifai also here are all the other details and explorations instead of using resnet res net and resnet as three of the five models it would have been better to use one resnet architecture and the other two say alexnet and network in network this would make the ensemble results a lot more compelling,6.0
465.json,this paper present an experimental study of the robustness of state of the art cnns to different types of attacks in the context of image classication specifically an attack aims to fool the classification system with a specially corrupted image i e making it misclassify the image as any wrong class non targeted attack or a target class chosen in advance by the attacker targeted attack for instance the attacker could corrupt an image of an ostrich in such a way that it would be classified as a megalith even though the attacker agenda is not so clear in this example it is still interesting to study the weaknesses of current systems in view of improving them in general and actual risks with e g autonomous vehicles the paper is mostly experimental in short it compares different strategies already published in previous papers for all popular networks vgg googlenet resnet and the two aforementionned types of attacks the experiments are well conducted and clearly exposed a convincing point is that attacks are also conducted on clarifai com which is a black box classification system some analysis and insightful explanations are also provided to help understanding why cnns are prone to such attacks section to sum up the main findings are that non targeted attacks are easy to perform even on a black box system non targeted attacks are more difficult to realize with existing schemes but the authors propose a new approach for that that vastly improves over existing attacks even though it still far from perfect success rate on clarifai com versus with previous schemes arguably the paper still has some weaknesses the authors are treating the resnet based networks as different yet they are obviously clearly correlated see table for instance this is naturally expected because their architecture is similar only their depth varies hence it does not sound very fair to state that one interesting finding is that the first misclassified label non targeted is the same for all models except vgg and googlenet i e the three resnet based networks a subjective measure is employed to evaluate the effectiveness of the attacks on the black box system while this is for a good reason clarifai com returns image labels that are different from imagenet it is not certain that the reported numbers are fair even though the qualitative results look convincing the novelty of the proposed approach optimizing an ensemble of network instead of a single network is limited however this was not really the point of the paper and it is effective so it seems ok overall the paper is quite long this is expected because it is an extensive evaluation study but still i suggest the authors prune some near duplicate content e g section has a high overlap with section etc the paper would benefit from additional discussions with the recent and related work of fawzi et al nips in section indeed the work of fawzi et al is mostly theoretical and well aligned with the experimental findings and observations in particular in section to conclude i think that this paper is somewhat useful for the community and could help to further improve existing architectures as well as better assess their flaws and weaknesses,7.0
465.json,i reviewed the manuscript as of december th summary the authors investigate the transferability of adversarial examples in deep networks the authors confirm that transferability exists even in large models but demonstrate that it is difficult to manipulate the network to adversarially perturb an image into a specifically desired label the authors additionally demonstrate real world attacks on a vision web service and explore the geometric properties of adversarial examples major comments the paper contains a list of many results and it is not clear what single message this paper provides as mentioned in the comments this paper is effectively pages and page of results in the appendix heavily discussed throughout the main body of the paper although there is no strict page limit for this conference i do feel this pushes the spirit of a conference publication i do not rule out this paper for acceptance based on the length but i do hold it as a negative because clarity of presentation is an important quality if this paper is ultimately accepted i would suggest that the authors make some effort to cut down the length even further beyond the pages posted elsewhere i have marked some sections to highlight areas that may be trimmed the section of geometric understanding is similar to results of adversarial perturbations of deep neural networks in warde farley and goodfellow see figure i am not clear what the authors show above and beyond these results if there are additional findings the authors should emphasize them the authors expand on observations by goodfellow et al and szegedy et al demonstrating that large scale models are susceptible to adversarial perturbations see also kurakin et al the authors additionally demonstrate that attempting to perform adversarial manipulation to convert an image to a particular desired label is more difficult the authors demonstrate that they can target a real world vision api these results are compelling but it is not clear what these results demonstrate above and beyond papernot et al as far i can understand i think that the most interesting result from this paper not previously described in the literature is to note about the unique difficulty about performing adversarial manipulation to convert an image to a particular desired label the rest of the results appear to expand on other results that have already appeared in the literature and the authors need to better explain what these makes these results unique above and beyond previous work areas to trim the paper table is not necessary just cite other results or write the top numbers in the text condense section and cite heavily figure panels may be overlaid to highlight a comparison,5.0
388.json,paper summary the paper introduces a question answering model called dynamic coattention network dcn it extracts co dependent representations of the document and question and then uses an iterative dynamic pointing decoder to predict an answer span the proposed model achieves state of the art performance outperforming all published models paper strengths the proposed model introduces two new concepts to qa models using attention in both directions and a dynamic decoder which iterates over multiple answer spans until convergence or maximum number of iterations the paper also presents ablation study of the proposed model which shows the importance of their design choices it is interesting to see the same idea of co attention performing well in different domains visual question answering and machine reading comprehension the performance breakdown over document and question lengths figure strengthens the importance of attention for qa task the proposed model achieves state of the art result on squad dataset the model architecture has been clearly described paper weaknesses future thoughts the paper provides model performance when the maximum number of iterations is and i would like to see how the performance of the model changes with the number of iterations i e the model performance when that number is and is there a clear trend what type of questions is the model able to get correct with more iterations as with many deep learning approaches the overall architecture seems quite complex and the design choices seem to be driven by performance numbers as future work authors might try to analyze qualitative advantages of different choices in the proposed model what type of questions are correctly answered because of co attention mechanism instead of attention in a single direction when using maxout highway network instead of a simple mlp etc preliminary evaluation novel and state of the art question answering approach model is clearly described in detail in my thoughts a clear accept,8.0
388.json,summary the paper proposes a novel deep neural network architecture for the task of question answering on the squad dataset the model consists of two main components coattention encoder and dynamic pointer decoder the encoder produces attention over the question as well as over the document in parallel and thus learns co dependent representations of the question and the document the decoder predicts the starting and the end token of the answer iteratively with the motivation that multiple iterations will help the model escape local maxima and thus will reduce the errors made by the model the proposed model achieved state of art result on squad dataset at the time of writing the paper the paper reports some analyses of the results such as performance across question types document question answer lengths etc the paper also performs some ablation studies such as performing only single round of iteration on decoder etc strengths the paper is well motivated with two main motivations co attending to the document and the question and iteratively producing the answer the proposed model architecture is novel and the design choices made seem reasonable the experiments show that the proposed model outperforms the existing model at the time of writing the paper on the squad dataset by significant margin the analyses of the results and the ablation studies performed as per someone request provide insights into the various modelling design choices made weaknesses questions suggestions in order to gain insights into how much each additional iteration in the decoder help i would like to see the following for every iteration report the mean f for questions that converged in that iteration along with the number of questions that converged in that iteration example of question in figure is an interesting example where the model is unable to decide between multiple local maxima despite several iterations could authors please report how often this happens in order to estimate how much modelling of attention in the encoder helps it would be good if authors could report the performance of the model when attention is not modeled at all in the encoder neither over question nor over document i would like to see the variation in the performance of the proposed model for questions that require different types of reasoning table in squad paper this would provide insights into what are the strengths and weaknesses of the proposed model w r t the type reasoning required in wang and jiang the attention is predicted over question for each word in the document but in table when performing ablation study to make the proposed model similar to wang and jiang c d is set to c q but isn t c q attention over document for each word in the question so how is this similar to wang and jiang s attention i think qa d will be similar to wang and jiang attention since qa d is attention over question for each word in the document please clarify in section n and m are swapped when explaining the document and question encoding matrix please fix it review summary the paper presents a novel and interesting model for the task of question answering on squad dataset and shows that the model outperforms existing models however to gain more insights into the functioning of the model i would like see more analyses of the results and one more ablation study see weaknesses section above,8.0
388.json,this paper proposed a dynamic coattention network for the question answering task with long contextual documents the model is able to encode co dependent representations of the question and the document and a dynamic decoder iteratively pointing the potential answer spans to locate the final answer overall this is a well written paper although the model is a bit complicated coattention encoder iterative dynamic pointering decoder and highway maxout network the intuitions behind and the details of the model are clearly presented also the performance on the squad dataset is good i would recommend this paper to be accepted,8.0
737.json,strengths an interesting proposal for a smaller cnn architecture designed for embedded cnn applications balanced exploration of cnn macroarchitecture and microarchitecture with fire modules x less memory usage than alexnet keeping similar accuracy strong experimental results weaknesses would be nice to test sqeezenet on multiple tasks lack of insights and rigorous analysis into what factors are responsible for the success of squeezenet for example how are resnet and googlenet connected to the current architecture another old paper analysis of correlation structure for a neural predictive model with application to speech recognition neural networks also showed that the by pass architecture by mixing linear and nonlinear prediction terms improves long term dependency in nn based on rigorous perturbation analysis can the current work be placed more rigorously on theoretical analysis,5.0
737.json,summary the paper presents a smaller cnn architecture called squeezenet for embedded deployment the paper explores cnn macroarchitecture and microarchitecture to develop squeezenet which is composed of fire modules pros achieves x less memory usage than alexnet while keeping similar accuracy cons questions complex by pass has less accuracy than simple by pass and simple by pass is like resnet bottlenecks and complex by pass is like inception modules in googlenet can we say that these two valiants of squeezenet are adaptation of concepts seen in googlenet and resnet if so then shouldn t be there a squeezenet like model that achieves similar accuracy compared with googlenet and resnet,7.0
367.json,the paper presents a novel look at binary auto encoders formulating the objective function as a min max reconstruction error over a training set given the observed intermediate representations the author shows that this formulation leads to a bi convex problem that can be solved by alternating minimisation methods this part is non trivial and is the main contribution of the paper proof of concept experiments are performed showing improvements for hidden layer auto encoders with respect to a vanilla approach the experimental section is fairly weak because the literature on auto encoders is huge and many variants were shown to perform better than straightforward approaches without being more complicated e g denoising auto encoders yet the paper presents an analysis that leads to a new learning algorithm for an old problem and is likely worth discussing,7.0
367.json,the author attacks the problem of shallow binary autoencoders using a minmax game approach the algorithm though simple appears to be very effective the paper is well written and has sound analyses although the work does not extend to deep networks immediately its connections with other popular minmax approaches eg gans could be fruitful in the future,7.0
625.json,this paper presents an architecture and corresponding algorithms for learning to act across multiple tasks described in natural language the proposed system is hierarchical and is closely related to the options framework however rather than learning a discrete set of options it learns a mapping from natural instructions to an embedding which implicitly dynamically defines an option this is a novel and interesting new perspective on options which had only slightly been explored in the linear setting see comments below i find the use of policy distillation particularly relevant for this setting this on its own could be a takeaway for many rl readers who might not necessarily be interested about nlp applications in general the paper does not describe a single simple end to end recipe for learning with this architecture it rather relies on many recent advances skillfully combined generalized advantage estimation analogy making regularizers l regularization memory addressing matrix factorization policy distillation i would have liked to see some analysis but understand that it would have certainly been no easy task for example when you say while the parameters of the subtask controller are frozen this sounds to me like you are having some kind of two timescale stochastic gradient descent i am also unsure how you deal with the smdp structure in your gradient updates when you move to the temporal abstractions setting i am inclined to believe that this approach has the potential to scale up to very large domains but paper currently does not demonstrate this empirically like any typical reviewer i would be tempted to say that you should perform larger experiments however i am also glad that you have shown that your system also performs well in a toy domain the characterization in figure is insightful and makes a good point for the analogy regularizer and need for hierarchy overall i think that the proposed architecture would inspire other researchers and would be worth being presented at iclr it also contains novel elements subtask embeddings which could be useful outside the deep and nlp communities into the more traditional rl communities parameterized options sutton et al did not explore the concept of parameterized options originally it only came later perhaps first with optimal policy switching algorithms for reinforcement learning comanici precup or unified inter and intra options learning using policy gradient methods levy shimkin konidaris also has a line of work on parametrized skills learning parameterized skills da silva konidaris barto or reinforcement learning with parameterized actions masson ranchod konidaris also i feel that there is a very important distinction to be made with the expression parametrized options in your work parametrized comes in two flavors in the spirit of policy gradient methods we can have options whose policies and termination functions are represented by function approximators in the same way that we have function approximation for value functions those options have parameters and we might call them parameterized because of that this is the setting of comanicy precup levy shimkin bacon precup mankowitz mann and mannor for example now there a second case where options policies skills take parameters as inputs and act accordingly this is what konidaris al means by parameterized whose meaning differs from the function approximation case above in your work the embedding of subtasks arguments is the input to your options and therefore behave as parameters in the sense of konidaris related work i ctrl f through the pdf but could not find references to any of s r k branavan work branavan phd thesis had to do with using control techniques from rl in order to interpret natural instructions so as to achieve a goal for example in reinforcement learning for mapping instructions to actions an rl agent learns from windows troubleshooting articles to interact with ui elements environment through a softmax policy over linear features learned by policy gradient methods as you mention under instruction execution the focus of your work in on generalization which is not treated explicitely afaik in branavan work still it shares some important algorithmic and architectural similarities which should be discussed explicitly or perhaps even compared to in your experiments as a baseline zero shot and uvfa it might also want to consider learning shared representations for value functions in multi task reinforcement learning borsa graepel shawe taylor under the section zero shot tasks generalization minor issues i first read the abstract without knowing what the paper would be about and got confused in the second sentence you talk about longer sequences of previously seen instructions but i did not know what clearly meant by instructions until the second to last sentence where you specify instructions described by natural language you could perhaps re order the sentences to make it clear in the second sentence that you are interested in nlp problems zero generalization i was familiar with the term one shot but not zero shot the way that the second sentence to have similar zero shot follows from the first sentence might as well hold for the one shot setting you could perhaps add a citation to zero shot or define it more explicitly from the beginning and compare it to the one shot setting it could also be useful if you explain how zero shot relates to just the notion of learning with priors under section you say cooperate with each other which sounds to me very much like a multi agent setting which your work does not explore in this way you might want to choose a different terminology or explain more precisely if there is any connection with the multi agent setting the second sentence of section is way to long and difficult to parse you could probably split it in two or three sentences,7.0
625.json,the paper presents a hierarchical drl algorithm that solves sequences of navigate and act tasks in a d maze domain during training and evaluation a list of sub goals represented by text is given to the agent and its goal is to learn to use pre learned skills in order to solve a list of sub goals the authors demonstrate that their method generalizes well to sequences of varying length as well as to new combinations of sub goals i e if the agent knows how to pick up a diamond and how to visit an apple it can also visit the diamond overall the paper is of high technical quality and presents an interesting and non trivial combination of state of the art advancements in deep learning dl and deep reinforcement learning drl in particular the authors presents a drl agent that is hierarchical in the sense that it can learn skills and plan using them the skills are learned using a differential temporally extended memory networks with an attention mechanism the authors also make a novel use of analogy making and parameter prediction however i find it difficult to understand from the paper why the presented problem is interesting and why had not it bee solved before since the domain being evaluated is a simple d maze using deep networks is not well motivated similar problems have been solved using simpler models in particular there is a reach literature about planning with skills that had been ignored completely by the authors since all of the skills are trained prior to the evaluation of the hierarchical agent the problem that is being solved is much more similar to supervised learning than reinforcement learning since when using the pre trained skills the reward is not particularly delayed the generalization that is demonstrated seems to be limited to breaking a sentence describing the subtask into words item location action the paper is difficult to read it is constantly switching between describing the algorithm and giving technical details in particular i find it to be overloaded with details that interfere with the general understanding of the paper i suggest moving many of the implementation details into the appendix the paper should be self contained please do not assume that the reader is familiar with all the methods that you use and introduce all the relevant notations i believe that the paper will benefit from addressing the problems i described above and will make a better contribution to the community in a future conference,3.0
760.json,the paper discusses a method to learn interpretable hierarchical template representations from given data the authors illustrate their approach on binary images the paper presents a novel technique for extracting interpretable hierarchical template representations based on a small set of standard operations it is then shown how a combination of those standard operations translates into a task equivalent to a boolean matrix factorization this insight is then used to formulate a message passing technique which was shown to produce accurate results for these types of problems summary the paper presents an novel formulation for extracting hierarchical template representations that has not been discussed in that form unfortunately the experimental results are on smaller scale data and extension of the proposed algorithm to more natural images seems non trivial to me quality i think some of the techniques could be described more carefully to better convey the intuition clarity some of the derivations and intuitions could be explained in more detail originality the suggested idea is reasonable but limited to binary data at this point in time significance since the experimental setup is somewhat limited according to my opinion significance is hard to judge details my main concern is related to the experimental evaluation while the discussed approach is valuable its application seems limited to binary images at this point in time can the authors comment there are existing techniques to extract representations of images which the authors may want to mention e g work based on grammars,5.0
760.json,this paper presents an approach to learn object representations by composing a set of templates which are leaned from binary images in particular a hierarchical model is learned by combining and or and pool operations learning is performed by using approximated inference with max product bp follow by a heuristic to threshold activations to be binary learning hierarchical representations that are interpretable is a very interesting topic and this paper brings some good intuitions in light of modern convolutional neural nets i have however some concerns about the paper the paper fails to cite and discuss relevant literature and claims to be the first one that is able to learn interpretable parts i would like to see a discussion of the proposed approach compared to a variety of papers e g compositional hierarchies of sanja fidler and or graphs used by leo zhu and alan yuille to model objects and or templates of song chun zhu group at ucla the claim that this paper is the first to discover such parts should be removed the experimental evaluation is limited to very toy datasets the papers i mentioned have been applied to real images e g by using contours to binarize the images i will also like to see how good bad the proposed approach is for classification in more well known benchmarks a comparison to other generative models such as vae gans etc will also be useful i will also like to see a discussion of the relation differences advantages of the proposed approach wrt to sum product networks and grammars other comments the paper claims that after learning inference is feed forward but since message passing is used it should be a recurrent network the algorithm and tech discussion should be moved from the appendix to the main paper the introduction claims that compression is a prove for understanding i disagree with this statement and should be removed i will also like to see a discussion relating the proposed approach to the deep rendering model it is not obvious how some of the constraints are satisfied during message passing also constraints are well known to be difficult to optimize with max product how do you handle this the learning and inference algorithms seems to be very heuristic e g clipping to heuristics on which messages are run could you analyze the choices you make doing multiple steps of is not a single backward pass i will reconsider my score in light of the answers,5.0
760.json,this paper presents a generative model for binary images images are composed by placing a set of binary features at locations in the image these features are or would together to produce an image in a hierarchical variant features classes can have a set of possible templates one of which can be active variables are defined to control which template is present in each layer a joint probability distribution over both the feature appearance and instance location variables is defined overall the goal of this work is interesting it would be satisfying if semantically meaningful features could be extracted allowing compositionality in a generative model of images however it is not clear this would necessarily result from the proposed process why would the learned features building blocks necessarily semantically meaningful in the motivating example of text rather than discovering letters features could correspond to many other sub units parts of letters or other features lacking direct semantic meaning the current instantiation of the model is limited it models binary image patterns the experiments are done on synthetic data and mnist digits the method recovers the structure and is effective at classification on synthetic data that are directly compositional on the mnist data the test errors are quite large and worse than a cnn except when synthetic data corruption is added further work to enhance the ability of the method to handle natural images or naturally occuring data variation would enhance the paper,4.0
449.json,this paper presents a strategy for building deep neural networks via rules for expansion and merging of sub networks pros the idea is novel the approach is described clearly cons the experimental evaluation is not convincing e g no improvement on svhn number of parameters should be mentioned for all models for fair comparison the effect of drop path seems to vanish with data augmentation,6.0
449.json,this paper proposes a new architecture that does not explicitly use residuals but constructs an architecture that is composed of networks with fractal structure by using expand and join operations using the fractal architecture authors argue and try to demonstrate that the large nominal network depth with many short paths is the key for training ultra deep networks while residuals are incidental the main bottleneck of this paper is that number of parameters needed for the fractalnet is significantly higher than the baselines which makes it hard to scale to ultra deep networks authors replied that wide resnets also require many parameters but this is not the case for resnet and other resnet variants resnet and resnet with stochastic depth scales to depth of with m parameters and to depth of with m parameters which is much less than the number of parameters for depths of and in table huang et al a it is not clear whether fractalnet can perform better than these depths with a reasonable computation authors report less parameters for layers but this scaling trick is not validated for other depths including depth in table on the other hand the number of parameters for layers with scaling trick is clearly still large compared to most of the baselines unsatisfactory comparison to these baselines makes the claims of authors unconvincing authors also claim that drop path to provide improvement compared to layer dropping procedure in huang et al b however the results show that the empirical gain of this specific regularization disappears when well known data augmentation techniques applied therefore the empirical effectiveness of drop path is not convincing too densenets huang et al a should be also included in the comparison since it outperforms most of the state of art res nets on both cifar and imagenet and more importantly outperforms the proposed fractalnet significantly and it requires significantly less computation table has res net variants as baselines however table has only resnet therefore imagenet comparison only shows that one can run fractalnet on imagenet and can perform comparably well to resnet which is not a satisfactory result given the improvements of other baselines over resnet in addition there is no improvement in svhn dataset results and this is not discussed in the empirical analysis also authors give a list of some improvements over inception szegedy et al but again these intuitive claims about effectiveness of these changes are not supported with any empirical analysis although the paper attempts to explore many interesting intuitive directions using the proposed architecture the empirical results are not support the given claims and the large number of parameters makes the model restrictive in practice hence the contribution does not seem to be significant pros provides an interesting architecture compared to resnet and its variants and investigates the differences to residual networks which can stimulate some other promising analysis cons number of parameters are very large compared to baselines that can have even much higher depths with smaller number of parameters the claims are intuitive but not supported well with empirical evidence path regularization does not yield improvement when the data augmentation is used the empirical results do not show whether the method is promising for ultra deep networks,5.0
449.json,this paper proposes a design principle for computation blocks in convolutional networks based on repeated application of expand and join operations resulting in a fractal like structure this paper is primarily about experimental evaluation since the objective is to show that a residual formulation is not necessary to obtain good performance at least on some tasks however in my opinion the evaluations in the paper are not convincing the primary issue is lack of a proper baseline against which the improvements can be clearly demonstrated by making isolated changes i understand that for this paper such a baseline is hard to construct since it is about a novel architecture principle this is why more effort should be put into this so that core insights from this paper can be useful even after better performing architectures are discovered the number of parameters and amount of computation should be used to indicate how fair the comparisons are between architectures some detailed comments in table comparisons to resnets the resnets from he et al b and wide resnets should be compared to fractalnet in lieu of a proper baseline the first outperforms fractalnet on cifar while the second outperforms it on both the authors compare to other results without augmentation but did not perform additional experiments without augmentation for these architectures the layer fractal net should not be compared to other models unless the parameter reduction tricks are utilized for the other models as well a proper comparison to inception networks should also be performed for these networks my guess is that the reason behind a seemingly ad hoc design of inception modules is to reduce the computational footprint of the model which is not a central motivation of fractal nets since this model is directly related to the inception module due to use of shorter and longer paths without shortcuts one can easily simplify the inception design to build a strong baseline e g by converting the concatenation operation to a mean operation among equally sized convolution outputs as an aside note that inception networks have already shown that residual networks are not necessary to obtain the best performance it should be noted that residual highway architectures do have a type of anytime property as shown by lesioning experiments in srivastava et al and viet et al the architecture specific drop path regularization is interesting but is used along with other regularizers such as dropout batch norm and weight decay and its benefit on its own is not clear overall it not clear to me that the experiments clearly demonstrate the utility of the proposed architecture szegedy christian sergey ioffe and vincent vanhoucke inception v inception resnet and the impact of residual connections on learning arxiv preprint arxiv,6.0
633.json,the authors proposes an interesting idea of connecting the energy based model descriptor and the generator network to help each other the samples from the generator are used as the initialization of the descriptor inference and the revised samples from the descriptor is in turn used to update the generator as the target image the proposed idea is interesting however i think the main flaw is that the advantages of having that architecture are not convincingly demonstrated in the experiments for example readers will expect quantative analysis on how initializing with the samples from the generator helps also the only quantative experiment on the reconstruction is also compared to quite old models considering that the model is quite close to the model of kim bengio readers would also expect a comparison to that model minor i am wondering if the analysis on the convergence is sound when considering the fact that samples from sgld are biased samples with fixed step size can you explain a bit more on how you get eqn when p x y is also dependent on wg,4.0
633.json,this paper introduces coopnets an algorithm which trains a deep energy model dem the descriptor with the help of an auxiliary directed bayes net e g the generator the descriptor is trained via standard maximum likelihood with langevin mcmc for sampling the generator is trained to generate likely samples under the dem in a single feed forward ancestral sampling step it can thus be used to shortcut expensive mcmc sampling hence the reference to cooperative training the above idea is interesting and novel but unfortunately is not sufficiently validated by the experimental results first and foremost two out of the three experiments do not feature a train test split and ignore standard training and evaluation protocols for texture generation see r datasets are also much too small as such these experiments only seem to confirm the ability of the model to overfit on the third in painting tasks baselines are almost non existent no vaes rbms dem etc which makes it difficult to evaluate the benefits of the proposed approach in a future revision i would also encourage the authors to answer the following questions experimentally what is the impact of the missing rejection step in langevin mcmc train with without what is the impact of the generator on the burn in process of the markov chain show sample auto correlation how bad is approximation of training the generator from tilde y hat x instead of tilde y tilde x run comparative experiments the paper would also greatly benefit from a rewrite focusing on clarity instead of hyperbole pioneering work in reference to closely related but non peer reviewed work and prose tale of two nets for example the authors fail to specify the exact form of the energy function this seems like a glaring omission pros interesting and novel idea cons improper experimental protocols missing baselines missing diagnostic experiments r heess n williams c k i and hinton g e learning generative texture models with extended fields of experts,3.0
633.json,this paper proposed a new joint training scheme for two probabilistic models of signals e g images which are both deep neural network based and are termed generator and descriptor networks in the new scheme termed cooperative training the two networks train together and assist each other the generator network provides samples that work as initial samples for the descriptor network and the descriptor network updates those samples to help guide training of the generator network this is an interesting approach for coupling the training of these two models the paper however is quite weak on the empirical studies in particular the training datasets are tiny from sets of image to what is the reason for not using larger sets i think the small datasets are leading to over training and are really masking the true value of the proposed cooperative training approach for most of the experiments presented in the paper it is hard to assess the specific value brought by the proposed cooperative training approach because baseline results are missing there are comparisons provided for face completion experiments but even there comparisons with descriptor or generator network trained separately or with other deep auto encoders are missing thus it is hard to conclude if and how much gain is obtained by cooperative training over say individually training the descriptor and generator networks another comment is that in the related work section i think relation with variational auto encoders kingma and welling should be included despite limitations mentioned above i think the ideas presented in the paper are intuitively appealing and worth discussing at iclr paper would be considerably strengthened by adding more relevant baselines and addressing the training data size issues,6.0
776.json,this paper proposes a method for iteratively improving the output of an existing machine translation by identifying potential mistakes and proposing a substitution in this case using an attention based model it is motivated by the method in which it is assumed human translators operate the paper is interesting and imaginative however in general terms i am somewhat sceptical of this kind of approach whereby a machine learning method is used to identify and correct the predictions of another method or itself because in the first case if the new method is better why not use it from the outset in place of the other method and in the second case since the method has no new information compared to previously why is it more likely to identify more past mistakes and correct them than identify past correct terms and turn them into new errors that is unless there is a specific reason that an iterative approach can be shown to converge to a better solution when run over several epochs this paper does not convince me on these points indeed unsurprisingly the authors note that the probability of correctly labelling a word as a mistake remains low this admittedly beats a random chance baseline but is not compared to something more meaningful such as simply contrasting the existing system with a more powerful convolutional model and labelling all discrepancies as mistakes the oracle experiments are rather meaningless they just serve to confirm that improving a translation is very easy when the existing mistakes have been identified but much harder when they are not although i do like the paper on the whole to really convince me that main objective ie that iterative improvement is beneficial has been satifactorily demonstrated it would be necessary to include stronger baselines and in particular to show that an iterative refinement scheme can really improve over a system closely matched to the attention based model both when used in isolation and when used in system combination with a pbmt system and to demonstrate that the pbmt system is not simply acting as a regulariser for the attention based model minor comments i find the notation excessively fiddly at times eg f i f i f i f i why use f i here when f is a matrix so surely the length of the slice is not dependent on i in the discussion in section it seems that this still creates a mismatch between the training and test conditions could anything be done about this,5.0
776.json,disclosure i am not an expert in machine translation algorithms summary a human translator does not come up with the final translation right away instead s he uses an iterative process starting with a rough draft which is corrected little by little the idea behind this paper is to implement a similar framework for an automated system this paper is generally well written it is my opinion however that drawings illustrating the architectures would help understanding how the different algorithms relate to one another i like a lot that you report on a preliminary experiment to give an intuition of how difficult the task is you should highlight the links between the task of finding the errors in a guess translation and the task of iterative refinement could you use post edited text to have a more solid ground truth my main concern with this paper is that in the experimental section the iterative approach tries to improve upon only one type of machine translation which immediately prompts these questions why did they choose that approach to improve on what is the part of the improvement that comes from the choice of the initial draft maybe it was a very bad draft here are some minor typos p a lookup table that replace s each word p i might be mistanken but it seems to me that j is used for two different things it is confusing p takes as input these representation s and outputs,7.0
664.json,this paper proposes an interesting application of the gan framework in steganography domain in addition to the normal gan discriminator there is a steganalyser discriminator that receives the negative examples from the generator and positive examples from the generator images that contain a hidden payload as a result the generator not only learn to generate realistic images by fooling the discriminator of the gan but also learn to be a secure container by fooling steganalyser discriminator the method is tested by training an independent steganalyser s on real images and generated images given that in the iclr community not many people are familiar with the literature of steganography i think this paper should have provided more context about how exactly this method can be used in practice what are the related works on setganalysis secure message embedding and probably a more thorough sets of experiments on more than one dataset the proposed sgan framework figure does make sense to me and i think it is very general and can have more applications other than the steganography domain but it is not clear to me why fooling the steganalyser discriminator s necessarily mean that we can fool an independent discriminator s also i find it surprising that a different seed value can make such a huge difference in the accuracy in short the ideas of this paper are interesting and potentially useful but i think the presentation of this paper should be improved so that it becomes more suitable for the iclr and machine learning community,5.0
664.json,i found this paper very original and thought provoking but also a bit difficult to understand it is very exciting to see a practical use case for image generating gans with potentially meaningful benchmarks aside from subjective realism i found eq interesting because it introduces a potentially non differentiable black box function stego into the training of s g do you in fact backprop through the stego function for the train test split why is the sgan trained on all k images would it not be cleaner to use the same splits for training sgan as for steganalysis purposes could this account for the sensitivity to random seed shown in table sec steganographic generative adversarial networks can potentially be used as a universal tool for generating steganography containers tuned to deceive any specific steganalysis algorithm this experiment showed that sgan can fool hugo but i do not see how it was tuned to deceive hugo or how it could be tuned in general for a particular steganalyzer although s seems to be fooled by the proposed method in general for image generation the discriminator d is almost never fooled i e contemporary gans never converge to actually fooling the discriminator even if they produce samples that sometimes fool humans what if i created an additional steganalyzer s x s x d x this i think would be extremely difficult to fool reliably because it requires realistic image generation after reading the paper several times it is still a bit unclear to me how or why precisely one would use a trained sgan i think the paper could be greatly improved by detailing step by step the workflow of how a hypothetical user would use a trained sgan this description should be aimed at a reader who knows nothing or very little about steganography e g most of iclr attendees,6.0
371.json,paper proposes a neural physics engine npe npe provides a factorization of physical scene into composable object based representations npe predicts a future state of the given object as a function composition of the pairwise interactions between itself and near by objects this has a nice physical interpretation of forces being additive in the paper npe is investigated in the context of d worlds with balls and obstacles overall the approach is interesting and has an interesting flavor of combining neural networks with basic properties of physics overall it seems like it may lead to interesting and significant follow up work in the field the concerns with the paper is mainly with evaluation which in places appears to be weak see below significance originality the approach is interesting while other methods have tried to build models that can deal with physical predictions the idea of summing over pair wise terms to the best of my knowledge is novel and much more in line with the underlying principles of mechanics as such while relatively simple it seems to be an important contribution clarity the paper is generally well written however large portion of the early introduction is rather abstract and it is difficult to parse until one gets to th paragraph i would suggest editing the early part of introduction to include more specifics about the approach or even examples to make text more tangible experiments generally there are two issues with experiments in my opinion the added indirect comparison with fragkiadaki et al does not appears to be quantitatively flattering with respect to the proposed approach and quantitative experiments on the role the size of the mask has on performance should really be added authors mention that they observe that mask is helpful but it is not clear how helpful or how sensitive the overall performance is to this parameter this experiment should really be added i do feel that despite few mentioned shortcomings that would make the paper stronger this is an interesting paper and should be published,7.0
721.json,this paper trains a generative model of image patches where dictionary elements undergo gated linear transformations before being combined the transformations are motivated in terms of lie group operators though in practice they are a set of fixed linear transformations this is motivated strongly in terms of learning a hierarchy of transformations though only one layer is used in the experiments except for a toy case in the appendix i like the motivation for this algorithm the realization seems very similar to a group or block sparse coding implementation i was disappointed by the restriction to linear transformations the experiments were all toy cases demonstrating that the algorithm can learn groups of gabor or center surround like features they would have been somewhat underpowered five years ago and seemed extremely small by today standards specific comments based on common practices in ml literature i have a strong bias to think of x as inputs and w as network weights latent variables are often z or a depending on your target audience i would suggest permuting your choice of symbols so the reader can more quickly interpret your model nit number all equations for easier reference sec it weird that the transformation is fixed but is still written as a function of x sec the updated text here confuses me actually i had thought that you were using a fixed set of linear transformations and were motivating in terms of lie groups but were not actually taking matrix exponentials in your algorithm the equations in the second half of this section suggest you are working with matrix exponentials though i am not sure which direction i am confused in but probably good to clarify the text either way btw there another possible solution to the local minima difficulty which is the one used in sohl dickstein there they introduce blurring operators matched to each transformation operator and gradient descent can escape local minima by detouring through coarser more blurred scales sec i believe by degrees of freedom you mean the number of model parameters not the number of latent coefficients that must be inferred should make this more clear is it more appropriate to compare reconstruction error while matching number of model parameters or number of latent variables i wonder if a convolutional version of this algorithm would be practical would make it more suited as a generative model of whole images post rebuttal update thank you for taking the time to write the rebuttal i have read it but it did not significantly effect my rating,5.0
721.json,this paper proposes an approach to unsupervised learning based on a modification to sparse coding that allows for explicit modeling of transformations such as shift rotation etc as opposed to simple pooling as is typically done in convnets results are shown for training on natural images demonstrating that the algorithm learns about features and their transformations in the data a comparison to traditional sparse coding shows that it represents images with fewer degrees of freedom this seems like a good and interesting approach but the work seems like its still in its early formative stages rather than a complete work with a compelling punch line for example one of the motivations is that you would like to represent pose along with the identity of an object while this work seems well on its way to that goal it does not quite get there it leaves a lot of dots still to be connected also there are a number of things that are not clear in the paper o the central idea of the paper it seems is the use of a transformational sparse coding tree to make tractable the inference of the lie group parameters xk but how exactly this is done is not at all clear for example the sentence the main idea is to gradually marginalize over an increasing range of transformations is suggestive but not clear this needs to be much better defined what do you mean by marginalization in this context o the connection between the lie group operator and the tree leaves and weights wb is not at all clear the learning rule spells out the gradient for the lie group operator but how this is used to learn the leaves of the tree is not clear a lot is left to the imagination here this is especially confusing because although the lie group operator is introduced earlier it is then stated that its not tractable for inference because there are too many local minima and this motivates the tree approach instead so its not clear why you are learning the lie group operator o it is stated that averaging over many data points smoothens the surface of the error function i do not understand why you would average over many data points it seems each would have its own transformation no o what data do you train on how is it generated do you generate patches with known transformations and then show that you can recover them please explain the results shown in figure look very interesting but given the lack of clarity in the above difficult to interpret and understand what this means and its significance i would encourage the authors to rewrite the paper more clearly and also to put more work into further developing these ideas which seem very promising,4.0
721.json,a new sparse coding model is introduced that learns features jointly with their transformations it is found that inference over per image transformation variables is hard so the authors suggest tying these variables across all data points turning them into global parameters and using multiple transformations for each feature furthermore it is suggested to use a tree of transformations where each path down the tree generates a feature by multiplying the root feature by the transformations associated with the edges the one layer tree model achieves similar reconstruction error as traditional sparse coding while using fewer parameters this is a nice addition to the literature on sparse coding and the literature on learning transformation models the authors identify and deal with a difficult inference problem that can occur in transformation models that said i am skeptical about the usefulness of the general approach the authors take it as a given that learning sparse features and transformations jointly is an important goal in itself but this is never really argued or demonstrated with experiments it doesn t seem like this method enables new applications extends our understanding of learning what where pathways in the brain or improve our ability to model natural images the authors claim that the model extracts pose information but although the model explicitly captures the transformation that relates different features in a tree at test time inference is only performed over the sparse coefficient associated with each feature transformation combination just like in sparse coding it is not clear what we gain by knowing that each coefficient is associated with a transformation especially since there are many models that do this general what where split it would be good to check that the x v b actually change significantly from their initialization values the loss surface still looks pretty bad even for tied transformations so they may actually not move much does the proposed model work better according to some measure compared to a model where x v b are fixed and chosen from some reasonable range of parameter values either randomly or spaced evenly one of the conceptually interesting aspects of the paper is the idea of a tree of transformations but the advantage of deeper trees is never demonstrated convincingly it looks like the authors have only just gotten this approach to work on toy data with vertical and horizontal bars finally it is not clear how the method could be extended to have multiple layers the transformation operators t can be defined in the first layer because they act on the input space but the same cannot be done in the learned feature space it is also not clear how the pose information should be further processed in a hierarchical manner or how learning in a deep version should work in summary i do not recommend this paper for publication because it is not clear what problem is being solved the method is only moderately novel and the novel aspects are not convincingly shown to be beneficial,4.0
490.json,this paper proposes augmenting rnn based language models with a pointer network in order to deal better with rare words the pointer network can point to words in the recent context and hence the prediction for each time step is a mixture between the usual softmax output and the pointer distribution over the recent words the paper also introduces a new language modelling dataset which overcomes some of the shortcomings of previous datasets the reason for the score i gave for this paper is that i find the proposed model a direct application of the previous work gulcehre et al which follows a similar approach but for machine translation and summarization the main differences i find is that gulcehre et al use an encoder decoder architecture and use the attention weights of the encoder to point to locations of words in the input while here an rnn is used and a pointer network produces a distribution over the full vocabulary by summing the softmax probabilities of words in the recent context the context query vector for the pointing network is also different but this is also a direct consequence of having a different application while the paper describes the differences between the proposed approach and gulcehre et al s approach i find some of the claims either wrong or not that significant for example quoting from section rather than relying on the rnn hidden state to decide when to use the pointer as in the recent work of gulcehre et al we allow the pointer component itself to decide when to use the softmax vocabulary through a sentinel as far as i can tell your model also uses the recent hidden state to form a query vector which is matched by the pointer network to previous words can you please clarify what you mean here in addition quoting from section which describes the model of gulcehre et al rather than constructing a mixture model as in our work they use a switching network to decide which component to use this is not correct the model of gulcehre is also a mixture model where an mlp with sigmoid output switching network is used to form a mixture between softmax prediction and locations of the input text finally in the following quote also from section the pointer network is not used as a source of information for the switching network as in our model it is not clear what the authors mean by source of information here is it the fact that the switching probability is part of the pointer softmax i am wondering how significant this difference is with regards to the proposed dataset there are also other datasets typically used for language modelling including the hutter prize wikipedia enwik dataset hutter and e text dataset mahoney can you please comment on the differences between your dataset and those as well i would be happy to discuss with the authors the points i raised and i am open to changing my vote if there is any misunderstanding on my part,7.0
490.json,this work is an extension of previous works on pointer models that mixes its outputs with standard softmax outputs the idea is appealing in general for context biasing and the specific approach appears quite simple the idea is novel to some extent as previous paper had already tried to combine pointer based and standard models but not as a mixture model as in this paper the paper is clearly written and the results seem promising the new dataset the authors created wikitext also seems of high interest a comment regarding notation the symbol pptr is used in two different ways in eq and eq pptr w vs pptr yi xi this is confusing as these are two different domains for eq the domain is a set of words and for eq the domain is a list of context words it would be helpful to use different symbol for the two objects,8.0
306.json,this paper describes a new approach to meta learning by interpreting the sgd update rule as gated recurrent model with trainable parameters the idea is original and important for research related to transfer learning the paper has a clear structure but clarity could be improved at some points pros an interesting and feasible approach to meta learning competitive results and proper comparison to state of the art good recommendations for practical systems cons the analogy would be closer to grus than lstms the description of the data separation in meta sets is hard to follow and could be visualized the experimental evaluation is only partly satisfying especially the effect of the parameters of it and ft would be of interest fig does not have much value remarks small typo in this means each coordinate has it its we plan on releasing the code used in our evaluation experiments this would certainly be a major plus,6.0
613.json,this paper proposes to use a causality score to weight a sparsity regularizer in that way selected variables trade off between being causal and discriminative the framework is primarily evaluated on a proprietary health dataset while the dataset does give a good motivation to the problem setting the paper falls a bit short for iclr due to the lack of additional controlled experiments relatively straightforward methodology given the approach of chalupka et al arxiv preprint which is a more interesting paper from a technical perspective and paucity of theoretical motivation at the core of this paper the approach is effectively to weight a sparsity regularizer so that causal variables as determined by a separate objective are more likely to be selected this is generally a good idea but we do not get a proper validation of this from the experiments as ground truth is absent a theorem on identifiability of causal discriminative variables from a data sample combined with adequate synthetic experiments would have probably been sufficient for example to push the paper towards accept from a technical perspective but as it is it is lacking in insight and reproducibility,5.0
613.json,the authors extend their method of causal discovery chalupka et al to include assumptions about sparsity via regularization they apply this extension to an interesting private dataset from sutter health while an interesting direction i found the presentation somewhat confused the methodological novelty smaller than the bulk of iclr works and the central results or perhaps data see below inadequate to address questions of causality first i found the presentation somewhat unclear the paper at some points seems to be entirely focused on healthcare data at other points it uses it as a motivating example and at other points it is neglected also algorithm seems unreferenced and i am not entirely sure why it is needed figure is not needed for this community the key methodological advance in this work appears in section causal regularizer but it is introduced amidst toy examples and without clear terminology or standard methodological assumptions build up in section bottom of first paragraph key data and results seem to be relegated to the appendices thus overall the paper read rather haphazardly finally there seems to be an assumption throughout of fairly intimate familiarity with the cholupka preprint which i think should be avoided this paper should stand alone second while the technical contributions novelty are not a focus of the paper presentation i am concerned by the lack of methodological advance essentially a regularization objective is added to the previous method which of itself is not a bad idea but i can not point to a technical novelty in the paper that the community can not do without third fundamentally i do not see how the experiments address the central question of causality they show regularization behaving as expected or rather influencing weights as expected but i do not think we really have any meaningful quantitative evidence that causality has been learned this was briefly discussed see ground truth causality and the response below i appreciate the technical challenges impossibility of having such a dataset but if that the case then i think this work is premature since there is no way to really validate overall it clearly a sincere effort but i found it wanting in terms of a few critical areas,4.0
582.json,this paper proposes combining different modalities of product content e g review text images co purchase info etc in order to learn one unified product representation for recommender systems while the idea of combining multiple sources of information is indeed an effective approach for handling data sparsity in recommender systems i have some reservations on the approach proposed in this paper some modalities are not necessarily relevant for the recommendation task or item similarity for example cover images of books or movies which are product types in the experiments of this paper do not tell us much about their content the paper should clearly motivate and show how different modalities contribute to the final task the connection between the proposed joint product embedding and residual networks is a bit awkward the original residual layers are composed of adding the original input vector to the output of an mlp i e several affine transformations followed by non linearities these layers allow training very deep neural networks up to layers as a result of easier gradient flow in contrast the pairwise residual unit of this paper adds the dot product of two item vectors to the dot product of the same vectors but after applying a simple non linearity the motivation of this architecture is not very obvious and is not well motivated in the paper while it is a minor point but the choice of the term embedding for the dot product of two items is not usual embeddings usually refer to vectors in r n and for specific entities here it refers to the final output and renders the output layer in figure pointless finally i believe the paper can be improved by focusing more on motivating architectural choices and being more concise in your description the paper is currently very long pages and i strongly encourage you to shorten it,3.0
582.json,the paper proposes a method to combine arbitrary content into recommender systems such as images text etc these various features have been previously used to improve recommender systems though what is novel here is the contribution of a general purpose framework to combine arbitrary feature types positively the idea of combining many heterogeneous feature types into rs is ambitious and fairly novel previous works have certainly sought to include various feature types to improve rss though combining different features types successfully is difficult negatively there are a few aspects of the paper that are a bit ad hoc in particular there are a lot of pieces here being glued together to build the system different parts are trained separately and then combined together using another learning stage there nothing wrong with doing things in this way and indeed it the most straightforward and likely to work approach but it pushes the contribution more toward the system building direction as opposed to the end to end learning direction which is more the focus of this conference further to the above this makes it hard to say how easily the model would generalize to arbitrary feature types say e g if i had audio or video features describing the item to incorporate such features into the system would require a lot of implementation work as opposed to being a system where i can just throw more features in and expect it to work the pre review comments address some of these issues some of the responses are not entirely convincing e g it would be better to have the same baselines across tables rather than dropping some because the case had already been made elsewhere other than that i like the effort to combine several different feature types in real recommender systems datasets i am not entirely sure how strong the baselines are they seem more like ablation style experiments rather than comparison against any state of the art rs,5.0
351.json,the paper presents an application of deep learning to genomic snp data with a comparison of possible approaches for dealing with the very high data dimensionality the approach looks very interesting but the experiments are too limited to draw firm conclusions about the strengths of different approaches the presentation would benefit from more precise math quality the basic idea of the paper is interesting and the applied deep learning methodology appears reasonable the experimental evaluation is rather weak as it only covers a single data set and a very limited number of cross validation folds given the significant variation in the performances of all the methods it seems the differences between the better performing methods are probably not statistically significant more comprehensive empirical validation could clearly strengthen the paper clarity the writing is generally good both in terms of the biology and ml but more mathematical rigour would make it easier to understand precisely what was done the different architectures are explained on an intuitive level and might benefit from a clear mathematical definition i was ultimately left unsure of what the raw endend model is given so few parameters it cannot work on raw k dimensional input but i could not figure out what kind of embedding was used the results in fig might be clearer if scaled so that maximum for each class is to avoid confounding from different numbers of subjects in different classes in the text please use the standard italics math font for all symbols such as n nd originality the application and the approach appear quite novel significance there is clearly strong interest for deep learning in the genomics area and the paper seeks to address some of the major bottlenecks here it is too early to tell whether the specific techniques proposed in the paper will be the ultimate solution but at the very least the paper provides interesting new ideas for others to work on other comments i think releasing the code as promised would be a must,6.0
351.json,the paper addresses the important problem d n in deep learning the proposed approach based on lower dimensional feature embeddings is reasonable and makes applying deep learning methods to data with large d possible the paper is well written and the results show improvements over reasonable baselines,7.0
701.json,this paper proposed to perform finetuning in an augmentation fashion by freezing the original network and adding a new model aside it the idea itself is interesting and complements existing training and finetuning approaches although i think there are a few baseline approaches that can be compared against such as ensemble in principle the idea is similar to an ensembling approach where multiple networks are ensembled together to get a final prediction the approach in figure should be compared with such ensemble baselines taking multiple source domain predictors possibly with the same modular setting as the proposed method and compare the performance comparison with late fusion if we combine the pretrained network and a network finetuned from the pretrained one and do a late fusion basically i think it is a valuable argument in section and figure that finetuning with a small amount of data may hurt the performance in general this builds the ground for freezing a pretrained network and only augmenting it not changing it i agree with the authors on this argument although currently other than figure there seem to be little empirical study that justifies it it is worth noting that figure seems to suggest that some of the module filters are either not converging or are learning unuseful features like the first two filters in a overall i think it is an interesting idea and i would love to see it better developed thus i am giving a weak accept recommendation but with a low confidence as the experiments section is not very convincing,6.0
701.json,this paper presents a new technique for adapting a neural network to a new task for which there is not a lot of training data the most widely used current technique is that of fine tuning the idea in this paper is to instead learn a network that learns features that are complementary to the fixed network additionally the authors consider the setting where the new network features are stitched to the old one at various levels in the hieararchy rather that it just being a parallel tower this work is similar in spirit if not in some details to the progressive nets paper by rusu et al as already discussed the motivations and experiments are certainly different so this submission has merit on its own the idea of learning a residual with the stitched connnections is very similar in spirit to the resnet work it would be nice to compare and contrast those approaches i ve never seen a batch being used times in a row during training does this work better than just regular sgd in figure it d be nice to label the y axis that figure would also benefit from not being a bar chart but simply emulating figure which is much more readable figure again what is an untrained model it s not immediately obvious why this is a good idea at all is tft simply fine tuning one more layer than retrain softmax i think that the results at the end of section are a bit weak because of usage of a big network i would definitely like to see how the results change if using a smaller net the authors claim throughout the paper that the purpose of the added connections and layers is to learn complementary features and they show this with some figures the latter are a convinving evidence but not proof or guarantee that this is what is actually happening i suggest the authors consider adding an explicit constraint in their loss that encourages that e g by having a soft orthogonality constraing assuming one can project intermediate features to some common feature dimensionality the usage of very small l regularization maybe achieves the same thing but there s no evidence for that in the paper in that we don t have any visualizations of what happens if there s no l reg one of the big questions for me while reading the paper was how would an ensemble of pre trained nets would do on the tasks that the authors consider this is especially relevant in the cars classification example where i suspect that a strong baseline is that of fine tuning vgg on this task fine tuning resnet on this task and possibly training a linear combination of the two outputs or just averaging them naively disappointing that there are no results in figure and except the ones from this paper it s really hard to situate this paper if we don t actually know how it compares to previously published results in general this was an interesting and potentially useful piece of work the problem of efficiently reusing the previously trained classifier for retraining on a small set is certainly interesting to the community while i think that this paper takes a good step in the right direction it falls a bit short in some dimensions comparisons with more serious baselines more understanding etc,6.0
644.json,the paper addresses an important problem namely on how to improve diversity in responses it is applaudable that the authors show results on several tasks showing the applicability across different problems in my view there are two weaknesses at this point the improvements for essentially all tasks seem rather minor and do not really fit the overall claim of the paper the approach seems quite ad hoc and it unclear to me if this is something that will and should be widely adopted having said this the gist of the proposed solution seems interesting but somewhat premature,4.0
644.json,summary this paper presents a new modified beam search algorithm that promotes diverse beam candidates it is a well known problem with both rnns and also non neural language models that beam search tends to generate beam candidates that are very similar with each other which can cause two separate but related problems search error beam search may not be able to discover a globally optimal solution as they can easily fall out of the beam early on simple common non diverse output the resulting output text tends to be generic and common this paper aims to address the second problem by modifying the search objective function itself so that there is a distinct term that scores diversity among the beam candidates in other words the goal of the presented algorithm is not to reduce the search error of the original objective function in contrast stack decoding and future cost estimation common practices in phrase based smt aim to address the search error problem merits i think the diverse beam search dbs algorithm proposed by the authors has some merits it may be useful when we cannot rely on traditional beam search on the original objective function either because the trained model is not strong enough or because of the search error or because the objective itself does not align with the goal of the application weaknesses it is however not entirely clear how the proposed method compares against more traditional approaches like stack decoding and future cost estimation on tasks like machine translation as the authors compare their algorithm mainly against l j s diverse lm models and simple beam search in fact modification to the objective function has been applied even in the neural mt context for example see equation in page of the following paper google neural machine translation system bridging the gap between human and machine translation,6.0
594.json,the author proposes the use of low rank matrix in feedfoward and rnns in particular they try their approach in a gru and a feedforward highway network author also presents as a contribution the passthrough framework which can describe feedforward and recurrent networks however this framework seems hardly novel relatively to the formalism introduced by lstm or highway networks an empirical evaluation is performed on different datasets mnist memory addition tasks sequential permuted mnist and character level penntreebank however there are few problems with the evaluation in the highway network experiment the author does not compare with a baseline we can not assess what it the impact of the low rank parameterization also it would be interesting to compare the result with a highway network that have this capacity bottleneck across layer first layer of size n second layer of size d third layer of size n and not in the gate functions also how did you select the hyperparameter values it is unfortunate that the character level penntreebank does not use the same experimental setting than previous works as it prevents from direct comparison also the overall bpc perplexity seems relatively high for this dataset it is therefore not clear how low rank decomposition would perform on this task applied on a stronger baseline author claims state of art in the memory task however their approach uses more parameters than the urnn k against k for the memory which makes the comparison a little bit unfair toward urnn it would be informative to see how low rank rnn performs using overall k parameters generally it would be good to see what is the impact of the matrix rank given a fix state size it would be informative as well to have the baseline and the urnn curve in figure for the memory addition task it is not clear when to use low rank or low rank diagonal from the experiments overall the evaluation in its current form in not really convincing except for the sequential mnist dataset,4.0
594.json,the paper proposes a low rank version of pass through networks to better control capacity which can be useful in some cases as shown in the experiments that said i found the results not very convincing overall results are overall not as good as state of the art on sequential mnist or the memory task but add one more hyper parameter to tune as i said it would help to show in tables and or figures competing approaches like urnns,5.0
594.json,the authors study the use of low rank approximation to the matrix multiply in rnns this reduces the number of parameters by a large factor and with a diagonal addition called low rank plus diagonal it is shown to work as well as a fully parametrized network on a number of tasks the paper is solid the only weakness being some claims about conceptual unification e g the first line of the conclusion we presented a framework that unifies the description various types of recurrent and feed forward neural networks as passthrough neural networks claiming this framework as a contribution of this paper is untrue the general framework is well known in the community and rnns have been presented in this way before aside from the above small point the true contribution is in making low rank rnns work the results are generally as good as fully parametrized networks they are hardly better though which makes it unclear why low rank networks should be used the contribution is thus not very strong in terms of results but even achieving the same results with fewer parameters is not easy and the studies were well executed and explained,6.0
717.json,the authors analyze trained neural networks by quantifying the selectivity of individual neurons in the network for a variety of specific features including color and category pros the paper is clearly written and has good figures i think they executed their specific stated goal reasonably well technically e g the various indexes they use seem well chosen for their purposes cons i must admit that i am biased against the whole enterprise of this paper i do not think it is well motivated or provides any useful insight whatever what i view their having done is produced and then summarized anecdotally a catalog of piecemeal facts about a neural network without any larger reason to think these particular facts are important in a way i feel like this paper suffers from the same problem that plagues a typical line of research in neurophysiology in which a catalog of selectivity distributions of various neurons for various properties is produced full stop as if that were in and of itself important or useful information i do not feel that either the original neural version of that project or this current model based virtual electrophysiology is that useful why should we care about the distribution of color selectivities why does knowing distribution as such constitute understanding to my mind it does not at least not directly here what they could have done to make a more useful investigation a from a neuroscience point of view they could have compared the properties that they measure in models to the same properties as measured in neurons the real brain if they could show that some models are better matches on these properties to the actual neural data than others that would be a really interesting result that is is to say the two isolated catalogs of selectivities from model neurons and real neurons alone seem pretty pointless but if the correspondence between the two catalogs was made both in terms of where the model neurons and the real neurons were similar and especially importantly where they were different that would be the beginning of nontrivial understanding such results would also complement a growing body of literature that attempts to link cnns to visual brain areas finding good neural data is challenging but whatever the result the comparison would be interesting and or b from an artificial intelligence point of view they could have shown that their metrics are prescriptive constraints that is suppose they had shown that the specific color and class selectivity indices that they compute when imposed as a loss function criterion on an untrained neural network cause the network to develop useful filters and achieve significantly above chance performance on the original task the networks were trained on this would be a really great result because it would not only give us a priori reason to care about the specific property metrics they chose but it would also help contribute to efforts to find unsupervised or semi supervised learning procedures since the metrics they compute can be estimated from comparatively small numbers of stimuli and or high level semantic labels to put this in perspective imagine that they had actually tested the above hypothesis and found it to be false that is that their metrics when used as loss function constraints do not improve performance noticeably above chance performance what would we then make of this whole investigation it would then be reasonable to think that the measured properties were essentially epiphenomenal and did not contribute at all to the power of neural networks in solving perceptual tasks the same could be said about neurophysiology experiments doing the same thing nb i have actually tried things just like this myself over the years and have found exactly this disappointing result specifically i have found a number of high level generic statistical property of dnns that seem like they might potentially interesting e g because they apparently correlate with complexity or appear to illustrate difference between low intermediate and high layers of dnns every single one of these when imposed as optimization constraints has basically lead nowhere on the challenging tasks like imagenet that cause the dnns to be interesting in the first place basically there is to my mind no evidence at this point that highly summarized generic statistical distributions of selectivities like those illustrated here place any interesting constraints on filter weights at all of course i have not tried the specific properties the authors highlight in these papers so maybe there something important there i know that both of these asks are pretty hard but i just do not know what else to say this work otherwise seems like a step backwards for what the community ought to be spending its time on,3.0
717.json,this paper attempts to understand and visualize what deep nets are representing as one ascends from low levels to high levels of the network as has been shown previously lower levels are more local image feature based whereas higher levels correspond to abstract properties such as object identity in semantic space we find higher level nodes to be more semantically selective whereas low level nodes are more diffuse this seems like a good attempt to tease apart deep net representations perhaps the most important finding is that color figures prominently into all levels of the network and that performance on gray scale images is significantly diminished the new nf measure proposed here is sensible but still based on the images shown to the network what one really wants to know is what function these nodes are computing i e out of the space of all possible images which most activate a unit of course this is a difficult problem but it would be nice to see us getting closer to understanding the answer the color analysis here i think brings us a bit closer the semantic analysis is nice but i am not sure what new insight we gain from this,7.0
469.json,the paper details an implementation of sparse full convolutions and a model to work out the potential speed up of various sparsity levels for cnns the first contribution is more about engineering but the authors make the source code available which is greatly appreciated the second contribution is perhaps more interesting as so far pruning methods have focused on saving memory with very modest speed gains imbuing knowledge of running speed into a pruning algorithm seems like the proper way to tackle this problem the authors are very methodical in how they build the model and evaluate it very thoroughly it seems that the same idea could be used not just for pruning existing models but also when building new architectures selecting layers and their parameters as to achieve an optimal throughput rate this could make for a nice direction for future work one point that is missing is some discussion of how transferable the performance model is to gpus this would make the technique easier to adopt broadly other areas for improvement the points in figure are hard to distinguish e g small red circle vs small red square and overall the figure could be made bigger specifying whether the base learning rate in section is the start or end rate of the annealing schedule typos punning p spares p,7.0
469.json,the authors provide a well engineered solution to exploiting sparsity in convolutional layers of a deep network by recasting it as sparse matrix vector multiplication this leads to very nice speedups and the analysis of when this is possible is also useful for practitioners my main concern with this paper is that the research aspect of it seems rather minimal and it mostly about performance engineering and comparisons it is upto the area chairs to decide how well such a paper fits in at iclr,6.0
310.json,thank you for an interesting read pros this paper tackles a very crucial problem of understanding communications between agents as more and more applications of reinforcement learning are being explored this approach brings us back to a basic question is the problem solving approach of machines similar to that of humans the task is simple enough to make the post learning analysis intuitive it was interesting to see how informed agents made use of multiple symbols to transmit the message where as agnostic agents relied only on symbols cons the task effectively boils down to image classification if the images sent are from different categories the symbols used are effectively the image class which the second agent learns to assign to either of the images by all means this approach boils down to a transfer learning problem which could probably be trained much faster than a reinforcement learning algorithm,7.0
310.json,to train natural language systems by putting multiple agents within an interactive referential communication game is very nice as the authors mention there has been some although seemingly not much previous work on using multi agent games to teach communication and it certainly seems like a direction worth pursuing moreover the approach of switching between these games and some supervised learning as in the experiment described in section and suggested in section seems particularly fruitful note for clarity i believe some of the network connections in fig have been omitted however given the rather highly customized architecture and the slightly hard to follow description in section the shorthand diagram only adds to the confusion the diagram probably needs to be fine tuned but at the very least especially if i am misunderstanding it a caption must still be added to help the reader interpret the figure overall the framework section is great and seems quite effective useful in various ways the results are reasonable and i expect there will be some interesting future variations on this work as well caveat while i am quite confident i understood the paper as per confidence score below i do not feel i am sufficiently familiar with the most closely related literature to accurately assess the place of this work within that context,7.0
310.json,in this paper a referential game is proposed between two agents both agents observe two images the first agent called the sender receive a binary target variable t and must send a symbol message to the second agent called the receiver such that this agent can recover the target the agents both get a reward if the receiver agent can predict the target the paper proposes to parametrize the agents as neural networks with pretrained representations of the images as feature vectors and train them using reinforce in this setting it is shown that the agents converge to optimal policies and that their learned communications e g the symbolic code transmitted from the sender to the receiver have some meaningful concepts in addition to this the paper presents experiments on a variant of the game grounded on different image classes in this setting the agents appear to learn even more meaningful concepts finally multi game setup is proposed where the sender agent is alternating between playing the game before and playing a supervised learning task classifying images not surprisingly when anchored to the supervised learning task the symbolic communications have even more meaningful concepts learning shared representations for communication in a multi agent setup is an interesting research direction to explore this is a much harder task compared to standard supervised learning or single agent reinforcement learning tasks which justifies starting with a relatively simple task to the best of my knowledge the approach of first learning communication between two agents and then grounding this communication in human language is novel as the authors remark this may be an alternative paradigm to standard sequence to sequence models which tend to focus on statistical properties of language rather than their functional aspects i believe the contributions of the proposed task and framework and the analysis and visualization of what the communicated tokens represent is a useful stepping stone for future work for this reason i think the paper should be accepted other comments how is the target t incorporated into the sender networks please clarify this table and table use percentage values differently in the first percentages seem to be written in the interval and in the second in the interval please correct this perhaps related to this in table the column obs chance purity seems to have extremely small values i assume this was mistake assest assess usufal usual,7.0
740.json,the paper presents an architecture to parallelize the optimization of nested functions based on the method of auxiliary coordinates mac carreira perpinan and wang this method decomposes the optimization into training individual layers and updating the auxiliary coordinates the paper focuses on binary autoencoders and proposes to partition the data onto several machines allowing the parameters to move between machines relatively good speedup factors are reported especially on larger datasets and a theoretical model of performance is presented that matches with the experiments my main concern is that even though the method is presented as a general framework for nested functions experiments focus on a restricted family of models i e binary autoencoders with linear or kernel encoders and linear decoders with only two components while the speedup factors are encouraging it is hard to get a sense of their importance as the binary autoencoder model considered is not well studied by other researchers and is not widely used i encourage the authors to apply this framework to more generic architectures and problems questions does this framework apply to some form of generic multi layer neural network if so some experimental results are useful what is the implication of applying this framework to more than two components an encoder and a decoder and non linear components it is desired to see a plot of performance as a function of time for different setups to demonstrate the speedup after convergence it seems the paper only focuses on the speedup factors per iteration for example increasing the mini batch size may improve the speed per iteration but may hurt the convergence speed did you consider a scenario where the dataset is too big that storing the data and auxiliary variables on multiple machines simultaneously is not possible the paper cites an arxiv manuscript with the same title by the authors multiple times please make the paper self contained and include any supplementary material in the appendix i believe without applying this framework to a more generic architecture beyond binary autoencoders this paper does not appeal to a wide audience at iclr hence weak reject,5.0
605.json,the authors propose a variational autoencoder for a specific form of tree generating model the generative model for trees seems reasonable but is not fully motivated if no previous references suggest this tree specification then clear motivation for e g the extension beyond cfg should be given beyond the one sentence provided given the tree model it may be natural to specify a tree model encoder but the posterior distribution does not respect the structure of the prior as the posterior distribution couples tree distant variables so there is in fact no good reason for this form and a more general network could be compared with the approach provides sensible differentiable functions for encoding the network the tests are indicative but the results are very similar to the tested approaches and it is not clear what the best evaluation metric ought to be significance the work may well be significant in the future but is currently somewhat preliminary lacks motivation chooses a tree structured encoder without particular motivation and is lacking in wider comparisons there is also some lack of current motivation for the model and no comparison with tractable models that do not need a variational autoencoder originality original but at the moment it is not clear such originality is necessary clarity good experiments sensible but not extensive or conclusive,3.0
384.json,the paper looks at the problem of locating the answer to a question in a text for this task the answer is always part of the input text for this the paper proposes to combine two existing works match lstm to relate question and text representations and pointer net to predict the location of the answer in the text strength the suggested approach makes sense for the task and achieves good performance although as the authors mention recent concurrent works achieve better results the paper is evaluated on the squad dataset and achieves significant improvements over prior work weaknesses it is unclear from the paper how well it is applicable to other problem scenarios where the answer is not a subset of the input text experimental evaluation it is not clear why the bi ans ptr in table is not used for the ensemble although it achieves the best performance it would be interested if this approach generalizes to other datasets other minor discussion points the task and approach seem to have some similarity of locating queries in images and visual question answering the authors might want to consider pointing to related works in this direction i am wondering how much this task can be seen as a guided extractive summarization i e where the question guides the summarization process page last paragraph missing searching this summary while the paper presents an interesting combination of two approaches for the task of answer extraction the novelty is moderate while the experimental results are encouraging it remains unclear how well this approach generalizes to other scenarios as it seems a rather artificial task,6.0
445.json,as discussed the there are multiple concurrent contributions in different packages submission by the authors that are in parts difficult to disentangle despite this fact it is impressive to see a system learning from natural feedback in an online fashion to the best of my knowledge this is a new quality of result that was achieved in particular as close to full supervision results are reached in some cases in this less constraint setting several points were raised that were in turn addressed by the authors formalisation of the task learning dialogue is not precise when can we declare success the answer of the authors is partially satisfying for this particular work it might make sense to more precisely set goals e g to be as good as full supervision along the line of the previous question dialogue can be seen as a form of noisy supervision can you please report the classic supervision baselines for the particular model used this would give a sense what fraction of the best case performance is achieved via dialogue learning the authors provided additional information along those lines and i think this helps to understand how much of the overall goal was achieved and open challenges is there an understanding of how much more difficult the mt setting is feedback could be hand labeled as positive or negative for an analysis or a handcrafted baseline could be tested that either extracts the reward via template matching or maybe even uses the length of the feedback as a proxy baseline it looks to me that short feedback is highly correlated with high reward correct answer the authors replied but it would have been clearer if they could have quantified such suggested baseline in order to confirm that there is no simple handcrafted baseline that would do well on the data but these concerns are marginal relation to prior work weston is not fully clear i understand that this submission should be understood as an independent submission of the prior work weston and not replacing it in this case weston makes this submission appear more incremental my understanding is that the punch line of this submission is the online part that leads in turn to more exploration is there any analysis on how much this aspect matters i couldn t find this in the experiments the authors clarified the raised issues the application of reinforcement learning and in particular fp is convincing there is a incremental nature to the paper and the impression is emphasised by multiple concurrent contributions of the authors on this research thread comparison to prior work in particular weston should be made more explicit not only in text but also in the experiments as the authors partially do in their reply to the reviewers question nevertheless this particular contribution is assessed as significant and worth sharing and seems likely to have impact on how we can learn in these less constraint setting,7.0
445.json,this paper builds on the work of weston using end to end memory network models for a limited form of dialogue with teacher feedback as the authors state in the comments it is closely related to the question answering problem with the exception that a teacher provides a response after the model s answer which does not always come with a positive reward thus the model must learn to use the teacher s feedback to significantly improve performance overall the paper is written clearly and several interesting models are tested it is certainly only a limited form of dialogue that is considered closer to question answering since the questions do not require the agent to look further back into the context but investigating in this direction could prove fruitful once the tasks are scaled up to be more difficult my main concern is with the paper s novelty in the words of the authors this paper has two primary differences with the work of weston i that earlier work did not use the natural reinforcement learning online setting but cheated with a fixed policy given in advance it is important to address the realistic online setting and assess whether the methods particularly fp still work or else what changes e g exploration balancing see fig and table are needed ii that earlier work had only simulated data and no real language data so was only toy this work uses mechanical turk to do real experiments which again is important to assess if these methods particularly fp work on real language point ii is very much appreciated but adding additional human testing data is not sufficient for a conference paper thus the main point of the paper is that the model also works if we collect the data online i e the agent s policy is used to collect data rather than a fixed policy beforehand while this is a step in the right direction i m not sure if it s significant enough for an iclr paper little model novelty is required to solve this additional requirement on these tasks beyond using epsilon greedy exploration thus the paper is borderline accept reject edit i have updated my score slightly in light of the author response where they make a good point that real world implementation should be more strongly considered as part of the contribution,6.0
445.json,summary this paper describes a set of experiments evaluating techniques for training a dialogue agent via reinforcement learning a standard memory network architecture is trained on both babi and a version of the wikimovies dataset as in weston which this work extends numerous experiments are performed comparing the behavior of different training algorithms under various experimental conditions strengths the experimentation is comprehensive i agree with the authors that these results provide additional useful insight into the performance of the model in the paper henceforth w weaknesses this is essentially an appendix to the earlier paper there is no new machine learning content secondarily the paper seems to confuse the distinction between training with an adaptive sampling procedure and training in interactive environments more generally in particular no comparisons are presented to the to the experiments with a static exploration policy presented in w when the two training can should be evaluated side by side the only meaningful changes between this work and w involve simple and already well studied changes to the form of this exploration policy my primary concern remains about novelty the extra data introduced here is welcome enough but probably belongs in a acl short paper or a technical report this work does not stand on its own and an iclr submission is not an appropriate vehicle for presenting it reinforcement learning update concerns in this section have been addressed by the authors this paper attempts to make a hard distinction between the reinforcement learning condition considered here and the non rl condition considered in w i do not think this distinction is nearly as sharp as it made out to be as already noted in weston the rbi objective is a special case of vanilla policy gradient with a zero baseline and off policy samples in this sense the version of rbi considered in this paper is the same as in w but with a different exploration policy reinforce is the same objective with a nontrivial baseline similarly the change in fp is only a change to the sampling policy the fixed dataset online learning distinction is not especially meaningful when the fixed dataset consists of endless synthetic data it should be noted that some variants of the exploration policy in w provide a stronger training signal than is available in the rl from scratch setting here in particular when piacc the training samples will feature much denser reward however if i correctly understand figures and in this paper the completely random initial policy achieves an average reward of on babi and on movies as good or better than the other exploration policies in w i think this paper would be a lot clearer if the delta from w were expressed directly in terms of their different exploration policies rather than trying to cast all of the previous work as not rl when it can be straightforwardly accommodated in the rl framework i was quite confused by the fact that no direct comparisons are made to the training conditions in the earlier work i think this is a symptom of the problem discussed above once this paper adopts the position that this work is about rl and the previous work is not it becomes possible to declare that the two training scenarios are incomparable i really think this is a mistake to the extent that the off policy sample generators used in the previous paper are worse than chance it is always possible to compare to them fairly here evaluating everything in the online setting and presenting side by side experiments would provide a much more informative picture of the comparative behavior of the various training objectives on policy vs off policy vanilla policy gradient methods like the ones here typically can not use off policy samples without a little extra hand holding importance sampling trust region methods etc they seem to work out of the box for a few of the experiments in this paper which is an interesting result on its own it would be nice to have some discussion of why that might be the case other notes the claim that batch size is related to off policy learning is a little odd there are lots of on policy algorithms that require the agent to collect a large batch of transitions from the current policy before performing an on policy update i think the experiments on fine tuning to human workers are the most exciting part of this work and i would have preferred to see these discussed and explored with in much more detail rather than being relegated to the penultimate paragraphs,5.0
629.json,the author works to compare dnns to human visual perception both quantitatively and qualitatively their first result involves performing a psychophysical experiment both on humans and on a model and then comparing the results actually i think the psychophysical data was collected in a different work and is just used here the specific psychophysical experiment determined separately for each of a set of approx images what the noise level of additive noise would have to be to make a just noticeable difference for humans in discriminating the noiseless image from the noisy one the authors then define a metric on neural networks that allows them to measure what they posit might be a similar property for the networks they then correlate the pattern of noise levels between neural networks that the humans deep neural networks end up being much better predictors of the human pattern of noise levels than simpler measure of image perturbation e g rms contrast a second result involves comparing dnns to humans in terms of their pattern errors in a series of highly controlled experiments using stimuli that illustrate classic properties of human visual processing including segmentation crowding and shape understanding they then used an information theoretic single neuron metric of discriminability to assess similar patterns of errors for the dnns again top layers of dnns were able to reproduce the human patterns of difficulty across stimuli at least to some extent a third result involves comparing dnns to humans in terms of their pattern of contrast sensitivity across a series of sine grating images at different frequencies there is a classic result from vision research as to what this pattern should be so it makes a natural target for comparison to models the authors define a dnn correlate for the propertie in terms of the cross neuron average of the l distance between responses to a blank image and responses to a sinuisoid of each contrast and frequency they then qualitatively compare the results of this metric for dnns models to known results from the literature on humans finding that like humans there is an apparent bandpass response for low contrast gratings and a mostly constant response at high contrast pros the general concept of comparing deep nets to psychophysical results in a detailed quantitative way is really nice they nicely defined a set of linking functions e g metrics that express how a specific behavioral result is to be generated from the neural network ie the l metrics in results and and the information theoretic measure in result the framework for setting up such linking functions seems like a great direction to me the actual psychophysical data seems to have been handled in a very careful and thoughtful way these folks clearly know what they are doing on the psychophysical end cons to my mind the biggest problem wit this paper is that that it does not say something that we did not really know already existing results have shown that dnns are pretty good models of the human visual system in a whole bunch of ways and this paper adds some more ways what would have been great would be a showing that they metric of comparison to humans that was sufficiently sensitive that it could pull apart various dnn models making one clearly better than the others b identifying a wide gap between the dnns and the humans that is still unfilled they sort of do this since while the dnns are good at reproducing the human judgements in result they are not perfect gap is between explained variance and inter human consistency this gap is potentially important so i would really like to see them have explored that gap more e g i widening the gap by identifying which images caused the gap most and focusing a test on those or ii closing the gap by training a neural network to get the pattern correct and seeing if that made better cnns as measured on other metrics tasks in other words i would definitely have traded off not having results and for a deeper exploration of result i think their overall approach could be very fruitful but it has not really been carried far enough here i found a few things confusing about the layout of the paper i especially found that the quantitative results for results and were not clearly displayed why was figure relegated to the appendix where are the quantifications of model human similarities for the data shown in figure is not this the whole meat of their second result this should really be presented in a more clear way where is the quantification of model human similarity for the data show in figure is not there a way to get the human contrast sensitivity curve and then compare it to that of models in a more quantitively precise way rather than just note a qualitative agreement it seems odd to me that this was not done,6.0
629.json,this paper compares the performance in terms of sensitivity to perturbations of multilayer neural networks to human vision in many of the tasks tested multilayer neural networks exhibit similar sensitivities as human vision from the tasks used in this paper one may conclude that multilayer neural networks capture many properties of the human visual system but of course there are well known adversarial examples in which small perceptually invisible perturbations cause catastrophic errors in categorization so against that backdrop it is difficult to know what to make of these results that the two systems exhibit similar phenomenologies in some cases could mean any number of things and so it would have been nice to see a more in depth analysis of why this is happening in some cases and not others for example for the noise perturbations described in the the first section one sees already that conv is correlated with human sensitivity so why not examine how the first layer filters are being combined to produce this contextual effect from that we might actually learn something about neural mechanisms although i like and am sympathetic to the direction the author is taking here i feel it just scratches the surface in terms of analyzing perceptual correlates in multilayer neural nets,6.0
783.json,this paper was easy to read the main idea was presented very clearly the main points of the paper and my concerns are below can be summarized as follows synchronous algoriths suffer from some struggeling nodes for which the algorithm has to wait from my own experience this has never happend for me on e g amazon ec cloud however it happens on our own cluster at my university if the cluster is shared and some users make some nodes very busy so maybe if the nodes would be dedicated to just user job it would not be such a big concer i am not sure what kind of cluster was used to produce figure and also how many experiments have you run in my own experience most of the time i get the gradient on time from all nodes equality fast but maybe just in less than of iterations i observe that it took maybe twice as long for some node also the increasing shape of the curve is somehow implying some weird implementation of communication is not it only because you are somehow serialize the communication and it would be maybe much faster if a mpireduce would be used even if we wait for the slowest guy asynchronous algorithms are cutting the waiting time however the convergence speed may be slower moreover those algorithms can be divergence it special care is not given to stale gradients also they have a nice guarantees for convex functions but the non convex dnn may cause pain they propose to take gradient from the first n workers out of n b workers available my concern here is that they focused only on the workers but what if the parameter server will became to slow what if the parameter server would be the bottleneck how would you address this situation but still if the number of nodes n is not large and the deep dnn is used i can imagine that the communciation will not take more than of the run time my largest concern is with the experiments different batch size implies that different learning rate should be chosen right how did you tune the learning rates and other parameters for e g figure you provide some formulas in a but clearly this can bias your figures right meaning that if you tune gamma beta for each n it could be somehow more representative also it would be nicer if you run the experiment many times and then report average best and worst case behaviour because now it can be just coinsidence right,6.0
783.json,this paper proposed a synchronous parallel sgd by employing several backup machines the parameter server does not have to wait for the return from all machines to perform the update on the model which reduce the synchronization overhead it sounds like a reasonable and straightforward idea my main concern is that this approach is only suitable for some very specific scenario that is most learners except a small number of learners are at the same pace to return the results if the efficiency of learners does not follow such distribution i do not think that the proposed algorithm will work so i suggest two revisions provide more experiments to show the performance with different efficiency distributions of learners assuming that all learners follow the same distribution of efficiency and show the expected idle time is minor by using the proposed algorithm,6.0
783.json,the paper claim that when supported by a number of backup workers synchronized sgd actually works better than async sgd the paper first analyze the problem of staled updates in async sgds and proposed the sync sgd with backup workers in the experiments the authors shows the effectiveness of the proposed method in applications to inception net and pixelcnn the idea is very simple but in practice it can be quite useful in industry settings where adding some backup workders is not a big problem in cost nevertheless i think the proposed solution is quite straightforward to come up with when we assume that each worker contains the full dataset and we have budge to add more workers so under this setting it seems quite natural to have a better performance with the additional backup workers that avoid the staggering worker problem and with this assumtion i am not sure if the proposed solution is solving difficult enough problem with novel enough idea in the experiments for fair comparison i think the async sgd should also have a mechanism to cut off updates of too much staledness just as the proposed method ignores all the remaining updates after having n updates for example one can measure the average time spent to obtain n updates in sync sgd setting and use that time as the cut off threashold in async sgd so that async sgd does not perform so poorly,5.0
453.json,the paper presents a second order method for training a neural networks while ensuring at the same time that weights and activations are binary through binarization the method aims to achieve model compression for subsequent deployment on low memory systems the method is abbreviated bpn for binarization using proximal newton algorithm the method incorporates the supervised loss function directly in the binarization procedure which is an important and desirable property authors mention that existing weight binarization methods ignore the effect of binarization to the loss the method is clearly described and related analytically to the previously proposed weight binarization methods the experiments are extensive with multiple datasets and architectures and demonstrate the generally higher performance of the proposed approach a minor issue with the feed forward network experiments is that only test errors are reported such information does not really give evidence for the higher optimization performance see also comment re anonreviewer questions stating that all baselines achieve near perfect training accuracy making the optimization problem harder e g by including an explicit regularizer into the training objective or by using a data extension scheme and monitoring the training objective instead of the test error could be a more direct way of demonstrating superior optimization performance the superiority of bpn is however becoming more clearly apparent in the subsequent lstm experiments,7.0
404.json,this paper introduces the quasi recurrent neural network qrnn that dramatically limits the computational burden of the temporal transitions in sequence data briefly and slightly inaccurately model starts with the lstm structure but removes all but the diagonal elements to the transition matrices it also generalizes the connections from lower layers to upper layers to general convolutions in time the standard lstm can be though of as a convolution with a receptive field of time step as discussed by the authors the model is related to a number of other recent modifications of rnns in particular bytenet and strongly typed rnns t rnn in light of these existing models the novelty of the qrnn is somewhat diminished however in my opinion their is still sufficient novelty to justify publication the authors present a reasonably solid set of empirical results that support the claims of the paper it does indeed seem that this particular modification of the lstm warrants attention from others while i feel that the contribution is somewhat incremental i recommend acceptance,6.0
404.json,this paper introduces a novel rnn architecture named qrnn qnns are similar to gated rnn however their gate and state update functions depend only on the recent input values it does not depend on the previous hidden state the gate and state update functions are computed through a temporal convolution applied on the input consequently qrnn allows for more parallel computation since they have less operations in their hidden to hidden transition depending on the previous hidden state compared to a gru or lstm however they possibly loose in expressiveness relatively to those models for instance it is not clear how such a model deals with long term dependencies without having to stack up several qrnn layers various extensions of qrnn leveraging zoneout densely connected or seqseq with attention are also proposed authors evaluate their approach on various tasks and datasets sentiment classification world level language modelling and character level machine translation overall the paper is an enjoyable read and the proposed approach is interesting pros address an important problem nice empirical evaluation showing the benefit of their approach demonstrate up to x speed up relatively to a lstm cons somewhat incremental novelty compared to balduzizi et al few specific questions is densely layer necessary to obtain good result on the imdb task how does a simple layer qrnn compare with layer lstm how does the i fo ifo pooling perform comparatively how does qrnn deal with long term time depency did you try on it on simple toy task such as the copy or the adding task,7.0
404.json,the authors describe the use of convolutional layers with intermediate pooling layers to more efficiently model long range dependencies in sequential data compared with recurrent architectures whereas the use of convolutional layers is related to the pixelcnn architecture oord et al the main novelty is to combine them with gated pooling layers to integrate information from previous time steps additionally the authors describe extensions based on zone out regularization densely connected layers and an efficient attention mechanism for encoder decoder models the authors report a striking speed up over rnns by up to a factor of while achieving similar or even higher performances major comment qrnns are closely related to pixelcnns which leverage masked dilated convolutional layers to speed up computations however the authors cite bytenet which builds upon pixelcnn only at the end of their manuscript and do not include it in the evaluation the authors should cite pixelcnn already when introducing qrnn in the methods sections and include it in the evaluation at the very least qrnn should be compared with bytenet for language translation how well does a fully convolutional model without intermediate pooling layers perform i e what is the effect to the introduced pooling layers are their performance difference between f fo and ifo pooling did the authors investigate dilated convolutional layers minor comments how does a model without dense connections perform i e what is the effect of dense connections to illustrate dense connections the authors might draw them in figure and refer to it in section the run time results shown in figure are very helpful but as far as i understood the breakdown shown on the left side was measured for language modeling referred in whereas the dependency on batch and sequence size shown on the right side for sentiment classification referred in i suggest to consistently show the results for either sentiment classification or language modeling or both at the very least the figure caption should describe the task explicitly labeling the left and right figure by a and b would further improve readability section describes a high speed up for long sequences and small batch sizes i suggest motivating why this is the case while computations can be parallelized along the sequence length it is less obvious why smaller batch sizes speed up computations the proposed encoder decoder attention is different from traditional attention in that attention vectors are not computed and used as input to the decoder sequentially but on top of decoder output states in parallel this should be described and motivated in the text sentiment classification what was the size of the hold out development set and how was it created the text describes that data were split equally into training and test set without describing the hold out set what was the convolutional filter size what is the speed up for the best hyper parameters batch size sequence length figure would be easier to interpret by actually showing the text on the y axis for the sake of space one might use a smaller text passage plot it along the x axis and show the activations of fewer neurons along the y axis showing more examples in the appendix would make the authors claim that neurons are interpretable even more convincing language modeling what was the size of the training test and validation set what was the convolutional filter size denoted as k is it correct that a very high learning rate of was used for six epochs at the beginning the authors should show learning curves for a models with and without zone out translation what was the size of the training test and validation set how does translation performance depend on k,5.0
404.json,this paper points out that you can take an lstm and make the gates only a function of the last few inputs ht f xt x t x t t instead of the standard ht f xt h t and that if you do so the networks can run faster and work better you are moving compute from a serial stream to a parallel stream and also making the serial stream more parallel unfortunately this simple effective and interesting concept is somewhat obscured by confusing language i would encourage the authors to improve the explanation of the model another improvement might be to explicitly go over some of the big oh calculations or give an example of exactly where the speed improvements are coming from otherwise the experiments seem adequate and i enjoyed this paper this could be a high value contribution and become a standard neural network component if it can be replicated and if it turns out to work reliably in multiple settings,7.0
392.json,this paper proposes an autoencoder approach to lossy image compression by minimizing the weighted sum of reconstruction error and code length the architecture consists of a convolutional encoder and a sub pixel convolutional decoder experiments compare psnr ssim and ms ssim performance against jpeg jpeg and a recent rnn based compression approach a mean opinion score test was also conducted pros the paper is clear and well written the decoder architecture takes advantage of recent advances in convolutional approaches to image super resolution the proposed approaches to quantization and rate estimation are sensible and well justified cons the experimental baselines do not appear to be entirely complete the task of using autoencoders to perform compression is important and has a large practical impact though directly optimizing the rate distortion tradeoff is not an entirely novel enterprise there are enough differences e g the quantization approach and sub pixel convolutional decoder to sufficiently distinguish this from earlier work i am not an image compression expert but the approach and results both seem compelling the main shortcoming is that the implementation of toderici et al b appears to be incomplete and there is no comparison to balle et al overall i feel that the fact that this architecture achieves competitive performance with jpeg while simultaneously setting the stage for future work that varies the encoder decoder size and data domain means the community will find this work to be of significant interest i have no further specific comments at this time as they were answered sufficiently in the pre review questions,7.0
668.json,the paper experimentally investigates a slightly modified version of label smoothing technique for neural network training and reports results on various tasks such smoothing idea is not new but was not investigated previously in wide range of machine learning tasks comments the paper should report the state of the art results for speech recognition tasks timit wsj even if models are not directly comparable the error back propagation of label smoothing through softmax is straightforward and efficient is there an efficient solution for bp of the entropy smoothing through softmax although the classification accuracy could remain the same the model will not estimate the true posterior distribution with this kind of smoothing this might be an issue in complex machine learning problems where the decision is made on higher level and based on the posterior estimations e g language models in speech recognition more motivation is necessary for the proposed smoothing,6.0
668.json,specifically this paper suggests regularizing the estimator of a probability distribution to prefer high entropy distributions this avoids overfitting i generally like this idea regularizing the behavior of the model often makes more sense than regularizing its parameters after all the behavior is interpretable whereas the parameters are uninterpretable and work together in mysterious ways to produce the behavior so one might be able to choose a more sensible prior over the behavior in other words prefer parameters not because they are individually close to but because they jointly lead to a distribution that is plausible or low risk a priori pro i believe that the idea is natural and sound that is i do not share the doubts of anonreviewer pro it possible that this has not been well explored yet in neural networks not sure pro the experimental results look good so maybe everyone should use this kind of regularizer con it is a kind of pollution of the scientific literature to introduce this idea to the community as if it were unconnected to almost anything else in machine learning there are many many papers that include a scaled entropy term in the optimization objective it not just for reinforcement learning please see the long list of connections in my pre review questions comments con experimental results should always be accompanied by significance tests and error analysis is your trained model actually doing better on the distribution of test data or was your test set too small to tell are the improvements robust across many different training sets what errors does your model fix and what errors does it introduce summary recommendation revise and resubmit iclr has lots of submissions i would prefer to reward authors who not only tried something but who properly contextualized it and carefully evaluated it otherwise there a race to the bottom where everyone wants to be the first to try something so that readers are confronted with a confusing sea of slapdash papers with unclear relationships,5.0
668.json,the authors propose a simple idea they penalize confident predictions by using the entropy of the predictive distribution as a regularizer the authors consider two variations on this idea in one they penalize the divergence from the uniform distribution in the other variation they penalize distance from the base rates they term this variation unigram but i find the name odd as i have never seen multi class labels described as unigrams before what would a bigram be the idea is simple and while it been used in the context of reinforcement learning it has not been popularized as a regularizer for improving generalization in supervised learning the justifications for the idea still lacks analysis and the author responses comparing it to l regularization have some holes a simple number line example with polynomial regression makes clear how l regularization could prevent a model from badly overfitting to accommodate every data point in contrast it seems trivial to fit every data point and satisfy arbitrarily high entropy of course the un regularized optimization is to maximize log likelihood not simply to maximize accuracy and perhaps something interesting may be happening at the interplay between the log likelihood objective and the regularization objective but the paper does not indicate precisely what i could imagine the following scenario when the network outputs probabilities near it can get high loss if the label is the entropy regularization could be stabilizing the gradient preventing sharp loss on outlier examples the regularization then might owe mainly to faster convergence could the authors analyze the effect empirically on the distribution of the gradient norms the strength of this paper is its empirical rigor the authors take their idea and put it through its paces on a host of popular and classic benchmarks spanning cnns and rnns it appears that on some datasets especially language modeling the confidence penalty outperforms label smoothing at present i rate this paper as a borderline contribution but i am open to revising my review pending further modifications typo in related work penalizing entropy you mean penalizing low entropy,5.0
393.json,this is a very nice paper the writing of the paper is clear it starts from the traditional attention mechanism case by interpreting the attention variable z as a distribution conditioned on the input x and query q the proposed method naturally treat them as latent variables in graphical models the potentials are computed using the neural network under this view the paper shows traditional dependencies between variables i e structures can be modeled explicitly into attentions this enables the use of classical graphical models such as crf and semi markov crf in the attention mechanism to capture the dependencies naturally inherit in the linguistic structures the experiments of the paper prove the usefulness of the model in various level seqseq and tree structure etc i think it s solid and the experiments are carefully done it also includes careful engineering such as normalizing the marginals in the model in sum i think this is a solid contribution and the approach will benefit the research in other problems,8.0
393.json,this is a solid paper that proposes to endow attention mechanisms with structure the attention posterior probabilities becoming structured latent variables experiments are shown with segmental atention as in semi markov models and syntactic attention as in projective dependency parsing both in a synthetic task tree transduction and real world tasks neural machine translation and natural language inference there is a small gain in using structured attention over simple attention in the latter tasks a clear accept the paper is very clear the approach is novel and interesting and the experiments seem to give a good proof of concept however the use of structured attention in neural mt seems does not seem to be fully exploited here segmental attention could be a way of approaching neural phrase based mt and syntactic attention offers a way of incorporating latent syntax in mt these seem very promising directions in particular it would be interesting to try to add some semi supervision on these attention mechanisms e g posterior marginals computed by an external parser to see if that helps learning the attention components of the network or at least help initializing them this seems to be the first interesting use of the backprop of forward backward inside outside stoyanov et al as stated in sec for general probabilistic models the forward step over structured attention corresponds to the computation of first order moments posterior marginals while the backprop step corresponds to second order moments gradients of marginals wrt log potentials i e hessian of log partition function this extends the applicability of the proposed approach to arbitrary graphical models where these quantities can be computed efficiently e g is there a generalized matrix tree formula that allows to do backprop for non projective syntax on the negative side i suspect the need for second order statistics may bring some numerical instability in some problems caused by the use of the signed log space field was this seen in practice minor comments typos last paragraph of sec standard attention attention third paragraph of sec the on log potentials sec results as it has no information about the source ordering what do you mean here,8.0
393.json,the authors propose to extend the standard attention mechanism by extending it to consider a distribution over latent structures e g alignments syntactic parse trees etc these latent variables are modeled as a graphical model with potentials derived from a neural network the paper is well written and clear to understand the proposed methods are evaluated on various problems and in each case the structured attention models outperform baseline models either one without attention or using simple attention for the two real world tasks the improvements obtained from the proposed approach are relatively small compared to the simple attention models but the techniques are nonetheless interesting main comments in the japanese english machine translation example the relative difference in performance between the sigmoid attention model and the structured attention model appears to be relatively small in this case i m curious if the authors analyzed the attention alignments to determine whether the structured models resulted in better alignments in other words if ground truth alignments are available for the dataset or if they can be human annotated for some test examples it would be interesting to measure the quality of the alignments in addition to the bleu metric in the final experiment on natural language inference i thought it was a bit surprising that using pretrained syntactic attention layers did not appear to improve model performance but instead appear to degrade performance i was curious if the authors have any hypotheses for why this is the case minor comments typographical error equation p z x q p z x q section past work has demonstrated that the techniques necessary for this approach past work has demonstrated the techniques necessary for this approach,8.0
686.json,the paper presents a method to reduce the memory footprint of a neural network at some increase in the computation cost this paper is a generalization of hashednets by chen et al icml where parameters of a neural network are mapped into smaller memory arrays using some hash functions with possible collisions instead of training the original parameters given a hash function the elements of the compressed memory arrays are trained using back propagation in this paper some new tricks are proposed including the compression space is shared among the layers of the neural network multiple hash functions are used to reduce the effects of collisions a small network is used to combine the elements retrieved from multiple hash tables into a single parameter fig of the paper describes the gist of the approach vs hashednets on the positive side the proposed ideas are novel and seem useful some theoretical justification is presented to describe why using multiple hash functions is a good idea all of the experiments suggest that the proposed mfh approach outperforms hashednets on the negative side the computation cost seems worse than hashednets and is not discussed immediate practical implication of the paper is not clear given that alternative pruning strategies perform better and should be faster at inference that said i believe this paper benefits the deep learning community as it sheds light into ways to share parameters across layers of a neural network potentially leading to more interesting follow ups i recommend accept while asking the authors to address the comments below more comments please discuss the computation cost for both hashednets and mfh for both fully connected and convolutional layers are the experiments only run once for each configuration please run multiple times and report average standard error for completeness please add u results to table in table u g is listed twice with two different numbers some sentences are not grammatically correct please improve the writing,6.0
405.json,the paper presents an action conditional recurrent network that can predict frames in video games hundreds of steps in the future the paper claims three main contributions modification to model architecture used in oh et al by using action at time t to directly predict hidden state at t exploring the idea of jumpy predictions predictions multiple frames in future without using intermediate frames exploring different training schemes trade off between observation and prediction frames for training lstm modification to model architecture the motivation seems good that in past work oh et al the action at t influences xt but not the state ht of the lstm this could be fixed by making the lstm state ht dependent on a t however this is of minor technical novelty also as pointed in reviewer questions a similar effect could be achieved by adding at as an input to the lstm at time t this could be done without modifying the lstm architecture as stated in the paper while the authors claim that combining at with ht and st performs worse than the current method which combines at only with ht i would have liked to see the empirical difference in combining at only with st or only with ht also a stronger motivation is required to support the current formulation further the benefits of this change in architecture is not well analyzed in experiments fig a provides the difference between oh et al with traditional lstm and current method however the performance difference is composed of components difference in training scheme and architecture this contribution of the architecture to the performance is not clear from this experiment the authors did claim in the pre review phase that fig a shows the difference in performance only due to architecture for seaquest however from this plot it appears that the gain at steps is only a small fraction of the overall gain in fig a it is difficult to judge the significance of the architecture modification from this result for one game exploring the idea of jumpy predictions as stated by the authors omitting the intermediate frames while predicting future frames could significantly sppedup simulations the results in fig b present some interesting observations that omitting intermediate frames does not lead to significant error increase for at least a few games however it is again not clear whether the modification in the current model leads to this effect or it could be achieved by previous models like oh et al while the observations themselves are interesting it would have been better to provide a more detailed analysis for more games also the novelty in dropping intermediate frames for speedup is marginal exploring different training schemes this is perhaps the most interesting observation presented in the paper the authors present the difference in performance for different training schemes in fig a the training schemes are varied based on the fraction of training phase which only uses observation frames and the fraction that uses only prediction frames the results show that this change in training can significantly affect prediction results and is the biggest contributor to performance improvement compared to oh et al while this observation is interesting this effect has been previously explored in detail in other works like schedule sampling bengio et al and to some extent in oh et al clarity of presentation the exact experimental setup is not clearly stated for some of the results for instance the paper does not say that fig a uses the same architecture as oh et al however this is stated in the response to reviewer questions fig is difficult to interpret the qualitative difference between oh et al and current method could be highlighted explicitly minor the qualitative analysis section requires the reader to navigate to various video links in order to understand the section this leads to a discontinuity in reading and is particularly difficult while reading a printed copy overall the paper presents some interesting experimental observations however the technical novelty and contribution of the proposed architecture and training scheme is not clear,5.0
540.json,the paper proposes a methodology for morphing a trained network to different architecture without having to retrain from scratch the manuscript reads well and the description is easy to follow however the results are not very convincing as the selected baselines are considerably far from the state of the art the paper should include comparisons with state of the art for example wide residual networks tables should also report number of parameters for each architecture this would help fair comparison,7.0
452.json,this paper shows that extending deep rl algorithms to decide which action to take as well as how many times to repeat it leads to improved performance on a number of domains the evaluation is very thorough and shows that this simple idea works well in both discrete and continuous actions spaces a few comments questions table could be easier to interpret as a figure of histograms figure could be easier to interpret as a table how was the subset of atari games selected the atari evaluation does show convincing improvements over ac on games requiring extended exploration e g freeway and seaquest but it would be nice to see a full evaluation on games this has become quite standard and would make it possible to compare overall performance using mean and median scores it would also be nice to see a more direct comparison to the straw model of vezhnevets et al which aims to solve some of the same problems as figar figar currently discards frames between action decisions there might be a tradeoff between repeating an action more times and throwing away more information have you thought about separating these effects you could train a model that does process intermediate frames just a thought overall this is a nice simple addition to deep rl algorithms that many people will probably start using i am increasing my score to based on the rebuttal and the revised paper,8.0
452.json,this paper proposes a simple but effective extension to reinforcement learning algorithms by adding a temporal repetition component as part of the action space enabling the policy to select how long to repeat the chosen action for the extension applies to all reinforcement learning algorithms including both discrete and continuous domains as it is primarily changing the action parametrization the paper is well written and the experiments extensively evaluate the approach with different rl algorithms in different domains atari mujoco and torcs here are some comments and questions for improving the paper the introduction states that all drl algorithms repeatedly execute a chosen action for a fixed number of time steps k this statement is too strong and is actually disproved in the experiments repeating an action is helpful in many tasks but not in all tasks the sentence should be rephrased to be more precise in the related work a discussion of the relation to semi mdps would be useful to help the reader better understand the approach and how it compares and differs e g the response from the pre review questions experiments can you provide error bars on the experimental results from running multiple random seeds it would be useful to see experiments with parameter sharing in the trpo experiments to be more consistent with the other domains especially since it seems that the improvement in the trpo experiments is smaller than that of the other two domains right now it is hard to tell if the smaller improvement is because of the nature of the task because of the lack of parameter sharing or something else the trpo evaluation is different from the results reported in duan et al icml why not use the same benchmark videos only show the policies learned with figar which are uninformative without also seeing the policies learned without figar can you also include videos of the policies learned without figar as a comparison point how many laps does ddpg complete without figar the difference in reward achieved seems quite substantial k vs k can the tables be visualized as histograms this seems like it would more effectively and efficiently communicate the results minor comments on the plot in figure the label for the first bar should be changed from to idea of deciding when necessary seems like it would be better to say idea of only deciding when necessary spaces durugkar et al missing a space r why could you use a letter to indicate a constant instead or a different notation,8.0
628.json,the paper discusses sub modular sum product networks as a tractable extension for classical sum product networks the proposed approach is evaluated on semantic segmentation tasks and some early promising results are provided summary i think the paper presents a compelling technique for hierarchical reasoning in mrfs but the experimental results are not yet convincing moreover the writing is confusing at times see below for details quality i think some of the techniques could be described more carefully to better convey the intuition clarity some of the derivations and intuitions could be explained in more detail originality the suggested idea is great significance since the experimental setup is somewhat limited according to my opinion significance is hard to judge at this point in time detailed comments i think the clarity of the paper would benefit significantly from fixes to inaccuracies e g alpha expansion and belief propagation are not scene understanding algorithms but rather approaches for optimizing energy functions computing the map state of an sspn in time sub linear in the network size seems counterintuitive because it means we are not allowed to visit all the nodes in the network the term deep probabilistic model should probably be defined the paper states that infersspn computes the approximate map state of the sspn equivalently the optimal parse of the image and i m wondering how the approximate map state can be optimal etc albeit being formulated for scene understanding tasks no experiments demonstrate the obtained results of the proposed technique to assess the applicability of the proposed approach a more detailed analysis is required more specifically the technique is evaluated on a subset of images which makes comparison to any other approach impossible according to my opinion either a conclusive experimental evaluation using e g iou metric should be given in the paper or a comparison to publicly available results is possible to simplify the understanding of the paper a more intuitive high level description is desirable maybe the authors can even provide an intuitive visualization of their approach,5.0
782.json,this paper introduces a novel hierarchical memory architecture for neural networks based on a binary tree with leaves corresponding to memory cells this allows for o log n memory access and experiments additionally demonstrate ability to solve more challenging tasks such as sorting from pure input output examples and dealing with longer sequences the idea of the paper is novel and well presented and the memory structure seems reasonable to have advantages in practice however the main weakness of the paper is the experiments there is no experimental comparison with other external memory based approaches e g those discussed in related work or experimental analysis of computational efficiency given overhead costs beyond just computational complexity despite that being one of the main advantages furthermore the experimental setups are relatively weak all on artificial tasks with moderate increases in sequence length improving on these would greatly strengthen the paper as the core idea is interesting,5.0
782.json,this paper proposes to use a hierarchical softmax to speed up attention based memory addressing in memory augmented network e g ntm memnn the model build a hierarchical softmax on top of the input sequence then at each time step search for the most relevant input to predict the next output this search is discrete and use its corresponding embedding to update the state of an lstm that will then produce the output finally the embedding of the used input is update by a write function an lstm working that takes hidden state of the other lstm as an input the model has a discrete component the search and is thus trained with reinforce in the experimental section they test their approach on several algorithmic tasks such as search sort the main advantage of replacing the full softmax by a hierarchical softmax is that during inference the complexity goes from o n to o log n it would be great to see if the gain in complexity allows to tackle problem which are a few orders of magnitude bigger than the one addressed with full softmax however the authors only test on toy sequences up to tokens which is quite small the model requires a relatively complex search mechanism that can only be trained with reinforce while this seems to work on problems with relatively small and simple sequences it would be great to see how performance changes with the size of the problem overall while the idea of replacing the softmax in the attention mechanism by a hierachical softmax is appealing this work is not quite convincing yet their approach is not very natural may be hard to train and may not be that simple to scale the experiment section is very weak,3.0
782.json,the authors introduce a new memory model which allows memory access in o log n time pros the paper is well written and everything is clear it a new model and i am not aware of a similar model it clear that memory access time is an issue for longer sequences and it is clear how this model solves this problem cons the motivation for o log n access time is to be able to use the model on very long sequences while it is clear from the definition that the computation time is low because of its design it is not clear that the model will really generalize well to very long sequences the model was also not tested on any real world task i think such experiments should be added to show whether the model really works on long sequences and real world tasks otherwise it is not clear if this is a useful model,5.0
690.json,the paper evaluates recent development in competitive ilsvrc cnn architectures from the perspective of resource utilization it is clear that a lot of work has been put into the evaluations the findings are well presented and the topic itself is important however most of the results are not surprising to people working with cnns on a regular basis and even if they are i am not convinced about their practical value it is hard to tell what we actually learn from these findings when approaching new problems with computational constraints or when in production settings in my opinion this is mainly because the paper does not discuss realistic circumstances main concerns the evaluation does not tell me much for realistic scenarios that mostly involve fine tuning networks as ilsvrc is just a starting point in most cases vgg for instance really shines for fine tuning but it is cumbersome to train from scratch and vgg works well for compression too so possibly it is a very good choice if these by now standard steps are taken into account such questions are of high practical relevance compressed networks have a much higher acc parameter density so comparison how well models can be compressed is important or at least comparing to some of the most well known and publicly available compressed networks there is no analysis on the actual topology of the networks and where the bottlenecks lie this would be very useful to have as well minor concern why did the authors choose to use batch normalization in nin and alexnet,4.0
690.json,the authors did solid work in collecting all the reported data however most findings do not seem to be too surprising to me finding mainly shows that all architectures and batch sizes manage to utilize the gpu fully or to the same percentage regarding finding i agree that from a linear relationship in figure you could conclude said hyperbolic relationship however for this finding to be relevant it has to hold especially for the latest generations of models these cluster in the upper left corner of figure and on their own do not seem to show too much of a linear behaviour therefore i think there is not enough evidence to conclude asymptotic hyperbolic behaviour for this the linear behaviour would have to be the stronger the more models approach the upper left corner finding seems to be a simple conclusion from finding as long as slower models are better and faster models do draw the same power finding holds finding is again similar to finding if all architectures manage to fully utilize the gpu inference time should be proportional to the number of operations maybe the most interesting finding would be that all tested models seem to use the same percentage of computational resources available on the gpu while one might expect that more complex models do not manage to utilize as much computational resources due to inter dependencies however actual gpu utilization was not evaluated and as the authors choose to use an older gpu one would expect that all models manage to make use of all available computational power additionally i think these findings would have to be put in relation with compressing techniques or tested on actual production networks to be of more interest,4.0
413.json,this paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs by only performing the computations required to capture changes between adjacent inputs the paper was clearly written the approach is clever and it neat to see a practical algorithm driven by what is essentially a spiking network the benefits of this approach are still more theoretical than practical it seems unlikely to be worthwhile to do this on current hardware i strongly suspect that if deep networks were trained with an appropriate sparse slowness penalty the reduction in computation would be much larger,8.0
413.json,the paper presents a method to improve the efficiency of cnns that encode sequential inputs in a slow fashion such that there is only a small change between the representation of adjacent steps in the sequence it demonstrates theoretical performance improvements for toy video data temporal mnist and natural movies with a powerful deep cnn vgg the improvement is naturally limited by the slowness of the cnn representation that is transformed into a sigma delta network cnns that are specifically designed to have slow representations will benefit most also it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method thus as of now the full potential of the method cannot be thoroughly evaluated however since the processing of sequential data seems to be a broad and general area of application it is conceivable that this work will be useful in the design and application of future cnns all in all this paper introduces an interesting idea to address an important topic it shows promising initial results but the demonstration of the actual usefulness and relevance of the presented method relies on future work,6.0
413.json,this is an interesting paper about quantized networks that work on temporal difference inputs the basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image video stream this is of course how the human visual system works and it is hence of interest even beyond the core machine learning community as an aside there is a strong community interested in event based vision such as the group of tobi delbrück and it might be interesting to connect to this community this might even provide a reference for your comments on page i guess the biggest novel contribution is that a rounding network can be replaced by a sigma delta network but that the order of discretization and summation doe make some difference in the actual processing load i think i followed the steps and most of my questions have already been answers in the pre review period my only question remaining is on page it should be noted that when we refer to temporal differences we refer not to the change in the signal over time but in the change between two inputs presented sequentially the output of our network only depends on the value and order of inputs not on the temporal spacing between them this does not make sense to me as i understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame so this statement rather confuses me and maybe should be dropped unless i do miss something here in which case some more explanation would be necessary figure should be made bigger an improvement of the paper that i could think about is a better discussion of the relevance of the findings yes you do show that your sigma delta network save some operation compared to threshold but is this difference essential for a specific task or does your solution has relevance for neuroscience,8.0
741.json,game of tic tac toe is considered tic tac toe board combinations are chosen so that a single move will result into victory of either the black or the white player there are possible moves players x locations a cnn is trained from a visual rendering of the game board to these possible outputs cam technique is used to visualize the salient regions in the inputs responsible for the prediction that cnn makes authors find that predictions correspond to the winning board locations authors claim that this is a very interesting finding cnn has figured out game rules cross modal supervision is applicable to higher level semantics i do not think be can be claimed because the knowledge of game rules is not tested by any experiment there is only one stage of a game i e last move that is considered further the results are on the training set itself the bare minimum requirement of any implicit or explicit representation of game rules is the ability to act in previously unseen states i e generalization even if the cnn did generalize i would avoid making any claims about knowledge of game rules for author definition of cross modal seems to be training from images to games moves in image classification we go from images labels i e between two different domains we already know cnns can perform such mappings cnns have been used to map images to actions such as in dqn my mnih et al or ddpg by lillicrap et al and a lot of other classical work such as alvin it unclear what points authors are trying to make for how interesting is an implicit attention mechanism is a subjective matter the authors claim a difference between the concepts of what do do and what will happen they claim by supervising for what will happen the cnn can automatically learn about what to do this is extensively studied in the model predictive control literature where model is what will happen next and the model is used to infer a control law what to do however in the experimental setup presented in the paper what will happen and what to do seem to be the exact same things for further analysis of what the cnn has learnt i would recommend a visualizing cam with respect to incorrect classes for eg visualize the cam with respect to player would lose instead of winning b split the data into train val and use the predictions on the val set for visualization these would be much more informative about what kind of generalizable features the cnn pays attention to in summary understanding why cnn make what decisions they make is a very interesting area of research while the emergence of an implicit attention mechanism may be considered to be an interesting finding by some many claims made by the authors are not supported by experiments see comments above,3.0
741.json,tic tac toe boards are rendered in various ways these boards are legal boards where the next legal play can end the game there are categories of such boards for the different locations of the next play and for the color of the next play the supervision is basically saying if you place a black square in the middle right black will win or if you place a white square in the upper left white will win a cnn is trained to predict these categories and can do so with accuracy the focus of the paper is using zhou et al class activation mapping to show where the cnn focuses when making it decision as i understand it an input to cam is the class of interest so let say it is class black wins with a play to the bottom right square if i have deciphered figure correctly figure should really be more clear about what each class is so we ask cam to determine the area of focus of the cnn for deciding whether class is exhibited the focus ends up being on the empty bottom right square because certainly you can not exhibit class if the bottom right square is occupied the cnn also needs to condition its decision on other parts of the board it needs to know whether there will be in a row from some direction but maybe that conditioning is weaker that kind of interesting but i am not sure about the deeper statements about discovering game rules that the paper hints at i am also not sure about the connection of this work to weakly supervised learning or multi modal learning the paper is pretty well written overall with some grammatical mistakes but i simply do not see the surprising discovery of this work i also have some concerns about how contrived this scenario is using a big expressive cnn for such a simple game domain and using a particular cnn visualization method i am not an expert in reinforcement learning which is not happening in this paper but is in related works on cnn game playing so maybe i am not appreciating the paper appropriately,3.0
604.json,this paper addresses automated argumentation mining using pointer network although the task and the discussion is interesting the contribution and the novelty is marginal because this is a single task application of pn among many potential tasks,4.0
604.json,this paper addresses the problem of argument mining which consists of finding argument types and predicting the relationships between the arguments the authors proposed a pointer network structure to recover the argument relations they also propose modifications on pointer network to perform joint training on both type and link prediction tasks overall the model is reasonable but i am not sure if iclr is the best venue for this work my first concern of the paper is on the novelty of the model pointer network has been proposed before the proposed multi task learning method is interesting but the authors only verified it on one task this makes me feel that maybe the submission is more for a nlp conference rather than iclr the authors stated that the pointer network is less restrictive compared to some of the existing tree predicting method however the datasets seem to only contain single trees or forests and the stack based method can be used for forest prediction by adding a virtual root node to each example as done in the dependency parsing tasks therefore i think the experiments right now cannot reflect the advantages of pointer network models unfortunately my second concern of the paper is on the target task given that the authors want to analyze the structures between sentences is the argumentation mining the best dataset for example authors could verify their model by applying it to the other tasks that require tree structures such as dependency parsing as for nlp applications i found that the assumption that the boundaries of ac are given is a very strong constraint and could potentially limit the usefulness of the proposed model overall in terms of ml i also feel that baseline methods the authors compared to are probably strong for the argument mining task but not necessary strong enough for the general tree forest prediction tasks as there are other tree forest prediction methods in terms of nlp applications i think the assumption of having ac boundaries is too restrictive and maybe iclr is not the best venture for this submission,5.0
487.json,experimental results look reasonable validated on tasks references could be improved for example i would rather see rumelhart paper cited for back propagation than the deep learning book,7.0
487.json,the paper proposes a sparsely connected network and an efficient hardware architecture that can save up to of memory compared to the conventional implementations of fully connected neural networks the paper removes some of the connections in the fully connected layers and shows performance and computational efficiency increase in networks on three different datasets it is also a good addition that the authors combine their method with binary and ternary connect studies and show further improvements the paper was hard for me to understand because of this misleading statement in this paper we propose sparsely connected networks by reducing the number of connections of fully connected networks using linear feedback shift registers lfsrs it led me to think that lfsrs reduced the connections by keeping some of the information in the registers however lfsr is only used as a random binary generator any random generator could be used but lfsr is chosen for the convenience in vlsi implementation this explanation would be clearer to me in this paper we propose sparsely connected networks by randomly removing some of the connections in fully connected networks random connection masks are generated by lfsr which is also used in the vlsi implementation to disable the connections algorithm is basically training a network with back propogation where each layer has a binary mask that disables some of the connections this explanation can be added to the text using random connections is not a new idea in cnns it was used between cnn layers in a paper by yann lecun and others,6.0
468.json,this paper proposes a network quantization method for compressing the parameters of neural networks therefore compressing the amount of storage needed for the parameters the authors assume that the network is already pruned and aim for compressing the non pruned parameters the problem of network compression is a well motivated problem and of interest to the iclr community the main drawback of the paper is its novelty the paper is heavily built on the results of han and only marginally extends han to overcome its drawbacks it should be noted that the proposed method in this paper has not been proposed before the paper is well structured and easy to follow although it heavily builds on han it is still much longer than han i believe that there is still some redundancy in the paper the experiments section starts on page whereas for han the experiments start on page therefore i believe much of the introductory text is redundant and can be efficiently cut experimental results in the paper show good compression performance compared to han while losing very little accuracy can the authors mention why there is no comparison with hang on resnet in table some comments it is not clear whether the procedure depicted in figure is the authors contribution or has been in the literature in section the authors approximate the hessian matrix with a diagonal matrix can the authors please explain how this approximation affects the final compression also how much does one lose by making such an approximation minor typos these are for the revised version of the paper page parag rd line from the end fined tuned fine tuned page one para to the end last line assigned for assigned to page line same as above page section line explore explored,7.0
468.json,this paper proposes a novel neural network compression technique the goal is to compress maximally the network specification via parameter quantisation with a minimum impact on the expected loss it assumes pruning of the network parameters has already been performed and only considers the quantisation of the individual scalar parameters of the network in contrast to previous work han et al a gong et al the proposed approach takes into account the effect of the weight quantisation on the loss function that is used to train the network and also takes into account the effect on a variable length binary encoding of the cluster centers used for the quantisation unfortunately the submitted paper is pages rather than the recommended the length of the paper seems unjustified to me since the first three sections first five pages are very generic and redundant can be largely compressed or skipped including figures and although not a strict requirement by the submission guidelines i would suggest the authors to compress their paper to pages this will improve the readability of the paper to take into account the impact on the network s loss the authors propose to use a second order approximation of the cost function of the loss in the case of weights that originally constitute a local minimum of the loss this leads to a formulation of the impact of the weight quantization on the loss in terms of a weighted k means clustering objective where the weights are derived from the hessian of the loss function at the original weights the hessian can be computed efficiently using a back propagation algorithm similar to that used to compute the gradient as shown in cited work from the literature the authors also propose to alternatively use a second order moment term used by the adam optimisation algorithm since it can be loosely interpreted as an approximate hessian in section the authors argue that with their approach it is more natural to quantise weights across all layers together due to the hessian weighting which takes into account the variable impact across layers of quantisation errors on the network performance the last statement in this section however was not clear to me in such deep neural networks quantising network parameters of all layers together is more efficient since optimizing layer by layer clustering jointly across all layers requires exponential time complexity with respect to the number of layers perhaps the authors could elaborate a bit more on this point in section the authors develop methods to take into account the code length of the weight quantisation in the clustering process the first method described by the authors based on previous work is uniform quantisation of the weight space which is then further optimised by their hessian weighted clustering procedure from section for the case of nonuniform codeword lengths to encode the cluster indices the authors develop a modification of the hessian weighted k means algorithm in which the code length of each cluster is also taken into account weighted by a factor lambda different values of lambda give rise to different compression accuracy trade offs and the authors propose to cluster weights for a variety of lambda values and then pick the most accurate solution obtained given a certain compression budget in section the authors report a number of experimental results that were obtained with the proposed methods and compare these results to those obtained by the layer wise compression technique of han et al and to the uncompressed models for these experiments the authors used three datasets mnist cifar and imagenet with data set specific architectures taken from the literature these results suggest a consistent and significant advantage of the proposed method over the work of han et al comparison to the work of gong et al is not made the results illustrate the advantage of the hessian weighted k means clustering criterion and the advantages of the variable bitrate cluster encoding in conclusion i would say that this is quite interesting work although the technical novelty seems limited but i m not a quantisation expert interestingly the proposed techniques do not seem specific to deep conv nets but rather generically applicable to quantisation of parameters of any model with an associated cost function for which a locally quadratic approximation can be formulated it would be useful if the authors would discuss this point in their paper,7.0
716.json,paper summary this work presents enet a new convnet architecture for semantic labeling which obtains comparable performance to the previously existing segnet while being x faster and using x less memory review summary albeit the results seem interesting the paper lacks detailed experimental results and is of limited interest for the iclr audience pros x faster x smaller design rationale described in detail cons the quality of the reference baseline is low for instance cityscapes results are iou while state of the art is iou thus the results are of limited interest the results that support the design rationale are not provided it is important to provide the experimental evidence to support each claim quality the work is interesting but feels incomplete if your model is x faster and smaller why not try build a model x longer to obtain improved results the paper focuses only on nimbleness at the cost of quality using a weak baseline this limits the interest for the iclr audience clarity the overall text is somewhat clear but the model description section could be more clear originality the work is a compendium of practitioners wisdom applied to a specific task it has thus limited originality significance i find the work that establishes a new best practices all in one quite interesting but however these must shine in all aspects being fast at the cost of quality will limit the impact of this work minor comments overall the text is proper english but the sentences constructions is often unsound specific examples below to improve the chances of acceptance i invite the authors to also explore bigger models and show that the same collected wisdom can be used both to reach high speed and high quality with the proper trade off curve being shown aiming for only one end of the quality versus speed curve limits too much the paper section mobile or battery powered require rates fps fps with which energy budget should not this be fps x watt rules and ideas rules seem too strong of a word guidelines is of utmost importance is of importance important is already important presents a trainable network therefore we compare to the large majority of inference the same way the sentence makes no sense to me i do not see the logical link between before and after therefore scen parsing scene parsing it is arguable if encoder and decoder can be called separate unlike in noh why is that relevant make explicit or remove real time is vague you mean x fps y w other existing architectures other architectures section does not the bn layer include a bias term can you get good results without any bias term table why is the initial layer a downsampling one since the results has half the size of the input section non linear operations what do you mean by settle to recurring pattern section dimensionality changes computationally expensive relative to what section dimensionality changes this technique speeds up ten times but does not provide the same results without an experimental validation changing an apple for an orange does not make the orange better than the apple section dimensionality changes found one problem problem would imply something conceptually wrong this is more an issue or an miss match when using resnet for semantic labelling section factorizing filters i am unsure of why you call nx filter asymmetric a filter could be xn yet be symmetric e g why not simply call them rectangular filters section factorizing filters why would this change increase the variety i would have expected the opposite section regularization define much better section x is adequate for practical applications for some applications section very quickly is vague and depends on the reader expectations please be quantitative section haver have section in this work in this work section unclear what you use the class weighting for is this for class balancing section cityscapes was cityscapes is section weighted by the average is each instance weighted relative the average object size section fastest model in the cityscapes fastest model in the public cityscapes,4.0
716.json,this paper aims at designing a real time semantic segmentation network the proposed approach has an encoder decoder architecture with many pre existing techniques to improvement the performance and speed my concern is that the most of design choices are pretty ad hoc and there is a lack of ablation study to validate each choice moreover most of the components are not new to the community indexed pooling dilated convolution prelu steerable convolution spatial dropout the so called early down sampling or would ecoder size are also just very straightforward trade off between speed and performance through reducing the size depth of the layers the performance and inference comparison is only conducted against a rather weak baseline segnet which also makes the paper less convincing on the public benchmark the proposed model does not achieve comparable results against state of the art as some other reviewer raised there are some stronger model that has similar efficiency compared with segnet the speed up improvement is good yet reasonable given all the components used however we also did see a big sacrifice in performance on some benchmarks which makes all these tricks less promising the only fact i found impressive is that the model size is mb which is of good practical use and helpful to dump on mobile devices however there is no analysis over how is the trade off between the model size and the performance and what design would result how much reduction in model size i did not find the memory consumption report for the inference stage which are perhaps even more crucial for embedded systems perhaps this paper does have a practical value for practical segmentation network design on embedding systems but i do not believe the paper brings insightful ideas that are worthy to be discussed in iclr either from the perspective of model compression or semantic segmentation,4.0
716.json,this paper describes a fast image semantic segmentation network many different techniques are combined to create a system much faster than the baseline segnet approach with accuracy comparable or somewhat worse in most of three datasets evaluated the choices and techniques used to achieve these speed optimizations are enumerated and described along with intuitions behind them however this section lacks measurements and experimental results showing the effects of these choices to me that would have been a key component to the paper as it stands now we only get to see final evaluation numbers which appear to describe a speed accuracy tradeoff with little insight into the pieces sum to get there in addition i feel there could be a more thorough comparison with different existing systems only segnet is shown in comparison tables even though many current systems are outlined in the related work additional datasets such as pascal or coco may be interesting here as well perhaps with a larger version of the enet model the system looks to be fast with decent accuracy on the majority of benchmarks described however as a practical implementation paper i feel it needs to more thoroughly demonstrate the effects of each component as well as possibly some of the sizing tuning in order to provide a more robust picture,5.0
595.json,the paper claims improved inference for density estimation of sparse data here text documents using deep generative gaussian models variational auto encoders and a method for deriving word embeddings from the model generative parameters that allows for a degree of interpretability similar to that of bayesian generative topic models to discuss the contributions i will quickly review the generative story in the paper first a k dimensional latent representation is sampled from a multivariate gaussian then an mlp with parameters theta predicts unnormalised potentials over a vocabulary of v words the potentials are exponentiated and normalised to make the parameters of a multinomial from where word observations are repeatedly sampled to make a document here intractable inference is replaced by the vae formulation where an inference network with parameters phi independently predicts for each document the mean and variance of a normal distribution amenable to reparameterised gradient computation the first and rather trivial contribution is to use tf idf features to inject first order statistics a global information into local observations the authors claim that this is particularly helpful in the case of sparse data such as text the second contribution is more interesting in optimising generative parameters theta and variational parameters phi the authors turn to a treatment which is reminiscent of the original svi procedure that is they see the variational parameters phi as global variational parameters and the predicted mean mu x and covariance sigma x of each observation x are treated as local variational parameters in the original vae local parameters are not directly optimised instead they are indirectly optimised via optimisation of the global parameters utilised in their prediction shared mlp parameters here local parameters are optimised holding generative parameters fixed line of algorithm the optimised local parameters are then used in the gradient step of the generative parameters line of algorithm finally global variational parameters are also updated line whereas indeed other authors have proposed to optimise local parameters i think that deriving this procedure from the more familiar svi makes the contribution less of a trick and easier to relate to some things are not entirely clear to me i think it would have been nice if the authors had shown the functional form of the gradient used in step of algorithm the gradient step for global variational parameters line of algorithm uses the very first prediction of local parameters thus ignoring the optimisation in step this is unclear to me perhaps i am missing a fundamental reason why that has to be the case either way please clarify the authors argue that this optimisation turns out helpful to modelling sparse data because there is evidence that the generative model p theta x z suffers from poor initialisation please discuss why you expect the initialisation problem to be worse in the case of sparse data the final contribution is a neat procedure to derive word embeddings from the generative model parameters these embeddings are then used to interpret what the model has learnt interestingly these word embeddings are context sensitive once that the latent variable models an entire document about figures a and b the caption says that solid lines indicate validation perplexity for m no optimisation of local parameters and dashed lines indicate m iterations of optimisation of local parameters but the legends of the figures suggest a different reading if i interpret the figures based on the caption then it seems that indeed deeper networks exposed to more data benefit from optimisation of local parameters are the authors pretty sure that in figure b models with m have reached a plateau so that longer training would not allow them to catch up with m curves as the authors explain in the caption x axis is not comparable on running time thus the question the analysis of singular values seems like an interesting way to investigate how the model is using its capacity however i can barely interpret figures c and d i think the authors could have walked readers through them as for the word embedding i am missing an evaluation on a predictive task also while illustrative table b is barely reproducible the text reads we create a document comprising a subset of words in the the context s wikipedia page which is rather vague i wonder whether this construct needs to be carefully designed in order to get table b in sum i have a feeling that the inference technique and the embedding technique are both useful but perhaps they should have been presented separately so that each could have been explored in greater depth,6.0
595.json,first i would like to apologize for the delay in reviewing summary in this paper a variational inference is adapted to deep generative models showing improvement for non negative sparse dataset the authors offer as well a method to interpret the data through the model parameters the writing is generally clear the methods seem correct the introspection approach appears to be original i found very interesting the experiment on the polysemic word embedding i would however have like to see how the obtained embedding would perform with respect to other more common embeddings in solving a supervised task minor eq too many closing parentheses,7.0
595.json,this paper introduces three tricks for training deep latent variable models on sparse discrete data tf idf weighting iteratively optimizing variational parameters after initializing them with an inference network a technique for improving the interpretability of the deep model the first idea is sensible but rather trivial as a contribution the second idea is also sensible but is conceptually not novel what is new is the finding that it works well for the dataset used in this paper the third idea is interesting and seems to give qualitatively reasonable results the quantitative semantic similarity results don t seem that convincing but i am not very familiar with the relevant literature and therefore cannot make a confident judgement on this issue,5.0
700.json,the proposed approach consists in a greedy layer wise initialization strategy for a deep mlp model which is followed by global gradient descent with dropout for fine tuning the initialization strategy uses a first randomly initialized sigmoid layer for dimensionality expansion followed by sigmoid layers whose weights are initialized by marginal fisher analysis mfa which learns a linear dimensionality reduction based on a neighborhood graph constructed using class label information i e supervised dimensionality reduction output layer is a standard softmax layer the approach is thus to be added to a growing list of heuristic layer wise initialization schemes the particular choice of initialization strategy while reasonable is not sufficiently well motivated in the paper relative to alternatives and thus feels rather arbitrary the paper lacks clarity in the description of the approach mfa is poorly explained with undefined notations in eq what is a it has not been properly defined the precise use of alluded denoising in the model is also unclear is there really training of an additional denoting objective or just input corruption the question of the arguably mild inconsistency of applying a linear dimensionality reduction algorithm that is trained without any sigmoid and then passing its learned representation through a sigmoid is not even raised this in addition to the fact that sigmoid hidden layers are no longer commonly used why did you not also consider using relus more importantly i suspect methodological problems with the experimental comparisons the paper mentions using default values for learning rate and momentum and having arbitrarily fixed epoch to no early stopping and l regularization to e for some models all hyper parameters should always be properly hyper optimized using a validation set or cross validation including early stopping and this separately for each model under comparison ideally also including layer sizes this is all the more important since you are considering smallish datasets so that the various initialization strategies act mainly as different indirect regularization schemes they thus need to be carefully tuned this casts serious doubts as to the amount of hyper parameter tuning close to none that went into training the alternative models used for comparison the marginal fisher analysis dimensionality reduction initialization strategy may well offer advantages but as it currently stands this paper doesn t yet make a sufficiently convincing case for it nor provide useful insights into the nature of the expected advantages i would also suggest for image inputs such as cifar to use the qualitative tool of showing the filters back projected to input space learned by the different initialization schemes under consideration as this could help visually gain insight as to what sets methods apart,3.0
700.json,this paper proposes to initialize the weights of a deep neural network layer wise with a marginal fisher analysis model making use of potentially the similarity metric pros there are a lot of experiments albeit small datasets that the authors tested their proposed method on cons lacking baseline such as discriminatively trained convolutional network on standard dataset such as cifar it is also unclear how costly in computation to compute the association matrix a in equation this is an ok paper where a new idea is proposed and combined with other existing ideas such as greedy layerwise stacking dropout and denoising auto encoders however there have been many papers with similar ideas perhaps years ago e g spcanet therefore the main novelty is the use of marginal fisher analysis as a new layer this would be ok but the baselines to demonstrate that this approach works better is missing in particular i would like to see a conv net or fully connected net trained from scratch with good initialization would do at these problems to improve the paper the authors should try to demonstrate without doubt that initializing layers with mfa is better than just random weight matrices,4.0
645.json,the proposed method is simple and elegant it builds upon the huge success of gradient based optimization for deep non linear function approximators and combines it with established linear many view cca methods a major contribution of this paper is the derivation of the gradients with respect to the non linear encoding networks which project the different views into a common space the derivation seems correct in general this approach seems very interesting and i could imagine that it might be applicable to many other similarly structured problems the paper is well written but it could be enhanced with an explicit description of the complete algorithm which also highlights how the joint embeddings g and u are updated i don t have prior experience with cca style many view techniques and it is therefore hard for me to judge the practical empirical progress presented here but the experiments seem reasonable convincing although generally only performed on small and medium sized datasets detailed comments the colours or the sign of the x axis in figure b seem to be flipped compared to figure it would be nice to additionally see a continuous rainbow coloured version for figures and to better identify neighbouring datapoints but more importantly i d like to see how the average reconstruction error between the individual network outputs and the learned representation develop during training is the mismatch between different views on a validation test set a useful metric for cross validation in general it seems the method is sensitive to regularization and hyperparameter selection because it has many more parameters compared to gcca and different regularization parameters have been chosen for different views and i wonder if there is a clear metric to optimize these,7.0
583.json,this paper examines computational creativity from a machine learning perspective creativity is defined as a model ability to generate new types of objects unseen during training the authors argue that likelihood training and evaluation are by construction ill suited for out of class generation and propose a new evaluation framework which relies on the use of held out classes of objects to measure a model ability to generate new and interesting object types i am not very familiar with the literature on computational creativity research so i can not judge on how well this work has been put into the context of existing work from a machine learning perspective i find the ideas presented in this paper new interesting and thought provoking as i understand the hypothesis is that the ability of a model to generate new and interesting types we do not know about correlates with its ability to generate new and interesting types we do know about and the latter is a good proxy for the former the extent to which this is true depends on the bias introduced by model selection just like when measuring generalization performance one should be careful not to reuse the same held out classes for model selection and for evaluation nevertheless i appreciate the effort that has been made to formalize the notion of computational creativity within the machine learning framework i view it as an important first step in that direction and i think it deserves its place at iclr especially given that the paper is well written and approachable for machine learning researchers,7.0
583.json,first the bad this paper is frustratingly written the grammar is fine but the first four pages are completely theoretical and difficult to follow without any concrete examples these sections would benefit greatly from a common example woven through the different aspects of the theoretical discussion the ordering of the exposition is also frustrating i found myself constantly having to refer ahead to figures and back to details that were important but seemingly presented out of order perhaps a reordering of some details could fix this recommendation give the most naturally ordered oral presentation of the work and then order the paper similarly finally the description of the experiments is cursory and i found myself wondering whether the details omitted were important or not including experimental details in a supplementary section could help assuage these fears the good what the paper does well is to gather together past work on novelty generation and propose a unified framework in which to evaluate past and future models this is done by repurposing existing generative model evaluation metrics for the task of evaluating novelty the experiments are basic but even the basic experiments go beyond previous work in this area to this reviewer s knowledge overall i recommend the paper be accepted but i strongly recommend rewriting some components to make it more digestible as with other novelty papers it would be read thoroughly by the interested few but it is likely to fight an uphill battle against the majority of readers outside the sub sub field of novelty generation for this reason the theory should be made even more intuitive and clear and the experiments and results even more accessible,6.0
583.json,the authors proposed an way to measure the generation of out of distribution novelty their methods implied if a model trained on mnist digits could generate some samples are more like letters judged by anther model trained both on mnist and letters the model trained on mnist could be seen as having the ability to generate novel samples some empirical experiments were reported the novelty is hard to define the proposed metric is also problematic a naive combination of mnist and letters dataset do not represent the natural distribution of handwritten digits and letters it means that the model trained on the combination could not properly distinguished digits and letters the proposed out of class count and out of class max are thus pointless for the novel samples in fig they are clearly digits i guess they quantize the samples to binary if they would quantize the samples to bit the resulting images would look even more like digits,4.0
307.json,attempts to use chatbots for every form of human computer interaction has been a major trend in with claims that they could solve many forms of dialogs beyond simple chit chat this paper represents a serious reality check while it is mostly relevant for dialog natural language venues to educate software engineer about the limitations of current chatbots it can also be published at machine learning venues to educate researchers about the need for more realistic validation of ml applied to dialogs so i would consider this work of high significance two important conjectures are underlying this paper and likely to open to more research while they are not in writing antoine bordes clearly stated them during a nips workshop presentation that covered this work considering the metrics chosen in this paper the performance of endend ml approaches is still insufficient for goal oriented dialogs when comparing algorithms relative performance on synthetic data is a good predictor of performance on natural data this would be quite a departure from previous observations but the authors made a strong effort to match the synthetic and natural conditions while its original algorithmic contribution consists in one rather simple addition to memory networks match type it is the first time these are deployed and tested on a goal oriented dialog and the experimental protocol is excellent the overall paper clarity is excellent and accessible to a readership beyond ml and dialog researchers i was in particular impressed by how the short appendix on memory networks summarized them so well followed by the tables that explained the influence of the number of hops while this paper represents the state of the art in the exploration of more rigorous metrics for dialog modeling it also reminds us how brittle and somewhat arbitrary these remain note this is more a recommendation for future research than for revision first they use the per response accuracy basically the next utterance classification among a fixed list of responses looking at table clearly shows how absurd this can be in practice all that matters is a correct api call and a reasonably short dialog though this would only give us a accuracy as the bot responses needed to reach the api call also have to be exact would the per dialog accuracy where all responses must be correct be better table shows how sensitive it is to the experimental protocol i was initially puzzled that the accuracy for subtask t was much lower that the accuracy for the full dialog t until the authors pointed me to the tasks definitions where t requires displaying options while t only requires displaying one for the concierge data what would happen if correct meant being the best not among the best while i cannot fault the authors for using standard dialog metrics and coming up with new ones that are actually too pessimistic i can think of one way to represent dialogs that could result in more meaningful metrics in goal oriented dialogs suppose i sell virtual assistants as a service being paid upon successful completion of a dialog what is the metric that would maximize my revenue in this restaurant problem the loss would probably be some weighted sum of the number of errors in the api call the number of turns to reach that api call and the number of rejected options by the user however such as loss cannot be measured on canned dialogs and would either require a real human user or an realistic simulator another issue closely related to representation learning that this paper fails to address or explain properly is what happens if the vocabulary used by the user does not match exactly the vocabulary in the knowledge base in particular for the match type algorithm to code indian as type of cuisine this word would have to occur exactly in the kb i can imagine situations where the kb uses some obfuscated terminology and we would like ml to learn the associations rather than humans to hand describe them,8.0
307.json,synopsis this paper introduces a new dataset for evaluating end to end goal oriented dialog systems all data is generated in the restaurant setting where the goal is to find availability and eventually book a table based on parameters provided by the user to the bot as part of a dialog data is generated by running a simulation using an underlying knowledge base to generate samples for the different parameters cuisine price range etc and then applying rule based transformations to render natural language descriptions the objective is to rank a set of candidate responses for each next turn of the dialog and evaluation is reported in terms of per response accuracy and per dialog accuracy the authors show that memory networks are able to improve over basic bag of words baselines thoughts i want to thank the authors for an interesting contribution having said that i am skeptical about the utility of end to end trained systems in the narrow domain setting in the open domain setting there is a strong argument to be made that hand coding all states and responses would not scale and hence end to end trained methods make a lot of sense however in the narrow domain setting we usually know and understand the domain quite well and the goal is to obtain high user satisfaction does not it then make sense in these cases to use the domain knowledge to engineer the best system possible given that the domain is already restricted i am also a bit disappointed that the goal is to rank instead of generate responses although i understand that this makes evaluation much easier i am also unsure how these candidate responses would actually be obtained in practice it seems that the models rank the set of all responses in train val test last sentence before sec since a key argument for the end to end training approach is ease of scaling to new domains without having to manually re engineer the system where is this information obtained for a new domain in practice generating responses would allow much better generalization to new domains as opposed to simply ranking some list of hand collected generic responses and in my mind this is the weakest part of this work finally as data is generated using a simulation by expanding cuisine price tuples using nl generation rules it necessarily constrains the variability in the training responses of course this is traded off with the ability to generate unlimited data using the simulator but i was unable to see the list of rules that was used it would be good to publish this as well overall despite my skepticism i think it is an interesting contribution worthy of publication at the conference i have updated my score following the clarifications and new results,7.0
307.json,this paper presents a new public dataset and tasks for goal oriented dialogue applications the dataset and tasks are constructed artificially using rule based programs in such a way that different aspects of dialogue system performance can be evaluated ranging from issuing api calls to displaying options as well as full fledged dialogue this is a welcome contribution to the dialogue literature which will help facilitate future research into developing and understanding dialogue systems still there are pitfalls in taking this approach first it is not clear how suitable deep learning models are for these tasks compared to traditional methods rule based systems or shallow models since deep learning models are known to require many training examples and therefore performance difference between different neural networks may simply boil down to regularization techniques the tasks are also completely deterministic which means evaluating performance on these tasks wo not measure the ability of the models to handle noisy and ambiguous interactions e g inferring a distribution over user goals or executing dialogue repair strategies which is a very important aspect in dialogue applications overall i still believe this is an interesting direction to explore as discussed in the comments below the paper does not have any baseline model with word order information i think this is a strong weakness of the paper because it makes the neural networks appear unreasonably strong yet simpler baselines could very likely be be competitive or better than the proposed neural networks to maintain a fair evaluation and correctly assess the power of representation learning for this task i think it important that the authors experiment with one additional non neural network benchmark model which takes into account word order information this would more convincly demonstrate the utility of deep learning models for this task for example the one could experiment with a logistic regression model which takes as input word embeddings similar to the supervised embeddings model bi gram features and match type features if such a baseline is included i will increase my rating to final minor comment in the conclusion the paper states the existing work has no well defined measures of performances this is not really true end to end trainable models for task oriented dialogue have well defined performance measures see for example a network based end to end trainable task oriented dialogue system by wen et al on the other hand non goal oriented dialogue are generally harder to evaluate but given human subjects these can also be evaluated in fact this is what liu et al do for twitter see also strategy and policy learning for non task oriented conversational systems by yu et al i have updated my score following the new results added in the paper,8.0
409.json,this paper introduces musicnet a new dataset application of ml techniques to music have been limited due to scarcity of exactly the kind of data that is provided here meticulously annotated carefully verified and organized containing enough hours of music and where genre has been well constrained in order to allow for sufficient homogeneity in the data to help ensure usefulness this is great for the community the description of the validation of the dataset is interesting and indicates a careful process was followed the authors provide just enough basic experiments to show that this dataset is big enough that good low level features i e expected sinusoidal variations can indeed be learned in an end to end context one might argue that in terms of learning representations the work presented here contributes more in the dataset than in the experiments or techniques used however given the challenges of acquiring good datasets and given the essential role such datasets play for the community in moving research forward and providing baseline reference points i feel that this contribution carries substantial weight in terms of expected future rewards if research groups were making great new datasets available on a regular basis that would place this in a different context but so far that is not the case in otherwords while the experiments techniques are not necessarily in the top of accepted papers per the review criteria i am guessing that the dataset is in the top or better,8.0
409.json,this paper describes the creation of a corpus of freely licensed classical music recordings along with corresponding midi scores aligned to the audio it also describes experiments in polyphonic transcription using various deep learning approaches which show promising results the paper is a little disorganised and somewhat contradictory in parts for example i find the first sentence in section musicnet would better be pushed one paragraph below so that the section be allowed to begin with a survey of the tools available to researchers in music also the description for table should probably appear somewhere in the methods section last example the abstract intro says the purpose is note prediction later th paragraph of intro there a claim that the focus is learning low level features of music i find this slightly disorienting although others uehara et al for example have discussed collection platforms and corpora this work is interesting because of its size and the approach for generating features i am interested in what the authors will to do expand the offerings in the corpus both in terms of volume and diversity,6.0
370.json,training highly non convex deep neural networks is a very important practical problem and this paper provides a great exploration of an interesting new idea for more effective training the empirical evaluation both in the paper itself and in the authors comments during discussion convincingly demonstrates that the method achieves consistent improvements in accuracy across multiple architectures tasks and datasets the algorithm is very simple alternating between training the full dense network and a sparse version of it which is actually a positive since that means it may get adapted in practice by the research community the paper should be revised to incorporate the additional experiments and comments from the discussion particularly the accuracy comparisons with the same number of epochs,8.0
370.json,summary the paper proposes a model training strategy to achieve higher accuracy the issue is train a too large model and you going to over fit and your model will capture noise prune models or make it too small then it will miss important connections and under fit thus the proposed method involves various training steps first they train a dense network then prune it making it sparse then train a sparse network and finally they add connections back and train the model as dense again dsd the dsd method is generic method that can be used in cnn rnn lstm the reasons why models have better accuracy after dsd are escape of saddle point sparsity makes model more robust to noise and symmetry break allowing richer representations pro the main point that this paper wants to show is that a model has the capacity to achieve higher accuracy because it was shown that it is possible to compress a model without losing accuracy and lossless compression means that there s significant redundancy in the models that were trained using current training methods this is an important observation that large models can get better accuracies as better training schemes are used cons questions the issue is that the accuracy is slightly increased or for most models and the question is what is the price paid for this improvement resource and performance concerns arises because training a large model is computationally expensive hours or even days using high performance gpus second question can i keep adding dense sparse and dense training iterations to get higher and higher accuracy improvement are there limitations to this dsdsd approach,8.0
370.json,this paper presents a training strategy for deep networks first the network is trained in a standard fashion second small magnitude weights are clamped to the rest of the weights continue to be trained finally all the weights are again jointly trained experiments on a variety of image text and speech datasets demonstrate the approach can obtain high quality results the proposed idea is novel and interesting in a sense it is close to dropout though as noted in the paper the deterministic weight clamping method is different the main advantage of the proposed method is its simplicity three hyper parameters are needed the number of weights to clamp to and the numbers of epochs of training used in the first dense phase and the sparse phase given these it can be plugged in to training a range of networks as shown in the experiments the concern i have is regarding the current empirical evaluation as noted in the question phase it seems the baseline methods are not trained for as many epochs as the proposed method standard tricks such as dropping the learning rate upon convergence and continuing to learn can be employed the response seems to indicate that these approaches can be effective i think a more thorough empirical analysis of performance over epochs learning rates etc would strengthen the paper an exploration regarding the sparsity hyper parameter would also be interesting,5.0
720.json,a method for click prediction is presented inputs are a categorical variables and output is the click through rate the categorical input data is embedded into a feature vector using a discriminative scheme that tries to predict whether a sample is fake or not the embedding vector is passed through a series of sum mult gates and k most important interactions are identified k max pooling this process is repeated multiple times i e multiple layers and the final feature is passed into a fully connected layer to output the click prediction rate authors claim use of gates and k max pooling allow modeling of interactions that lead to state of art results it is not straightforward to apply ideas in papers like wordvec to obtain feature embeddings and consequently they use the idea of discriminating between fake and true samples for feature learning theoretically convolutions can act as sum gates between pairs of input dimensions authors make these interactions explicit i e imposed structure by using gates now the merit of the proposed method can be tested if a network using gates outperforms a network without gates this baseline is critically missing i e embedding vector followed by a series of convolution pooling layers another related issue is that i am not sure if the number of parameters in the proposed model and the baseline models is similar or not for instance what is the total number of parameters in the ccpm model v s the proposed model overall there is no new idea in the paper this by itself is not grounds for rejection if the paper outperforms established baselines however such comparison is weak and i encourage authors to perform these comparisons,4.0
720.json,the paper proposes a way to learn continuous features for input data which consists of multiple categorical data the idea is to embed each category in a learnable low dimensional continuous space explicitly compute the pair wise interaction among different categories in a given input sample which is achieved by either taking a component wise dot product or component wise addition perform k max pooling to select a subset of the most informative interactions and repeat the process some number of times until you get the final feature vector of the given input this feature vector is then used as input to a classifier regressor to accomplish the final task the embeddings of the categories are learnt in the usual way in the experiment section the authors show on a synthetic dataset that their procedure is indeed able to select the relevant interactions in the data on one real world dataset ipinyou the model seems to outperform a couple of simple baselines my major concern with this paper is that their nothing new in it the idea of embedding the categorical data having mixed categories has already been handled in the past literature where essentially one learns a separate lookup table for each class of categories an input is represented by concatenation of the embeddings from these lookup table and a non linear function a deep network is plugged on top to get the features of the input the only rather marginal contribution is the explicit modeling of the interactions among categories in equations other than that there nothing else in the paper not only that i feel that these interactions can and should automatically be learned by plugging in a deep convolutional network on top of the embeddings of the input so i am not sure how useful the contribution is the experimental section is rather weak they authors test their method on a single real world data set against a couple of rather weak baselines i would have much preferred for them to evaluate against numerous models proposed in the literature which handle similar problems including wsabie while the authors argued in their response that wsabie was not suited for their problem i strongly disagree with that claim while the original wsabie paper showed experiments using images as inputs their training methodology can easily be extended to other types of data sets including categorical data for instance i conjecture that the model i proposed above embed all the categorical inputs concatenate the embeddings plug a deep conv net on top and train using some margin loss will perform as well if not better than the hand coded interaction model proposed in this paper of course i could be wrong but it would be far more convincing if their model was tested against such baselines,5.0
720.json,in this paper the author proposed an approach for feature combination of two embeddings v and v this is done by first computing the pairwise combinations of the elements of v and v with complicated nonlinearity and then pick the k max as the output vector for triple or higher order combinations two or more consecutive pairwise combinations are performed to yield the final representations it seems that the approach is not directly related to categorical data and can be applied to any embeddings even if they are not one hot so is there any motivation that brings about this particular approach what is the connection there are many papers with similar ideas ccpm a convolutional click prediction model that the authors have compared against also proposes very similar network structure conv k max conv k max in the paper the author does not mention their conceptual similarity and difference versus ccpm compact bilinear pooling,4.0
777.json,the paper introduces supervised deep learning with layer wise reconstruction loss in addition to the supervised loss and class conditional semantic additive noise for better representation learning total correlation measure and additional insights from auto encoder are used to derive layer wise reconstruction loss and is further combined with supervised loss when combining with supervised loss the class conditional additive noise model is proposed which showed consistent improvement over the baseline model experiments on mnist and cifar datasets while changing the number of training examples per class are done extensively the derivation of equation from total correlation is hacky moreover assuming graphical model between x y and z it should be more carefully derived to estimate h x z and h z y the current proposal encoding z and y from x and decoding from encoded representation is not really well justified is sigma in equation trainable parameter or hyperparameter if it is trainable how it is trained if it is not how are they set does j correspond to one of the class the proposed feature augmentation sounds like simply adding gaussian noise to the pre softmax neurons that being said the proposed method is not different from gaussian dropout wang and manning icml but applied on different layers in addition there is a missing reference disturblabel regularizing cnn on the loss layer cvpr that applied synthetic noise process on the loss layer experiments should be done for multiple times with different random subsets and authors should provide mean and standard error overall i believe the proposed method is not very well justified and has limited novelty,4.0
777.json,the paper presents a new regularization technique for neural networks which seeks to maximize correlation between input variables latent variables and outputs this is achieved by defining a measure of total correlation between these variables and decomposing it in terms of entropies and conditional entropies authors explain that they do not actually maximize the total correlation but a lower bound of it that ignores simple entropy terms and only considers conditional entropies it is not clearly explained what is the rationale for discarding these entropy terms entropies measures are applying to probability distributions i e this implies that the variables in the model should be random the link between the conditional entropy formulation and the reconstruction error is not made explicit in order to link these two views i would have expected for example a noise model for the units of the network later in the paper it is claimed that the original ladder network is not suitable for supervised learning with small samples and some empirical results seek to demonstrate this but a more theoretical explanation why it is the case would have been welcome the mnist results are shown for a particular convolutional neural network architecture however most ladder network results for this dataset have been produced on standard fully connected architectures results for such neural network architecture would have been desirable for more comparability with original ladder neural network results,3.0
624.json,the main merit of this paper is to draw again attention to how crucial initialization of deep network can be and to counter the popular impression that modern architectures and improved gradient descent techniques make optimization local minima and saddle points no longer a problem while the paper provides interesting counter examples that showcase how bad initialization mixed with particular data can lead the optimization to get stuck at a poor solution these feel like contrived artificial constructs more importantly the paper does not consider popular heuristics that likely help to avoid getting stuck such as non saturating activation functions e g leaky relu batch norm skip connections resnet that can all be thought of as contributing to keep the gradients flowing the paper puts up a big warning sign about potential initialization problems with standard relu nets but without proposing new solutions or workarounds nor carrying out a systematic analysis of how this picture is affected by most commonly used current heuristic techniques in architecture initialization and training such a broader scope analysis especially if it did lead to insights of practical relevance could much increase the value of the paper for the reader,5.0
624.json,this paper studies the error surface of deep rectifier networks giving specific examples for which the error surface has local minima several experimental results show that learning can be trapped at apparent local minima by a variety of factors ranging from the nature of the dataset to the nature of the initializations this paper develops a lot of good intuitions and useful examples of ways that training can go awry even though the examples constructed in this paper are contrived this does not necessarily remove their theoretical importance it is very useful to have simple examples where things go wrong however the broader theoretical framing of the paper appears to be going after a strawman the underlying easiness of optimizing deep networks does not simply rest just in the emerging structures due to high dimensional spaces but is rather tightly connected to the intrinsic characteristics of the data these models are run on i believe this perspective is already contained in several of the works cited as not belonging to this perspective choromanska et al for instance analyze gaussian inputs and so clearly make claims based on characteristics of the data the models are run on more broadly the loss function is determined jointly by the dataset and the model parameters and so no account of the error surface can be separated from dataset properties it is not clear to me what emerging structures due to high dimensional spaces are or what they could be that would make them independent of the dataset and initial model parameters the emerging structure of the error surface is necessarily related to the dataset and model parameters again a key worry with this paper is that it is aiming at a strawman replica methods characterize average behavior for infinite systems so it is not surprising that specific finite sized systems might yield poor optimization landscapes the paper seems surprised that training can be broken with a bad initialization but initialization is known to be critical even for linear networks saddle points are not innocuous with bad initializations dramatically slowing learning e g saxe et al it seems like the proof of proposition may have an error suppose cdfb and cdfw we have p learning fails h k meaning that the probability of failure increases as the number of hidden units increases it seems like it should rather be ignoring the bias p fails p w h k in this case the limit as k infinity depends on how h scales with k so it is no longer necessarily true that one does not have a globally good behaviour of learning regardless of the model size the paper also appears to insufficiently distinguish between local minima and saddle points section states it shows training being stuck in a local minimum but this is based on training with a fixed budget of epochs it is not possible to tell whether this result reflects a genuine local minimum or a saddle point based on simulation results it may also be the case that while rectifiers suffer from genuine blind spots sigmoid or soft rectifier nonlinearities may not on the xor problem with two hidden nodes for instance it was thought that were local minima but in fact there are none e g l hamey analysis of the error surface of the xor network with two hidden nodes if the desire is simply to show that training does not converge for particular finite problems much simpler counterexamples can be constructed and would suffice set all hidden unit weights to zero for instance in the response to prereview questions the authors write if the complete characterization of the error surface was indeed universally valid we would not be able to break the learning with the initialization but as mentioned previously the basic results for even deep linear networks show that a bad initialization at or near a saddle point will break learning again it seems this paper is attacking a straw man along the lines of nothing can possibly go wrong with neural network training no prior theoretical result claims this the figure explanation seems counterintuitive to me simply scaling the input if the weight matrices are initialized with zero biases will not change the regions over which each relu activates that is this manipulation does not achieve the goal of concentrating most of the data points in very few linear regions a far more likely explanation is that the much weaker scaling has not been compensated by the learning algorithm but the algorithm would converge if run longer the response notes that training has been conducted for an order of magnitude longer than required for the unscaled input to converge but the scaling on the data is not one but five orders of magnitude and indeed the training does converge without issue for scaling up to four orders of magnitude the response notes that adam should compensate for the scaling factor but this depends on the details of the adam implementation the epsilon factor used to protect against division by zero for example this paper contains many interesting results but a variety of small technical concerns remain,5.0
331.json,this paper presents an approach for skills transfer from one task to another in a control setting trained by rl by forcing the embeddings learned on two different tasks to be close l penalty the experiments are conducted in mujoco with a set of experiments being from the state of the joints links and a set of experiments on the pixels they exhibit transfer from arms with different number of links and from a torque driven arm to a tendon driven arm one limitation of the paper is that the authors suppose that time alignment is trivial because the tasks are all episodic and in the same domain time alignment is one form of domain adaptation transfer that is not dealt with in the paper that could be dealt with through subsampling dynamic time warping or learning a matching function e g neural network general remarks the approach is compared to cca which is a relevant baseline however as the paper is purely experimental another baseline worse than cca would be to just have the random projections for f and g the embedding functions on the two domains to check that the bad performance of the no transfer version of the model is due to over specialisation of these embeddings i would also add for information that the problem of learning invariant feature spaces is also linked to metric learning e g xing et al more generally no parallel is drawn with multi task learning in ml in the case of knowledge transfer it may make sense to anneal alpha the experiments feel a bit rushed in particular the performance of the baseline being always no transfer at all is uninformative at least a much bigger sample budget should be tested also why does figure b contain no cca nor direct mapping results another concern that i have with the experiments if how did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer overall the study of transfer is most welcomed in rl the experiments in this paper are interesting enough for publication but the paper could have been more thorough,7.0
331.json,this paper explores transfer in reinforcement learning between agents that may be morphologically distinct the key idea is for the source and target agent to have learned a shared skill and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent the paper is related to much other work on transfer that uses shared latent spaces such as cca and its variants including manifold alignment and kernel cca the paper reports on experiments using a simple physics simulator between robot arms consisting of three vs four links for comparison a simple cca based approach is shown although it would have been preferable to see comparisons for something more current and up to date such as manifold alignment or kernel cca a three layer neural net is used to construct the latent feature spaces the problem of transfer in rl is extremely important and receives less attention than it should this work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent this is a promising approach however the comparisons to related approaches is not very up to date and the domains are fairly simplistic there is little by way of theoretical development of the ideas using mdp theory,6.0
761.json,this paper takes a first step towards learning to statically analyze source code it develops a simple toy programming language that includes loops and branching the aim is to determine whether all variables in the program are defined before they are used the paper tries a variety of off the shelf sequence classification models and develops a new model that makes use of a differentiable set to keep track of which variables have been defined so far result show that an lstm model can achieve accuracy and the differentiable set model can achieve accuracy with sequence level supervision and accuracy with strong token level supervision an additional result is used whereby an lstm language model is trained over correct code and then low probability where a threshold to determine low is tuned by hand tokens are highlighted as sources of possible error one further question is if the authors could clarify what reasoning patterns are needed to solve these problems does the model need to e g statically determine whether an if condition can ever evaluate to true in order to solve these tasks or is it just as simple as checking whether a variable appears on a lhs before it appears on a rhs later in the textual representation of the program strengths learning a static analyzer is an interesting concept and i think there is good potential for this line of work the ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis the experimental setup seems reasonable the differentiable set seems like a useful albeit simple modelling tool weaknesses the setup is very toy and it not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer the models are mostly very simple the one novelty on the modelling front the differentiable set provides a small win on this task but it not clear if it is a useful general construct or not overall i think it an interesting start and i am eager to see how this line of work progresses in my opinion it a bit too early to accept this work to iclr but i would be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code and as they push towards scenarios where the learned static analyzer would be useful perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses,4.0
761.json,the authors are trying to understand whether static analysis can be learned as i hinted in my question i think that all of the interesting complexity of static analysis has been removed in the toy language extraordinarily simple logic using a set can solve the problem posed and an lstm unsurprisingly can learn the extraordinarily simple logic when given a differentiable set object this extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved lstms and deep learning have had remarkable successes in solving messy real world language problems it certainly possible that lstms could solve static analysis but being technically timid is not the right way to go about it,3.0
389.json,the paper proposed a novel samplernn to directly model waveform signals and achieved better performance both in terms of objective test nll and subjective a b tests as mentioned in the discussions the current status of the paper lack plenty of details in describing their model hopefully this will be addressed in the final version the authors attempted to compare with wavenet model but they did not manage to get a model better than the baseline lstm rnn which makes all the comparisons to wavenets less convincing hence instead of wasting time and space comparing to wavenet detailing the proposed model would be better,9.0
389.json,the paper introduces samplernn a hierarchical recurrent neural network model of raw audio the model is trained end to end and evaluated using log likelihood and by human judgement of unconditional samples on three different datasets covering speech and music this evaluation shows the proposed model to compare favourably to the baselines it is shown that the subsequence length used for truncated bptt affects performance significantly but interestingly a subsequence length of samples ms is sufficient to get good results even though the features of the data that are modelled span much longer timescales this is an interesting and somewhat unintuitive result that i think warrants a bit more discussion the authors have attempted to reimplement wavenet an alternative model of raw audio that is fully convolutional they were unable to reproduce the exact model architecture from the original paper but have attempted to build an instance of the model with a receptive field of about ms that could be trained in a reasonable time using their computational resources which is commendable the architecture of the wavenet model is described in detail but it found it challenging to find the same details for the proposed samplernn architecture e g which value of r is used for the different tiers how many units per layer i think a comparison in terms of computational cost training time and number of parameters would also be very informative surprisingly table shows a vanilla rnn lstm substantially outperforming this model in terms of likelihood which is quite suspicious as lstms tend to have effective receptive fields of a few hundred timesteps at best one would expect the much larger receptive field of the wavenet model to be reflected in the likelihood scores to some extent similarly figure shows the vanilla rnn outperforming the wavenet reimplementation in human evaluation on the blizzard dataset this raises questions about the implementation of the latter some discussion about this result and whether the authors expected it or not would be very welcome table and figure also show the tier samplernn outperforming the tier model in terms of likelihood and human rating respectively which is very counterintuitive as one would expect longer range temporal correlations to be even more relevant for music than for speech this is not discussed at all i think it would be useful to comment on why this could be happening overall this an interesting attempt to tackle modelling very long sequences with long range temporal correlations and the results are quite convincing even if the same can not always be said of the comparison with the baselines it would be interesting to see how the model performs for conditional generation seeing as it can be more easily be objectively compared to models like wavenet in that domain other remarks upsampling the output of the models is done with r separate linear projections this choice of upsampling method is not motivated why not just use linear interpolation or nearest neighbour upsampling what is the advantage of learning this operation do not the r linear projections end up learning largely the same thing give or take some noise the third paragraph of section indicates that bit linear pcm was used this is in contrast to wavenet for which an bit mu law encoding was used and this supposedly improves the audio fidelity of the samples did you try this as well section mentions the discretisation of the input and the use of a softmax to model this discretised input without any reference to prior work that made the same observation a reference is given in but it should probably be moved up a bit to avoid giving the impression that this is a novel observation,8.0
521.json,pros introduction of a nice filter banks and its implementation good numerical results refinement of the representation via back propagation and a demonstration that it speeds up learning cons the algorithms section are not necessary and they even affect the presentation of the paper however a source code would be great the link with a scattering transform is not clear sometimes as mentionned in some of my comments the writing could be improved from a personal point of view i also believe the negative points i mention can be easily removed,6.0
521.json,the authors advocate use of chirplets as a basis for modeling audio signals they introduce a fast chiplet transform for efficient computation also introduced is the idea of initializing pre training cnn layers to mimic chirplet transform of audio signal similar to ideas proposed by mallet et al on scattering transforms the paper is fairly easy to follow but in a few places contains undefined terms e g am fm map while the idea of using chirplet transform is interesting my main concern is that the empirical evidence provided is in a rather narrow domain of bird call classification furthermore the accuracy gains shown in that domain are relatively small map for log mel features vs for chirplet transforms i would recommend that authors provide evidence for how this generalizes to other audio including speech tasks,4.0
464.json,i have not much to add to my pre review comments it a very well written paper with an interesting idea lots of people currently want to combine rl with nlp it is very en vogue nobody has gotten that to work yet in any really groundbreaking or influential way that results in actually superior performance on any highly relevant or competitive nlp task most people struggle with the fact that nlp requires very efficient methods on very large datasets and rl is super slow hence i believe this direction has not shown much promise yet and it not yet clear it ever will due to the slowness of rl but many directions need to be explored and maybe eventually they will reach a point where they become relevant it is interesting to learn the obviously inherent grammatical structure in language though sadly again the trees here do not yet capture much of what our intuitions are regardless it an interesting exploration worthy of being discussed at the conference,7.0
608.json,authors propose using periodic activation functions sin instead of tanh for gradient descent training of neural networks this change goes against common sense and there would need to be strong evidence to show that it a good idea in practice the experiments show slight improvement for some mnist configurations they show strong improvement almost higher accuracy after iterations on a toy algorithmic task it not clear that this activation function is good for a broad class of algorithmic tasks or just for the two they present hence evidence shown is insufficient to be convincing that this is a good idea for practical tasks,4.0
599.json,this paper presents a modified gated rnn caled gru d that deals with time series which display a lot of missing values in their input they work on two fronts the first deals with the missing inputs directly by using a learned convex combination of the previous available value forward imputation and the mean value mean imputation the second includes dampening the recurrent layer not unlike a second reset gate but parametrized according to the time elapsed since the last available value of each attributes positives clear definition of the task handling missing values for classification of time series many interesting baselines to test the new model against the model presented deals with the missing values in a novel ml type way learn new dampening parameters the extensive tests done on the datasets is probably the greatest asset of this paper negatives the paper could use some double checking for typos the section a really belongs in the main article as it deals with important related works swap it with the imprecise diagrams of the model if you need space no mention of any methods from the statistics litterature here are the two main points of this review that informs my decision the results while promising are below expectations the paper hasn t been able to convince me that gru simple without intervals isn t just as well suited for the task of handling missing inputs as gru d in the main paper gru simple is presented as the main baseline yet it includes a lot of extraneous parameters the intervals that according to table probably hurts the model more than it helps it having a third of it s parameters being of dubious value it brings the question of the fairness of the comparison done in the main paper especially since in the one table where gru simple without intervals is present gru d doesn t significantly outperforms it my second concern and biggest is with some claims that are peppered through the paper the first is about the relationship with the presence rate of data in the dataset and the diagnostics i might be wrong but that only indicates that the doctor in charge of that patient requested the relevant analyses be done according to the patient s condition that would mean that an expert system based on this data would always seem to be one step behind the second claim is the last sentence of the introduction which sets huge expectations that were not met by the paper another is that simply concatenating masking and time interval vectors fails to exploit the temporal structure of missing values is unsubstantiated and actually disproven later in the paper yet another is the conclusion that since gru models displayed the best improvement between a subsample of the dataset and the whole of it means that the improvement is going to continue to grow as more data is added this fails to consider that non gru models actually started with much better results than most gru ones lastly is their claim to capture informative missingness by incorporating masking and time intervals directly inside the gru architecture while the authors did make these changes the fact that they also concatenate the mask to the input just like gru simple without intervals leads me to question the actual improvement made by gru d given that while i find that the work that has been put into the paper is above average i wouldn t accept that paper without a reframing of the findings and a better focus on the real contribution of this paper which i believe is the novel way to parametrize the choice of imputation method,6.0
599.json,this paper proposed a way to deal with supervised multivariate time series tasks involving missing values the high level idea is still using the recurrent neural network specifically gru in this paper to do sequence supervised learning e g classification but modifications have been made to the input and hidden layers of rnns to tackle the missing value problem pros the insight of utilizing missing value is critical the observation of decaying effect in the healthcare application is also interesting the experiment seems to be solid the baseline algorithms and analysis of results are also done properly cons the novelty of this work is not enough adding a decaying smooth factor to input and hidden layers seems to be the main modification of the architecture the datasets used in this paper are small the decaying effect might not be able to generalize to other domains,5.0
599.json,the authors propose a rnn method for time series classification with missing values that can make use of potential information in missing values it is based on a simple linear imputation of missing values with learnable parameters furthermore time intervals between missing values are computed and used to scale the rnn computation downstream the authors demonstrate that their method outperforms reasonable baselines on small to mid sized real world datasets the paper is clearly written imo the authors propose a reasonable approach for dealing with missing values for their intended application domain where data is not abundant and requires smallish models i m somewhat sceptical if the benefits would carry over to big datasets where more general less handcrafted multi layer rnns are an option,6.0
560.json,this paper investigates the impact of orthogonal weight matrices on learning dynamics in rnns the paper proposes a variety of interesting optimization formulations that enforce orthogonality in the recurrent weight matrix to varying degrees the experimental results demonstrate several conclusions enforcing exact orthogonality does not help learning while enforcing soft orthogonality or initializing to orthogonal weights can substantially improve learning while some of the optimization methods proposed currently require matrix inversion and are therefore slow in wall clock time orthogonal initialization and some of the soft orthogonality constraints are relatively inexpensive and may find their way into practical use the experiments are generally done to a high standard and yield a variety of useful insights and the writing is clear the experimental results are based on using a fixed learning rate for the different regularization strengths learning speed might be highly dependent on this and different strengths may admit different maximal stable learning rates it would be instructive to optimize the learning rate for each margin separately maybe on one of the shorter sequence lengths to see how soft orthogonality impacts the stability of the learning process fig for instance shows that a sigmoid improves stability but perhaps slightly reducing the learning rate for the non sigmoid gaussian prior rnn would make the learning well behaved again for weightings less than fig shows singular values converging around rather than does initializing to orthogonal matrices multiplied by confer any noticeable advantage over standard orthogonal matrices especially on the t k copy task curiously larger margins and even models without sigmoidal constraints on the spectrum no margin performed well as long as they were initialized to be orthogonal suggesting that evolution away from orthogonality is not a serious problem on this task this is consistent with the analysis given in saxe et al where for deep linear nets if a singular value is initialized to but dies away during training this is because it must be zero to implement the desired input output map more broadly an open question has been whether orthogonality is useful as an initialization as proposed by saxe et al where its role is mainly as a preconditioner which makes optimization proceed quickly but doesn t fundamentally change the optimization problem or whether it is useful as a regularizer as proposed by arjovsky et al and henaff et al that is as an additional constraint in the optimization problem minimize loss subject to weights being orthogonal these experiments seem to show that mere initialization to orthogonal weights is enough to reap an optimization speed advantage and that too much regularization begins to hurt performance i e substantially changing the optimization problem is undesirable this point is also apparent in fig in terms of the training loss on mnist fig no margin does almost indistinguishably from a margin of or however in terms of accuracy a margin of is best this shows that large or nonexistent margins i e orthogonal initializations enable fast optimization of the training loss but among models that attain similar training loss the more nearly orthogonal weights perform better this starts to separate out the optimization speed advantage conferred by orthogonality from the regularization advantage it confers it may be useful to more explicitly discuss the initialization vs regularization dimension in the text overall this paper contributes a variety of techniques and intuitions which are likely to be useful in training rnns,7.0
560.json,the paper is well motivated and is part of a line of recent work investigating the use of orthogonal weight matrices within recurrent neural networks while using orthogonal weights addresses the issue of vanishing exploding gradients it is unclear whether anything is lost either in representational power or in trainability by enforcing orthogonality as such an empirical investigation that examines how these properties are affected by deviation from orthogonality is a useful contribution the paper is clearly written and the primary formulation for investigating soft orthogonality constraints representing the weight matrices in their svd factorized form which gives explicit control over the singular values is clean and natural albeit not necessarily ideal from a practical computational standpoint as it requires maintaining multiple orthogonal weight matrices each requiring an expensive update step i am unaware of this approach being investigated previously the experimental side however is somewhat lacking the paper evaluates two tasks a copy task using an rnn architecture without transition non linearities and sequential permuted sequential mnist these are reasonable choices for an initial evaluation but are both toy problems and do not shed much light on the practical aspects of the proposed approaches an evaluation in a more realistic setting would be valuable e g a language modeling task furthermore while investigating pure rnn makes sense for evaluating effects of orthogonality it feels somewhat academic lstms also provide a mechanism to capture longer term dependencies and in the tasks where the proposed approach was compared directly to an lstm it was significantly outperformed it would be very interesting to see the effects of the proposed soft orthogonality constraint in additional architectures e g deep feed forward architectures or whether there any benefit when embedded within an lstm although this seems doubtful overall the paper addresses a clear cut question with a well motivated approach and has interesting findings on some toy datasets as such i think it could provide a valuable contribution however the significance of the work is restricted by the limited experimental settings both datasets and network architectures,5.0
649.json,this paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like cbow or skip gram with a focus one the issue of bound word dependency type he nsubj vs unbound word alone he representations for context at training time the empirical results are extremely mixed and no specific novel method consistently outperforms existing methods the paper is systematic and i have no major concerns about its soundness however i do not think that this paper is of broad interest to the iclr community the paper is focused on a fairly narrow detail of representation learning that is entirely specific to nlp and its results are primarily negative a short paper at an acl conference would be a more reasonable target,4.0
472.json,in this paper the authors propose a method to explicitly regularize sparse coding to encode neighbouring datapoints with similar sets of atoms from the dictionary by clustering training examples with knn in input space the resulting algorithm is relatively complex and computationally relatively expensive but the authors provide detailed derivations and use arguments from proximal gradient descent methods to prove convergence i did not follow all the derivations only some in general the paper is well written and the authors explain the motivation behind the algorithms design in detail in the abstract the authors mention extensive experimental results but i find the experiments not very convincing with experiments on the usps handwritten digits dataset why not mnist coil and coil and uci the datasets are all relatively small and the algorithm is run with dictionary sizes between p to p this seems surprising because the authors state that they implemented srsc in cuda c with extreme efficiency page but more importantly i find it hard to interpret and compare the results the paper reports accuracy and and normalized mutual information for a image retrieval clustering task where the proposed srsc is used as a feature extractor the improvements relative to standard sparse coding seem very small often in terms of nmi it looks more promising in terms of accuracy and if i understand the description on page correctly than the test set was used to select some hyperparameters the best similarity measure for clustering step there is no comparisons to other baselines state of the art image clustering methods besides of providing features for a small scale image clustering system are there maybe ways to more directly evaluate the properties and qualities of a sparse coding approach e g reconstruction error sparsity maybe even denoising performance in summary i think in it current form the paper lacks the evaluation and experimental results for an iclr publication intuitively i agree with the authors that the proposed regularization is an interesting direction but i don t see experiments that directly show that the regularization has the desired effect and the improvements in the clustering task where srsc is used as a feature extractor are very modest,6.0
472.json,i would like to thank the authors for their detailed response to my questions the paper proposes a support regularized version of sparse coding that takes into account the underlying manifold structure of the data for this purpose the authors augment the classic sparse coding loss with a term that encourages near by points to have similar active set convergence guarantees for the optimization procedure are presented experimental evaluation on clustering and semi supervised learning shows the benefits of the proposed approach the paper is well written and a nice read the most relevant contribution of this work is to including and optimizing the regularization function and not an approximation or surrogate the authors derive a a pgd styple iterative method and present convergence analysis for it thanks for the clarifications regarding the assumptions used in section it would be nice to include some of that in the manuscript the authors also propose a fast encoding scheme for their proposed method the authors included a new experiment in semi supervised consists of a very interesting use of the method and the fast approximation while this is an interesting addition i think that using fast encoders is not particularly novel or the main part of the work converting iterative optimization algorithms into feed forward nets for accelerating the inference process has been done in the past several times with quite similar problems is natural that this can be done and not very surprising maybe would be interesting to evaluate how important is to have an architecture matching the optimization algorithm compared to a generic network though some of this analysis has also been performed in the past,7.0
479.json,first i would like to apologize for the delay in reviewing summary this work introduces a novel memory based artificial neural network for reading comprehension experiments show improvement on state of the art the originality of the approach seems to be on the implementation of an iterative procedure with a loop testing that the current answer is the correct one in order to get a better sense of the reason for improvement it would be interesting to have a complexity and or a time analysis of the algorithm i might be mistaken but i do not see you reporting anything on the actual number of loops necessary in the reported experiments the dataset description in section should be moved to section where the other datasets are described,7.0
479.json,thie paper proposed an iterative memory updating model for cloze style question answering task the approach is interesting and result is good for the paper i have some comments actually the model in the paper is not single model it proposed two models one consists of reading writing adaptive computation and answer module the other one is reading composing writing gate querying and answer module based on the method section and the experiment it seems the adaptive computation model is simpler and performs better and without two time memory update in single iteration and composing module the model is similar to neural turing machine what is the mlp setting in the composing module this paper tested different size of hidden state i do not find any relation between those numbers how could you find is there any tricks helping you find those numbers it needs more ablation study about using different t such as t according to my understanding for the adaptive computation it would stop when the pt so what is the distribution of t in the testing data,6.0
750.json,summary this paper extends and analyzes the gradient regularizer of hariharan and girshick in that paper a regularizer was proposed which penalizes gradient magnitudes and it was shown to aid low shot learning performance this work shows that the previous regularizer is equivalent to a direct penalty on the magnitude of feature values weighted differently per example the analysis goes to to provide two examples where a feature penalty favors a better representation the first example addresses the xor problem constructing a network where a feature penalty encourages a representation where xor is linearly separable the second example analyzes a layer linear network showing improved stability of a nd order optimizer when the feature penalty is added one last bit of analysis shows how this regularizer can be interpreted as a gaussian prior on both features and weights since the prior can be interpreted as having a soft whitening effect the feature regularizer is like a soft version of batch normalization experiments show small improvements on a synthetic xor test set on the omniglot dataset feature regularization is better than most baselines but is worse than moment matching networks an experiment on imagenet similar to hariharan and girshick also shows effective low shot learning strengths the core proposal is a simple modification of hariharan and girshick the idea of feature regularization is analyzed from multiple angles both theoretically and empirically the connection with batch normalization could have broader impact weaknesses in section the gradient regularizer of hariharan and girshick is introduced while introducing the concept some concern is expressed about the motivation and it is not very clear why small gradients on every sample produces good generalization experimentally this seems to be the central issue to me the paper details some related analysis it does not offer a clear answer to this problem the purpose and generality of section is not clear the analysis provides a specific case xor with a non standard architecture where feature regularization intuitively helps learn a better representation however the intended take away is not clear the take away may be that since a feature penalty helps in this case it should help in other cases i am hesitant to buy that argument because of the specific architecture used in this section the result seems to rely on the choice of an x non linearity which is not often encountered in recent neural net literature the point might also be to highlight the difference between a weight penalty and a feature penalty because the two seem to encourage different values of b in this case however there is no comparison to a weight penalty on b in section as far as i can tell eq depends on either assuming an l or cross entropy loss a more general class of losses for which eq holds is not provided this should be made clear before eq is presented the omniglot and imagenet experiments are performed with batch normalization yet the paper points out that feature regularization may be similar in effect to batch norm since the resnet cnn baseline includes batch norm and there are clear improvements over that baseline the proposed regularizer has a clear additional positive effect however results should be provided without batch norm so a comparison between the two methods can be performed the imagenet experiment should be more like hariharan and girshick in particular the same split of classes should be used provided in the appendix and performance should be measured using n novel examples per class using k nearest neighbors minor a brief comparison to matching networks is provided in section but the performance of matching networks should also be reported in table from the approach section intuitively when close to convergence about half of the data cases recommend to update a parameter to go left while the other half recommend to go right could the intuition be clarified there are many directions in high dimensional space and many ways to divide them into two groups is the sgm penalty of hariharan and girshick implemented for this paper or using their code either is acceptable but clarification would be appreciated should the first equal sign in eq be proportional to not equal to the work is dense in nature but i think the presentation could be improved in particular more detailed derivations could be provided in an appendix and some details could be removed from the main version in order to increase focus on the results e g the derviation in section overall evaluation this paper provides an interesting set of analyses but their value is not clear there is no clear reason why a gradient or feature regularizer should improve low shot learning performance despite that experiments support that conclusion the analysis is interesting by itself and the analysis may help lead to a clearer explanation the work is a somewhat novel extension and analysis of hariharan and girshick some points are not completely clear as mentioned above,6.0
750.json,this paper proposes analysis of regularization weight froebius norm and feature l norm showing that it is equivalent to another proposed regularization gradient magnitude loss they then argue that it is helpful to low shot learning it is numerically stable it is a soft version of batch normalization finally they demonstrate experimentally that such a regularization improves performance on low shot tasks first this is a nice analysis of some simple models and proposes interesting insights in some optimization issues unfortunately the authors do not demonstrate nor argue in a convincing manner that such an analysis extends to deep non linear computation structures i feel like the authors could write a full paper about results can be derived for φ x with convex differentiable non linear activation functions such as relu both via analysis and experimentation to measure numerical stability second the authors again show an interesting correspondance to batch normalization but imo fail to experimentally show its relevance finally i understand the appeal of the proposed method from a numerical stability point of view but am not convinced that it has any effect on low shot learning in the high dimensional spaces that deep networks are used for i commend the authors for contributing to the mathematical understanding of our field but i think they have yet to demonstrate the large scale effectiveness of what they propose at the same time i feel like this paper does not have a clear and strong message it makes various interesting claims about a number of things but they seem more or less disparate and only loosely related to low shot learning notes an expectation taken with respect to the empirical distribution generated by the training set generally the training set is viewed as a montecarlo sample of the underlying unknown data distribution mathcal d we can see that our model learns meaningful representations it gets a improvement on the baseline but there is no analysis of the meaningfulness of the representations table should be table please be mindful of formatting some citations should be parenthesized and there are numerous extraneous and missing spacings between words and sentences,6.0
750.json,the paper proposes to use a last layer feature penalty as regularization on the last layer of a neural net although the equations suggest a weighting per example dropping this weight alphai works equally well the proposed approach relates to batch norm and weight decay experiments are given on low shot settting there seem to be two stories in the paper feature penalty as a soft batch norm version and low shot learning why is feature penalty specifically adapted to low shot learning and not a more classical supervised task regarding your result on omniglot i believe it is still about worse than the matching networks which you refer to but do not put in table why overall the idea is simple but feels like preliminary while it is supposed to be a soft bn bn itself gets better performance than feature penalty and both together give even better results is something still missing in the explanation edits after revised version thank you for adding more information to the paper i feel it is still too long but hopefully you can reduce it to pages as promised however i am still not convinced the paper is ready to be accepted mainly for the following reasons on omniglot the paper is still significantly far from the current state of the art the new experiments do not really confirm infirm the relationship with bn you added an explanation of why fp works for low shot setting by showing it controls the vc dimension and hence is good to control overfitting with a small number of training examples but this discussion is basic and does not really shed more light than the obvious i am pushing up your score from to for the improved version but i still think it is below acceptance level,5.0
615.json,the paper proposes a new second order method l sr to train deep neural networks it is claimed that the method addresses two important optimization problems in this setting poor conditioning of the hessian and proliferation of saddle points the method can be viewed as a concatenation of sr algorithm of nocedal wright and limited memory representations byrd et al first of all i am missing a more formal theoretical argument in this work in general providing more intuition would be helpful too which instead is provided in the works of dauphin or martens the experimental section in not very convincing considering that the performance in terms of the wall clock time is not reported and the advantage over some competitor methods is not very strong even in terms of epochs i understand that the authors are optimizing their implementation still but the question is considering the experiments are not convincing why would anybody bother to implement l sr to train their deep models the work is not ready to be published,4.0
584.json,this work investigates a joint learning setup where tasks are stacked based on their complexity to this end experimental evaluation is done on pos tagging chunking dependency parsing semantic relatedness and textual entailment the end to end model improves over models trained solely on target tasks although the hypothesis of this work is an important one the experimental evaluation lacks thoroughness first a very simple multi task learning baseline should be implemented where there is no hierarchy of tasks to test the hypothesis of the tasks should be ordered in terms of complexity second since the test set of chunking is included in training data of dependency parsing the results related to chunking with jmtall are not informative third since the model does not guarantee well formed dependency trees thus results in table are not fair minor issue chunking is not a word level task although the annotation is word level chunking is a structured prediction task where we would like to learn a structured annotation over a sequence,3.0
584.json,the paper introduce a way to train joint models for many nlp tasks traditionally we treat these tasks as pipeline the later tasks will depending on the output of the previous tasks here the authors propose a neural approach which includes all the tasks in one single model the higher level tasks takes the predictions from the lower level tasks and the hidden representations of the lower level tasks also proposed in this paper is the successive regularization intuitively this means that when training the high level tasks we don t want to change the model in the lower levels by too much so that the lower level tasks can keep a reasonable accuracy of prediction on the modeling side i think the proposed model is very similar comparing to zhang and weiss acl and spinn bowman et al in a even simpler way the number of the experiments are good but i am not sure i am convinced by the numbers in table since the patterns are not very clear there sometimes the performance of the higher level tasks even goes down when training with more tasks sometimes it does go up but also not very significant and stable the dependency scores although i don t think this is a serious problem comparing the uas las when the output is not guaranteed to be a well formed tree isn t strictly speaking fair i admit that the successive regularization make sense intuitively and is a very interesting direction to try however without a careful study of the training schema of such model the current results on successive regularization do not convince me that it should be the right thing to do in such models the current results are not strong enough to show that the training methods need to be explored here including things as iteratively train on different tasks and the relationship between the number of training iterations of a task and it s training set size and loss on this task etc,5.0
357.json,this paper introduces an approach for future frame prediction in videos by decoupling motion and content to be encoded separately and additionally using multi scale residual connections qualitative and quantitative results are shown on kth weizmann and ucf datasets the idea of decoupling motion and content is interesting and seems to work well for this task however the novelty is relatively incremental given previous cited work on multi stream networks and it is not clear that this particular decoupling works well or is of broader interest beyond the specific task of future frame prediction while results on kth and weizmann are convincing and significantly outperform baselines the results are less impressive on less constrained ucf dataset the qualitative examples for ucf are not convincing as discussed in the pre review question overall this is a well executed work with an interesting though not extremely novel idea given the limited novelty of decoupling motion and content and impact beyond the specific application the paper would be strengthened if this could be shown to be of broader interest e g for other video tasks,7.0
357.json,the paper presents a method for predicting video sequences in the lines of mathieu et al the contribution is the separation of the predictor into two different networks picking up motion and content respectively the paper is very interesting but the novelty is low compared to the referenced work as also pointed out by anonreviewer there is a similarity with two stream networks and also a whole body of work building on this seminal paper separating motion and content has also been proposed for other applications e g pose estimation details the paper can be clearly understood if the basic frameworks like gans are known but the presentation is not general and good enough for a broad public example losses to are well known from the matthieu et al paper however to make the paper self contained they should be properly explained and it should be mentioned that they are additional losses the main target is the gan loss the adversarial part of the paper is not properly enough introduced i do agree that adversarial training is now well enough known in the community but it should still be properly introduced this also involves the explanation that ldisc is the loss for a second network the discriminator and explaining the role of both etc equation c is not explained are these motion vectors c is also overloaded with the feature dimension c the residual nature of the layer should be made more apparent in equation there are several typos absence of articles and prepositions of etc the paper should be reread carefully,6.0
707.json,this paper presents a new type of language model that treats entity references as latent variables the paper is structured as three specialized models for three applications dialog generation with references to database entries recipe generation with references to ingredients and text generation with coreference mentions despite some opaqueness in details that i will discuss later the paper does a great job making the main idea coming through which i think is quite interesting and definitely worth pursuing further but it seems the paper was rushed into the deadline as there are a few major weaknesses the first major weakness is that the claimed latent variables are hardly latent in the actual empirical evaluation as clarified by the authors via pre review qas all mentions were assumed to be given to all model variants and so it would seem like an over claim to call these variables as latent when they are in fact treated as observed variables is it because the models with latent variables were too difficult to train right a related problem is the use of perplexity as an evaluation measure when comparing reference aware language models to vanilla language models essentially the authors are comparing two language models defined over different event space which is not a fair comparison because mentions were assumed to be given for the reference aware language models and because of the fact that mention generators are designed similar to a pointer network the probability scores over mentions will naturally be higher compared to the regular language model that needs to consider a much bigger vocabulary set the effect is analogous to comparing language models with aggressive unk and a small vocabulary set to a language models with no unk and a much larger vocabulary set to mitigate this problem the authors need to perform one of the following additional evaluations either assuming no mention boundaries and marginalizing over all possibilities treating latent variables as truly latent or showing other types of evaluation beyond perplexity for example bleu meteor human evaluation etc on the corresponding generation task the other major weakness is writing in terms of technical accuracy and completeness i found many details opaque and confusing even after qas i wonder if the main challenge that hinders the quality of writing has something to do with having three very specialized models in one paper each having a lot of details to be worked out which may have not been extremely important for the main story of the paper but nonetheless not negligible in order to understand what is going on with the paper perhaps the authors can restructure the paper so that the most important details are clearly worked out in the main body of the paper especially in terms of latent variable handling how to make mention detection and conference resolution truly latent and if and when entity update helps which in the current version is not elaborated at all as it is mentioned only very briefly for the third application coreference resolution without any empirical comparisons to motivate the update operation,6.0
707.json,this paper explores language modeling applications with an explicit modeling of reference expressions dialog receipt generation and coreferences while these are important tasks for nlp and the authors have done a number of experiments the paper is limited for a few reasons this paper is not clearly written and is pretty hard to follow some details in particular there are many obvious math errors such as missing the marginalization sum in eq and p z i v should be here on page pointer switch section the major novelty seems to be the dimensional attention from the table and the pointer to the d table these are more of a customization of existing work to a particular task with d tables as a part of the input to seqseq model with both attentions and pointer networks the empirical results are not very conclusive yet limited by either the relatively small data size or the lack of well established baseline for some new applications e g the recipe generation task overall this paper as it is for now is more suitable for a workshop rather than for the main conference,5.0
642.json,the paper studies the impact of using customized number representations on accuracy speed and energy consumption of neural network inference several standard computer vision architectures including vgg and googlenet are considered for the experiments and it is concluded that floating point representations are preferred over fixed point representations and floating point numbers with about bits are sufficient for the considered architectures resulting in a small loss in accuracy the paper provides a nice overview of floating and fixed point representations and focuses on an important aspect of deep learning that is not well studied there are several aspects of the paper that could be improved but overall i am leaned toward weak accept assuming that the authors address the issues below the paper is not clear that it is only focusing on neural network inference please include the word inference in the title abstract to clarify this point and mention that the findings of the paper do not necessarily apply to neural network training as training dynamics could be different the paper does not discuss the possibility of adopting quantization tricks during training which may result in the use of fewer bits at inference the paper is not clear whether in computing the running time and power consumption it includes all of the modules or only multiply accumulate units also how accurate are these numbers given different possible designs and the potential difference between simulation and production please elaborate on the details of simulation in the paper the whole discussion about efficient customized precision search seem unimportant to me when such important hardware considerations are concerned even spending x simulation time is not that important the exhaustive search process could be easily parallelized and one may rather spend more time at simulation at the cost of finding the exact best configuration rather than an approximation that said weak configurations could be easily filtered after evaluating just a few examples nvidia pascal gp gpu supports fp this should be discussed in the paper and relevant nvidia papers documents should be cited more comments parts of the paper discussing efficient customized precision search are not clear to me as future work the impact of number representations on batch normalization and recurrent neural networks could be studied,6.0
592.json,this paper is refreshing and elegant in its handling of over sampling in vae problem is that good reconstruction requires more nodes in the latent layers of the vae not all of them can or should be sampled from at the creative regime of the vae which ones to choose the paper offers and sensible solution problem is that real life data sets like cifar have not being tried so the reader is hard pressed to choose between many other just as natural solutions one can e g run in parallel a classifier and let it choose the best epitome in the spirit of spatial transformers ace reference the list can go on we hope that the paper finds its way to the conference because it addresses an important problem in an elegant way and papers like this are few and far between on a secondary note regarding terminology pls avoid using the kl term as in section there are so many kl terms related to vae s it ultimately gets out of control generative error is a more descriptive term because minimizing it is indispensable for the generative qualities of the net the variational error for example is also a kl term equation in reference as is the upper bound commonly used in vae s your formula and its equivalent the kl expression as in formula in reference the latter expression is frequently used and is handy for say importance sampling as in reference,6.0
592.json,the paper presents a version of a variational autoencoder that uses a discrete latent variable that masks the activation of the latent code making only a subset an epitome of the latent variables active for a given sample the justification for this choice is that by letting different latent variables be active for different samples the model is forced to use more of the latent code than a usual vae while the problem of latent variable over pruning is important and has been highlighted in the literature before in the context of variational inference the proposed solution does not seem to solve it beyond for instance a mixture of vaes indeed a mixture of vaes would have been a great baseline for the experiments in the paper as it uses a categorical variable the mixture component along with multiple vaes the main difference between a mixture and an epitomic vae is the sharing of parameters between the different mixture components in the epitomic vae case the experimental section presents misleading results the log likelihood of the proposed models is evaluated with parzen window estimator a significantly more accurate lower bound on likelihood that is available for the vaes is not reported in reviewer experience continuous mnist likelihood of upwards of nats is easy to obtain with a modestly sized vae the exposition changes between dealing with binary mnist and continuous mnist experiments this is confusing because these versions of the dataset present different challenges for modeling with likelihood based models continuous mnist is harder to model with high capacity likelihood optimizing models because the dataset lies in a proper subspace of the dimensional space some pixels are always or almost always equal to and hence probability density can be arbitrarily large on this subspace models that try to maximize the likelihood often exploit this option of maximizing the likelihood by concentrating the probability around the subspace at the expense of actually modeling the data the samples of a well tuned vae trained on binary mnist or a vae trained on continuous mnist to which noise has been appropriately added tend to look much better than the ones presented in experimental results the claim that the vae uses its capacity to overfit to the training data is not justified no evidence is presented that the reconstruction likelihood on the training data is significantly higher than the reconstruction likelihood on the test data it misleading to use a technical term like overfitting to mean something else the use of dropout in dropout vae is not specified is dropout applied to the latent variables or to the hidden layers of the encoder decoder the two options will exhibit very different behaviors mnist evae samples and reconstructions look more like a more diverse version of d vae samples reconstructions they are blurry the model does not encode precise position of strokes this is consistent with an interpretation of evae as a kind of mixture of smaller vaes rather than a higher dimensional vae it is misleading to claim that it outperforms a high dimensional vae based on this evidence in reviewer opinion the paper is not yet ready for publication a stronger baseline vae evaluated with evidence lower bound or another reliable method is essential for comparing the proposed evae to vaes,5.0
711.json,this paper proposes rasor a method to efficiently representing and scoring all possible spans in an extractive qa task while the test set results on squad have not been released it looks likely that they are not going to be state of the art with that said the idea of enumerating all possible spans proposed in this paper could potentially improve many architectures the paper is very well written and the analysis ablations in the final sections are mostly interesting especially figure which confirms what we would intuitively believe based on its potential to positively impact other researchers working on squad i recommend that the paper is accepted,7.0
711.json,this paper presents an architecture for answer extraction task and evaluates on the squad dataset the proposed model builds fixed length representations of all spans in the answer document based on recurrent neural network it outperforms a few baselines in exact match and f on squad it is unfortunate that the blind test results are not obtained yet due to the copyright issue there are quite a few other systems submissions on the squad leader board that were available for comparison given that there no result on the test set reported the grid search for hyperparameters on the dev set directly is also a concern even though the authors did cross validation experiments,6.0
711.json,the authors proposed rasor to address the problem of finding the best answer span according to a given question the focus of the paper is mainly on how to model the relationship between question and the answer spans the idea proposed by this paper is reasonable but not ground breaking the analysis is interesting and potentially useful i would hope the authors can go extra miles to analyze different choices of boundary prediction models and make a more convincing case for the necessity of modeling the score of the span globally the main idea behind rasor is to globally normalize and rank the scores of the possible answer spans rasor is able to achieve this by first modeling the hidden vectors of all words with lstms then the representation of a text span is formed by concatenating the corresponding hidden vectors of the start and the end word of the corresponding chunk the approach is reasonable but not earth shattering also the table shows that the improvement over end prediction point is not very large i appreciate the fact that authors conduct several analysis experiments as some of them are quite interesting for example it seems that question independent representation is also very import to the performance in addition to the current analysis i also want to get a clear idea on what makes the current model be better than the match lstm is it hyper parameter tuning or it is due to the use of the question independent representation another good thing about the proposed model is that it is relatively simple so there is a chance that the proposed techniques can be combined with other newly proposed ones,6.0
341.json,this paper proposed a novel adversarial framework to train a model from demonstrations in a third person perspective to perform the task in the first person view here the adversarial training is used to extract a novice expert or third person first person independent feature so that the agent can use to perform the same policy in a different view point while the idea is quite elegant and novel i enjoy reading it more experiments are needed to justify the approach probably the most important issue is that there is no baseline e g what if we train the model with the image from the same viewpoint it should be better than the proposed approach but how close are they how the performance changes when we gradually change the viewpoint from third person to first person another important question is that maybe the network just blindly remembers the policy in this case the extracted feature could be artifacts of the input image that implicitly counts the time tick in some way and thus domain agonistic but can still perform reasonable policy since the experiments are conduct in a synthetic environment this might happen an easy check is to run the algorithm on multiple viewpoint and or with blurred differently rendered images and or with random initial conditions other ablation analysis is also needed for example i am not fully convinced by the gradient flipping trick used in eqn and in the experiments there is no ablation analysis for that gan em style training versus gradient flipping trick for the experiments fig does not have error bars and is not very convincing,5.0
341.json,the paper presents an interesting new problem setup for imitation learning an agent tries to imitate a trajectory demonstrated by an expert but said trajectory is demonstrated in a different state or observation space than the one accessible by the agent although the dynamics of the underlying mdp are shared the paper proposes a solution strategy that combines recent work on domain confusion losses with a recent irl method based on generative adversarial networks i believe the general problem to be relevant and agree with the authors that it results in a more natural formulation for imitation learning that might be more widely applicable there are however a few issues with the paper in its current state that make the paper fall short of being a great exploration of a novel idea i will list these concerns in the following in arbitrary order the paper feels at times to be a bit hurriedly written this also mainly manifests itself in the experiments see comment below and makes a few fairly strong claims in the introduction that in my opinion are not backed up by their approach for example advancements in this class of algorithms would significantly improve the state of robotics because it will enable anyone to easily teach robots new skills given that the current method to my understanding has the same issues that come with standard gan training e g instability etc and requires a very accurate simulator to work well since trpo will require a large number of simulated trajectories in each step this seems like an overstatement there are some sentences that are ungrammatical or switch tense in the middle of the sentence making the paper harder to read than necessary e g page we find that this simple approach has been able to solve the problems the general idea of third person imitation learning is nice clear and at least to my understanding also novel however instead of exploring how to generally adapt current irl algorithms to this setting the authors pick a specific approach that they find promising using gans for irl and extend it a significant amount of time is then spent on explaining why current irl algorithms will fail in the third person setting i fail to see why the situation for the gan based approach is any different than that of any other existing irl algorithm to be more clear i see no reason why e g behavioral cloning could not be extended with a domain confusion loss in exactly the same way as the approach presented to this end it would have been nice to rather discuss which algorithms can be adapted in the same way and also test them and which ones cannot one straightforward approach to apply any irl algorithm would for example be to train two autoencoders for both domains that share higher layers a domain confusion loss on the highest layer should that not result in features that are directly usable if not why while the general argument that existing irl algorithms will fail in the proposed setting seems reasonable it is still unfortunate that no attempts have been made to validate this empirically no comparison is made regarding what happens when one e g performs supervised learning behavioral cloning using the expert observations and then transfers to the changed domain how well would this work in practice also how fast can different irl algorithms solve the target task in general assuming a first person perspective although i like the idea of presenting the experiments as being directed towards answering a specific set of questions i feel like the posed questions somewhat distract from the main theme of the paper question suddenly makes the use of additional velocity information to be a main point of importance and the experiments regarding question in the end only contain evaluations regarding two hyperparameters ignoring all other parameters such as the parameters for trpo the number of rollouts per iteration the number of presented expert episodes and the design choices for the gan i understand that not all of these can be evaluated thoroughly in a conference paper but i feel like some more experiments or at least some discussion would have helped here the presented experimental evaluation somewhat hides the cost of trpo training with the obtained reward function how many roll outs are necessary in each step the experiments lack some details how are the expert trajectories obtained the domains for the pendulum experiment seem identical except for coloring of the pole is that correct i am surprised this small change seems to have such a detrimental effect figure shows average performance over trials what about figure if this is also average performance what is the variance here given that gans are not easy to train how often does the training fail were you able to re use the hyperparameters across all experiments update i updated the score please see my response to the rebuttal below,6.0
654.json,the authors present a method for training probabilistic models by maximizing a stochastic variational lower bound type objective training involves sampling and then learning a transition based inference to walk back samples to the data because of its focus on transitions it can be used to learn a raw transition operator rather than purely learning an energy based model the objective is intuitively appealing because of its similarity to previous successful but less principled training methods for mrfs like contrastive divergence the idea for the algorithm is appealing and it looks like it could find a nice place in the literature however the submission in its current form is not yet ready for publication experiments are qualitative and the generated samples are not obviously indicative of a high model quality as pointed out elsewhere the mathematical analysis does not currently demonstrate tightness of the variational bound in the case of a learned transition operator more evaluation using e g annealed importance sampling to estimate held out likelihoods is necessary assuming that the analysis can be repaired the ability to directly parametrize a transition operator an interesting strength of this method should be explored in further experiments and contrasted with the more standard energy based modeling this looks like a promising idea and other reviews and questions have already raised some important technical points which should help strengthen this paper for future submission,4.0
654.json,i very much like the underlying idea for this paper i was not convinced by the execution in its current state my primary concern is the one i expressed in my pre review question below which i do not think the authors addressed specifically i think the choice of q s s p s s will make the forward and reverse trajectories almost pathologically mismatched to each other and will thus make the variational bound extremely loose and high variance the claim about the tightness of the bound in appendix d relies on the assumption that the transition distribution obeys detailed balance the learned transition distribution in the paper does not obey detailed balance and therefore the tightness claim in appendix d does not hold in section you briefly discuss the idea of learning an energy function rather than directly learning a transition distribution i think this would be excellent and in that case you could choose an mcmc transition operator that does obey detailed balance for that energy function i did not go through appendix d beyond this step the experimental results were not visually impressive i suspect this is primarily driven by the mismatch between generative and inference trajectories see my concern above and in the pre review question below also see note below for sec i suspect some terms are being dropped from the training gradient the paper is optimizing a variational bound on log likelihood you should really really really report and compare log likelihoods against competing methods detailed comments below some of these were written based on a previous version of the paper sec first paragraph is very difficult to follow these modes these spurious modes these spurious modes sec s v h s v h sec with an mcmc with an mcmc chain ideally an mcmc e g via mcmc mcmc is not ideal it just often the best we can do sec last bullet could make the temperature infinite for the last step in which case the last step will sample directly from the prior and the posterior and the prior will be exactly the same sec using an energy function would be great especially because many mcmc transition operators obey detailed balance you would be far less prone to suffer from the forward backward transition mismatch that is my primary concern about this technique eq what is alpha how does it depend on the temperature it never specified sec last paragraph in gsn section note that q also depends on theta so by not backpropagating through the full q chain you are dropping terms from the gradient sec non equilibrium thermodynamics note that the noneq paper also increases the noise variance as the distance from the data increases fig right left mislabeled fig label panes fig after how many walkback steps,5.0
654.json,this paper proposes a new kind of generative model based on an annealing process where the transition probabilities are learned directly to maximize a variational lower bound on the log likelihood overall the idea is clever and appealing but i think the paper needs more quantitative validation and better discussion of the relationship with prior work in terms of prior work ais and raise are both closely related algorithms and share much of the mathematical structure with the proposed method for this reason it s not sufficient to mention them in passing in the related work section those methods and their relationship to variational walkback need to be discussed in detail if i understand correctly the proposed method is essentially an extension of raise where the transition probabilities are learned rather than fixed based on an existing mrf i think this is an interesting and worthwhile extension but the relationship to existing work needs to be clarified the analysis of appendix d seems incorrect it derives a formula for the ratios of prior and posterior probabilities but this formula only holds under the assumption of constant temperature in which case the ratio is very large when the temperature is varied the analysis of neal applies and the answer is different one of the main selling points of the method is that it optimizes a variational lower bound on the log likelihood even more accurate estimates can be obtained using importance sampling it ought to be easy to report log likelihood estimates for this method so i wonder why such estimates aren t reported there are lots of prior results to compare against on mnist in addition a natural baseline would be raise so that one can check if the ability to learn the transitions actually helps i think the basic idea here is a sound one so i would be willing to raise my score if the above issues are addressed in a revised version minor comments a recognized obstacle to training undirected graphical models is that ml training requires sampling from mcmc chains in the inner loop of training for each example this seems like an unfair characterization since the standard algorithm is pcd which usually takes only a single step per mini batch some of the methods discussed in the related work are missing citations the method is justified in terms of carving the energy function in the right direction at each point but i m not sure this is actually what s happening isn t the point of the method that it can optimize a lower bound on the log likelihood and therefore learn a globally correct allocation of probability mass,4.0
480.json,while my above review title is too verbose it would be a more accurate title for the paper than the current one an overall better title would probably be somewhere in between the overall approach is interesting all three of the key techniques aux tasks skip diagonal connections and the use of internal labels for the kind of data available make a lot of sense i found some of the results hard to understand interpret some of the explanation in the discussion below has been helpful e g see my earlier questions about fig and the paper would benefit from including more such explanations it may be worthwhile very briefly mentioning the relationship of diagonal connections to other emerging terms for similar ideas e g skip connections etc skip seems to me to be accurate regardless of how you draw the network whereas diagonal only makes sense for certain visual layouts in response to comment in the discussion below leading to less over segmentation of action bouts and corresponding discussion in section of the paper i would be like to have a bit more about this in the paper i have assumed that per bout refers to per action event but now i am not certain that i have understood this correctly i e can a bout last for a few minutes given the readership i think it would not be inappropriate to define some of these things explicitly in response to comment about fly behaviours that last minutes vs milliseconds this is interesting and i would be curious to know how classification accuracy relates to the time scale of the behaviour e g are most of the mistakes on long term behaviours i realize that this would only tell part of the story e g if you have a behaviour that has both a long term duration but that also has very different short term characteristics than many other behaviours it should be easy to classify accuractely despite being long term if easy to investigate this i would add a comment about it if this is hard to investigate it probably not worth it at this point although it something you might want to look at in future in response to comment about scaling to human behavior i agree that in principle adding conv layers directly above the sensory input would be the right thing to try but seriously there is usually a pretty big gap between what should work and what actually works as i am sure the authors are aware indeed i am sure the authors have a much more experiential and detailed understanding of the limitations of their work than i do what i see presented is a nice system that has been demonstrated to handle spatiotemporal trajectories the claims made should correspond to this i would consider adjusting my rating to a depending on future revisions,7.0
746.json,i was holding off on this review hoping to get the missing details from the code at,4.0
746.json,the basic idea of this contribution is very nice and worth pursuing how to use the powerful divide and conquer algorithm design strategy to learn better programs for tasks such as sorting or planar convex hull however the execution of this idea is not convincing and needs polishing before acceptance as it is right now the paper has a proof of concept feel that makes it great for a workshop contribution my main concern is that the method presented is currently not easily applicable to other tasks typically demonstrations of program induction from input output examples on well known tasks serves the purpose of proving that a generic learning machine is able to solve some well known tasks and will be useful on other tasks due to its generality this contribution however presents a learning machine that is very hand tailored to the two chosen tasks the paper essentially demonstrates that with enough engineering hardcoding the recurrency structure designing problem specific rules of supervision at lower recurrency levels one can get a partially trainable sorter or convex hull solver i found the contribution relatively hard to understand high level ideas are mixed with low level tricks required to get the model to work and it is not clear either how the models operate nor how much of them was actually learned and how much was designed the answer to the questions did hep nut did not make it into the paper mixing the descriptions of the tricks required to solve the two tasks makes things even more confusing i believe that the paper would be much more accessible if instead of promising a general solution it clearly stated the challenges faced by the authors and the possible solutions highlights proof of concept of a partially trainable implementation of the important divide and conquer paradigm explicit reasoning about complexity of induced programs the solution isn t generic enough to be applicable to unknown problems the networks require tricks specific to each problem the writing style pictures the method as very general but falls back on very low level details specific to each task,4.0
746.json,i find this paper extremely hard to read the main promise of the paper is to train models for combinatorial search procedures especially for dynamic programming to learn where to split and merge the present methodology is supposed to make use of some form of scale invariance property which is scarcely motivated for most problems this approach should be relevant for however the general research direction is fruitful and important the paper would be much more readable if it would start with a clear formal problem formulation followed by some schematic view on the overall flow and description on which parts are supervised which parts are not also a tabular form and sample of the various kinds problems solved by this method could be listed in the beginning as a motivation with some clear description on how they fit the central paradigm and motivate the rest of the paper in a more concrete manner instead the paper is quite chaotic switching between low level and high level details problem formulations and their solutions in a somewhat random hard to parse order both split and merge phases seem to make a lot of discrete choices in a hierarchical manner during training the paper does not explain how those discrete choices are backpropagated through the network in an unbiased manner if that is the case at all in general the direction this paper is exciting but the paper itself is a frustrating read in its present form i have spent several hours on it without having to manage to achieve a clear mental image on how all the presented pieces fit together i would revise my score if the paper would be improved greatly from a readability perspective but i think it would require a major rewrite,3.0
603.json,this paper considers the code completion problem given partially written source code produce a distribution over the next token or sequence of tokens this is an interesting and important problem with relevance to industry and research the authors propose an lstm model that sequentially generates a depth first traversal over an ast not surprisingly the results improve over previous approaches with more brittle conditioning mechanisms bielik et al still simply augmenting previous work with lstm based conditioning is not enough of a contribution to justify an entire paper some directions that would greatly improve the contribution include considering distinct traversal orders does this change the predictive accuracy any other ways of dealing with unk tokens the ultimate goal of this paper is to improve code completion and it would be great to go beyond simply neurifying previous methods comments last two sentences of related work claim that other methods can only examine a limited subset of source code aside from being a vague statement it is not accurate the models described in bielik et al and maddison tarlow can in principle condition on any part of the ast already generated the difference in this work is that the lstm can learn to condition in a flexible way that does not increase the complexity of the computation in the denying prediction experiments the most interesting number is the prediction accuracy which is p accurate model does not predict unk i think it would also be interesting to see p accurate unk is not ground truth clearly the models trained to ignore unk losses will do worse overall but do they do worse on non unk tokens,5.0
603.json,this paper studies the problem of source code completion using neural network models a variety of models are presented all of which are simple variations on lstms adapted to the peculiarities of the data representation chosen code is represented as a sequence of nonterminal terminal pairs with terminals being allowed to be empty another minor tweak is the option to deny prediction which makes sense in the context of code completion in an ide as it probably better to not make a prediction if the model is very unsure about what comes next empirically results show that performance is worse than previous work on predicting terminals but better at predicting nonterminals however i find the split between terminals and nonterminals to be strange and it not clear to me what the takeaway is surely a simple proxy for what we care about is how often the system is going to suggest the next token that actually appears in the code why not compute this and report a single number to summarize the performance overall the paper is ok but it has a flavor of we ran lstms on an existing dataset the results are ok but not amazing there are also some issues with the writing that could be improved see below in total i do not think there is a big enough contribution to warrant publication at iclr detailed comments i find the ntnt model strange in that it predicts the nonterminal and the terminal independently conditional upon the hidden state the discussion of related work needs reworking for example bielik et al does not generalize all of the works listed at the start of section and the maddison citation is wrong,4.0
603.json,while the overall direction is promising there are several serious issues with the paper which affect the novelty and validity of the results incorrect claims about related work affecting novelty this work is not the first to explore a deep learning approach to automatic code completion toward deep learning software repositories msr also uses deep learning for code completion and is not cited code completion with statistical language models pldi is cited incorrectly it also does code completion with recurrent neural networks phog is independent of javascript it does representation learning and has been applied to other languages e g python see oopsla below this submission is not the only one that can automatically extract features some high precision cited baselines do it structured generative models of natural source code is an incorrect citation it is from icml and has more authors it is also a log linear model and conditions on more context than claimed in this submission uses a non comparable prediction task for non terminal symbols the type of prediction made here is simpler than the one used in phog and state of the art see oopsla paper below and thus the claimed point improvement is not substantiated in particular in javascript there are types of nodes however a phog and oopsla predictions considers not only these types but also whether there are right siblings and children of a node this is necessary for predicting tree fragments instead of a sequence of nodes it however makes the prediction harder than the one considered here it leads to labels a x increase not comparing to state of the art the state of the art however is not the basic phog cited here but probabilistic model for code with decision trees oopsla which appeared before the submission deadline for iclr,4.0
551.json,summary the authors propose a histogram based state representation with differentiable motion models and observation updates for state tracking from observations linear model with gaussian noise is used as the motion model while a neural network is used to learn the measurement model they track robot states in d hallway and a d arena positives show how to encode prior knowledge about state transitions in the architecture no assumptions about the observation model which is learned purely from data better accuracy than baselines with limited training data negatives the motion model is too simplistic the authors in their response to earlier questions say that a generic feed forward neural network could be used to model more complicated motions however then the novelty of their framework is not clear as then the proposed model would just be a couple of neural networks to learn the motion and observation models the observation model again is too simplistic e g one dimensional observations and is proposed to be a generic feed forward network here again the technical novelty is not clear the histogram based representation is not scalable as also highlighted by the authors hence the proposed approach as it is cannot be applied to more complicated settings in figure a b where they compare the state estimation accuracy with other baselines i e lstms it is clear that the accuracy of the lstm has not saturated while that of their model has they should do larger scale experiments with more training data e g k k k samples note that while sample efficiency is a desirable property also discussed in section we do expect models with prior knowledge to work better for small number of samples than models which do not assume any structure experiments with larger number of samples would be insightful,4.0
551.json,the authors propose a time series model with discrete states for robotics applications i think the proposed method is too simplistic to be useful in the presented form eg the state space dimensionality topology is exactly matched to the experiments displacements in the transition model are linear in the actions observations are one dimensional this seems to be quite behind the current state of the art eg embed to control by watter et al where a state representation is learned directly from pixels furthermore the authors do not compare to any other method except for an out of the box lstm model also i feel like there must be a lot of prior work for combining hmms nns out there i think it would be necessary for the authors to relate their work to this literature,3.0
443.json,the paper proposes an online variant of segment to segment transducers which allows to circumvent the necessity of observing whole sentence before making target predictions authors mostly build on their previous work allowing additionally to leverage independent priors on the target hypotheses like the language grammar or sentence length strong points well written interesting idea of combining various sources of information in a bayesian framework for seqseq models handling something in an online manner typically makes things more difficult and this is what the authors are trying to do here which is definitely of interest to the community strong experimental section with some strong results though not complete see weak points weak points authors do not improve on computational complexity w r t tillmann proposal hence the algorithms may be found difficult to apply in scenarios where inputs may be long this already takes into account a rather constrained model of alignment latent variables what about the baseline where you only combine direct lm and bias contributions no channel was there any non obvious algorithmic constraint why this has not been included some other minor comments related to the first weak point can you elaborate more on how the clue of your work is conceptually different from the work of tillmann et al except of course the fact you use connectionist discriminative models to derive particular conditional probabilities how sensitive is the model to different choices of hyper parameters in eq do you naively search through the search space of those or do something more clever some more comments on details of the auxiliary direct model would be definitely of interest how crucial is the correct choice of the pruning variables k and k sec makes no markovian assumptions no first order markovian assumption typos table chanel channel one before last row apologies for late review,7.0
443.json,this paper proposes the neural noisy channel model p x y where x y is a input to out sequence pair based on the authors previous work on segment to segment neural transduction ssnt model for the noisy channel model the key difference from sequence to sequence is that the complete sequence y is not observed beforehand ssnt handles this problem elegantly by performing incremental alignment and prediction however this paper does not present anything that is particular novel on top of the ssnt the ssnt model is still applicable by reverting the input and output sequences the authors said that an unidirectional lstm has to be used as an encoder instead of the bidirectional lstm but i think the difference is minor the decoding algorithm presented in the appendix is relatively new the experimental study is very comprehensive and strong however there is one important baseline number that is missing for all the experiments can you give the number that uses direct lm bias and if you can give direct bias number would be even better although using a lm for the direct model does not make a lot of sense mathematically however it works pretty well in practice and the lm can rescore and smooth your predictions see deep speech end to end speech recognition in english and mandarin from baidu for example i think the lm may be also the key to explain why noisy channel is much better than direct model in table a couple minor questions are it is not very clear to me is your direct model in the experiments ssnt or sequence to sequence model o x y training complexity is ok but it would be great to further cut down the computational cost as it is still very expensive for long input sequences for example for paragraph or document level modeling or speech sequences the paper is well written and overall it is still an interesting paper as the channel model is always of great interest to the general public,6.0
455.json,this paper introduces an energy based generative adversarial network gan and provides theoretical and empirical results modeling a number of image datasets including large scale versions of categories of imagenet as far as i know energy based gans ebgan were introduced in kim and bengio but the proposed version makes a number of different design choices first it does away with the entropy regularization term that kim and bengio introduced to ensure that the gan discriminator converged to an energy function proportional to the log density of the data at optimum this implies that the discriminator in the proposed scheme will become uniform at convergence as discussed in the theoretical section of the paper however the introductory text seems to imply otherwise that one could recover a meaningful score function from the trained energy function discriminator this should be clarified second this version of the ebgan setting includes two innovations the introduction of the hinge loss in the value function and the use of an auto encoder parametrization for the energy function these innovations are not empirically justified in any way this is disappointing as it would be really good to see empirical results supporting the arguments made in support of their introduction the two significant contributions of this paper are the theoretical analysis of the energy baesd gan formalism showing that the optimum corresponds to a nash equilibrium and the impressive empirical results on large images that set a new standard in what straight gan style models can achieve the theoretical results seem solid to me and make a nice contribution regarding the quantitative results in table it seems not appropriate to bold the ebgan line when it seems to be statistically indistinguishable form the rasmus et al results though it is not mentioned here the use of bold typically indicates the state of the art i think this paper could be be much stronger if the two novel contributions to the energy based gan setting were more thoroughly explored with ablation experiments that being said i think this paper has already become a contribution other are building on including at least two other iclr submissions and so i think it should be accepted for publication at iclr,7.0
455.json,this paper proposes a novel extension of generative adversarial networks that replaces the traditional binary classifier discriminator with one that assigns a scalar energy to each point in the generator output domain the discriminator minimizes a hinge loss while the generator attempts to generate samples with low energy under the discriminator the authors show that a nash equilibrium under these conditions yields a generator that matches the data distribution assuming infinite capacity experiments are conducted with the discriminator taking the form of an autoencoder optionally including a regularizer that penalizes generated samples having a high cosine similarity to other samples in the minibatch pros the paper is well written the topic will be of interest to many because it sets the stage for the exploration of a wider variety of discriminators than currently used for training gans the theorems regarding optimality of the nash equilibrium appear to be correct thorough exploration of hyperparameters in the mnist experiments semi supervised results show that contrastive samples from the generator improve classification performance cons the relationship to other works that broaden the scope of the discriminator e g or use a generative network to provide contrastive samples to an energy based model is not made clear in the paper from visual inspection alone it is difficult to conclude whether eb gans produce better samples than dc gans on the lsun and celeba datasets it is difficult to assess the effect of the pt regularizer beyond visual inspection as the inception score results are computed with the vanilla eb gan specific comments sec it is unclear to me why a reconstruction loss will necessarily produce very different gradient directions sec it is confusing that pulling away is abbreviated as pt sec it seems strange that the inception model trained on natural images is being used to compute kl scores for mnist using an mnist trained cnn to compute inception style scores seems to be more appropriate here figure there is little variation across the histograms so this figure is not very enlightening appendix a in the proof of theorem it is unclear to me why a nash equilibrium of the system exists typos minor comments abstract probabilistic gans should probably be traditional or classical gans theorem a nash equilibrium exists sec should be several papers were presented overall i have some concerns with the related work and experimental evaluation sections but i feel the model is novel enough and is well justified by the optimality proofs and the quality of the generated samples springenberg jost tobias unsupervised and semi supervised learning with categorical generative adversarial networks arxiv preprint arxiv kim taesup and yoshua bengio deep directed generative models with energy based probability estimation arxiv preprint arxiv,7.0
793.json,summary this paper proposes to use surprisal driven feedback for training recurrent neural networks where they feedback the next step prediction error of the network as an input to the network authors have shown a result on language modeling tasks contributions the introduction of surprisal driven feedback which is just the feedback from the errors of the model from the previous time steps questions a point which is not fully clear from the paper is whether if you have used the ground truth labels on the test set for the surprisal feedback part of the model i assume that authors do that since they claim that they use the misprediction error as additional input criticisms the paper is really badly written authors should rethink the organization of the paper most of the equations presented in the paper about bptt are not necessary for the main text and could be moved to appendix the justification is not convincing enough experimental results are lacking only results on a single dataset are provided although the authors claim that they got sota on enwiki there are other papers such as the hypernetworks that got better results than the result they achieve this claim is wrong the model requires the ground truth labels for the test set however this assumption really limits the application of this technique to a very limited set of applications more or less rules out most conditional language modeling tasks high level review pros a simple modification of the model that seems to improve the results and it is an interesting modification cons the authors need to use test set labels writing of the paper is bad the authors assume that they have access to the ground truth labels during the test set experimental results are lacking,4.0
793.json,this paper proposes to use previous error signal of the output layer as an additional input to recurrent update function in order to enhance the modelling power of a dynamic system such as rnns this paper makes an erroneous assumption test label information is not given in most of the real world applications except few applications this means that the language modelling task which is the only experiment of this paper may not be the right task to test this approach also comparing against the models that do not use test error signal at inference time is unfair we cannot just say that the test label information is being observed this only holds in online prediction problems the experiment is only conducted on one dataset reporting state of the art result but unfortunately this is not true there are already more than four papers reporting better numbers than the one reported in this task however the author did not cite them i understand that this paper came before the other papers but the manuscript should be updated before the final decision the model size is still missing and without this information it is hard to judge the contribution of the proposed trick,3.0
793.json,this paper proposes to leverage surprisal as top down signal in rnn more specifically author uses the error corresponding to the previous prediction as an extra input at the current timestep in a lstm the general idea of suprising driven feedback is interesting for online prediction task it is a simple enough idea that seems to bring some significant improvements however the paper in its current form has some important flaws overall the paper writing could be improved in particular section and is composed mostly by the equations of the forward and backward propagation of feedback rnn and feedback lstm however author provides no analysis along with those equations it is therefore not clear what insight the author tries to express in those sections in addition feedback rnn is not evaluated in the experimental section so it is not clear why feedback rnn is described the experimental evaluation is limited only one dataset enwik is explored i think it is necessary to try the idea on different datasets to see if feedback lstm sees some consistent improvements also author claims state of art on enwik but hypernetwork already cited in the paper achieves better results bpc table in the hypernetworks paper author only compares to methods that do not use last prediction error as extra signal i would argue that a comparison with dynamic evaluation would be more fair feedback lstm uses prediction error as extra input in the forward prop while dynamic evaluation backprop it through the network and change the weight accordingly also they do not propagate the prediction error in the same way they both leverage extra supervised information through the prediction errors in summary pros interesting idea seems to improve performances cons paper writing weak evaluation only one dataset compare only with approaches that does not use the last timestep error signal,3.0
402.json,this was an interesting paper the algorithm seems clear the problem well recognized and the results are both strong and plausible approaches to hyperparameter optimization based on smbo have struggled to make good use of convergence during training and this paper presents a fresh look at a non smbo alternative at least i thought it did until one of the other reviewers pointed out how much overlap there is with the previously published successive halving algorithm too bad still i am excited to try it i am cautiously optimistic that this simple alternative to smbo may be the first advance to model search for the skeptical practitioner since the case for random search grid search,8.0
402.json,this paper presents hyperband a method for hyperparameter optimization where the model is trained by gradient descent or some other iterative scheme the paper builds on the successive halving random search approach of jamieson and talwalkar and addresses the tradeoff between training fewer models for a longer amount of time or many models for a shorter amount of time effectively the idea is to perform multiple rounds of successive halving starting from the most exploratory setting and then in each round exponentially decreasing the number of experiments but granting them exponentially more resources in contrast to other recent papers on this topic the approach here does not rely on any specific model of the underlying learning curves and therefore makes fewer assumptions about the nature of the model the results seem to show that this approach can be highly effective often providing several factors of speedup over sequential approaches overall i think this paper is a good contribution to the hyperparameter optimization literature it s relatively simple to implement and seems to be quite effective for many problems it seems like a natural extension of the random search methodology to the case of early stopping to me it seems like hyperband would be most useful on problems where a random search itself is expected to perform well and b the computational budget is sufficiently constrained so that squeezing out the absolute best performance is not feasible and near optimal performance is sufficient i would personally like to see the plots in figure run out far enough that the other methods have had time to converge in order to see what this gap between optimal and near optimal really is if there is one i m not sure i agree with the use of randomx as a baseline i can see why it s a useful comparison because it demonstrates the benefit of parallelism over sequential methods but virtually all of these other methods also have parallel extensions i think if randomx is shown then i would also like to see smacx spearmintx tpex etc i also think it would be worth seeing x x and so forth and how hyperband fares against these baselines,7.0
394.json,the authors propose a conceptually simple method for regularisation of recurrent neural networks the idea is related to dropout but instead of zeroing out units they are instead set to their respective values at the preceding time step element wise with a certain probability overall the paper is well written the method is clearly represented up to issues raised by reviewers during the pre review question phase the related work is complete and probably the best currently available on the matter of regularising rnns the experimental section focuses on comparing the method with the current sota on a set of nlp benchmarks and a synthetic problem all of the experiments focus on sequences over discrete values an additional experiment also shows that the sequential jacobian is far higher for long term dependencies than in the dropout case overall the paper bears great potential however i do see some points as raised during the pre review questions i would like to see the results of experiments that feature a complete hyper parameter search i e a proper model selection process as it should be standard in the community i do not see why this was not done especially as the author count seems to indicate that the necessary resources are available i want to repeat at this point that table of the paper shows that validation error is not a reliable estimator for testing error in the respective data set thus overfitting the model selection process is a serious concern here zoneout does not seem to improve that much in the other tasks zoneout is not investigated well mathematically e g an analysis of the of the form of gradients from unit k at time step t to unit k at time step t r would have been interesting especially as these are not necessarily non zero for dropout also the question whether zoneout has a variational interpretation in the spirit of yarin gal s work is an obvious one i can see that it is if we treat zoneout in a resnet framework and dropout on the incremental parts overall little effort is done answering the question why zoneout works well even though the literature bears plenty of starting points for such analysis the data sets used are only symbolic it would have been great if more ground was covered i e continuous data such as from dynamical systems to me it is not obvious whether it will transfer right away an extreme amount of tricks is being published currently for improved rnn training how does zoneout stand out it is a nice idea and simple to implement however the paper under delivers the experiments do not convince me see and there authors do not provide convincing theoretical insights either consequently the paper reduces to a epsilon improvement great text mediocre experimental evaluation little theoretical insight,7.0
681.json,i find the general direction of the work is promising but in my opinion the paper has three main drawback while the motivation and overall idea seem very reasonable the derivation is not convincing mathematically the experiments are limited and the presentation needs significant improvement the writing and wording are in general poorly structured to the point that it is sometimes difficult to follow the proposed ideas the overall organization needs improvement and the connection between sections is not properly established the paper could be significantly improved by simply re writing it i am not fully convinced by the motivation for the proposed non linearity c as described on page the authors argue that waldspurger suggests that higher order nonlinearities might be beneficial for sparsity but unless i am missing something that work seems to suggest that in the general case higher order nonlinearities can be neglected could you please comment on this on the other hand adding a second order term to the descriptor seems an interesting direction as long as stability to small variations is preserved which should be shown experimentally the experimental section is rather limited the paper would be stronger with a thorough numerical evaluation the presented results in my opinion do not show convincingly a clear advantage of the proposed method over a standard implementation of the scattering transform in order to show the merits of the proposed approach it would be really helpful to directly compare running times and compression rates questions can you show empirically that the proposed higher order nonlinearity produces sparser representations than the complex modulus other minor issues the proof of section should be preceded by a clear statement in the form of a proposition hadamart hadamard valid set validation set nonzeros coefficients nonzero coefficients figure is difficult to understand please provide more details figure is supposed to show a comparison to a standard implementation of the scattering network but it does not seem to be such comparison in that figure please explain please verify the references the first reference states mallat,4.0
681.json,overview this work seems very promising but i believe it should be compared with more baselines and more precisely described and explained from a signal processing point of view pros new descriptor fast implementation cons a lack of rigor b too long accordingly to the content c the computational gain of the algorithm is not clear d the work is not compared with its most obvious baseline a scattering transform i will detail each cons a section the author motivates the use of scattering transform because it defines a contraction of the space that relies on geometric features the nonlinearity used in the scattering network is the complex modulus which is piecewise linear a real modulus is piecewise linear a complex modulus has a shape of bell when interpreting c as r could you clarify omega is not introduced could you give a precise reference page paper of this claim higher order nonlinearity refers to x instead of x as it is usually done in the scattering network section the motivation of the non linearity is not clear first this non linearity might potentially increase a lot the variance of your architecture since it depends on higher moments up to i think a fair analysis would be to compute numerically the normalized variance e g divided by the averaged l norm as a sanity check besides one should prove that the energy is decreasing it is not possible to argue that this architecture is similar to a scattering transform which has precise mathematical foundations and those results are required since the setting is different permutation is not a relevant variability the notion of sparsity during the whole paper sometimes refers to the number of value either the l norm mathematically a small value even is still a non value did you compute the graph of the figure on the bird dataset you might use a ratio instead for clarity the wavelet that is defined is not a morlet wavelet,4.0
619.json,the authors consider a simple optimization technique consisting of adding gradient noise with a specific schedule they test their method on a number of recently proposed neural networks for simulating computer logic end to end memory network neural programmer neural random access machines on these networks the question of optimization has so far not been studied as extensively as for more standard networks a study specific to this class of models is therefore welcome results consistently show better optimization properties from adding noise in the training procedure one issue with the paper is that it is not clear whether the proposed optimization strategy permits to learn actually good models or simply better than those that do not use noise a comparison to results obtained in the literature would be desirable for example in the mnist experiments of section the optimization procedure reaches in the most favorable scenario an average accuracy level of approximately which is still far from having actually learned an interesting problem representation a linear model would probably reach similar accuracy i understand that the architecture is specially designed to be difficult to optimize layers of hus but it would have been more interesting to consider a scenario where depth is actually beneficial for solving the problem,4.0
619.json,this paper presents a simple method of adding gradient noise to improve the training of deep neural networks this paper first appeared on arxiv over a year ago and while there have been many innovations in the area of improving the training of deep neural networks in tha time batch normalization for rnns layer normalization normalization propagation etc this paper does not mention or compare to these methods in particular the authors state however recent work on applying batch normalization to recurrent networks laurent et al has not shown promise in improving generalization ability for recur rent architectures which are the focus of this work this statement is simply incorrect and was thoroughly explored in e g cooijmans et al that establish that batch normalization is effective for rnns the proposed method itself is extremely simple and is similar to numerous training strategies that have previously been advocated in the literature as a result the contribution would be incremental at best and could be significant with sufficiently strong empirical results supporting this particular variant however as discussed above there are now multiple training strategies and algorithms in the literature that are not empirically compared unfortunately this paper is now fairly seriously out of date it would not be appropriate to publish this at iclr,4.0
619.json,the authors propose to add noise to the gradients computed while optimizing deep neural networks with stochastic gradient based methods they show results multiple data sets which indicate that the method can counteract bad parameter initialization and that it can be especially beneficial for training more complicated architectures the method is tested on a multitude of different tasks and architectures the results would be more convincing if they would be accompanied by confidence intervals but i understand that some of the experiments must have taken very long to run i like that the results include both situations in which the gradient noise helps a lot and situations in which it doesn t seem to add much to the other optimization or initialization tools employed the quantity of the experiments and the variety of the models provide quite convincing evidence that the effect of the gradient noise generalizes to many settings the results were not always that convincing in section the method only helped significantly when a sub optimal training scheme was used for example the results on mnist are not very good compared to the state of the art since the method is so simple i was hoping to see more theoretical arguments for its usefulness that said the experimental investigations into the importance of the annealing procedure the comparison with the effect of gradient stochasticity and the comparison with weight noise provide some additional insight the paper is well written and cites relevant prior work the proposed method is described clearly and concisely which is to be expected given its simplicity the proposed idea is not very original as the authors acknowledge very similar algorithms have been used for training and it is pretty much identical to simulating langevin dynamics but with the goal of finding a single optimum in mind rather than approximating an expected value the work is the evaluation of an old tool in a new era where models have become bigger and more complex despite the lack of novelty of the method i do think that the results are valuable the method is so easy to implement and seems to be so useful for complicated model which are hard to initialize that it is important for others in the field to know about it i suspect many people will at least try the method the variety of the architectures and tasks for which the method was useful suggests that many people may also add it to their repertoire of optimization tricks pros the idea is easy to implement the method is evaluated on a variety of tasks and for very different models some interesting experiments which compare the method with similar approaches and investigate the importance of the annealing scheme the paper is well written cons the idea is not very original there is no clear theoretical motivation of analysis not all the results are convincing,7.0
530.json,understanding relations between objects is an important task in domains like vision language and robotics however models trained on real life datasets can often exploit simple object properties not relation based to identify relations eg animals of bigger size are typically predators and small size animals are preys such models can predict relations without necessarily understanding them given the difficulty of the task a controlled setting is required to investigate if neural networks can be designed to actually understand pairwise object relations the current paper takes a significant step in answering this question through a controlled dataset also multiple experiments are presented to validate the relation learning ability of proposed relation networks rn the dataset proposed in the paper ensures that relation classification models can succeed only by learning the relations between objects and not by exploiting predator prey like object properties the paper presents very thorough experiments to validate the claim that rns truly learn the relation between objects in particular the ability of the rn to force a simple linear layer to disentangle scene description from vae latent space and permuted description is very interesting this clearly demonstrates that the rn learns object relations the one shot experiments again demonstrate this ability in a convincing manner this requires the model to understand relations in each run represent them through an abstract label and assign the label to future samples from the relationship graph some suggestions is g psi permutation invariant as well since it works on pairs of objects how did you ensure that the mlp is invariant to the order of the objects in the pair the rns need to operate over pairs of objects in order to identify pairwise interactions however in practical applications there are more complicated group interactions eg ternary interaction person riding a bike wears helmet would this require g of rn to not just operate on pairs but on every possible subset of objects in the scene more generally is such a pairwise edge based approach scalable to larger number of objects the authors mention that a deep network with a sufficiently large number of parameters and a large enough training set should be capable of matching the performance of a rn this is an interesting point and could be true in practice have the authors investigated this effect by trying to identify the minimum model capacity and or training examples required by a mlp to match the performance of rn for the provided setup this would help in quantifying the significance of rn for practical applications with limited examples in other words the task in sec could benefit from another plot the performance of mlp and rn at different amounts of training samples while the simulation setup in the current paper is a great first step towards analyzing the relation learning ability of rns it is still not clear if this would transfer to real life datasets i strongly encourage the authors to experiment on real life datasets like coco visual genome or hico as stated in the pre review stage minor some terminologies in the paper such as objects and scene descriptions used to refer to abstract entities can be misleading for readers from the object detection domain in computer vision this could be clarified early on in the introduction minor some results like fig which shows the ability of rn to generalize to unseen categories are quite interesting and could be moved to the main draft for completeness the paper proposes a network which is capable of understanding relationships between objects in a scene this ability of the rn is thoroughly investigated through a series of experiments on a controlled dataset while the model is currently evaluated only on a simulated dataset the results are quite promising and could translate to real life datasets as well,7.0
530.json,this paper proposes relation networks in order to model the pairwise interactions between objects in a visual scene the model is very straight forward first an mlp with shared weights is applied to each pair of objects finally a prediction is created by an mlp which operates by summing non linear functions of these pairs of objects experimental evaluation is done in a synthetic dataset that is generated to fit the architecture hand crafted in this paper the title of the paper claims much more than the paper delivers discovering objects and their relations is a very important task however this paper does not discover objects or their relations instead each objects is represented with hand coded ground truth attributes and only a small set of trivial relationships are discovered e g relative position discovering objects and their relationships has been tackled for several decades in computer vision cv the paper does not cite or compare to any technique in this body of literature this is typically refer to as contextual models can the proposed architecture help object detection and or scene classification would it work in the presence of noise e g missing detections non accurate detection estimates complex texture would it work when the attributes of objects are estimated from real images i will be more convinced if experiments where done in real scenes in the case of indoor scenes datasets such as nyuv sun rgb d scenenn chen et al cvpr text to image correference could be used in outdoor scenes kitti and the relationships between cars pedestrians and cyclist could also serve as benchmark without showing real scenes this paper tackles a too toy problem with a very simple model which does not go much further than current context models which model pairwise relationships between objects with mrfs with deep nets etc,3.0
530.json,this paper proposes a relation network rn to model relations between input entities such as objects the relation network is built in two stages first a lower level structure analyzes a pair of input entities all pairs of input entities are fed to this structure next the output of this lower level structure is aggregated across all input pairs via a simple sum this is used as the input to a higher level structure in the basic version these two structures are each multi layer perceptrons mlps overall this is an interesting approach to understanding relations among entities the core idea is clear and well motivated pooling techniques that induce invariance can be used to learn relations the idea builds on pooling structures e g spatial temporal average max pooling to focus on pairwise relations the current pairwise approach could potentially be extended to higher order interactions modulo scaling issues experiments on scene descriptions and images verify the efficacy of relation networks the mlp baselines used are incapable of modeling the structured dependencies present in these tasks it would be interesting to know if pooling operators e g across object max pooling in an mlp or data augmentation via permutation would be effective for training mlps at these tasks regardless the model proposed here is novel and effective at handling relations and shows promise for higher level reasoning tasks,7.0
475.json,this paper presents a way of training deep generative models with discrete hidden variables using the reparameterization trick it then applies it to a particular dbn like architecture and shows that this architecture achieves state of the art density modeling performance on mnist and similar datasets the paper is well written and the exposition is both thorough and precise there are several appendices which justify various design decisions in detail i wish more papers in our field would take this degree of care with the exposition the log likelihood results are quite strong especially given that most of the competitive algorithms are based on continuous latent variables probably the main thing missing from the experiments is some way to separate out the contributions of the architecture and the inference algorithm e g what if a comparable architecture is trained with vimco or if the algorithm is applied to a previously published discrete architecture i m a bit concerned about the variance of the gradients in the general formulation of the algorithm see my comment variance of the derivatives of f below i think the response is convincing but the problem as well as engineering principles for the smoothing distribution are probably worth pointing out in the paper itself since the problem seems likely to occur unless the user is aware of it e g my proposal of widely separated normals would be a natural distribution to consider until one actually works through the gradients something not commonly done in the age of autodiff frameworks another concern is how many sequential operations are needed for inference in the rbm model note is this actually an rbm or a general boltzmann machine the q distribution takes the form of an autoregressive model where the variables are processed one at a time section mentions the possibility of grouping together variables in the q distribution and this is elaborated in detail in appendix a but the solution requires decomposing the joint into a product of conditionals and applying the cdfs sequentially so either way it seems like we re stuck handling all the variables sequentially which might get expensive minor the second paragraph of section needs a reference to appendix a,9.0
475.json,this is an interesting paper on how to handle reparameterization in vaes when you have discrete variables the idea is to introduce a smoothing transformation that is shared between the generative model and the recognition model leading to cancellations a second contribution is to introduce an rbm as the prior model p z and to use autoregressive connections in generative and recognition models the whole package becomes a bit entangled and complex and it is hard to figure out what causes the claimed good performance experiments that study these contributions separately would have been nice the framework does become a little complex but this should not be a problem if nice software is delivered that can be used in a plug and play mode overall the paper is very rich with ideas so i think it would be a great contribution to the conference,8.0
567.json,the authors develop a way learn subspaces of multiple views such that data point neighborhoods are similar in all of the views this similarity is measured between distributions of neighbors in pairs of views the motivation is that this is a natural criterion for information retrieval i like the idea of preserving neighborhood relationships across views for retrieval tasks and it is nice that the learned spaces can have different dimensionalities for different views however the empirical validation seems preliminary the paper has been revised from the authors iclr submission and the revisions are welcome but i think the paper still needs more work in order to be publishable in its current form it could be a good match for the workshop track the experiments are all on very small data sets e g examples in each of train test on the mnist task and not on real tasks the authors point out that they are not focusing on efficiency and presumably computation requirements keep them from considering larger data sets however it is not clear that there is any conclusion that can be drawn that would apply to more realistic data sets considering the wealth of work that been done on multi view subspace learning with application to real tasks it is very hard to see this as a contribution without showing that it is applicable in such realistic settings on a more minor point the authors claim that no other information retrieval based approaches exist and i think this is a bit overstated for example the contrastive loss of hermann blunsom multilingual models for compositional distributed semantics acl is related to information retrieval and would be a natural one to compare against the presentation is a bit sloppy with a number of vague points and confusing wordings examples the term dependency gets used in the paper a lot in a rather colloquial way this gets confusing at times since it is used in a technical context but not using its technical definition an information retrieval task of the analyst vague and not quite grammatical the probability that an analyst who inspected item i will next pick j for inspection is not well defined in the discussion of kl divergence i do not quite follow the reasoning about its relationship to the cost of misses etc it would help to make this more precise or perhaps drop it kl divergence is pretty well motivated here anyway does c penalty get added to c or is it used instead i was a bit confused here it is stated that cca iteratively finds component pairs note that while cca can be defined as an iterative operation it need not and typically is not solved that way but rather all projections are found at once how is pca done between xi and xi we apply nonlinear dimensionality algorithm what is this algorithm i do not quite follow what the task is in the case of the image patches and stock prices other minor comments typos etc the figure fonts are too small difference measures different measures since hence any two not grammatical between feature based views and views external neighborhoods,4.0
588.json,this paper applies convnet based object detection techniques to detection of weather events from d climate data additionally exploring the effect of using an unsupervised autoencoder style objective term pros the application of object detection techniques to extreme weather event detection problem is unique to my knowledge the paper is well written and describes the method well including a survey of the related work the best model makes use of d convolutions and unsupervised learning both of which are relatively unexplored in the detection literature both of these aspects are validated and shown to produce at least small performance improvements over a d and or purely supervised approach cons the benefits of the d convolutional architecture and unsupervised learning end up being a little underwhelming with map for the d semi sup result vs map for the d sup result it s a bit strange that d sup and d semi sup are each worse than the d sup base result i d expect each aspect to give a slight improvement over the base result given that using both together gives the best results perhaps there was not a thorough enough hyperparameter search for these cases the paper does acknowledge this and provide potential explanations in sec however as other reviewers pointed out the use of the iou criterion for true positives is very loose relative to the standard criterion on the other hand if the results visualized in figure are typical a overlap criterion could be reasonable for this domain as the detector does seem to localize events well enough that the system could be used to expedite human review of the climate images for extreme events still it would be useful to also report results at higher overlap thresholds minor eq should probably be the squared l norm i e the sum of squares rather than the l norm itself minor table shouldn t the semi supervised models have more parameters than the corresponding supervised ones due to the decoder layers overall this paper is well written and applies some interesting underutilized techniques to a relatively unique domain the results are not striking but the model is ablated appropriately and shown to be beneficial for a final version it would be nice to see results at higher overlap thresholds,6.0
588.json,edit the thoughtful author responses addressed my major concerns the github links for data and code will be really helpful for reproducing results i have not looked carefully but this is great the revision addressed many issues including the additional results as such i am upgrading my rating from a to a and recommend acceptance of the paper the paper proposes to apply deep nets to perform detection and localization of extreme weather events in simulated weather data the problem is related to object detection in computer vision in that the input is a d image multichannel spatial weather data or d video temporal version of the data and the output is a bounding box spatial temporal localization of a weather event and class label weather event type it differs from standard object detection in that the input has multiple heterogenous channels and labeled data is scarce a simple but quite reasonable deep net is proposed for the task based on similar approaches in computer vision while proposal based systems are most popular in vision currently in particular faster rcnn the proposed approach is simple and a fine starting point there is little innovation on the part of the detection system but as noted it is a valid application of ideas from computer vision to the task at hand the authors propose both a supervised approach only ground truth bounding box location label is used and a semi supervised approach that additionally incorporates the reconstruction loss as a regularization in all cases the losses are fairly standard and again reasonable the only confusing bit is that the semi supervised loss actually has all the labels used for the supervised loss and additionally incorporates the reconstruction loss hence the semi supervised loss is actually stronger which makes the terminology a bit confusing the paper is easy to follow but notation is sloppy for example above equation it states that the loss is a weighted combination of reconstruction error and bounding box regression loss actually it s a combination of the supervised and unsupervised loss lsup and lunsup and lrec is not defined although i assume lrec lunsup the paper is fairly non technical but nevertheless these minor issues should be fixed e g see also reference to figure and the biggest concern w the paper though is experimental results only a single figure and table of results are shown figure and table the metrics are not defined what is mean average recall only d versus d version of the model are shown and supervised and semi supervised moreover numbers seem a bit all over the place without consistent patterns e g why is d supervised better than the seemingly much strong d semi supervised one of the things that is unclear is how many events are actually in the training testing data and more importantly how good are these results in absolute terms regardless the experiments are fairly sparse and ablation studies and more discussion lacking it is also unclear if future researchers will be able to reproduce the experimental setting a commitment to open source the data or a way to reproduce the experiments would be critical for future authors minor nit the authors use both a classification loss and an objectness loss i ve never seen both used together like this normally objectness is used in two stage object proposal systems where in the first stage class agnostic proposals are given and in the second stage these are cropped and a class specific classifier is applied i strongly suspect removing the objectness loss would not impact results since the classification loss should provide strictly stronger supervisory signal regardless this is a fairly non standard choice and should be justified experimentally overall this is a borderline paper i do believe that it is valuable to apply computer vision techniques to a domain that i ve see little work on in our community that being said i have no expertise on this type of data it s possible this deep learning techniques are now routinely used in the climate science literature i suspect not though overall there is little novelty on the algorithmic side in this paper the equations in section are commonly used in the cv literature the use of reconstruction loss to improve results in the data sparse setting is interesting but the experimental results are inconclusive the experimental validation is generally insufficient reproducibility for future research is difficult unless the data is open sourced overall i think this paper is a good start and with improved experiments and more careful writing i think could eventually make for a decent paper,6.0
422.json,this paper presents a variational inference based method for learning nonlinear dynamical systems unlike the deep kalman filter the proposed method learns a state space model which forces the latent state to maintain all of the information relevant to predictions rather than leaving it implicit in the observations experiments show the proposed method is better able to learn meaningful representations of sequence data the proposed dvbf is well motivated and for the most part the presentation is clear the experiments show interesting results on illustrative toy examples i think the contribution is interesting and potentially useful so i d recommend acceptance the svae method of johnson et al deserves more discussion than the two sentences devoted to it since the method seems pretty closely related like the dvbf the svae imposes a markovianity assumption and it is able to handle similar kinds of problems from what i understand the most important algorithmic difference is that the svae q network predicts potentials whereas the dvbf q network predicts innovations what are the tradeoffs between the two section says they do the latter in the interest of solving control related tasks but i m not clear why this follows is there a reason svaes don t meet all the desiderata mentioned at the end of the introduction since the svae code is publicly available one could probably compare against it in the experiments i m a bit confused about the role of uncertainty about v in principle one could estimate the transition parameters by maximum likelihood i e fitting a point estimate of v but this isn t what s done instead v is integrated out as part of the marginal likelihood which i interpret as giving the flexibility to model different dynamics for different sequences but if this is the case then shouldn t the q distribution for v depend on the data rather than being data independent as in eqn,7.0
422.json,the paper proposes to use the very standard svgb in a sequential setting like several previous works did however they proposes to have a clear state space constraints similar to linear gaussian models markovian latent space and conditional independence of observed variables given the latent variables however the model is in this case non linear these assumptions are well motivated by the goal of having meaningful latent variables the experiments are interesting but i am still not completely convinced by the regression results in figure namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function also why is not the model from watter et al not included after rereading i am not sure i understand why the coordinates should be combined in a x checkerboard as said in figure a then paper is well motivated and the resulting model is novel enough the bouncing ball experiment is not quite convincing especially in prediction as the problem is fully determined by its initial velocity and position,6.0
658.json,the paper aim is as argued in the paper and the responses to other reviewers comments that spn and mpn can be interpreted as encoders and decoders of rl well this is an interesting perspective and could be potentially worth a paper however the current draft is far from being convincing in that respect and i am talking about the updated improved version as of now the paper does not require minor revisions to make this point apparent but a significant and major rewrite which seems beyond what the authors have done so far the experiments are as also pointed out by other reviewers rather unstructured and difficult to see much of an insight i should probably also list as the other other reviewers flaws and issues with the experiments but given the detailed comments by the other reviewers there seems to be little additional value in doing so so in essence the paper simply does not deliver at this point on its promise as far as i am concerned and in that sense i suggest a very clear reject for this conference as for the dataset employed mnist should be considered a toy dataset for pretty much all purposes these days and in that sense the dataset choice is not helping me and many other people that you might want to convince to safe this paper,3.0
571.json,the paper proposes two approaches to boosting generative models both based on likelihood ratio estimates the approaches are evaluated on synthetic data as well as on mnist dataset for the tasks of generating samples and semi supervised learning while the idea of boosting generative models and the proposed methods are interesting the reviewer finds the experiments unconvincing for the following reasons the bagging baseline in section seems to be just refitting a model to the same dataset raising the probability to power alpha and renormalizing this makes it more peaked but it not clear why this is a good baseline please let me know if i misunderstood the procedure the sample generation experiment in section uses a very slowly converging markov chain as can be seen in the similarity of plots c and f d and g e and h it seems unlikely therefore that the resulting samples are from the stationary distribution a qualitative evaluation using ais seems to be necessary here in the same section the choices for alphas seem quite arbitrary what happens when a more obvious choice of alphai for all i is made it seems hard to infer anything from the semisupervised classification results reported the baseline rbm seems to perform as well as the boosted models the work is mostly clearly written and as far as the reviewer knows original,5.0
434.json,the paper shows that bn which does not work out of the box for rnns can be used with lstm when the operator is applied to the hidden to hidden and the input to hidden contribution separately experiments are conducted to show that it leads to improved generalisation error and faster convergence the paper is well written and the idea well presented i the data sets and consequently the statistical assumptions used are limited e g no continuous data only autoregressive generative modelling ii the hyper parameters are nearly constant over the experiments it is ruled out that they have not been picked in favor of one of the methods e g just judging from the text a different learning rate could have lead to equally fast convergence for vanilla lstm concluding the experiments are flawed and do not sufficiently support the claim an exhaustive search of the hyper parameter space could rule that out,7.0
526.json,this paper develops a theoretical guarantee for the convergence of the training error the result is quite general that covers the training of a wide range of neural network models the key idea of the paper is approximate the training loss by its linear approximation since its linearity in the variables thus convex the authors plug in results that has been developed in the literature of online learning this paper has good novelty in using the taylor approximation thus greatly simplifying the analysis of the behaviour of the model however there are two problems about the main result of this paper theorem it is not clear if the taylor optimum would converge or not as noticed by the authors the upper bound is path dependent appendix tries to claim that this taylor optimum indeed converges but the proof is buggy in the proof of lemma it is proved that the difference between two sequential taylor optimum is approaching note that this is actually weaker than being cauchy sequence and insufficient to guarantee convergence the lefthand side of equation i will denote it by l in this review is not equivalent to training error an upper bound on this average error is not sufficient to guarantee the convergence of the training error neither take the gradient descent for example thus each minibatch x n is the whole training set the convergence of the training error should be lim n infty l f w n x n y n the convergence of l is necessary but not sufficient to imply the convergence of the training error another concern about theorem but it is minor compared to the two problems mentioned above is that to achieve the o sqrt n rate the algorithm has to pick a particular learning rate larger or smaller learning rate in the order of n will lead to significantly worse regret but in the experiments of the paper the learning rates are not picked according to the theorem overall this paper has a good motivation and good novelty it could be further developed into a good paper but due to the two problems and a buggy proof mentioned above i think it is not ready for publish yet,3.0
526.json,this paper adopts taylor approximations of neural nets for separating convex and non convex components of the optimization this enables them to bound the training error by the taylor optimum and regret theorem this is a nice theoretical result applicable to popular deep nets the empirical studies back up the theoretical claim,7.0
463.json,this paper looks at how to train if there are significant label noise present this is a good paper where two main methods are proposed the first one is a latent variable model and training would require the em algorithm alternating between estimating the true label and maximizing the parameters given a true label the second directly integrates out the true label and simply optimizes the p z x pros the paper examines a training scenario which is a real concern for big dataset which are not carefully annotated cons the results on mnist is all synthetic and it hard to tell if this would translate to a win on real datasets comments equation should be expensive what happens if you are training on imagenet with classes it would be nice to see how well you can recover the corrupting distribution parameter using either the em or the integration method overall this is an ok paper however the ideas are not novel as previous cited papers have tried to handle noise in the labels i think the authors can make the paper better by either demonstrating state of the art results on a dataset known to have label noise or demonstrate that a method can reliably estimate the true label corrupting probabilities,5.0
463.json,the paper addressed the erroneous label problem for supervised training the problem is well formulated and the presented solution is novel the experimental justification is limited the effectiveness of the proposed method is hard to gauge especially how to scale the proposed method to large number of classification targets and whether it is still effective for example it would be interesting to see whether the proposed method is better than training with only less but high quality data from figure it seems with more data the proposed method tends to behave very well when the noise fraction is below a threshold and dramatically degrades once passing that threshold analysis and justification of this behavior whether it is just by chance or an expected one of the method would be very useful,7.0
674.json,the paper proposes to provide a theoretical explanation for why deep convolutional neural networks are invertible at least when going back from certain intermediate layers to the image itself it does so by considering the invertibility of a single layer assuming the convolutional filters essentially correspond to incoherent measurements satisfying rip in my opinion while this is an interesting direction of research the paper is not ready for publication i feel the treatment does not go sufficiently towards explaining the phenomenon in deep neural networks even after reading the response from the authors i feel the results are only a minor variation of the standard results from compressive sensing for sparse reconstruction with incoherent measurements a deep neural network is fundamentally different from a single layer it is the deep part that makes the forward task work as the authors note there is significant deterioration when iht is applied recursively therefore at best the theory explains the partial invertibility of a single layer that a single layer is approximately invertible is not surprising that a cascade of layers is for any theoretical analysis of this phenomenon to be useful i believe it must go beyond analyzing a single compressive measurement type layer and try to explain how much of the same theory holds for a cascade i say this because it entirely possible that the sparse recovery theory breaks down beyond a single layer and invertibility ends up being a property caused by correlations between the weights of different layers in other words there is no way to tell from the current results for individual layers whether they are in fact a step towards explaining the invertibility of whole networks,4.0
674.json,the authors propose a theoretical framework to analyze the recoverability of sparse activations in intermediate layers of deep networks using theoretical tools from compressed sensing they relate the computations that are performed by a cnn and a particular recovery algorithm iterative hard thresholding iht they present proofs of necessary conditions for recoverability to hold and also show detailed empirical evidence of how they hold in practice this is a well written paper that presents a new angle on why the current cnn architectures work so well the authors give a brief but sufficient review of the fundamentals of compressed sensing present their main result relating feed forward networks and iht a surprising result and progress naturally to a detailed experimental section the introductory analysis at the beginning of section in particular delivers the gist of why the method should work with very approachable and simple math which is not common in theoretical papers the increasing complexity of the experiments done in small steps shows a nice progression from artificial distributions to a realistic experiment a few aspects should be improved first of all although the treatment of relu non linearities is sufficient it is assumed with little discussion that max pooling non linearities should not present a problem as well a discussion of how this is inverted e g with pooling switches is needed the relationship between feed forward nets and algorithm assumes tied weights it might be worthwhile to mention that the result is stronger for the case of rnns where this is the case by design although it might be obvious it might help some readers to briefly note that the reconstruction algorithm is meant to be applied to each layer sequentially basing the activations of each layer on the one above it in back propagation order finally the filter coherence measure must be defined either mathematically or with a proper reference,7.0
674.json,summary of the paper the paper studies the invertiblity of convolutional neural network in the random model a reconstruction algorithm similar to iht is proposed for layer wise inversion of the network clarity the paper is confusing wrt to standard notations in deep learning comments the paper makes two simplifications in the analysis of a cnn that makes it map to a model based compressive sensing framework the non linearity relu is dropped this is a big simplification for random gaussian weights for instance we know by jl that we can preserve l distance when relu is applied the metric changes see for instance the kernel for n in,5.0
731.json,the method in this paper introduces a binary encoding level in the pv dbow and pv dm document embedding methods from le mikolov the binary encoding consists in a sigmoid with trained parameters that is inserted after the standard training stage of the embedding for a document to encode the binary vector is obtained by forcing the sigmoid to output a binary output for each of the embedding vector components the binary vector can then be used for compact storage and fast comparison of documents pros the binary representation outperforms the semantic hashing method from salakhutdinov hinton the experimental approach sound they compare on the same experimental setup as salakhutdinov hinton but since in the meantime document representations improved le mikolov they also combine this new representation with an rbm to show the benefit of their binary pv dbow pv dm cons the insertion of the sigmoid to produce binary codes from lin al in the training process is incremental the explanation is too abstract and difficult to follow for a non expert see details below a comparison with efficient indexing methods used in image retrieval is missing for large scale indexing of embedding vectors derivations of the inverted multi index are probably more interesting than binary codes see eg babenko lempitsky efficient indexing of billion scale datasets of deep descriptors cvpr detailed comments section the motivation for producing binary codes is not given also the experimental section could give some timings and mem usage numbers to show the benefit of binary embeddings figure there is enough space to include more information on the representation of the model model parameters training objective characteristic sizes dropout in particular in fig it is not clear why embedding lookup and linear projection cannot be merged in a single smaller lookup table presumably because there is an intermediate training objective that prevents this p this way the length of binary codes is not tied to the dimensionality of word embeddings why not section this is the experimental setup of salakhutdinov hinton specify this and whether there is any difference between the setups similarity of the inferred codes say here that codes are compared using hamming distances binary codes perform very well despite their far lower capacity do you mean smaller size than real vectors fig these plots could be dropped if space is needed section one could argue that transferring from wikipedia to anything else cannot be called transferring since wikipedia purpose is to include all topics and lexical domains section specify how the d real vectors are compared l distance inner product fig specify what the raw performance of the large embedding vectors is without pre filtering with binary codes or equivalently the perf of code size hamming dis etc,6.0
731.json,this paper presents a method to represent text documents and paragraphs as short binary codes to allow fast similarity search and retrieval by using hashing techniques the real valued paragraph vectors by le mikolov is extended by adding a stochastic binary layer on top of the neural network architecture two methods for binarizing the final activations are compared simply adding noise to sigmoid activations to encourage discritization binarizing the activations in the forward pass and keeping them real valued in the backward pass straight through estimation the paper presents encouraging results by using straight through estimation on newsgroup and rcv text datasets by using and bit binary codes on the plus side the application presented in the paper is interesting and important the exposition of the paper is clean and clear however the novelty of the approach is limited from a machine learning standpoint the literature on binary hashing beyond semantic hashing and krizhevsky binary autoencoders in is not explained an important baseline is missing where real valued paragraph vectors are learned first and then converted to binary codes using off the shelf hashing methods e g random projection lsh by charikar bre by kulis darrell itq by gong lazebnik mlh by norouzi fleet etc given the lack of novelty and the missing baseline i do not recommend this paper in its current for publication in the iclr conference proceeding moving forward this paper may be more suitable for nlp conferences as it is more on the applied side more comments i believe from an practical perspective it may be easier to first learn real valued paragraph vectors and then quantize them for indexing that said an end to end approach as proposed in this paper may perform better i would like to see an empirical comparison between the proposed end to end approach and a simpler two stage quantization method suggested here see estimating or propagating gradients through stochastic neurons by bengio et al discussing straight through estimation and some other alternatives the paper argues that the length of binary codes cannot be longer than bits because longer codes are not suitable for document hashing this is not quite right given multi probe hashing mechanisms for example see mult index hashing by norouzi et al see hashing for similarity search a survey by wang et al for a survey of related work on binary hashing and quantization you seem to ignore the extensive work done on binary hashing,5.0
731.json,this work proposes a model that can learn short binary codes via paragraph vectors to allow fast retrieval of documents the experiments show that this is superior to semantic hashing the approach is simple and not very technically interesting for a code size of the loss compared to a continuous paragraph vector seems moderate the paper asks the reader to refer to the salakhutdinov and hinton paper for the baseline numbers but i think they should be placed in the paper for easy reference for simplicity the paper could show the precision at and recall for the proposed model and semantic hashing it also seems that the semantic hashing paper shows results on rcv and not rcv rcv is twice the size of rcv and is english only so it seems that these results are not comparable it would be interesting to see how many binary bits are required to match the performance of the continuous representation a comparison to the continuous pv dbow trained with bigrams would also make it a more fair comparison figure in the paper shows a loss from using the real binary pv dbow it seems that if a user needed high quality ranking after the retrieval stage and they could afford the extra space and computation then it would be better for them to use a standard pv dbow to obtain the continuous representation at that stage minor comments first line after the introduction is sheer is the sheer th line from the bottom of p words embeddings word embeddings in table what does code size refer to for pv dbow is this the number of elements in the continuous vector th line from the bottom of p w we th line after section covers wide covers a wide,6.0
361.json,the paper addresses the problem of predicting learning curves the key difference from prior work is that the authors learn a neural network that generalizes across hyperparameter settings and the authors use a bayesian neural network with sghmc the authors demonstrate that the proposed approach is effective on extrapolating partially observed curves as well as predicting unobserved learning curves on various architectures fc cnn lr and vae this seems very promising for bayesian optimization i would love to see an experiment that evaluates the relative advantage of this proposed method have you thought about ways to handle learning rate decays perhaps you could run the algorithm on a random subset of data and extrapolate from that i was thinking of other evaluation measures in addition to mse and ll in practice we care about the most promising run would it make sense to evaluate how accurately each method identified the best run minor comments fonts are too small and almost illegible on my hard copy please increase the font size for legends and axes in the figures fig not all figures seem to have six lines are the lines overlapping in some cases,7.0
361.json,this paper proposes a new bayesian neural network architecture for predicting the values of learning curves during the training of machine learning models this is an exploratory paper in that the ultimate goal is to use this method in a bayesian optimization system but for now the experiments are limited to assessing the quality of the predictions this builds on previous work in domhan however in this work the model incorporates information from all tested hyperparameter settings rather than just extrapolating from a single learning curve this paper also explores two mcmc methods for inference sgld and sghmc but i couldn t tell if either of these were tested in domhan as well the performance seems overall positive particularly in the initial phase of each curve where there is very little information in this case as expected sharing knowledge across curves helps one regime which did not seem to be tested but might be very informative is when some curves in the training set have been mostly or fully observed this might be a case where sharing information really helps something that concerns me about this approach is the timing the authors stated that to train the network takes about seconds in the worst case with epochs this results in a little over hours spent training the bayesian network this is a non trivial fraction of the several hours it takes to train the model being tuned the bayesian network makes many separate predictions as shown in figure it would be interesting to see how accurate some of these individual pieces are for example did you bound the asymptotic value of the learning curve since you mostly predicted accuracy if not did the value tend to lie in below are some minor questions comments figure axes should read validation accuracy figure can you describe lastseenvalue although it seems self explanatory it s good to be explicit in the bottom left figure and why isn t it used anywhere else as a baseline figure and table are you predicting just the final value of the curves or every value along each curve conditioned on the previous values why do you only use basis functions does this sufficiently capture all of the flexibility of these learning curves would more basis functions help or hurt,7.0
418.json,this work introduces a novel method for training gans by displacing simultaneous sgd and unrolling the inner optimization in the minmax game as a computational graph the paper is very clearly written and explains the justification very well the problem being attacked is very significant and important the approach is novel however similar ideas have been tried to solve problems unrelated to gans the first quantitative experiment is section where the authors attempt to find the best z which can generate training examples this is done by using l bfgs on g z x the claim is that if we are able to find such a z then the generator can generate this particular training example it demonstrated that step gans are not able to generate many training examples while unrolled gans do however i find this experiment unreasonable being able to find a certain z which generates a certain sample does not guarantee that this particular mode is high probability in fact an identity function can potentially beat all the gan models in the proposed metric and due to cantor proof of equivalence between all powers of real spaces this applies to smaller dimension of z as well more realistically it should be possible to generate any image from a generator by finding a very specific z that a certain z exists which can generate a sample does not prove that the generator is not missing modes it just proves that the generator is similar enough to an identity function to be able to generate any possible image this metric is thus measuring something potentially tangential to diversity or mode dropping another problem with this metric is that that showing that the optimization is not able to find a z for a specific training examples does not prove that such a z does not exist only that it harder to find so this comparison might just be showing that unrolled gans have a smoother function than step gans and thus easier to optimize for z the second quantitative experiment considers mean pairwise distance between generated samples and between data samples the first number is likely to be small in the case of a mode dropping gan the authors argue that the two numbers being closer to each other is an indication of the generated samples being as diverse as the data once again this metric is not convincing the distances are being measured in pixel space a gan model could be generating garbage and yet still perform very well in this metric there are no other quantitative results in the paper even though the method is optimizing diversity for a sanity check scores for quality such as inception scores or ssl performance would have been useful another metric that the authors can consider is training gan using this approach on the tri mnist dataset concatenation of mnist digits which results in easily identifiable modes then demonstrate that the gan is able to generate all the modes with equal probability this is not a perfect metric either but arguably much better than the metrics in this paper this metric is used in this iclr submission,7.0
418.json,the paper presents an approach for tackling the instability problem that is present in generative adversarial networks the general idea is to allow the generator to peek ahead at how the discriminator will evolve its decision boundary over time with the premise that this information should prevent the generator from collapsing to produce only samples from a single mode of the data distribution this is a very well written paper that clearly motivates its attack on an important open issue the experiments are well carried out and strongly support the presented idea the pursued approach is substantially more elegant than current existing hacks that are commonly used to make gans work in practice i however have three main issues that let me partly doubt the success of the method if these can be resolved this paper is a clear candidate for acceptance i am not entirely convinced that the same effect cannot be obtained by the following procedure simply train the discriminator for an extended number of k steps when updating the generator say a number equivalent to the unrolling steps used in the current experiments then after the generator was updated undo the k updates to the discriminator and do new update step instead i only briefly glanced at your response to reviewer which seems to imply you now tried something similar to this setup by stopping gradient flow at an appropriate point although i think this is not exactly equivalent i tried to reproduce the simple mnist example but using a fully connected network instead of an rnn generator without much success even when unrolling the discriminator for steps the generator still engages in mode seeking behavior or does not train at all this could either be because of a bug in my implementation or because of some peculiarities of the rnn generator or because i did not use batch normalization anywhere if it is one of the latter two this would entail a dependence of the proposed approach on specific forms of the discriminator and generator and should be discussed my code can be found here,7.0
789.json,this paper attempts to learn a markov chain to estimate a probability distribution over latent variables z such that p x z can be eased to generate samples from a data distribution the paper in its current form is not acceptable due to the following reasons no quantitative evaluation the authors do include samples from the generative model which however are insufficient to judge performance of the model see comment the description of the model is very unclear i had to indulge in a lot of charity to interpret what the authors must be doing what does q z mean does it mean the true posterior p z x what is the generative model here typically it p z p x z vaes use a variational approximation q z x to the true posterior p z x are you trying to say that your model can sample from the true posterior p z x comments using additive noise in the input does not seem like a reasonable idea any justification of why this is being done approaches which learn transition operators are usually very amenable to data augmentation based semi supervised learning i encourage the authors to improve their paper by testing their model on semi supervised learning benchmarks,3.0
623.json,this paper investigates the hessian of small deep networks near the end of training the main result is that many eigenvalues are approximately zero such that the hessian is highly singular which means that a wide amount of theory does not apply the overall point that deep learning algorithms are singular and that this undercuts many theoretical results is important but it has already been made watanabe almost all learning machines are singular foci this is one paper in a growing body of work investigating this phenomenon in general the references for this paper could be fleshed out much further a variety of prior work has examined the hessian in deep learning e g dauphin et al identifying and attacking the saddle point problem in high dimensional non convex optimization nips or the work of amari and others experimentally it is hard to tell how results from the small sized networks considered here might translate to much larger networks it seems likely that the behavior for much larger networks would be different a reason for optimism though is the fact that a clear bulk outlier behavior emerges even in these networks characterizing this behavior for simple systems is valuable overall the results feel preliminary but likely to be of interest when further fleshed out this paper is attacking an important problem but should do a better job situating itself in the related literature and undertaking experiments of sufficient size to reveal large scale behavior relevant to practice,3.0
623.json,the paper analyzes the properties of the hessian of the training objective for various neural networks and data distributions the authors study in particular the eigenspectrum of the hessian which relates to the difficulty and the local convexity of the optimization problem while there are several interesting insights discussed in this paper such as the local flatness of the objective function as well as the study of the relation between data distribution and hessian a somewhat lacking aspect of the paper is that most described effects are presented as general while tested only in a specific setting without control experiments or mathematical analysis for example regarding the concentration of eigenvalues to zero in figure it is unclear whether the concentration effect is really caused by training e g increasing insensitivity to local perturbations or the consequence of a specific choice of scale for the initial parameters in figure the complexity of the data is not defined it is not clear whether two fully overlapping distributions the hessian would then become zero is considered as complex or simple data some of the plots legends fig and and labels are unreadable in printed format plots of figure do not have the same range for the x axis the image of hessian matrix of figure does not render properly in printed format,4.0
336.json,it is refreshing that openai has taken the time to resurrect classic heuristics like down sampling and dropout into pixelcnn some sort of ar technique like pixelcnn probably holds the missing keys needed to eventually have decent originally created images from cifar or other real life data sets so any engineering streamlining as in this paper is welcome to the general public especially when helping to avoid expensive clusters of gpus only deepmind can afford in this sense openai is fulfilling its mission and we are all very grateful thus the paper is a welcome addition and we hope it finds its way into what appears to be an experimental cs conference anyway on a more conceptual level our hope is that openai with so talented a team will stop competing in these contrived contests to improve by basis points certain obscure log likelihoods and instead focus on the bigger picture problems why for example almost two years later the class conditional cifar samples as on the left of figure in this paper column class of horses are still inferior to say the samples on figure of reference forgive the pun but are not we beating a dead horse here yes resolution and sharpness have improved due to good engineering but nobody in the general public will take these samples seriously despite the claims put forward by some on the deepmind team pixelcnn is not a fully generative neural net as rigorously defined in section of reference but merely a perturbative net in the vain of the boltzmann machine after the procrustean experience of lost decades on boltzmann machines the time perhaps has come to think more about the fundamentals and less about the heuristics,9.0
766.json,this paper proposes a pedestrian detection method using fast rcnn framework with batch normalization where edgeboxes is used to collect pedestrian proposals instead of selective search as used in the original fast rcnn method the proposed method is evaluated in inria and eth dataset pros the proposed method shows good performance but not state of the art cons lack of novelty fast rcnn and its variants e g fasterrcnn,3.0
766.json,the authors apply the commonly used fast rcnn detection system to pedestrian detection they use edgeboxes object proposals and incorporate batch norm into their network results are shown on the inria and eth pedestrian datasets they are reasonable but not state of the art results are not shown on caltech pedestrians the standard modern dataset used to evaluate pedestrian detection perhaps more importantly the paper has no novelty the detection system described in this paper is a standard application of fast rcnn to pedestrian detection the implementation is not state of the art and there is no novelty in this work edgeboxes has been used with fast rcnn before the authors don t seem to be aware of more recent developments in object detection including faster rcnn,2.0
770.json,this paper proposes to incorporate knowledge base facts into language modeling thus at each time step a word is either generated from the full vocabulary or relevant kb entities the authors demonstrate the effectiveness on a new generated dataset wikifacts which aligns wikipedia articles with freebase facts the authors also suggest a modified perplexity metric which penalizes the likelihood of unknown words at a high level i do like the motivation of this paper named entity words are usually important for downstream tasks but difficult to learn solely based on statistical co occurrences the facts encoded in kb could be a great supply for this however i find it difficult to follow the details of the paper mainly section and think the paper writing needs to be much improved i cannot find where f symbkey f voca f copy are defined w v w s are confusing ek seems to be the average of all previous fact embeddings it is necessary to make it clear enough ht ct flstm x t h t ct is not used the notion of fact embeddings is also not that clear i understand that they are taken as the concatenation of relation and entity object entities in the end for the anchor topic itself facts do you learn the embedding for the special relations and use the entity embeddings from transe on generating words from kb entities fact description it sounds a bit strange to me to generate a symbol position first most entities are multiple words and it is necessary to keep that order also it might be helpful to incorporate some prior information for example it is common to only mention obama for the entity barack obama,6.0
770.json,the paper proposes an evolution upon traditional recurrent language models to give the capability to deal with unknown words it is done by pairing the traditional rnnlm with a module operating on a kb and able to copy from kb facts to generate unseen words it is shown to be efficient and much better than plain rnnlm on a new dataset the writing could be improved the beginning of section in particular is hard to parse there have been similar efforts recently like pointer sentinel mixture models by merity et al that attempt to overcome limitations of rnnlms with unknown words but they usually do it by adding a mechanism to copy from a longer past history the proposal of the current paper is different and more interesting to me in that it try to bring knowledge from another source kb to the language model this is harder because one needs to leverage the large scale of the kb to do so being able to train that conveniently is nice the architecture appears sound but the writing makes it hard to fully understand completely so i can not give a higher rating other comments how to cope with the dependency on the kb freebase is not updated anymore so it is likely that a lot of the new unseen words in the making are not going to be in freebase what is the performance on standard benchmarks like penn tree bank how long is it to train compare to a standard rnnlm what is the importance of the knowledge context e how is initialized the fact embedding a t for the first word when a word from a fact description has been chosen as prediction copied how is it encoded in the generation history for following predictions if it has no embedding unknown word in other words what happens if michelle in the example of section is not in the embedding dictionary when one wants to predict the next word,6.0
770.json,this paper addresses the practical problem of generating rare or unseen words in the context of language modeling since language follows a zipf s law most approaches limit the vocabulary because of computation reasons and hence rare words are often mapped to a unk token rare words are especially important in context of applications such as question answering mt etc this paper proposes a language modeling technique which incorporates facts from knowledge bases kbs and thus has the ability to generate potentially unseen words from kbs this paper also releases a dataset by aligning words with freebase facts and corresponding wikipedia descriptions the model first selects a kb fact based on the previously generated words and facts based on the selected fact it then predicts whether to generate a word based on the vocabulary or to output a symbolic word from the kb for the latter the model is trained to predict the position of the word from the fact description overall the paper could use some rewriting especially the notations in section the experiments are well executed and they definitely get good results the heat maps at the end are very insightful comments this contributions of this paper would be much stronger if it showed improvements in a practical applications such as question answering although the paper clearly mentions that this technique could be applied to improve qa in section it is unclear why the authors refer the entity as a topic this makes the text a little confusing since a topic can also be associated with something abstract but in this case the topic is always a freebase entity is it really necessary to predict a fact at every step before generating a word in other words how many distinct facts on average does the model choose to generate a sentence intuitively a natural language sentence would be describe few facts about an entity if the fact generation step could be avoided by adding a latent variable which decides if the fact should be generated or not the model will also be faster in equation the model has to make a hard decision to choose the fact for this to be end to end trained every word needs to be annotated with a corresponding fact which might not be always a realistic scenario for e g in domains such as social media text learning position embeddings for copying knowledge words seems a little counter intuitive does the sequence of knowledge words follow any particular structure like word o is always the last name e g obama it would also be nice to compare to char level lm which inherently solves the unknown token problem,6.0
320.json,the paper proposes a novel approach for learning visual servoing based on q iteration the main contributions of the paper are bilinear dynamics model for predicting next frame features based on action and current frame formulation of servoing with a q function that learns weights for different feature channels an elegant method for optimizing the bellman error to learn the q function pros the paper does a good job of exploring different ways to connect the action ut and frame representation yt to predict next frame features y t they argue in favour of a locally connected bilinear model which strikes the balance between computation and expressive ability cons while sec makes good arguments for different choices i would have liked to see more experimental results comparing the approaches fully connected convolutional and locally connected dynamics pros the idea of weighting different channels to capture the importance of obejcts in different channels seems more effective than treating errors across all channels equally this is also validated experimentally where unweighted performance suffers consistently solving the bellman error is a difficult problem in q learning approaches the current paper presents a solid optimization scheme based on the key observation that scaling q function parameters does not affect the best policy chosen this enables a more elegant fqi approach as opposed to typical optimization schemes which ct gamma minu q t fixed cons however i would have liked to see the difference between fqi and such an iterative approach which holds the second term in eq fixed experimental results overall i find the experimental results unsatisfying given the small scale and toy simulations however the lack of benchmarks in this domain needs to be recognized also as pointed out in pre review section the idea of modifying the vgg needs to be experimentally validated in its current form it is not clear whether the modified vgg would perform better than the original version overall the contribution of the paper is solid in terms of technical novelty and problem formulations however the paper could use stronger experiments as suggested to earlier to bolster its claims,7.0
320.json,this paper investigates the benefits of visual servoing using a learned visual representation the authors propose to first learn an action conditional bilinear model of the visual features obtained from a pre trained vgg net from which a policy can be derived using a linearization of the dynamics a multi scale multi channel and locally connected variant of the bilinear model is presented since the bilinear model only predicts the dynamics one step ahead the paper proposes a weighted objective which incorporates the long term values of the current policy the evaluation problem is addressed using a fitted value approach the paper is well written mathematically solid and conceptually exhaustive the experiments also demonstrate the benefits of using a value weighted objective and is an important contribution of this paper this paper also seems to be the first to outline a trust region fitted q iteration algorithm the use of pre trained visual features is also shown to help empirically for generalization overall i recommend this paper as it would benefit many researchers in robotics however in the context of this conference i find the contribution specifically on the representation problem to be limited it shows that a pre trained vgg representation is useful but does not consider learning it end to end this is not to say that it should be end to end but proportionally speaking the paper spends more time on the control problem than the representation learning one also the policy representation is fixed and the values are approximated in linear form using problem specific features this does not make the paper less valuable but perhaps less aligned with what i think iclr should be about,8.0
320.json,summary this paper proposes to tackle visual servoing specifically target following using spatial feature maps from convolutional networks pre trained on general image classification tasks the authors combine bilinear models of one step dynamics of visual feature maps at multiple scales with a reinforcement learning algorithm to learn a servoing policy this policy is learned by minimizing a regularized weighted average of distances to features predicted by the aforementioned model of visual dynamics contributions controlled experiments in simulation quantifying the usefulness of pre trained deep features for visual servoing clear performance benefits with respect to many sensible baselines including ones using ground truth bounding boxes principled learning of multi scale visual feature weights with an efficient trust region fitted q iteration algorithm to handle the problem of distractors good sample efficiency thanks to the choice of q function approximator and the model based one step visual feature dynamics open source virtual city environment to benchmark visual servoing suggestions for improvement more complex benchmark although the environment is not just a toy synthetic one the experiments would benefit greatly from more complex visual conditions clutter distractors appearance and motion variety environment richness and diversity etc at least the realism and diversity of object appearances could be vastly improved by using a larger number of d car models including more realistic and diverse ones that can be obtained from google sketchup for instance and populating the environment with more distractor cars in traffic or parked this is important as the main desired quality of the approach is robustness to visual variations end to end and representation learning although the improvements are already significant in the current synthetic experiments it would be interesting to measure the impact of end to end training i e also fine tuning the convnet as it is possibly needed for better generalization in more challenging visual conditions it would also allow to measure the benefit of deep representation learning for visual servoing which would be relevant to iclr there is no representation learning so far although the method can be straightforwardly adapted as the authors mention briefly reproducibility the formalism and algorithms are clearly explained but there is a slightly overwhelming mass of practical tricks and implementation details described with varying levels of details throughout the paper and appendix grouping simplifying or reorganizing the exposition of these implementation details would help but a better way would probably consist in only summarizing the most important ones in section and link to an open source implementation of the method for completeness typos p learning is a relative ly recent addition p be applied to directly learn conclusion in spite of the aforementioned limits of the experiments this paper is interesting and solid in part thanks to the excellent reply to the pre review questions and the subsequent improved revision this leads me to believe the authors are more than capable of following to a significant extent the aforementioned suggestions for improvement thus leading to an even better paper,7.0
459.json,the paper proposed a nice framework leveraging tucker and tensor train low rank tensor factorization to induce parameter sharing for multi task learning the framework is nice and appealing however mtl is a very well studied problem and the paper considers simple task for different classification and it is not clear if we really need deep learning for these simple datasets a comparison with existing shallow mtl is necessary to show the benefits of the proposed methods and in particular being deep on the dataset the authors ignore them on the basis of speculation and it is not clear if the proposed framework is really superior to simple regularizations like the nuclear norm the idea of nuclear norm regularization can also be extended to deep learning as gradient descent are popular in all methods,5.0
459.json,this paper proposed a deep multi task representation learning framework that learns cross task sharing structure at every layer in a deep network with tensor factorization and end to end knowledge sharing this approach removed the requirement of a user deﬁned multi task sharing strategy in conventional approach their experimental results indicate that their approach can achieve higher accuracy with fewer design choices although factorization ideas have been exploited in the past for other tasks i think applying it to mtl is interesting the only thing i want to point out is that the saving of parameter is from the low rank factorization in the conventional mtl each layer weight size can also be reduced if svd is used btw recent neural network mtl was explored first earlier than work cited in speech recognition community see e g huang j t li j yu d deng l and gong y may cross language knowledge transfer using multilingual deep neural network with shared hidden layers in ieee international conference on acoustics speech and signal processing pp ieee,8.0
662.json,the authors proposed a dynamic neural turing machine d ntm model that overcomes the rigid location based memory access used in the original ntm model the paper has two main contributions introducing a learnable addressing to ntm curriculum learning using hybrid discrete and continuous attention the proposed model was empirically evaluated on facebook babi task and has shown improvement over the original ntm pros comprehensive comparisons of feed forward controllers v s recurrent controllers encouraging results on the curriculum learning on hybrid discrete and continuous attentions cons very weak ntm baseline due to some hyper parameter engineering in table err comparing to the ntm err reported in table in graves et al hybrid computing using a neural network with dynamic external memory in fact the ntm baseline in graves et al is better than the proposed d ntm with gru controller maybe it is worthwhile to reproduce their results using the hyper parameter setting in their table which could potentially lead to better d ntm performance section of the paper is hard to follow the overall clarity of the paper needs improvement,6.0
662.json,this paper introduces a variant of the neural turing machine ntm graves et al where key and values are stored they try both continuous and discrete mechanisms to control the memory the model is quite complicated and seem to require a lot of tricks to work overall it seems that more than different terms appear in the cost function and many different hacks are required to learn the model it is hard to understand the justification for all of these tricks and sophisticated choices there is no code available nor plan to release it afaik the model is evaluated on a set of toy problems the babi task and achieves performance that are only slightly above those of a vanilla lstm but are much worse than the different memory augmented models proposed in the last few years in terms of writing the description of the model is quite hard to follow describing different blocks independently optimization tricks and regularization the equations are hard to read using non standard notation e g softplus overloading notations wt b or write similar equations in different ways for example eq compared to why are two equations in scalar and the other in vectors why is there an arrow instead of an equal overall it is very hard to put together all the pieces of this model s there is no code available and i m afraid there is not enough details to be able to reproduce their numbers finally the performance on the babi tasks are quite poor compared to other memory augmented models,4.0
399.json,this paper proposes a method for significantly increasing the number of parameters in a single layer while keeping computation in par with or even less than current sota models the idea is based on using a large mixture of experts moe i e small networks where only a few of them are adaptively activated via a gating network while the idea seems intuitive the main novelty in the paper is in designing the gating network which is encouraged to achieve two objectives utilizing all available experts aka importance and distributing computation fairly across them aka load additionally the paper introduces two techniques for increasing the batch size passed to each expert and hence maximizing parallelization in gpus experiments applying the proposed approach on rnns in language modelling task show that it can beat sota results with significantly less computation which is a result of selectively using much more parameters results on machine translation show that a model with more than x number of parameters can beat sota while incurring half of the effective computation i have the several comments on the paper i believe that the authors can do a better job in their presentation the paper currently is at pages which is too long in my opinion but i find that section the crux of the paper needs better motivation and intuitive explanation for example equation deserves more description than currently devoted to it additional space can be easily regained by moving details in the experiments section e g architecture and training details to the appendix for the curious readers experiment section can be better organized by finishing on experiment completely before moving to the other one there are also some glitches in the writing e g the end of section the paper is missing some important references in conditional computation e g,7.0
399.json,this paper describes a method for greatly expanding network model size in terms of number of stored parameters in the context of a recurrent net by applying a mixture of experts between recurrent net layers that is shared between all time steps by process features from all timesteps at the same time the effective batch size to the moe is increased by a factor of the number of steps in the model thus even for sparsely assigned experts each expert can be used on a large enough sub batch of inputs to remain computationally efficient another second technique that redistributes elements within a distributed model is also described further increasing per expert batch sizes experiments are performed on language modeling and machine translation tasks showing significant gains by increasing the number of experts compared to both soa as well as explicitly computationally matched baseline systems an area that falls a bit short is in presenting plots or statistics on the real computational load and system behavior while two loss terms were employed to balance the use of experts these are not explored in the experiments section it would have been nice to see the effects of these more along with the effects of increasing effective batch sizes e g measurements of the losses over the course of training compared to the counts histogram distributions of per expert batch sizes overall i think this is a well described system that achieves good results using a nifty placement for the moe that can overcome what otherwise might be a disadvantage for sparse computation small comment i like fig but it not entirely clear whether datapoints coincide between left and right plots the h h line has points on left but on the right also would be nice if the colors matched between corresponding lines,7.0
376.json,this paper performs a very important service exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures in particular the basic rnn motifs that have recently been popular pros this paper addresses an important question i and many others would have liked to know the answer to but did not have the computational resources to thoroughly attack it this is a nice use of google resources to help the community the work appears to have been done carefully so that the results can be believed the basic answer arrived at that in the typical training environment lstms are reliable but basically grus are the answer seems fairly decisive and practically useful of course the real answer is more complicated than my little summary here but the subtleties are discussed nicely in the paper the insistence on a strong distinction between capacity and trainability helps nicely clear up a misconception about the reasons why gated architectures work in sum they are much more easily trainable but somewhat lower capacity than vanilla rnns and in hard tasks the benefits of better trainability far outweigh the costs of mildly lower capacity the point about the near equivalence of capacity at equal numbers of parameters is very useful the paper makes it clear the importance of hp tuning something that has sometimes gotten lost in the vast flow of papers about new architectures the idea of quantifying the fraction of infeasible parameters e g those that diverge is nice because it a practical problem that everyone working with these networks has but often is not addressed the paper text is very clearly written cons the work on the ugrnns and the rnns seems a bit preliminary i do not think that the authors have clearly shown that the rnn should be recommended with the same generality as the gru i would at the least want some better statistics on the significance of differences between rnn and gru performances quantifying the results in figure layer panel in a way the high standards for declaring an architecture useful that are set in the paper make the ugrnns and rnn contributions seem less important i do not really mind having them in the paper though i guess the point of this paper is not really to be novel in the first place which is totally fine with me though i do not know what the iclr area chairs will think the paper gives short shrift to the details of the hp algorithm itself they do say our setting of the tuner s internal parameters was such that it uses batched gp bandits with an expected improvement acquisition function and a matern kernel with feature scaling and automatic relevance determination performed by optimizing over kernel hps and give some good references but i expect that actually trying to replicate this involves a lot of missing details i found some of the figures a bit hard to read at first esp fig mostly due to the panels being small having a lot of details and bad choices for visual cleanliness the neuroscience reference bits per synapse seems a little bit of a throw away to me because the connection between these results and the experimental neuroscience is very tenuous or at any rate not well explained i guess it just in the discussion but it seems gratuitous maybe it should couched in slightly less strong terms nothing is really strongly shown to be in agreement here between computational architectures and neuroscience but perhaps they could say something like we wonder if it is anything other than coincidence that our bits result is numerically similar to the bits measurement from neuroscience,8.0
726.json,paper summary this paper develops a generalization of dropout using information theoretic principles the basic idea is that when learning a representation z of input x with the aim of predicting y we must choose a z such that it carries the least amount of information about x as long as it can predict y this idea can be formalized using the information bottleneck lagrangian this leads to an optimization problem which is similar to the one derived for variational dropout the difference being that information dropout allows for a scaling factor associated with the kl divergence term that encourages noise the amount of noise being added is made a parameterized function of the data and this function is optimized along with the rest of the model experimental results on cifar and mnist show small improvements over binary dropout strengths the paper highlights an important conceptual link between probabilistic variational methods and information theoretic methods showing that dropout can be generalized using both formalisms to arrive at very similar models the presentation of the model is excellent the experimental results on cluttered mnist are impressive weaknesses the results on cifar in figure b seem to be on a validation set unless the axis label is a typo it is not clear why the test set was not used this makes it hard to compare to results reported in springenberg et al as well as other results in literature quality the theoretical exposition is high quality figure gives a nice qualitative assessment of what the model is doing however the experimental results section can be made better for example by matching the results on cifar as reported in springenberg et al and trying to improve on those using information dropout clarity the paper is well written and easy to follow originality the derivation of the information dropout optimization problem using ib lagrangian is novel however the final model is quite close to variational dropout significance this paper will be of general interest to researchers in representation learning because it highlights an alternative way to think about latent variables as information bottlenecks however unless the model can be shown to achieve significant improvements over simple dropout its wider impact is likely to be limited overall the paper presents an insightful theoretical derivation and good preliminary results the experimental section can be improved minor comments and suggestions expecially especially trough through there is probably a minus sign missing in the expression for h y z above eq figure a has error bars but b does not it might be a good idea to have those for figure b as well please consider comparing figure with the activity map of a standard cnn trained with binary dropout so we can see if similar filtering out is happening there already,6.0
726.json,an interesting connection is made between dropout tishby et al information bottleneck and vaes specifically classification of y from x is split in two faces an inference model z q z x a prior p z and a classifier y p y z by optimizing the objective e x y data e z q z x log p x y lambda kl q z x p z with lambda an information bottleneck z is formed where lambda controls an upper bound on the number of bits traveling through z the objective is equivalent to a vae objective with downweighted kl posterior prior an encoder that takes as input x and a decoder that only predicts x related work section is discussed sufficiently in section would be better to remind us the definition of mutual information connection to vaes in section is interesting unfortunately the mnist cifar results are not great since the method is potentially more flexible than other forms of dropout this is slightly disappointing it unclear why the cifar results seem to be substantially worse than the results originally reported for that architecture it unclear which version of beta was used in figure a overall i think the theory presented in the paper is promising however the paper lacks sufficiently convincing experimental results and i encourage the authors to do further experiments that prove significant improvements at least on cifar perhaps on larger problems,6.0
458.json,overview this paper introduces a biasing term for sgd that in theoretical results and a toy example yields solutions with an approximately equal or lower generalization error this comes at a computational cost of estimating the gradient of the biasing term for each iteration through stochastic gradient langevin dynamics approximating an mcmc sample of the log partition function of a modified gibbs distribution the cost is equivalent to adding an inner for loop to the standard sgd algorithm for each minibatch pros reviews and distills many results and theorems from past decades that suggest a promising way forward for increasing the generalizability of deep neural networks generally very well written and well presented results with interesting discussion of eigenvalues of hessian as a way to characterize flat minima promising mathematical arguments suggest that e sgd has generalization error bounded below by sgd motivating further research in the area cons points suggested for a rebuttal one claim of the paper given in the abstract is experiments on competitive baselines demonstrate that entropy sgd leads to improved generalization and has the potential to accelerate training this does not appear to be supported by the current set of experiments as the authors comment in the discussion section in our experiments entropy sgd results in a comparable generalization error as sgd but always has a lower cross entropy loss it not clear to me how to reconcile those two claims similarly the claim of accelerated training is not convincingly supported in the present version of the paper vanilla sgd requires a single forward pass through all m minibatches during one epoch for a parameter update but the new method e sgd requires l m forward passes during one epoch where l is the number of langevin updates which require a minibatch sample each this could in fact mean that e sgd has worse computational complexity to reach the same point in a remark on p the authors note that a single epoch is defined to be the number of parameter updates required to run through the dataset once it s not clear to me how this answers the objection to a factor of l additional computations required for the inner loop sgld iterations sgld appears to introduces a potentially costly tradeoff that must be carefully managed by a user of e sgd as the previous two points suggest the paper could use some attention to the magnitude of the claims for example the introduction reads actively biasing towards wide valleys aids generalization in fact we can optimize solely the free energy term to obtain similar generalization error as sgd on the original loss function according the the values reported on pp only on mnist is the generalization error using only the free energy term the log partition function of the modified gibbs distribution equivalent to using only the sgd loss function this corresponds to setting rho to in equation on cifar rho is used another contribution of this paper the characterization of the optimization landscape in terms of the eigenvalues of the hessian and low generalization error being associated with flat local extrema is helpful and interesting i found the plots clear and useful as another reviewer has already pointed out there are high level similarities to flat minima by hochreiter and schmidhuber the authors have responded already by adding a paragraph that helpfully explores some differences with h s however the similarities should also be carefully identified and mentioned h s includes detailed theoretical analysis that could be helpful for future work in this area and has independently discovered a similar approach to training generalizable networks it not clear how the assumption about the eigenvalues that were made in section appendix b affect the application of this result to real world problems what magnitude of c needs to be chosen does this correspond to a measurable characteristic of the dataset it a little mysterious in the current version of the paper,8.0
458.json,note an earlier version of the review almost identical to the present one for an earlier version of the paper available on arxiv can be found here,6.0
458.json,the paper introduces a new regularization term which encourages the optimizer to search for a flat local minimum of reasonably low loss instead of seeking a sharp region of a low loss this is motivated by some empirical observations that local minima of good generalization performance tend to have flat shape to achieve this a regularization term based on the free local energy is proposed and the gradient of this term which do not have tractable closed form solution is obtained by performing monte carlo estimation using sgld sampler in the experiments the authors show some evidence of the flatness of good local minima and also the performance of the proposed method in comparison to the adam optimizer the paper is well and clearly written i enjoyed reading the paper the connection to the concept of free energy in optimization framework seems interesting the motivation of pursuing flatness is also well analyzed with a few experiments i am wondering if the first term in eqn is correct i guess it should be f x not f x also i am wondering why the authors did not add the experiment results on rnn in the evaluation of the performance because char lstm for text generation was already used for the flatness experiments i think adding more experiments on various models and applications of deep architectures e g rnn seqseq etc will make the author claim more persuasive i also found the mixed usage of the terminology e g free energy and free entropy a bit confusing,7.0
458.json,this paper presents a principled approach to finding flat minima the motivation to seek such minima is due to their better generalization ability the idea is to add to the original loss function a new term that exploits both width and depth of the objective function in fact the regularization term can be interpreted as gaussian convolution of the exponentiated loss therefore the introduced regularization term is essentially gaussian smoothed version of the exponentiated loss the smoothing obviously tends to suppress sharp minima overall developing such regularization term based on thermodynamics concepts is very interesting i have a couple of concerns that the authors may want to clarify in the rebuttal when reporting the generalization performance the experiments report the number of epochs showing the proposed algorithm reaches better generalization in fewer epochs than plain sgd is this the number of epochs it takes by line of your algorithm or it is the total number of epochs line and all combined if the former it is not a fair comparison if you multiply the number of epochs of sgd line by the number iterations it takes to approximate langevin dynamics it seems you obtain little gain against plain sgd the proposed algorithm approximates the smoothed exponentiated loss by smoothing i refer to convolution with the gaussian i am wondering how it compares against simpler idea of smoothing the original loss dropping exponentiation is the difference only in the motivation e g thermodynamics interpretation or it is deeper e g the proposed scheme lends itself to more accurate approximation and or achieves better generalization bound in terms of the attained smoothness smoothing the cost function without exponentiation allows simpler approximation monte carlo integration instead of mcmc e g see section of,9.0
321.json,edited the score the paper presents a method for hierarchical rl using stochastic neural networks the paper has introduced using information theoretic measure of option identifiability as an additional reward for learning a diverse mixture of sub policies one nice result in the paper is the comparison with strong baseline which directly combines the intrinsic rewards with sparse rewards and shows that this supposedly smooth reward can t solve tasks besides the argument made from the authors on difficulty on long term credit assignment benefits from hierarchical abstraction one possible explanation for this might be the diversity requirement imposed in sub policy training which is assumed to be off in the baseline case wonder if this can shed insights into improving the baseline and proposing new end to end hierarchical policy learning as hierarchical reps option critic etc papers do nice visualizations the paper presents a promising direction and it may be strengthened further by possibly addressing some of the following points limited diversification of sub policies both concatenation and bilinear integration allow only minimal differentiations in sub policies through first hidden weight which is not a problem in the tested tasks because they essentially require same locomotion policies with minimal diversification but such limitation can be more obvious in other tasks where ideal sub policies are more diverse thus it is interesting to see it apply on harder non locomotion domains where ideal sub policies are not that similar e g for manipulation solving some task from one state can be very different from solving it from another state limitation on hierarchical policies manager network is trained while the sub policies are fixed furthermore the time steps for sub policies are fixed this requires intrinsic rewards and their learned sub policies to be very good for solving down stream tasks it would be nice to see some more discussions results on handling such cases ideally connecting to end to end hierarchical policy learning intrinsic unsupervised rewards seem domain specific supervised rewards because of this seems unavoidable,7.0
321.json,i like the setting presented in this paper but i have several criticism questions what are the failure model of this work as richness of behaviors get complex i expected this approach to have issues with the diversity of skills that could be discovered looking at sec let x be a random variable denoting the grid in which the agent is currently situated is the space discretized and if so why and what happens if it is not expanding on the first point does the approach work with more complicated embodiment say a link swimmer instead of i think this is important to assess the generality of this approach authors claim that recently heess et al have independently proposed to learn a range of skills in a pre training environment that will be useful for the downstream tasks which is similar to our framework however their pre training setup requires a set of goals to be specified in comparison we use intrinsic rewards as the only signal to the agent during the pre training phase the construction of which only requires very minimal domain knowledge i do not entirely agree with this the rewards that this paper proposes are also quite hand crafted and specific to a seemingly limited set of control tasks,8.0
622.json,this paper shows how spin glass techniques that were introduced in choromanska et al to analyze surface loss of deep neural networks can be applied to deep residual networks this is an interesting contribution but it seems to me that the results are too similar to the ones in choromanska et al and thus the novelty is seriously limited main theoretical techniques described in the paper were already introduced and main theoretical results mentioned there were in fact already proved the authors also did not get rid of lots of assumptions from choromanska et al path independence assumptions about weights distributions etc,3.0
622.json,summary in this paper the authors study resnets through a theoretical formulation of a spin glass model the conclusions are that resnets behave as an ensemble of shallow networks at the start of training by examining the magnitude of the weights for paths of a specific length but this changes through training through which the scaling parameter c from assumption a increases causing it to behave as an ensemble of deeper and deeper networks clarity this paper was somewhat difficult to follow being heavy in notation with perhaps some notation overloading a summary of some of the proofs in the main text might have been helpful specific comments in the proof of lemma i am not sure where the sequence beta comes from i do not see how it follows from the resnet structure used in the paper is somewhat different from normal with multiple layers being skipped can the same analysis be used if only one layer is skipped it seems like the skipping mostly affects the number of paths there are of a certain length the new experiments supporting the scale increase in practice are interesting i am not sure about theorems necessarily proving this link theoretically however particularly given the simplifying assumption at the start of section,7.0
675.json,first up i want to point out that this paper is really long like pages long without any supplementary material while iclr does not have an official page limit it would be nice if authors put themselves in the reviewer shoes and did not take undue advantage of this rule having or pages in addition to the conventional page limit is ok but more than doubling the pages is quite unfair now for the review the paper proposes a new artificial dataset for sequence learning i call it artificial because it was artificially generated from the original mnist dataset which is a smallish dataset of real images of handwritten digits in addition to the dataset the authors propose to train recurrent networks using a schedule over the length of the sequence which they call incremental learning the experiments show that their proposed schedule is better than not having any schedule on this data set furthermore they also show that their proposed schedule is better than a few other intuitive schedules the authors verify this by doing some ablation studies over the model on the proposed dataset i have following issues with this paper i did not find anything novel in this paper the proposed incremental learning schedule is nothing new and is a natural thing to try when learning sequences similar idea have already been tried by a number of authors including bengio and ranzato the only new piece of work is the ablation studies which the authors conduct to tease out and verify that indeed the improvement in performance is due to the curriculum used furthermore the authors only test their hypothesis on a single dataset which they propose and is artificially generated why not use it on a real sequential dataset such as language modeling does the technique not work in that scenario in fact i am quite positive that for language modeling where the vocabulary size is huge the performance gains will be no where close to the reported in the paper i am not convinced about the value of having this artificial dataset already there are so many real world sequential dataset available including in text speech finance and other areas what exactly does this dataset bring to the table is not super clear to me while having another dataset may not be a bad thing in itself i almost felt that this dataset was created for the sole purpose of making the proposed ideas work it would have been so much better had the authors shown experiments on other datasets as i said the paper is way too long a significant part of the length of the paper is due to a collection of experiments which are completely un related to the main message of the paper for instance the experiment in section is completely unrelated to the story of the paper same is true with the transfer learning experiments of section,3.0
675.json,the submitted paper proposes a new way of learning sequence predictors in the lines of incremental learning and curriculum learning easier samples are presented first and the complexity is increased during training the particularity here is that the complexity is defined as the length of the sequences given for training the premise being is that longer sequences are harder to learn since they need a more complex internal representation the targeted application is sequence prediction from primed prefixes tested on a single dataset which the authors extract themselves from mnist the idea in the paper is interesting and worth reading there are also many interesting aspects of evaluation part as the authors perform several ablation studies to rule out side effects of the tests the proposed learning strategy is compared to other strategies however my biggest concern is still with evaluation the authors tested the method on a single dataset which is non standard and derived from mnist given the general nature of the claim in order to confirm the interest of the proposed algorithm it need to be tested on other datasets public datasets and on a different application the paper is too long and should be trimmed significantly the transfer learning part from prediction to classification is a different story and i do not see a clear connection to the main contribution of the paper the presentation and organization of the paper could be improved it is quite sequentially written and sometimes reads like a student report the loss given in the long unnumbered equation on page should be better explained provide explanations for each term and make clearer what the different symbols mean learning is supervised so which variables are predictions and which are observations from the data ground truth names in table do not correspond to the descriptions in section,5.0
675.json,this paper presents a thorough analysis of different methods to do curriculum learning the major issue i have with it is that the dataset used seems very specific and does not necessarily justified as mentioned by anonreviewer it would have been great to see experiments on more standard tasks also i really can not understand how the performance of ffnn models can be so good please elaborate on this see last comment however the paper is well written the comparisons of the described methods are interesting and would probably apply to some other datasets as well the paper is way too long pages please reduce it or move some of the results to an appendix section the method described is extremely similar to the one described in reinforcement learning neural turing machines zaremba et al,5.0
730.json,the paper proposes and analyses three methods applied to traditional lstms monte carlo test time model averaging average pooling and residual connections it shows that those methods help to enhance traditional lstms on sentiment analysis although the paper is well written the experiment section is definitely its dead point firstly although it shows some improvements over traditional lstms those results are not on par with the state of the art secondly if the purpose is to take those extensions as strong baselines for further research the experiments are not adequate the both two datasets which were used are quite similar though they have different statistics i thus suggest to carry out more experiments on more diverse tasks like those in lstm a search space odyssey besides those extensions are not really novel,5.0
730.json,this paper presents three improvements to the standard lstm architecture used in many neural nlp models monte carlo averaging embed average pooling and residual connections each of the modifications is trivial to implement so the paper is definitely of interest to any nlp researchers experimenting with deep learning with that said i am concerned about the experiments and their results the residual connections do not seem to consistently help performance on sst the vertical residuals help but the lateral residuals hurt and on imdb it is the opposite more fundamentally there need to be more tasks than just sentiment analysis here i am not quite sure why the paper focus is on text classification as any nlp task using an lstm encoder could conceivably benefit from these modifications it would be great to see a huge variety of tasks like qa mt etc which would really make the paper much stronger at this point while the experiments that are included in the paper are very thorough and the analysis is interesting there need to be more tasks to convince me that the modifications generalize so i do not think the paper is ready for publication,5.0
730.json,i agree with the other reviewer that the application areas are limited in the paper i agree with the overall sentiment of the paper to evaluate effectiveness of some of the more recent techniques in this area in conjunction with the recurrent networks the paper advertises itself as a method or a list of methods of improving the recurrent baselines when performing experiments however fails or not shown to generalize to other tasks effectiveness of these methods need to be shown across a wide variety of tasks if we intend to replace traditional baselines in general rather than a specific subset of applications i like the desire to evaluate many of the recent techniques and having many replications of experiments towards this end which is a strong point of the paper however whether there are synergies of some of the enhancements with sentiment analysis or not we cannot see from these results it would be interesting to see whether some of these results generalize across a wide variety of tasks,5.0
360.json,in supervised learning a significant advance occurred when the framework of semi supervised learning was adopted which used the weaker approach of unsupervised learning to infer some property such as a distance measure or a smoothness regularizer which could then be used with a small number of labeled examples the approach rested on the assumption of smoothness on the manifold typically this paper attempts to stretch this analogy to reinforcement learning although the analogy is somewhat incoherent labels are not equivalent to reward functions and positive or negative rewards do not mean the same as positive and negative labels still the paper makes a worthwhile attempt to explore this notion of semi supervised rl which is clearly an important area that deserves more attention the authors use the term labeled mdp to mean the typical mdp framework where the reward function is unknown they use the confusing term unlabeled mdp to mean the situation where the reward is unknown which is technically not an mdp but a controlled markov process in the classical rl transfer learning setup the agent is attempting to transfer learning from a source labeled mdp to a target labeled mdp where both reward functions are known but the learned policy is known only in the source mdp in the semi supervised rl setting the target is an unlabeled cmp and the source is both a labeled mdp and an unlabeled cmp the basic approach is to use inverse rl to infer the unknown labels and then attempt to construct transfer a further restriction is made to linearly solvable mdps for technical reasons experiments are reported using three relatively complex domains using the mujoco physics simulator the work is interesting but in the opinion of this reviewer the work fails to provide a simple sufficiently general notion of semi supervised rl that will be of sufficiently wide interest to the rl community that remains to be done by a future paper but in the interim the work here is sufficiently interesting and the problem is certainly a worthwhile one to study,6.0
360.json,this paper formalizes the problem setting of having only a subset of available mdps for which one has access to a reward the authors name this setting semi supervised reinforcement learning ssrl as a reference to semi supervised learning where one only has access to labels for a subset of the dataset they provide an approach for solving ssrl named semi supervised skill generalization sg which builds on the framework of maximum entropy control the whole approach is straightforward and amounts to an em algorithm with partial labels they alternate iteratively between estimating a reward function parametrized and fitting a control policy using this reward function they provide experiments on tasks obstacle link reacher link reacher with vision half cheetah in mujoco the paper is well written and is overall clear the appendix provides some more context i think a few implementation details are missing to be able to fully reproduce the experiments from the paper but they will provide the code the link to inverse reinforcement learning seems to be done correctly however there is no reference to off policy policy learning and for instance it seems to me that the tau in d samp term of equation could benefit from variance reduction as in e g tb lambda precup et al or retrace lambda munos et al the experimental section is convincing but i would appreciate a precision and small discussion of this sentence to extensively test the generalization capabilities of the policies learned with each method we measure performance on a wide range of settings that is a superset of the unlabeled and labeled mdps with numbers for the different scenarios or the replacement of superset by union if this is the case it may explain better the poor results of oracle on obstacle and link reacher and reinforce the further sentences in the obstacle task the true reward function is not sufficiently shaped for learning in the unlabeled mdps hence the reward regression and oracle methods perform poorly correction on page tuple mi s a t r is a tuple overall i think that this is a good and sound paper i am personally unsure as to if all the parallels and or references to previous work are complete thus my confidence score of pun intended,7.0
360.json,the paper proposes to study the problem of semi supervised rl where one has to distinguish between labelled mdps that provide rewards and unlabelled mdps that are not associated with any reward signal the underlying is very simple since it aims at simultaneously learning a policy based on the reinforce entropy regularization technique and also a model of the reward that will be used as in inverse reinforcement learning as a feedback over unlabelled mdps the experiments are made on different continous domains and show interesting results the paper is well written and easy to understand it is based on a simple but efficient idea of simultaneously learning the policy and a model of the reward and the resulting algorithm exhibit interesting properties the proposed idea is quite obvious but the authors are the first ones to propose to test such a model the experiments could be made stronger by mixing continuous and discrete problems but are convincing,8.0
527.json,this paper proposes an extension of the multiplicative rnn where the authors apply the same reparametrization trick to the weight matrices of the lstm the paper proposes some interesting tricks but none of them seems to be very crucial for instance in eq the authors propose to multiply the output gate inside the activation function in order to alleviate the saturation problem in logistic sigmoid or hyperbolic tangent also the authors share mt across the inference of different gating units and cell state candidates at the end this brings only times increase on the number of model parameters lastly the authors use a variant of rmsprop where they add an additional hyper parameter ell and schedule it across the training time it would be nicer to apply the same tricks to other baseline models and show the improvement with regard to each trick with the new architectural modification to the lstm and all the tricks combined the performance is not as great as we would expect why didn t the authors apply batch normalization layer normalization or zoneout to their models was there any issue with applying one of those regularization or optimization techniques at the fourth paragraph of section where the authors connect dynamic evaluation with fast weights is misleading i find it a bit hard to connect dynamic evaluation as a variant of fast weights fast weights do not use test error signal in the paper the authors claim that dynamic evaluation uses the error signal and gradients to update the weights which potentially increases its effectiveness but also limits its scope to conditional generative modelling when the outputs can be observed after they are predicted and i am afraid to tell that this assumption is very misleading we should never assume that test label information is given at the inference time the test label information is there to evaluate the generalization performance of the model in some applications we may get the label information at test time e g stock prediction weather forecasting however in many other applications we don t for instance in machine translation we do not know what is the best translation at the end unlike weather forecasting also it would be fair to apply dynamic evaluation to all the other baseline models as well to compare with the bpc score achieved by the proposed mlstm the quality of the work is not that bad but the novelty of the paper is not that good either the performance of the proposed model is oftentime worse than other methods and it is only better when dynamic evaluation is coupled together however dynamic evaluation can improve the other methods as well ilya et al generating text with recurrent neural networks icml,4.0
570.json,this paper extends mostly on top of the work of qa bilstm and qa bilstm with attentions as proposed in tan et al and tan et al in the following ways it trains a topic specific word embedding using an approach similar to paragraphvec by leveraging the topic and title information provided in the data it considers the multiple unit answer selection problem e g one sentence selected from answer section and another selected from supplemental section vs the single answer selection problem as studied in tan et al and the mechanism used to retain the coherence between different parts of the answers is inspired by the attention mechanism introduced by tan et al while the practical results presented in the paper is interesting the main innovations of this paper are rather limited,4.0
435.json,this heuristic to improve gradient descent in image classification is simple and effective but this looks to me more like a workshop track paper demonstration of the algorithm is limited to one task cifar and there is no theory to support it so we do not know how it will generalize on other tasks working on dnns for nlp i find some observations in the paper opposite to my own experience in particular with architectures that combine a wide variety of layer types embedding rnn cnn gating i found that adam type techniques far outperform simple sgd with momentum as they save searching for the right learning rate for each type of layer but adam only works well combined with poliak averaging as it fluctuates a lot from one batch to another revision the authors substantially improved the contents of the paper including experiments on another set than cifar the workshop track has been modified to breakthrough work so my recommendation for it is not longer appropriate i have therefore improved my rating,7.0
435.json,this an interesting investigation into learning rate schedules bringing in the idea of restarts often overlooked in deep learning the paper does a thorough study on non trivial datasets and while the outcomes are not fully conclusive the results are very good and the approach is novel enough to warrant publication i thank the authors for revising the paper based on my concerns typos flesh flush,7.0
435.json,this paper describes a way to speed up convergence through sudden increases of otherwise monotonically decreasing learning rates several techniques are presented in a clear way and parameterized method is proposed and evaluated on the cifar task the concept is easy to understand and the authors chose state of the art models to show the performance of their algorithm the relevance of these results goes beyond image classification pros simple and effective method to improve convergence good evaluation on well known database cons connection of introduction and topic of the paper is a bit unclear fig and are hard to read lines are out of bounds and maybe only the best setting for t and tmult would be clearer the baseline also does not seem to converge remarks an loss surface for t against tmult would be very helpful also understanding the relationship of network depth and the performance of this method would add value to this analysis,7.0
659.json,the paper describes a recurrent transducer that uses hard monotonic alignments at each step a discrete decision is taken either to emit the next symbol or to consume the next input token the model is moderately novel similar architecture was proposed for speech recognition,5.0
589.json,this paper investigates the modeling of graph sequences authors propose graph convolutional recurrent networks grcn that extends convlstm shi et al for data having an unregular graph structure at each timestep they replace the d convolution with a graph convolutional operator from defferrad et al authors propose two variations of the grcn model in model the graph convolution is only applied on the input data in model the graph convolution is applied on both input data and the previous hidden states they evaluate their approaches on two different tasks video generation using the movingmnist dataset and world level language modelling using penntreebank on movingmnist authors show that their grcn improves upon convlstm however they evaluate only with one layer convlstm while shi et al report better results with layers also not as good as grcn it would be nice to evaluate gcrcn in that setting as well while the authors show an improvement of grcn relatively to convlstm grcn on this task seems relatively weak compared to recent works such as the video pixel networks kalchbrenner et al it contradicts the claim that model has shown good performance in the case of video prediction in the conclusion for the penntreebank experiments author compares their model with fc lstm with or without dropout however the results in zaremba et al still seems different than the one reported here in zaremba et al they reports a test perplexity of for the large regularized lstm in their table which outperforms the score of the grcn also following works such as variational dropout or zoneout have since improve upon zaremba results is there some differences in the experimental setting it would be nice to have results that are directly comparable to previous work pros interesting model cons overall the proposed contribution is relatively incremental compared to shi et al and defferrad et al weak results of grcn relatively to previous works in the experiments that do not convince of the grcn advantages,4.0
589.json,the authors address the problem of modeling temporally changing signal on a graph where the signal at one node changes as a function of the inputs and the hidden states of its neighborhood the size of which is a hyperparameter the approach follows closely that of shi et al but it is generalized to arbitrary graph structures rather than a fixed grid by using graph convolutions of defferrard et al this is not a strict generalization because the graph formulation treats all edges equally while the conv kernels in shi et al have a built in directionality the authors show results on a moving mnist and on the penn tree bank language modeling task the paper model and experiments are decent but i have some concerns the proposed model is not exceptionally novel from a technical perspective i usually do not mind if this is the case provided that the authors make up for the deficiency with thorough experimental evaluation clear write up and interesting insights into the pros cons of the approach with respect to previous models in this case i lean towards this not being the case the experiment results section is rather terse and light on interpretation i am not fully up to date on the latest of penn tree bank language modeling results but i do know that it is a hotly contested and well known dataset i am surprised to see a comparison only to zaremba et al where i would expect to see multiple other results the writing is not very clear and the authors do not make sufficiently strong attempt to compare the models or provide insight or comparisons into why the proposed model works better in particular unless i am mistaken the word probabilities are a function of the neighborhood in the graph what is the width of this graph for example suppose i sample a word in one part of the graph does not this information have to propagate to the other parts of the graph along the edges also it not clear to me how the model can achieve reasonable results on moving mnist when it cannot distinguish the direction of the moving edges the authors state this but do not provide satisfying insight into how this can work how does a pixel know that it should turn on in the next frame i wish the authors thought about this more and presented it more clearly in summary the paper has somewhat weak technical contribution the experiments section is not very thorough and the insights are sparse,4.0
423.json,this work brings multiple discriminators into gan from the result multiple discriminators is useful for stabilizing the main problem of stabilizing seems is from gradient signal from discriminator the authors motivation is using multiple discriminators to reduce this effect i think this work indicates the direction is promising however i think the authors may consider to add more result vs approach which enforce discriminator gradient such as gan with dae improving generative adversarial networks with denoising feature matching to show advantages of multiple discriminators,6.0
423.json,the paper extends the gan framework to accommodate multiple discriminators the authors motivate this from two points of view having multiple discriminators tackle the task is equivalent to optimizing the value function using random restarts which can potentially help optimization given the nonconvexity of the value function having multiple discriminators can help overcome the optimization problems arising when a discriminator is too harsh a critic a generator receiving signal from multiple discriminators is less likely to be receiving poor gradient signal from all discriminators the paper main idea looks straightforward to implement in practice and makes for a good addition to the gan training toolbelt i am not very convinced by the gam and by extension the gmam evaluation metric without evidence that the gan game is converging even approximately it is hard to make the case that the discriminators tell something meaningful about the generators with respect to the data distribution in particular it does not inform on mode coverage or probability mass misallocation the learning curves figure look more convincing to me they provide good evidence that increasing the number of discriminators has a stabilizing effect on the learning dynamics however it seems like this figure along with figure also show that the unmodified generator objective is more stable even with only one discriminator in that case is it even necessary to have more than one discriminator to train the generator using an unmodified objective overall i think the ideas presented in this paper show good potential but i would like to see an extended analysis in the line of figures and for more datasets before i think it is ready for publication update the rating has been revised to a following discussion with the authors,7.0
531.json,this paper proposes a generative model of videos composed of a background and a set of d objects sprites optimization is performed under a vae framework the authors proposal of an outer product of softmaxed vectors resulting in a d map that is delta like composed with a convolution is a very interesting way to achieve translation of an image with differentiable parameters it seems to be an attractive alternative to more complicated differentiable resamplers such as those used by stns when only translation is needed below i have made some comments regarding parts of the text especially the experiments that are not clear the experimental section in particular seems rushed with some results only alluded to but not given not even in the appendix for an extremely novel and exotic proposal showing only synthetic experiments could be excused however though there is some novelty in the method it is disappointing that there is not even an attempt at trying to tackle a problem with real data i suggest as an example aerial videos such as those taken from drone platforms since the planar assumption that the authors make would most probably hold in that case i also suggest that the authors do another pass at proof reading the paper there are missing references fig unfinished sentences caption of fig and the aforementioned issues with the experimental exposition,4.0
531.json,this paper presents an approach to modeling videos based on a decomposition into a background d sprites with a latent hidden state the exposition is ok and i think the approach is sensible but the main issue with this paper is that it is lacking experiments on non synthetic datasets as such while i find the graphics inspired questions the paper is investigating interesting i do not think it is clear that this work introduces useful machinery for modeling more general videos i think this paper is more appropriate as a workshop contribution in its current form,4.0
474.json,after the discussion below i looked at previous work by the authors mus rover on which this paper was based on one hand this was very helpful for me to better understand the current paper on the other hand this was very needed for me to better understand the current paper overall while i think that i like this work and while i am familiar with the jsb chorales with probabilistic approaches with n grams etc i did find the paper quite hard to follow at various parts the extensive use of notation did not help the clarity i think the ideas and approaches are good and certainly worth publishing and worth pursuing i am not sure that in the paper current form iclr is an appropriate venue incidentally the issue is not the application as i think that music applications can be very appropriate nor is the problem necessarily with the approach see my next suggestion i get the sense that a long form journal publication would actually give the authors the space necessary to fully explain these ideas provide clearer running examples where needed provide the necessary background for the appropriate readership provide the necessary background on the previous system perhaps demonstrating results on a second dataset to show generality of the approach etc a short conference paper just seems to me to be too dense a format for giving this project the description it merits if it were possible to focus on just one aspect of this system then that might work but i do not have good suggestions for exactly how to do that if the paper were revised substantially though i cannot suggest details for how to do this within the appropriate page count i would consider raising my score i do think that the effort would be better invested in turning this into a long and clearer journal submission addendum based on discussions here revisions i have revised my score,6.0
618.json,this paper presents an improved formulation of cnn aiming to separate geometric transformation from inherent features the network can estimate the transformation of filters given the input images this work is based on a solid technical foundation and is motivated by a plausible rationale yet the value of this work in practice is subject to questions it relies on the assumption that the input image is subject to a transformation on a certain lie group locally do such transformations constitute real challenges in practice state of the art cnns e g resnet are already quite resilient to such local deformations what such components would add to the state of the art limited experiments on cifar does not seem to provide a very strong argument the computational cost is not discussed,5.0
618.json,this works applies steerable frames for various tasks where convolutional neural networks with location invariant operators are traditionally applied authors provide a detailed overview of steerable frames followed with an experimental section which applies dynamic steerable network to small machine learning problems where the steerability is conceptually useful even though the evaluation is performed only on few small tasks the reason why more tasks were not evaluated is that piece wise pose invariance is needed only for a subset of tasks the fact that simply using overcomplete bases as a sort of feature pre processing improves the results for already highly optimized resnet and densenet architectures is quite interesting achievement for the edge detection a relatively hard baseline is selected the dynamic filter networks which already attempts to achieve position invariant filters the fact that dsfn improves the performance on this task verifies that regressing the parametrization of the steerable filters yields better results than regressing the filters directly in the last experiment authors apply the network to video classification using lstms and they show that the improved performance is not due to increased capacity of the network in general it is quite interesting work even though it does not offer ground breaking results mainly in a sense of not performing experiments on larger tasks it is theoretically interesting and shows promising results there are few minor issues and suggestions related to the paper for the lstm experiment in order to be more exact it would be useful to include information about total number of parameters as the network which estimates the pose also increases the number of parameters would it be possible to provide more details about how the back propagation is done through the steerable filters for the edge detection experiment it would be useful to provide results for some standard baseline e g cnn with a similar number of parameters simply to see how useful it is to have location variant filters for this task the last sentence in second paragraph on page is missing a verb also it is maybe unnecessary the hyphenation for convnet is incorrect on multiple places probably hyphenation conv net would fix it,7.0
395.json,the authors propose a new software package for probabilistic programming taking advantage of recent successful tools used in the deep learning community the software looks very promising and has the potential to transform the way we work in the probabilistic modelling community allowing us to perform rapid prototyping to iterate through ideas quickly the composability principles are used insightfully and the extension of inference to hmc for example going beyond vi inference which is simple to implement using existing deep learning tools makes the software even more compelling however the most important factor of any ppl is whether it is practical for real world use cases this was not demonstrated sufficiently in the submission there are many example code snippets given in the paper but most are not evaluated the dirichlet process mixture model example figure is an important one do the proposed black box inference tools really work for this snippet and will the gan example figure converge when optimised with real data to convince the community of the practicality of the package it will be necessary to demonstrate these empirically currently the only evaluated model is a vae with various inference techniques which are not difficult to implement using pure tf presentation paper presentation could be improved for example the authors could use more signalling for what is about to be explained on page qbeta and qz are used without explanation the authors could mention that an example will be given thereafter i would also suggest to the authors to explain in the preface how the layers are implemented and how the kl is handled in vi for example it will be useful to discuss what values are optimised and what values change as inference is performed even before section this was not clear for the majority of the paper experiments why is the run time not reported in table what are the difficulties around convergence encountered with the analytical entropies inference issues become more difficult to diagnose as inference is automated are there tools to diagnose these with the provided toolbox did hmc give sensible results in the experiment at the bottom of page only run time is reported how difficult is it to get the inference to work eg hmc when we do not have full control over the computational graph structure and sampler it would be extremely insightful to give a table comparing the performance run time predictive log likelihood etc of the various inference tools on more models what benchmarks do you intend to use in the model zoo the difficulty with probabilistic modelling is that there are no set benchmarks over which we can evaluate and compare many models model zoo is sensible for the caffe ecosystem because there exist few benchmarks a large portion of the community was working on imagenet for example what datasets would you use to compare the dpmm on for example minor comments table i would suggest to compare to li turner with alpha the equivalent of hellinger distance as they concluded this value performs best i am not sure why alpha was chosen here how do you handle discrete distributions eg figure xreal is not defined in figure i would suggest highlighting m in figure comma instead of period after rized in on page in conclusion i would say that the software developments presented here are quite exciting and i am glad the authors are pushing towards practical and accessible inference for all in its current form though i am forced to give the submission itself a score of,5.0
395.json,the paper introduces edward a probabilistic programming language built over tensorflow and python and supporting a broad range of most popular contemporary methods in probabilistic machine learning quality the edward library provides an extremely impressive collection of modern probabilistic inference methods in an easily usable form the paper provides a brief review of the most important techniques especially from a representation learning perspective combined with two experiments on implementing various modern variational inference methods and gpu accelerated hmc the first experiment variational inference would be more valuable if there was a clear link to complete code to reproduce the results provided the hmc experiment looks ok except the characterising stan as a hand optimised implementation seems unfair as the code is clearly not hand optimised for this specific model and hardware configuration i do not think anyone doubts the quality of your implementation so please do not ruin the picture by unsubstantiated sensationalist claims instead of current drama i would suggest comparing head to head against stan on single core and separately reporting the extra speedups you gain from parallelisation and gpu these numbers would also help the readers to estimate the performance of the method for other hardware configurations clarity the paper is in general clearly written and easy to read the numerous code examples are helpful but also difficult as it is sometimes unclear what is missing it would be very helpful if the authors could provide and clearly link to a machine readable companion a jupyter notebook would be great but even text or html would be easier to copy paste from than a pdf like the paper with complete runnable code for all the examples originality the edward library is clearly a unique collection of probabilistic inference methods in terms of the paper the main threat to novelty comes from previous publications of the same group the main paper refers to tran et al a which covers a lot of similar material although from a different perspective it is unclear if the other paper has been published or submitted somewhere and if so where significance it seems very likely edward will have a profound impact on the field of bayesian machine learning and deep learning other comments in sec you draw a clear distinction between specialised languages including stan and turing complete languages such as edward this seems unfair as i believe stan is also turing complete additionally no proof is provided to support the turing completeness of edward,8.0
680.json,summary this paper proposes a neural machine translation model that translates the source and the target texts in an end to end manner from characters to characters the model can learn morphology in the encoder and in the decoder the authors use a hierarchical decoder authors provide very compelling results on various bilingual corpora for different language pairs the paper is well written the results are competitive compared to other baselines in the literature review i think the paper is very well written i like the analysis presented in this paper it is clean and precise the idea of using hierarchical decoders have been explored before e g can you cite those papers this paper is mainly an application paper and it is mainly the application of several existing components on the character level nmt tasks in this sense it is good that authors made their codes available online however the contributions from the general ml point of view is still limited some requests can you add the size of the models to the table can you add some of the failure cases of your model where the model failed to translate correctly an overview of the review pros the paper is well written extensive analysis of the model on various language pairs convincing experimental results cons the model is complicated mainly an architecture engineering application paper bringing together various well known techniques not much novelty the proposed model is potentially slower than the regular models since it needs to operate over the characters instead of the words and uses several rnns serban iv sordoni a bengio y courville a pineau j hierarchical neural network generative models for movie dialogues arxiv preprint arxiv jul,6.0
680.json,update after reading the authors responses the paper revision dated dec i have removed the comment insufficient comparison to past work in the title update the score from the main reason for the score is on novelty the proposal of hgru the use of the r matrix are basically just to achieve the effect of whether to continue from character level states or using word level states it seems that these solutions are specific to symbolic frameworks like theano which the authors used and tensorflow this however is not a problem for languages like matlab which luong manning used or torch this is a well written paper with good analysis in which i especially like figure however i think there is little novelty in this work the title is about learning morphology but there is nothing specifically enforced in the model to learn morphemes or subword units for example maybe some constraints can be put on the weights in wi in figure to detect morpheme boundaries or some additional objective like mdl can be used though it not clear how these constraints can be incorporated cleanly moreover i am very surprised that litte comparison only a brief mention was given to the work of luong manning which trains deep layer word character models and achieves much better results on english czech e g bleu compared to bleu achieved in the paper i think the hgru thing is over complicated in terms of presentation if i read correctly what hgru does is basically either continue the character decoder or reset using word level states at boundaries which is what was done in luong manning even make it more efficient by not having to decode all target words at the morpheme level it would be good to know the speed of the model proposed in this iclr submission what end up new in this paper are perhaps different analyses on what a character based model learns adding an additional rnn layer in the encoder one minor comment annotate ht in figure minh thang luong and christopher d manning achieving open vocabulary neural machine translation with hybrid word character models acl,5.0
680.json,the paper presents one of the first neural translation systems that operates purely at the character level another one being,7.0
403.json,the neural turing machine and related external memory models have demonstrated an ability to learn algorithmic solutions by utilizing differentiable analogues of conventional memory structures in particular the ntm dnc and other approaches provide mechanisms for shifting a memory access head to linked memories from the current read position the ntm which is the most relevant to this work uses a differentiable version of a turing machine tape the controller outputs a kernel which softly shifts the head allowing the machine to read and write sequences since this soft shift typically smears the focus of the head the controller also outputs a sharpening parameter which compensates by refocusing the distribution the premise of this work is to notice that while the ntm emulates a differentiable version of a turing tape there is no particular reason that one is constrained to follow the topology of a turing tape instead they propose memory stored at a set of points on a manifold and shift actions which form a lie group in this way memory points can have have different relationships to one another rather than being constrained to z this is mathematically elegant and here they empirically test models with the shift group r acting on r and the rotation group acting on a sphere overall the paper is well communicated and a novel idea the primary limitation of this paper is its limited impact while this approach is certainly mathematically elegant even likely beneficial for some specific problems where the problem structure matches the group structure it is not clear that this significantly contributes to building models capable of more general program learning instead it is likely to make an already complex and slow model such as the ntm even slower in general it would seem memory topology is problem specific and should therefore be learned rather than specified the baseline used for comparison is a very simple model which does not even having the sharpening the ntm approach to solving the problem of head distributions becoming smeared there is also no comparison with the successor to the ntm the dnc which provides a more general approach to linking memories based on prior memory accesses minor issues footnote on page is misleading regarding the dnc while the linkage matrix explicitly excludes the identity the controller can keep the head in the same position by gating the following of the link matrix figures on page are difficult to follow,7.0
403.json,the paper proposes a new memory access scheme based on lie group actions for ntms pros well written novel addressing scheme as an extension to ntm seems to work slightly better than normal ntms some interesting theory about the novel addressing scheme based on lie groups cons in the results the lantm only seems to be slightly better than the normal ntm the result tables are a bit confusing no source code available the difference to the properties of normal ntm does not become too clear esp it is said that lantm are better than ntm because they are differentiable end to end and provide a robust relative indexing scheme but ntm are also differentiable end to end and also provide a robust indexing scheme it is said that the head is discrete in ntm but actually it is in space r n i e it is already continuous it does not become clear what is meant here no tests on real world tasks only some toy tasks no comparisons to some of the other ntm extensions such as d ntm or sparse access memory sam,6.0
403.json,paper summary this paper formalizes the properties required for addressing indexing memory augmented neural networks as well as how to pair the addressing with read write operation it then proposes a framework in which any lie group as the addressing space experiments on algorithmic tasks are reported review summary this paper brings unity and formalism in the requirement for memory addressing while maintaining differentiable memories its proposal provide a generic scheme to build addressing mechanisms when comparing the proposed approach with key value networks the unbounded number of memory cells and the lack of incentive to reuse indexes might reveal impractical detailed review the paper reads well has appropriate relevance to related work the unified presentation of memory augmented networks is clear and brings unity to the field the proposed approach is introduced clearly is powerful and gives a tool that can be reused after reading the article i do not appreciate that the growing memory is not mentioned as a drawback it should be stressed and a discussion on the impact it has on efficiency scalability is needed,8.0
546.json,thank you for an interesting perspective on the neural approaches to approximate physical phenomenon this paper describes a method to extrapolate a given dataset and predict formulae with naturally occurring functions like sine cosine multiplication etc pros the approach is rather simple and hence can be applied to existing methods the major difference is incorporating functions with or more inputs which was done successfully in the paper it seems that mlp even though it is good for interpolation it fails to extrapolate data to model the correct function it was a great idea to use basis functions like sine cosine to make the approach more explicit cons page the claim that x cos ax b cos ax π b x sin ax b x for y in is not entirely correct there should be some restrictions on a and b as well as the approximate equality does not hold for all real values of a and b although for a pi and b pi the claim is correct so the model is predicting a correct solution within certain limits most of the experiments involve up to variables it would be interesting to see how the neural approach models hundreds of variables another way of looking at the model is that the non linearities like sine cosine multiplication act as basis functions if the data is a linear combination of such functions the model will be able to learn the weights as division is not one of the non linearities predicting expressions in equation seems unlikely hence i was wondering is it possible to make sure that this architecture is a universal approximator suggested edits page it seems that there is a typographical error in the expression cos ax π b x sin ax b x when compared with the predicted formula in figure b it should be cos ax π b x sin ax b x,7.0
792.json,inspired by the analysis on the effect of the co label similarity hinton et al this paper proposes a soft target regularization that iteratively trains the network using weighted average of the exponential moving average of past labels and hard labels as target argument of loss they claim that this prevents the disappearing of co label similarity after early training and yields a competitive regularization to dropout without sacrificing network capacity in order to make a fair comparison to dropout the dropout should be tuned carefully showing that it performs better than dropout regularization for some particular values of dropout table does not demonstrate a convincing advantage it is possible that dropout performs better after a reasonable tuning with cross validation the baseline architectures used in the experiments do not belong the recent state of art methods thus yielding significantly lower accuracy it seems also that experiment setup does not involve any data augmentation the results can also change with augmentation it is not clear why number of epochs are set to a small number like without putting some convergence tests therefore the significance of the method is not convincingly demonstrated in empirical study co label similarities could be calculated using softmax results at final layer rather than using predicted labels the advantage over dropout is not clear in figure the dropout is set to without any cross validation regularizing by enforcing the training steps to keep co label similarities is interesting idea but not very novel and the results are not significant pros provides an investigation of regularization on co label similarity during training cons the empirical results do not support the intuitive claims regarding proposed procedure iterative version can be unstable in practice,3.0
511.json,this paper presents an algorithm for approximating the solution of certain time evolution pdes the paper presents an interesting learning based approach to solve such pdes the idea is to alternate between sampling points in space time generating solution to pde at those sampled points regressing a space time function to satisfy the latter solutions at the sampled points and hopefully generalize beyond those points i actually find the proposed algorithm interesting and potentially useful in practice the classic grid based simulation of pdes is often too expensive to be practical due to the curse of dimensionality hence learning the solution of pdes makes a lot of sense for practical settings on the other hand as the authors point out simply running gradient descent on the regression loss function does not work because of the non differentiablity of the min that shows up in the studied pdes therefore i think the proposed idea is actually very interesting approach to learning the pde solution in presence of non differentability which is indeed a challenging setup for numerically solving pdes the paper motivates the problem time evolution pde with min operator applied to the spatial derivatives by applications in control thery but i think there is more direct interest in such problems for the machine learning community and even deep learning community for example,7.0
511.json,approximating solutions to pdes with nn approximators is very hard in particular the hjb and hji eqs have in general discontinuous and non differentiable solutions making them particularly tricky unless the underlying process is a diffusion in which case the ito term makes everything smooth but this paper does not do that what is worse there is no direct correlation between a small pde residual and a well performing policy tsitsiklis beard todorov i forget there been lots of work on this which is not properly cited the d toy examples are inadequate what reason is there to think this will scale to do anything useful there are a bunch of typos range kutta more than anything this paper is submitted to the wrong venue there are no learned representations here you are just using a nn that not what iclr is about resubmit to acc adprl or cdc sorry for terseness despite rough review i absolutely love this direction of research more than anything you have to solve harder control problems for people to take notice,3.0
507.json,this paper introduces a new dataset to evaluate word representations the task considered in the paper called outlier detection also known as word intrusion is to identify which word does not belong to a set of semantically related words the task was proposed by camacho collados navigli as an evaluation of word representations the main contribution of this paper is to introduce a new dataset for this task covering languages the dataset was generated automatically from the wikidata hierarchy entities which are instances of the same category are considered as belonging to the same cluster and outliers are sampled at various distances in the tree several heuristics are then proposed to exclude uninteresting clusters from the dataset developing good ressources to evaluate word representations is an important task the new dataset introduced in this paper might be an interesting addition to the existing ones however it is hard to say by only reviewing the paper i am a bit concerned by the lack of discussion and comparison with existing approaches besides word similarity datasets in particular i believe it would be interesting to discuss the advantages of this evaluation dataset compared to existing ones such as word analogies the proposed evaluation also seems highly related to entity typing which is not discussed in the paper overall i believe that introducing ressources for evaluating word representations is very important for the community however i am a bit ambivalent about this submission i am not entirely convinced that the proposed dataset have clear advantages over existing ressources it also seems that existing tasks such as entity typing already capture similar properties of word representations finally it might be more relevant to submit this paper to lrec than to iclr,5.0
507.json,this paper describes a new benchmark for word representations spotting the odd one out the authors build upon an idea recently presented at the repeval workshop but are able to collect a significantly larger amount of examples by relying on existing ontologies although the innovation is relatively incremental it is an important step in defining challenging benchmarks for general purpose word representations while humans are able to perform this task almost flawlessly given adequate domain knowledge the experiments in this paper show that current embeddings fall short the technical contribution is thorough the dataset construction appears logical and the correlation analysis is convincing i would like to see it accepted at iclr,8.0
507.json,first let me praise the authors for generating and releasing an nlp data set a socially useful task the authors use an algorithm to generate a cluster per language data set in semantic similarity this brings up a few points if the point of using the algorithm is to be scalable why release such a small data set it roughly the same order of magnitude as the data sets released in the semeval tasks over the recent years i would have expected something orders of magnitude larger the authors hand checked a small subset of the clusters they found one where it was ambiguous and should probably have been removed mechanical turk can scale pretty well why not post facto filter all of the clusters using mt this is in effect how imagenet was created and it has millions of items evaluating data set papers is an tricky issue what makes a data set good or publishable there are a number of medium sized nlp data sets released every year e g through semeval those are designed to address tasks in nlp that people find interesting i do not know of a data set that exactly addresses the task that the authors propose the task is trying to address the idea of semantic similarity which has had multiple data sets thrown at it since semeval i wish that the paper had included comparisons to show that the particular task data combination is better suited for analyzing semantic similarity than other existing data sets two final notes a this paper does not seem very well suited to iclr new nlp data sets may be indirectly useful for evaluating word embeddings and hence representations but i did not learn much from the paper glove is empirically less good for semantic similarity than other embeddings if true why that would be interesting b the first proposal for the put a word into a cluster and see if it stands out task in the context of human evaluation of topic models is jonathan chang jordan boyd graber chong wang sean gerrish and david m blei reading tea leaves howhumans interpret topic models neural information processing systems which deserves a citation i think,6.0
696.json,the paper aims to consolidate some recent literature in simple types of reading comprehension tasks involving matching questions to answers to be found in a passage and then to explore the types of structure learned by these models and propose modifications these reading comprehension datasets such as cnn daily mail are on the simpler side because they do not generally involve chains of reasoning over multiple pieces of supporting evidence as can be found in datasets like mctest many models have been proposed for this task and the paper breaks down these models into aggregation readers and explicit reference readers the authors show that the aggregation readers organize their hidden states into a predicate structure which allows them to mimic the explicit reference readers the authors then experiment with adding linguistic features including reference features to the existing models to improve performance i appreciate the re naming and re writing of the paper to make it more clear that the aggregation readers are specifically learning a predicate structure as well as the inclusion of results about dimensionality of the symbol space further i think the effort to organize and categorize several different reading comprehension models into broader classes is useful as the field has been producing many such models and the landscape is unclear the concerns with this paper are that the predicate structure demonstrated is fairly simple and it is not clear that it provides insight towards the development of better models in the future since the explicit reference readers need not learn it and the cnn daily mail dataset has very little headroom left as demonstrated by chen et al the desire for dramatic improvements in performance mentioned in the discussion section probably cannot be achieved on these datasets more complex datasets would probably involve multi hop inference which this paper does not discuss further the message of the paper is a bit scattered and hard to parse and could benefit from a bit more focus i think that with the explosion of various competing neural network models for nlp tasks contributions like this one which attempt to organize and analyze the landscape are valuable but that this paper might be better suited for an nlp conference or journal such as tacl,6.0
696.json,this paper aims to provide an insightful and analytic survey over the recent literature on reading comprehension with the distinct goal of investigating whether logical structure or predication as the authors rephrased in their response arises in many of the recent models i really like the spirit of the paper and appreciate the efforts to organize rather chaotic recent literature into two unified themes aggregation readers and explicit reference models overall the quality of writing is great and section was especially nice to read i m also happy with the proposed rewording from logical structure to predication and the clarification by the authors was detailed and helpful i think i still have slight mixed feelings about the contribution of the work first i wonder whether the choice of the dataset was ideal in the first place to accomplish the desired goal of the paper there have been concerns about cnn dailymail dataset chen et al acl and it is not clear to me whether the dataset supports investigation on logical structure of interesting kinds maybe it is bound to be rather about lack of logical structure second i wish the discussion on predication sheds more practical insights into dataset design or model design to better tackle reading comprehension challenges in that sense it may have been more helpful if the authors could make more precise analysis on different types of reading comprehension challenges what types of logical structure are lacking in various existing models and datasets and point to specific directions where the community needs to focus more,6.0
696.json,the paper proposed to analyze several recently developed machine readers and found that some machine readers could potentially take advantages of the entity marker given that the same marker points out to the same entity i usually like analysis papers but i found the argument proposed in this paper not very clear i like the experiments on the stanford reader which shows that the entity marker in fact helps the stanford reader on wdw i found that results rather interesting however i found the organization and the overall message of this paper quite confusing first of all it feels that the authors want to explain the above behavior with some definition of the structures however i am not sure that how successful the attempt is for me it is still not clear what the structures are this makes reading section a bit frustrating i am also not sure what is the take home message of this paper does it mean that the entity marking should be used in the mr models should we design models that can also model the entity reference at the same time what are the roles of the linguistic features here should we use linguistic structure to overcome the reference issue overall i feel that the analysis is interesting but i feel that the paper can benefit from having a more focused argument,5.0
415.json,the author proposed a simple but yet effective technique in order to regularized neural networks the results obtained are quite good and the technique shows to be effective when it it applied even on state of the art topologies that is welcome because some regularization techniques used to be applied in easy task or on a initial configuration which results are still far from the best known results,7.0
415.json,the paper proposes a new regulariser for cnns that penalises positive correlations between feature weights but does not affect negative correlations an alternative version which penalises all correlations regardless of sign is also considered the paper refers to these as local and global respectively which i find a bit confusing as these are very general terms that can mean a plethora of things the experimental validation is quite rigorous several experiments are conducted on benchmark datasets mnist cifar cifar svhn and improvements are demonstrated in most cases while these improvements may seem modest the baselines are already very competitive as the authors pointed out in some cases it does raise some questions about statistical significance though more results with the global regulariser i e not just on mnist would have been interesting as the main novelty in the paper seems to be leaving the negative correlations alone so it would be interesting to see exactly how much of a difference this makes one of my main concerns is ambiguity stemming from the fact that the paper sometimes discusses activations and sometimes filter weights but refers to both as features however the authors have already said they will address this the paper somewhat ignores interactions with the choice of nonlinearity which seems like it could be very important especially because the goal is to obtain feature activations that are uncorrelated and this is done only by applying a penalty to the weights i e in a data agnostic way and also ignoring any nonlinearity i believe the authors already mentioned in their responses to reviewer questions that this would be addressed but i think this important and it definitely needs to be discussed in response to the authors answer to my question about the role of biases as they point out it is perfectly possible to combine their proposed technique with the multi bias approach but this was not really my point rather the latter is an example that challenges the idea that features should not be positively correlated redundant which seems to be the assumption that this work is built upon my current intuition is that it okay to have correlated features as long as you are not wasting model capacity on them this is the case for multi bias seeing as the weights are shared across sets of correlated features the dichotomy between regularisation methods that reduce capacity and those that do not which is described in the introduction seems a bit arbitrary to me especially considering that weight decay is counted among the former and the proposed method is counted among the latter i think this very much depends on ones definition of model capacity clearly weight decay does not actually reduce the number of parameters in a model overall the work is perhaps a bit incremental but it seems to be well executed the results are convincing even if they are not particularly ground breaking,7.0
550.json,the paper proposes a modified dae objective where it is the mapped representation of the corrupted input that is pushed closer to the representation of the uncorrupted input this thus borrows from both denoising dae for the stochasticity and from the contractive cae auto encoders objectives which the paper doesn t compare to for the representational closeness and as such appears rather incremental in common with the cae a collapse of the representation can only be avoided by additional external constraints such as tied weights batch normalization or other normalization heuristics while i appreciates that the authors added a paragraph discussing this point and the usual remediations after i had raised it in an earlier question i think it would deserve a proper formal treatment note that such external constraints do not seem to arise from the information theoretic formalism as articulated by the authors this casts doubt regarding the validity or completeness of the proposed formal motivation as currently exposed what the extra regularization does from an information theoretic perspective remains unclearly articulated e g interpretation of lambda strength on the experimental front empirical support for the approach is very weak few experiments on synthetic and small scale data the modified dae test errors on mnist are larger than those of original dae all the time expect for one precise setting of lambda and then the original dae performance is still within the displayed error bar of the modified dae so it is unclear whether the improvement is actually statistically significant,4.0
550.json,the work introduced a new form of regularization for denoising autoencoders which explicitly enforces robustness in the encoding phrase w r t input perturbation the author motivates the regularization term as minimizing the conditional entropy of the encoding given the input the modifier denoising autoencoders is evaluated on some synthetic datasets as well as mnist along with regular auto encoders and denoising autoencoders the work is fairly similar to several existing extensions to auto encoders e g contractive auto encoders which the author did not include in the comparison the experiment section needs more polishing more details should be provided to help understand the figures in the section,4.0
550.json,the paper proposes to add an additional term to the denoising autoencoder objective the new term is well motivated it introduces an asymmetry between the encoder and decoder forcing the encoder to represent a compressed denoised version of the input the authors propose to avoid the trivial solution introduced by the new term by using tied weights or normalized euclidean distance error the trivial solution occurs by scaling the magnitude of the code down in the encoder and back up in the decoder the proposed auto encoder scheme is very similar to a host of other auto encoders that have been out in the literature for some time the authors evaluate the proposed scheme on toy data distributions in d as well as mnist although the work is well motivated it certainly seems like an empirically unproven and incremental improvement to an old idea,5.0
317.json,the paper presents a new framework to solve the sr problem amortized map inference and adopts a pre learned affine projection layer to ensure the output is consistent with lr also it proposes three different methods to solve the problem of minimizing cross entropy generally it is a great paper however i still have several comments the proposed amortized map inference is novel and different from the previous sr methods combined with gan this framework can obtain plausible and good results compared with another gan based sr methods photo realistic single image super resolution using a generative adversarial network question may arise as to what this new formulation adds to the latest state of the art using an affine projection architecture as a constraint the model do not need any corresponding hr lr image pairs for training however when training the affine projection layer we still need the hr lr image pairs does it mean that we merely transfer this training procedure to the training of affine projection the paper presents many results of the framework including the results of natural images from imagenet can the author also provide the results of set set or bsd which are conventional test dataset for sr so that we can perform a fair comparison with previous work i see that the size of the results of nature images presented in this paper are limited to can this framework perform well on images with larger size because sr will encounter input with arbitrary size a normal gan will have a noise term as a latent space so that it can be better illustrated as learning a distribution do the author try the noise vector overall this paper provides a new framework for sr with solid theoretical analysis the idea is novel and the author explore many methods though there still exist questions like the necessity and more experiments are needed i think this work will will provide good inspiration to the community,8.0
317.json,sincere apologies for the late review this paper argues to approach super resolution as amortised map estimation a projection step to keep consistent hr lr dependencies is proposed and experimentally verified to obtain better results throughout further three different methods to solve the resulting cross entropy problem in eq are proposed and tested summary very good paper very well written and presented experimental results are sufficient the paper presents well chosen toy examples and real world applications from my understanding the contributions for the field of super resolutions are novel parts that are specific for the training of gans may have appeared in different variants elsewhere see also discussion i believe that this paper will be relevant to future work on super resolution the finding that gan based model training yields most visually appealing results suggests further work in this domain manuscript should be proof read once more there were some very few typos that may be worth fixing,9.0
747.json,this paper proposes a new method interior gradients for analysing feature importance in deep neural networks the interior gradient is the gradient measured on a scaled version of the input the integrated gradient is the integral of interior gradients over all scaling factors visualizations comparing integrated gradients with standard gradients on real images input to the inception cnn show that integrated gradients correspond to an intuitive notion of feature importance while motivation and qualitative examples are appealing the paper lacks both qualitative and quantitative comparison to prior work only the baseline simply the standard gradient is presented as reference for qualitative comparison yet the paper cites numerous other works deeplift layer wise relevance propagation guided backpropagation that all attack the same problem of feature importance lack of comparison to any of these methods is a major weakness of the paper i do not believe it is fit for publication without such comparisons my pre review question articulated this same concern and has not been answered,3.0
602.json,summary the authors propose a multi hop gated attention model which models the interactions between query and document representations for answering cloze style questions the document representation is attended to sequentially over multiple hops using similarity with the query representation using a dot product as the scoring attention function the proposed method improves upon cnn daily mail who did what datasets or is comparable to cbt dataset the state of the art results pros nice idea on heirarchical attention for modulating the context document representation by the task specific query representation the presentation is clear with thorough experimental comparison with the latest results comments the overall system presents a number of architectural elements attention at multiple layers multi hop query based attention for the context or gated attention encoding the query vector at each layer independently it is important to breakdown the gain in performance due to the above factors the ablation study presented in section helps establish the importance of gated attention above however it is not clear how much multiple hops of gated attention contribute to the performance how important is it to have a specialized query encoder for each layer understanding the above better will help simplify the architecture the tokens are represented using l w and c w it is not clear if c w is crucial for the performance of the proposed method there is a significant performance drop when c w is absent e g in ga reader although there are other changes in ga reader which could affect the performance hence it is not clear how much does the main idea i e gated attention contributes towards the superior performance of the proposed method,6.0
602.json,this paper presents an interesting idea for iteratively re weighting the word representations in a document hence the gru coded doc representation as well with a simple multiplication operation as the authors correctly pointed out such an operation serves as a filter to reduce the attentions to less relevant parts in the document hence leading to better performance of the modeling the results are or close to the state of the art for a few cloze style qa tasks this paper would deserve an even higher score if the following limitations could be addressed better while interesting and conceptually simple though with significant increased computational overheads the architecture proposed in the paper is for a very specific task the improvement of the main idea of this paper gated attention is less significant comparing ga reader vs ga reader while the latter includes a number of engineering tricks such as adding character embedding and using a word embedding trained from larger corpus glove as well as some small improvements on the modeling by using token specific attention in i also wish the authors can shed more lights on what a role the k number of hops plays both intuitively and empirically i feel more insights could be obtained if we do more deeper analysis of k impacts to different types of questions for example,6.0
481.json,this paper investigate the phenomenon of the adversarial examples and the adversarial training on the dataset of imagenet while the final conclusions are still vague this paper raises several noteworthy finding from its experiments the paper is well written and easy to follow although i still have some concerns about the paper see the comments below this paper has good contributions and worth to publish pros for the first time in the literature this paper proposed the concept of label leaking although its effect only becomes significant when the dataset is large it should be carefully handled in the future research works along this line using the ratio of clean accuracy over adversarial accuracy as the measure of robust is more reasonable compared to the existing works in the literature cons although the conclusions of the paper are based on the experiments on imagenet the title of the paper seems a little misleading i consider section as the main contribution of the paper note that section and section are not specific to large scale dataset thus emphasizing the large scale in the title and in the introduction seems improper basically all the conclusions of the paper are made based on observing the experimental results further tests should have been performed to verify these hypotheses without that the conclusions of the paper seems rushy for example one dataset of imagenet can not infer the conclusions for all large scale datasets,6.0
481.json,this paper is a well written paper this paper can be divided into parts adversary training on imagenet empirical study of label leak single multiple step attack transferability and importance of model capacity for part i don t think training without clean example will not make reasonable imagenet level model ian s experiment in explaining and harnessing adversarial examples did not use batchnorm which may be important for training large scale model this part looks like an extension to ian s work with inception v model i suggest to add an experiment of training without clean samples for part the experiments cover most variables in adversary training yet lack technical depth the depth model capacity experiments can be explained by regularizer effect of adv training label leaking is novel in transferability experiment with fgsm if we do careful observe on some special mnist fgsm example we can find augmentation effect on numbers which makes grey part on image to make the number look more like the other numbers although this effect is hard to be observed with complex data such as cifar or imagenet they may be related to the authors observation fgsm examples are most transferable in this part the authors raise many interesting problems or guess but lack theoretical explanations overall i think these empirical observations are useful for future work,6.0
710.json,this paper presented an unsupervised approach for the automatic segmentation of bioacoustic data the authors applied an existing approach hierarchical dirichlet process hidden markov models to their task the originality of their work is the investigation of this approach on a new task which they argue is more difficult namely bioacoustic segmentation they provide evidence that this is a difficult task by explaining that there does not exist a consensus among human experts on how this should be done however they do not provide convincing results that their approach is successful as it fails in many cases to replicate the correct segmentations as defined by their baseline human experts in addition the clarity of the writing is extremely poor including many grammatical errors and awkward sentences,4.0
655.json,update i thank the author for his comments at this point the paper is still not suitable for publication so i am leaving the rating untouched this paper proposes a transfer learning method addressing optimization complexity and class imbalance my main concerns are the following the paper is quite hard to read due to typos unusual phrasing and loose use of terminology like distributed transfer learning meaning fine tuning softmax meaning fully connected deep learning meaning base neural network etc i m still not sure i got all the details of the actual algorithm right the captions to the figures and tables are not very informative one has to jump back and forth through the paper to understand what the numbers images mean from what i understand the authors use conventional transfer learning to refer to fine tuning of the fully connected layers only i m judging by figure in this case it s essential to compare the proposed method with regimes when some of the convolutional layers are also updated this comparison is not present in the paper comments on the pre review questions question if the paper only considers the case c l it would be better to reduce the notation clutter question it is still not clear what the authors mean by distributed transfer learning figure is supposed to highlight the difference from the conventional approach fine tuning of the fully connected layers by the way i don t think softmax is a conventional term for fully connected layers from the diagram it follows that the base cnn has the same number of convolutional filters at every layer and in order to obtain a distributed ensemble we need to connect for some reason filters with the same indices this does not make a lot of sense to me but i m probably misinterpreting the figure could the authors revise the diagram to make it clearer overall i think the paper needs significant refinement in order improve the clarity of presentation and thus cannot be accepted as it is now,3.0
593.json,this paper investigates deep generative models with multiple stochastic nodes and gives them meaning by semi supervision from a methodological point of view there is nothing fundamentally novel it is very similar to the semi supervised work of kingma et al although this work has sometimes more than two latent nodes it is not a complex extension there is a fairly classical auxiliary variable trick used to make sure the inference network for y is trained over all data points by supposing y is in fact is a latent variable with an observation tilde y the observation is y if y is observed or uninformative for unobserved y alternatively one can separate the inference used to learn the generative model which throws out inference over y if it is observed from an inference used to exercise the model approximate the complex p y x in the model by a simpler q y x effectively inferring the target p y x for the data where only x is collected results are strong although on simple datasets overall this is a well written interesting paper but lacking in terms of methodological advances minor i feel the title is a bit too general for the content of the paper i personally do not agree with the strong contrast made between deep generative models and graphical models deep generative models are graphical models but they are more typically learned and un interpretable than classical graphical models and having multiple stochastic variables is not exclusive to graphical models see draw deep kalman filter recurrent vae etc the word tructure is a bit problematic here the paper seems more concerned with disentangling and semanticizing the latent representation of a generative model by supervision it is debatable whether the models themselves have structure,6.0
439.json,this is a good paper well written that presents a simple but effective approach to predict code properties from input output pairs the experiments show superiority to the baseline with speedup factors between one to two orders of magnitude this is a solid gain the domain of programs is limited so there is more work to do in trying such ideas on more difficult tasks using neural nets to augment the search is a good starting point and a right approach instead of generating full complex code i see this paper as being above the threshold for acceptance,6.0
439.json,this paper presents an approach to learn to generate programs instead of directly trying to generate the program the authors propose to train a neural net to estimate a fix set of attributes which then condition a search procedure this is an interesting approach which make sense as building a generative model of programs is a very complex task faster computation times are shown in the experimental section with respect to baselines including dfs enumeration etc in a setup with very small programs of length up to instructions have to be found it is not clear to me how the proposed approach scales to larger programs where perhaps many attributes will be on is there still an advantage the authors use as metric the time to find a single program whose execution will result in the set of input output pairs given as input however as mentioned in the paper one is not after a generic program but after the best program or a rank list of all programs or top k programs that result in a correct execution could the authors show experiments in this setting would still be useful to have the proposed approach what would the challenges be in this more realistic scenario in the second experiment the authors show results where the length of the program at training time is different than the length at test time however the results are shown when only of the programs are finished could you show results for finding all programs the paper is missing an analysis of the results what type of programs are difficult how often is the nnet wrong how does this affect speed what are the failure modes of the proposed method the authors proposed to have a fix length representation of the each input output pair and then use average pooling to get the final representation however why would average pooling make sense here would it make more sense to combine the predictions at the decoder not the encoder learning from only executions seems very difficult to me for programs so small it might be ok but going to more difficult and longer programs this setting does not seem reasonable in summary an interesting paper this paper tackles a problem that is outside my area of expertise so i might have miss something important,7.0
706.json,the authors introduce some new prior and approximate posterior families for variational autoencoders which are compatible with the reparameterization trick as well as being capable of expressing multiple modes they also introduce a gating mechanism between prior and posterior they show improvements on bag of words document modeling and dialogue response generation the original abstract is overly strong in its assertion that a unimodal latent prior p z cannot fit a multimodal marginal intz p x z p x dz with a dnn response model p x z it cannot possibly capture more complex aspects of the data distribution critical restriction etc while the assertion that a unimodal latent prior is necessary to model multimodal observations is false there are sensible motivations for the piecewise constant prior and posterior for example if we think of a vae as a sort of regularized autoencoder where codes are constrained to fill up parts of the prior latent space then there is a sphere packing argument to be made that filling a gaussian prior with gaussian posteriors is a bad use of code space although the authors do not explore this much a hypercube based tiling of latent code space is a sensible idea as stated i found the message of the paper to be quite sloppy with respect to the concept of multi modality there are types of multimodality at play here multimodality in the observed marginal distribution p x which can be captured by any deep latent gaussian model multimodality in the prior p z which makes sense in some situations e g a model of mnist digits could have prior modes corresponding to latent codes for each digit class and multimodality in the posterior z for a given observation xi q zi xi the final type of multimodality is harder to argue for except in so far as it allows the expression of flexibly shaped distributions without highly separated modes i believe flexible posterior approximations are important to enable fine grained and efficient tiling of latent space but i do not think these need to have multiple strong modes i would be interested to see experiments demonstrating otherwise for real world data i think this paper should be more clear about the different types of multi modality and which parts of their analysis demonstrate which ones i also found it unsatisfactory that the piecewise variable analysis did not show different components of the multi modal prior corresponding to different words but rather just a separation between the gaussian and the piecewise variables as i mention in my earlier questions i found it surprising that the learned variance and mean for the gaussian prior helps so dramatically with g nvdm likelihood when the powerful networks transforming to and from latent space should make it scale invariant explicitly separating out the contributions of a reimplemented base model prior posterior interpolation and the learned prior parameters would strengthen these experiments overall the very strong improvements on the text modeling task over nvdm seem hard to understand and i would like to see an ablation analysis of all the differences between that model and the proposed one the fact that adding more constant components helps for document modeling is interesting and it would be nice to see more qualitative analysis of what the prior modes represent i also would be surprised if posterior modes were highly separated and if they were it would be interesting to explore if they corresponded to e g ambiguous word senses the experiments on dialog modeling are mostly negative results quantitatively the observation that the the piecewise constant variables encode time related words and the gaussian variables encode sentiment is interesting especially since it occurs in both sets of experiments this is actually quite interesting and i would be interested in seeing analysis of why this is the case as above i would like to see an analysis of the sorts of words that are encoded in the different prior modes and whether they correspond to e g groups of similar holidays or days in conclusion i think the piecewise constant variational family is a good idea although it is not well motivated by the paper the experimental results are very good for document modeling but without ablation analysis against the baseline it is hard to see why they should be with such a small modification in g nvdm the fact that h nvdm performs better is interesting though this paper should better motivate the need for different types of multi modality and demonstrate that those sorts of things are actually being captured by the model as it is the paper introduces an interesting variational family and shows that it performs better for some tasks but the motivation and analysis is not clearly focused to demonstrate that this is a broadly applicable family it would also be good to do experiments on a more standard datasets like mnist even without an absolute log likelihood improvement if the method yielded interpretable multiple modes this would be a valuable contribution,4.0
643.json,the authors propose a simple modification of online dictionary learning inspired by neurogenesis they propose to add steps of atom addition or atom deletion in order to extent the online dictionary learning algorithm algorithm of mairal et al such extensions helps to adapt the dictionary to changing properties of the data the online adaptation is very interesting even if it is quite simple the overall algorithm is quite reasonable but not always described in sufficient details for example the thresholds or conditions for neuronal birth or death are not supported by a strong analysis even if the resulting algorithm seems to perform well on quite extensive experiments the overall idea is nevertheless interesting even if not completely new and the paper generally well written and pretty easy to follow the analysis is however quite minimal it could have been interesting to study the evolving properties of the dictionary to analyse its accuracy for following the changes in the data etc still this is a nice work,7.0
643.json,i would like to thank the authors for their detailed response and clarifications this work proposes new training scheme for online sparse dictionary learning the model assumes a non stationary flow of the incoming data the goal and the challenge is to learn a model in an online manner in a way that is capable of adjusting to the new incoming data without forgetting how to represent previously seen data the proposed approach deals with this problem by incorporating a mechanism for adding or deleting atoms in the dictionary this procedure is inspired by the adult neurogenesis phenomenon in the dentate gyrus of the hippocampus the paper has two main innovations over the baseline approach mairal et al i neuronal birth which represents an adaptive way of increasing the number of atoms in the dictionary ii neuronal death which corresponds to removing useless dictionary atoms neural death is implemented by including an group sparsity regularization to the dictionary atoms themselves the group corresponds to a column of the dictionary this promotes to shrink to zero atoms that are not very useful keeping controlled the increase of the dictionary size i believe that the strong side of the paper is its connections with the adult neurogenesis phenomenon which is in my opinion a very nice feature the paper is very well written and easy to follow on the other hand the overall technique is not very novel although not exactly equivalent similar ideas have been explored while the neural death is implemente elegantly with a sparsity promoting regularization term the neural birth is performed by relying on heuristics that measure how well the dictionary can represent new incoming data which depending on the level of non stationarity in the incoming data or presence of outliers could be difficult to set still having adaptive dictionary size is very interesting the authors could also cite some references in model selection literature in particular some ideas such as mdl have been used for automatically selecting the dictionary size i believe this work does not address the online setting but still its a relevant reference to have for instance ramirez ignacio and guillermo sapiro an mdl framework for sparse coding and dictionary learning ieee transactions on signal processing,5.0
751.json,this paper presents a heuristic for avoiding large negative rewards which have already been experienced by distilling such events into a danger model the paper is well written including some rather poetic language the heuristic is evaluated in two toy domains i would think that in order to properly evaluate this one would use a well known benchmark e g atari atari seems particularly apt since those games are full of catastrophes i e sudden death this reviewer favourite quotes imagine a self driving car that had to periodically hit a few pedestrians in order to remember that it s undesirable the child can learn to adjust its behaviour without actually having to stab someone the catastrophe lurking just past the optimal shave,5.0
751.json,the topic of keeping around highly rewarding or dangerous states is important and has been studied extensively in the rl literature after the pre review comments authors do mention that they compared against expected sarsa but i would really like to see these and other extensive baselines before accepting this paper there is also an increasing amount of literature of using reward replay buffers in deep rl agents c f jaderberg max et al reinforcement learning with unsupervised auxiliary tasks blundell charles et al model free episodic control narasimhan et al language understanding for text based games using deep reinforcement learning which could perhaps reinforce the agent to avoid revisiting catastrophic states overall the approach presented is not very principled for instance why is not catastrophe directly provided as a signal to the learner instead of a separate model,4.0
791.json,this paper proposes an unsupervised training objective based on patch contrasting for visual representation learning using deep neural networks in particular the feature representations of the patches from the same image are encouraged to be closer than the those from different images the distance ratios of positive training pairs are optimized the proposed method are empirically shown to be effective as an initialization method for supervised training strengths the training objective is reasonable in particular high level features show translation invariance the proposed methods are effective for initializing neural networks for supervised training on several datasets weaknesses the methods are technically similar to the exemplar network dosovitskiy cropping patches from a single image can be taken as a type of data augmentation which is comparable to the data augmentation of positive sample the exemplar in dosovitskiy the paper is experimentally misleading the results reported in this paper are based on fine tuning the whole network with supervision however in table the results of exemplar convnets dosovitskiy is from unsupervised feature learning the network is not finetuned with labeled samples and only a classifier is trained upon the features therefore the comparison is not fair i suspect that exemplar convnets dosovitskiy would achieve similar improvements from fine tuning so without such comparisons head to head comparison with and without fine tuning based on the same architecture except for the loss the experimental results are not fully convincing regarding the comparison to what where autoencoder zhao et al it will be interesting to compare against it in large scale settings as shown by zhang et al icml augmenting supervised neural networks with unsupervised objectives for large scale image classification training an alexnet is not very time consuming with latest e g titan x level gpus the proposed method seems useful only for natural images where different patches from the same image can be similar to each other,5.0
791.json,the proposed self supervised loss is formulated using a siamese architecture and encourages patches from the same image to lie closer in feature space than a contrasting patch taken from a different random image the loss is very similar in spirit to that of doersch et al iccv and isola et al iclr workshop it seems that the proposed loss is actually a simplified version of doersch et al iccv in that it does not make use of the spatial offset a freely available self supervised signal in natural images intuitively it seems that the self supervised problem posed by this method is strictly simpler and therefore less powerful than that of the aforementioned work i would like to see more discussion on the comparison of these two approaches nevertheless the proposed method seems to be effective in achieving good empirical results using this simple loss though more implementation details should be provided such as the effect of patch size overlap between sampled patches and any other important measures taken to avoid trivial solutions,6.0
791.json,this paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting though likely applicable to fully connected nets as well the method is that of spatial constrasting i e of building triplets from patches of input images and learning a presentation that assigns a high score for patches coming from the same image and a low score for patches from diferent images the method is simple enough that i am surprised that no one has tried this before at least according to the previous work in the submission here are some comments the usage of p fi fi in section is a bit odd may be worth defining mathematically what kind of probability the authors are talking about or just taking that part out probability can be replaced with another word i would like to know more about how the method is using the batch statistics end of section by sampling from it unless the authors simply mean that the just sample from all the possible triples in their batch shouldn t the number of patches sampled in algorithm be a hyper parameter rather than just be have the authors tried any other value i think there are some missing details in the paper like the patch size or whether the authors have played with it at all i think this is an important hyper parameter the stl results are quite impressive but cifar maybe not so much for cifar i d expect that one can try to pre train on say imagenet cifar to build a better representation have the authors considered this all in all this is an interesting piece of work with some obvious applications and it seems relatively straightforward to implemenent and try i think i would ve liked more understanding of what the spatial contrasting actually learns more empirical studies on the effects of various parameter choices e g patch size and more attempts at beating the state of the art e g cifar,7.0
590.json,the paper proposed an end to end machine learning model called dynamic reader for the machine reading comprehension task compared to earlier systems the proposed model is able to extract and rank a set of answer candidates from a given document there are many recent models focusing on building good question answering systems by extracting phrases from a given article it seems that there are two different aspects that are unique in this work the use of convolution model and dynamic chunking convolution network is often only used for modeling character based word embeddings so i am curious about its effectiveness on representing phrases therefore i wish there could be more analysis on how effective it is as the authors do not compare the convolution framework to other alternative approaches such as lstm the comparisons are important as the authors uses uni gram bi gram and tri gram information in the convolution network and it is not clear to me that if tri gram information is still needed for lstm models the dynamic chunking is a good idea and a very similar idea is proposed in some of the recent papers such as kenton et al which also targets at the same dataset however i would like to see more analysis on the dynamic chunking why this approach is a good approach for representing answer chunks given the representation of the chunk is constructed by the first and the end word representations generated by a convolution network i am not sure about the ability of this representation to capture the long answer phrases the authors do not use character base embedding but use some of the previous trained nlp models it would be interesting if the authors could show what are the advantages and disadvantages of using linguistic features compared to character embeddings in short there are several good ideas proposed in the paper but the lack of proper analysis make it difficult to judge how important the proposed techniques are,5.0
590.json,summary the paper propose a reading comprehension question answering system for the recent qa task where answers of a question can be either single tokens or spans in the given text passage the model first encodes the passage and the query using a recurrent neural network with an attention mechanism the model calculates the importance of each word on the passage with respect to each word in the question the encoded words in the passage are concatenated with the attention the resulting vector is re encoded with a further rnn three convolutional neural networks with different filter size gram are used to further capture local features candidate answers are selected either matching pos patterns of answers in the training set or choosing all possible text span until a certain length each candidate answer has three representations one for each n gram representation the compatibility of these representation with the question representation is then calculated the scores are combined linearly and used for calculating the probability of the candidate answer being the right answer for the question the method is tested on the squad dataset and outperforms the proposed baselines overall judgment the method presented in this paper is interesting but not very motivated in some points for example it is not explained why in the attention mechanism it is beneficial to concatenate the original passage encoding with the attention weighted ones the contributions of the paper are moderately novel proposing mainly the attention mechanism and the convolutional re encoding in fact combining questions and passages and score their compatibility has became a fairly standard procedure in all qa models detailed comments equation i should be s not s l i still do not understand the sentence the best function is to concatenate the hidden stat of the fist word in a chunk in forward rnn and that of the last word in backward rnn the rnn is over what all the words in the chunk in the passage the answer the authors gave in the response does not clarify this point,6.0
355.json,the paper describes approaches taken to train learning agents for the d game doom the authors propose a number of performance enhancements curriculum learning attention zoomed in centered frames reward shaping game variables post training rules inspired by domain knowledge the enhancements together lead to a clear win as demonstrated by the competition results from fig the curriculum learning clearly helps with learning over increasingly difficult settings a nice result is that there is no overfitting to the harder classes once they have learned probably because the curriculum is health and speed the authors conclude from fig that the adaptive curriculum is better and more stable that pure ac however this is a bit of a stretch given that graph they go on to say that pure ac does not learn at all in the harder map but then show no result graph to back this claim tbl shows a clear benefit of the post training rules if the goal is to solve problems like these d shooters then this paper makes a significant contribution in that it shows which techniques are practical for solving the problem and ultimately improving performance in these kinds of tasks still i am just not excited about this paper mainly because it relies so heavily of many sources of domain knowledge it is quite far from the pure reinforcement learning problem the results are relatively unsurprising maybe they are novel for this problem though i am not sure we can realistically draw any conclusions about figure in the paper current form i recommend the authors increase the resolution or run some actual metrics to determine the fuzziness clarity of each row image something more concrete than an arrow of already low resolution images added after rebuttal i still do not see any high res images for figure or any link to them but i trust that the authors will add them if accepted,6.0
355.json,this paper basically applies ac to d spatial navigation tasks this is not the first time ac has been applied to d navigation in fact the original paper reported these experiments although the experimental results are great i am not sure if this paper has any additional insights to warrant itself as a conference paper it might make more sense as a workshop paper are the graphs in fig constructed using a single hyper parameter sweep i think the authors should report results with many random initializations to make the comparisons more robust overall the two main ideas in this paper ac and curriculums are not really novel but the authors do make use of them in a real system,4.0
355.json,this is a solid paper that applies ac to doom enhancing it with a collection of tricks so as to win one of the vizdoom competitions i think it is fair to expect the competition aspect to overshadow the more scientific approach of justifying every design decision in isolation but in fact the authors do a decent job at the latter two of my concerns have remained unanswered see anonreviewer below in addition the citation list is rather thin for example reward shaping has a rich literature as do incrementally more difficult task setups dating back at least to mark ring s work in the s there has also been a lot of complementary work on other fps games i m not asking that the authors do any direct comparisons but to give the reader a sense of context in which to place this,7.0
375.json,this paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation this paper also shows the connection between this new weighting scheme and some previous work here are some comments on technical details the word discourse is confusing i am not sure whether the words discourse in discourse vector cs and the one in most frequent discourse have the same meaning is there any justification about c related to syntac not sure what thie line means in fact the new model was discovered by our detecting the common component c in existing embeddings in section computing the sentence embedding is there any explanation about the results on sentiment in table,7.0
621.json,the paper tackles the task of music generation they use an orderless nade model for the task of fill in the notes given a roll of t timesteps of pitches they randomly mask out some pitches and the model is trained to predict the missing notes this follows how the orderless nade model can be trained during sampling one normally follows an ancestral sampling procedure for this an ordering is defined over outputs and one runs the model on the current input samples one of the outputs according to the order adds this output to the next input and continues this procedure until all outputs have been sampled the key point of the paper is that this is a bad sampling strategy instead they suggest the strategy of yao et al which uses a blocked gibbs sampling approach the blocked gibbs strategy instead masks n inputs randomly and independently samples them and repeats this procedure the point of this strategy is the make sure the sampling chain mixes well which will happen for large n however since the samples are independent having a large n gives incoherent samples thus the authors follow an annealed schedule for n making it smaller over time which will eventually reduce to ancestral sampling giving global structure to the sample they conduct a variety of experiments involving both normal metrics and human evaluations and find that this blocked gibbs sampling outperforms other sampling procedures this is a well written paper great job my main problem with the paper is that having read uria and yao i do not know how much i have learned from this work in the context of this being an iclr submission if this was submitted to some computational music art conference this paper would be a clear accept however for iclr i do not see enough novelty compared with previous works this builds upon orderless nade is an established model the blocked gibbs sampling and annealing scheme are basically the exact same one used in yao thus the main novelty of this paper is its application to the music domain and finding that yao method works better for sampling music this is a good contribution but more tailored to those working in the music domain if the authors found that these results also hold for other domains like images e g on cifar tiny imagenet and text e g document generation then i would change my mind and accept this paper for iclr even just trying musical domains other than bach chorales would be useful however as it stands the experiments are not convincing enough,5.0
621.json,the paper presents a way to model the distribution of four part bach chorales using convolutional neural networks furthermore it addresses the task of artificial music generation by sampling from the model using blocked gibbs sampling and shows the cnn model for the distribution seems very appropriate for the data at hand also the analysis of the proposed sampling schemes with the analogy between gibbs sampling and human music composition are very interesting i am not too sure about the evaluation though since the reported likelihoods are not directly comparable to previous work i have difficulties judging the quality of the quantitative results for the human evaluation i would like to see the data for the direct comparisons between the models e g how did nade vs bach perform also i find the question what piece of music do you prefer a stronger test than the question what piece is more musical to you because i don t really know what musical means to the amt workers finally while i think the bach chorales are interesting musical pieces that deserve to be subject of the analysis but i find it hard to judge how well this modelling approach will transfer to other types of music which might have a very different data distribution nevertheless in conclusion i believe this is an exciting model for an interesting task that produces non trivial musical data,6.0
733.json,this paper presents an anomaly based host intrusion detection method lstm rnn is used to model the system call sequences and the averaged sequence likelihood is then used to determine anomaly which is the attack this paper also compares an ensemble method with two baselines as classification model this is is well written and more of ideas are clearly presented it demonstrates an interesting application of lstm sequential modeling to hids problem the overall novelty is limited considering the major technical components like lstm rnn and ensemble method are already established the contribution of the proposed ensemble method needs further evaluation because it is also possible to use ensemble ideas in knn and kmc baselines,5.0
733.json,the authors propose using an lstm on a sequence of system calls to perform network intrusion detection nids the idea of using neural networks in general for nids is old the idea of using some sort of nn on top of a sequence of system calls for nids is published the idea of using lstms for nids is published the paper in operates on counts of n grams of system calls rather than on the raw sequence but that pre processing does not seem heavy to me overall the proposed system works as well as other proposed nids system and the paper checks portability which is good but on the con side i do not see this paper as adding a lot to the state of the art in nids nor does is the paper well matched to iclr i did not learn a lot about representations from this paper many people have thrown lstm at sequence problems therefore i think it below threshold for iclr the authors may wish to submit to a security conference references debar herve monique becker and didier siboni a neural network component for an intrusion detection system research in security and privacy proceedings ieee computer society symposium on ieee creech gideon and jiankun hu a semantic approach to host based intrusion detection systems using contiguousand discontiguous system call patterns ieee transactions on computers staudemeyer ralf c applying long short term memory recurrent neural networks to intrusion detection south african computer journal,5.0
733.json,in this paper a novel approach for anomaly detection is considered for the task of intrusion detection based on system call sequence the system call sequence is regarded as a language and multiple lstm rnn language models are trained and ensembled diversity in the ensemble is achieved by choosing different hyper parameters for each lstm lm the combination of the lms is done by averaging transformations of the likelihoods i really like the fact that no attack data is used during training and i like the lm and ensemble approach the only high level drawbacks i have are the following which might have a simple answer as i am not an expert in this field relaying of system calls seems weak if the attacker has access to some normal sequences of system calls all she can fool the system by interleaving its malicious system calls with normal ones in a way that will artificially raise the likelihood of the sequence a few lines covering other anomaly detection tasks where rnns are used can be added to the introduction to give a better idea about the novelty of the approach,8.0
533.json,the authors present a novel approach to surprise based intrinsic motivation in deep reinforcement learning the authors clearly explain the difference from other recent approaches to intrinsic motivation and back up their method with results from a broad class of discrete and continuous action domains they present two tractable approximations to their framework one which ignores the stochasticity of the true environmental dynamics and one which approximates the rate of information gain somewhat similar to schmidhuber formal theory of creativity fun and intrinsic motivation the results of this exploration bonus when added to trpo are generally better than standard trpo however i would have appreciated a more thorough comparison against other recent work on intrinsic motivation for instance bellemare et al recently achieved significant performance gains on challenging atari games like montezuma revenge by combining dqn with an exploration bonus however montezuma revenge is not presented as an experiment here such comparisons would significantly improve the strength of the paper,6.0
533.json,this paper provides a surprise based intrinsic reward method for reinforcement learning along with two practical algorithms for estimating those rewards the ideas are similar to previous work in intrinsic motivation including vime and other work in intrinsic motivation as a positive the methods are simple to implement and provide benefits on a number of tasks however they are almost always outmatched by vime and not one of their proposed method is consistently the best of those proposed perhaps the most consistent is the surprisal which is unfortunately not asymptotically equal to the true reward the authors claim massive speed up but the numerical measurements show that vime is slower to initialize but not significantly slower per iteration otherwise perhaps a big o analysis would clarify the claims overall it a decent simple technique perhaps slightly incremental on previous state of the art,6.0
564.json,the authors of the paper explore the idea of incorporating skip connections over time for rnns even though the basic idea is not particularly innovative a few proposals on how to merge that information into the current hidden state with different pooling functions are evaluated the different models are compared on two popular text benchmarks some points the experiments feature only nlp and only prediction tasks it would have been nice to see the models in other domains i e modelling a conditional distribution p y x not only p x further sensory input data such as audio or video would have given further insight as pointed out by other reviewers it does not feel as if the comparisons to other models are fair sota on nlp changes quickly and it is hard to place the experiments in the complete picture it is claimed that this helps long term prediction i think the paper lacks a corresponding analysis as pointed out in an earlier question of mine it is claimed that lstm trains slow and is hard to scale for one does this not match my personal experience then the prevalence of lstm systems in production systems e g google baidu microsoft clearly speaks against this i like the basic idea of the paper but the points above make me think it is not ready for publication,4.0
564.json,this paper proposes an idea of looking n steps backward when modelling sequences with rnns the proposed rnn does not only use the previous hidden state t but also looks further back t k steps where k the paper also proposes a few different ways to aggregate multiple hidden states from the past the reviewer can see few issues with this paper firstly the writing of this paper requires improvement the introduction and abstract are wasting too much space just to explain unrelated facts or to describe already well known things in the literature some of the statements written in the paper are misleading for instance it explains among various neural network models recurrent neural networks rnns are appealing for modeling sequential data because they can capture long term dependency in sequential data using a simple mechanism of recurrent feedback and then it says rnns cannot actually capture long term dependencies that well rnns are appealing in the first place because they can handle variable length sequences and can model temporal relationships between each symbol in a sequence the criticism against lstms is hard to accept when it says lstms are slow and because of the slowness they are hard to scale at larger tasks but we all know that some companies are already using gigantic seqseq models for their production lstms are used as building blocks in their systems this indicates that the lstms can be practically used in a very large scale setting secondly the idea proposed in the paper is incremental and not new to the field there are other previous works that propose to use direct connections to the previous hidden states however the previous works do not use aggregation of multiple number of previous hidden states most importantly the paper fails to deliver a proper analysis on whether its main contribution is actually helpful to improve the problem posed in the paper the new architecture is said that it handles the long term dependencies better however there is no rigorous proof or intuitive design in the architecture that help us to understand why it should work better by the design of the architecture and speaking in very high level it seems like the model maybe helpful to mitigate the vanishing gradients issue by a linear factor it is always a good practice to have at least one page to analyze the empirical findings in the paper thirdly the baseline models used in this paper are very weak their are plenty of other models that are trained and tested on word level language modelling task using penn treebank corpus but the paper only contains a few of outdated models i cannot fully agree on the statement to the best of our knowledge this is the best performance on ptb under the same training condition these days rnn based methods usually score below in terms of the test perplexity which are far lower than achieved in this paper zhang et al architectural complexity measures of recurrent neural networks nips,3.0
732.json,while this paper has some decent accuracy numbers it is hard to argue for acceptance given the following motivation based on the incorrect assumption that the paragraph vector would not work on unseen data numerous basic formatting and bibtex citation issues lack of novelty of yet another standard directed lda like bag of words bigram model,4.0
732.json,it feels that this paper is structured around a shortcoming of the original paragraph vectors paper namely an alleged inability to infer representation for text outside of the training data i am reasonably sure that this is not the case unfortunately on that basis the premise for the work presented here no longer holds which renders most of the subsequent discussion void while i recommend this paper be rejected i encourage the authors to revisit the novel aspects of the idea presented here and see if that can be turned into a different type of paper going forward,3.0
657.json,the paper presents a few tricks to compress a wide and shallow text classification model based on n gram features these tricks include using optimized product quantization to compress embedding weights pruning some of the vocabulary elements hashing to reduce the storage of the vocabulary this is a minor component of the paper the paper focuses on models with very large vocabularies and shows a reduction in the size of the models at a relatively minor reduction of the accuracy the problem of compressing neural models is important and interesting the methods section of the paper is well written with good high level comments and references however the machine learning contributions of the paper are marginal to me the experiments are not too convincing mainly focusing on benchmarks that are not commonly used the implications of the paper on the state of the art rnn text classification models is unclear the use of optimized product quantization for approximating inner product is not particularly novel previous work also considered doing this most of the reduction in the model sizes comes from pruning vocabulary elements the method proposed for pruning vocabulary elements is simply based on the assumption that embeddings with larger l norm are more important a coverage heuristic is taken into account too from a machine learning point of view the proper baseline to solve this problem is to have a set of relaxed binary coefficients for each embedding vector and learn the coefficients jointly with the weights an l regularizer on the coefficients can be used to encourage sparsity from a practical point of view i believe an important baseline is missing what if one simply uses fewer vocabulary elements e g based on subword units see,5.0
657.json,the paper proposes a series of tricks for compressing fast linear text classification models the paper is clearly written and the results are quite strong the main compression is achieved via product quantization a technique which has been explored in other applications within the neural network model compression literature in addition to the gong et al work which was cited it would be worth mentioning quantized convolutional neural networks for mobile devices cvpr,6.0
728.json,the framework of semi markov decision processes sdmps has been long used to model skill learning and temporal abstraction in reinforcement learning this paper proposes a variant of such a model called a semi aggregated mdp model the formalism of samdp is not defined clearly enough to merit serious attention the approach is quasi heuristic and explained through examples rather than clear definition the work also lacks sufficient theoretical rigor simple experiments are proposed using d grid worlds to demonstrate skills grid worlds have served their purpose long enough in reinforcement learning and it is time to retire them more realistic domains are now routinely used and should be used in this paper as well,4.0
728.json,the paper presents a method for visualization and analysis of policies from observed trajectories that the policies produce the method infers higher level skills and clusters states the result is a simplified discrete higher order state and action transition matrix this model can be used for analysis modeling and interpretation to construct semi aggregated mdp the authors propose combining ideas for creating semi mpds and agregrated mdps the method consists of choosing features state clustering skill inference reward and skill length inference and model selection the method was demonstrated on a small grid world problem and dqn trained agent for playing atari games the authors correctly identify that tools and means for interpretibility of rl methods are important for analysis and deployment of such methods for real world applications this is particularly true in robotics and high consequence systems the end result of the presented method is a high level transition matrix there is a big body of literature looking into hierarchical rl methods where lower level skills are combined with higher level policies the presented method has the similar result but the advantage of the presented method is that it comes up with a structure and analyzes already trained agent which is very interesting the paper would benefit from emphasizing this difference and contrasting with the broader body of literature to build the model the authors propose combining the ideas from two existing ideas semi mpds and agregrated mdps with using modified k means for state clustering it appears that the novelty of the presented method is limited the paper would have been stronger if the authors explicitly stated the contributions over combining existing methods and better highlighted the practical utility of the method the evaluation section would be made stronger with more analytical results and precise evaluation showing full strength of the method the paper is difficult to read to improve readability the semi aggregated mdp section should include more precise description of the methods the narrative that builds intuition is welcome in addition to the existing narrative algorithms and formulas where applicable should be included as well the paper should be self contained for example more background on occams razor principle should be included reduce the number of acronyms in particular similarly sounding acronyms define acronyms before using be more clear on the contributions contrast with relevant literature and the specific benefits of the presented method fix typos formatting mistakes etc as they can be distracting for reading the approach of reverse engineering the hierarchy and learning high level transition matrix is very interesting and promising perhaps the method can be used to outperform single network approach by using the model as an input to more specialized hierarchical trainers and learn complex behaviors more optimally then possible with one large network approach unfortunately the paper falls short in the novelty precision and clarity,4.0
682.json,the authors propose a novel energy function for rbms using the leaky relu max cx x activation function for the hidden units analogous to relu units in feed forward networks these leaky relu rbms split the input space into a combinatorial number of regions where each region defines p v as a truncated gaussian a further contribution of the paper is in proposing a novel sampling scheme for the leaky rbm one can run a much shorter markov chain by initializing it from a sample of the leaky rbm with c which yields a standard multi variate normal over the visibles and then slowly annealing c in low dimension a similar scheme is shown to outperform ais for estimating the partition function experiments are performed on both cifar and svhn this is an interesting paper which i believe would be of interest to the iclr community the theoretical contributions are strong the authors not only introduce a proper energy formulation of relu rbms but also a novel sampling mechanism and an improvement on ais for estimating their partition function unfortunately the experimental results are somewhat limited the pcd baseline is notably absent including bernoulli visible leaky relu hidden would have allowed the authors to evaluate likelihoods on standard binary rbm datasets as it stands performance on cifar and svhn while improved with leaky relu is a far cry from more recent generative models vae based or auto regressive models while this comparison may be unfair it will certainly limit the wider appeal of the paper to the community furthermore there is the issue of the costly projection method which is required to guarantee that the energy function remain bounded covariance matrix over each region be psd again while it may be fair to leave that for future work given the other contributions this will further limit the appeal of the paper pros introduces an energy function having the leaky relu as an activation function introduces a novel sampling procedure based on annealing the leakiness parameter similar sampling scheme shown to outperform ais cons results are somewhat out of date missing experiments on binary datasets more comparable to prior rbm work missing pcd baseline cost of projection method,6.0
378.json,overview this work proposes to link trajectory log probabilities and rewards by defining under appreciated rewards this suggests that there is a linear relationship between trajectory rewards and their log probability which can be exploited by measuring the resulting mismatch that is when an action sequence under appreciates its reward its log probability is increased this method is a simple modification to the well known reinforce method requiring only one extra hyperparameter tau and intuitively provides us with a better exploration mechanism than epsilon greedy or random exploration the method is tested on algorithmic environments and compared to entropy regularized reinforce and double q learning and performs equally or better than those two baselines especially in more complex environments remarks the focus in the introduction on algorithmic tasks may be a double edged sword it is an interesting domain to test your hypothesis and benchmark your method at the same time it distracts the reader from the imo generality of the proposed method in the introduction you say the reward is sparse in section on tasks you then say there is a reward at each correct emission i e each time step this is only corrected to end of episode reward in section after having discussed results i would move or mention this in section approach seems quite sensible to tau being in the same range as logpi a h but you only try tau for urex i am not sure i understand nor agree with this experimentation choice an alternative to grid search is random search bergstra bengio it may illustrate better hyperparameter robustness and allow you to explore more in the same number of experiment opinion an interesting approach to policy gradient to be sure it tackles the very important question of how should agents explore i am ambivalent to claiming that an algorithm is robust to hyperparmeters simply because it performs better on the selected hyperparameter range all you really show is that it performs well some amount of time when the hyperparams lay in that range could not it be that ment needs different hyperparameters just being devil advocate here i see why matching tau with logpi is the obvious choice but it implies a very strong prior that the reward to a factor of tau lies in the same space as the log policy one point of failure i see but correct me if i am wrong is that as the length of the trajectory grows the reward is expected to grow linearly so short ways to get some reward will be less explored than long ways of getting the same reward creating an imbalance unless the reward is shaped such that shorter trajectories get more reward which is only the case in task it might have been good to also compare with methods explicitly trying to explore better with value functions e g prioritized experience replay schaul et al at the risk of repeating myself tau plays a major role in this method but there is little analysis on its effect on experiments the methodology and reasoning is clearly explained and i think this paper communicates its message very well that message is novel albeit a minor modification to a well known algorithm it is well motivated and i think a welcome addition to literature concerning exploration in rl the experiments are chosen accordingly and results seem to reflect the hypothesis of the authors i realize the tyranny of extensive experimentation and the scarcity of time but i do think that this paper would benefit from more or cleverer experimentation as well as demonstrating more explicitly the impact of the method on exploration reading this paper convinced me that measuring mismatch between a trajectory observed reward and its probability given the current policy is a clever and well motivated thing to do yet i think that the paper could have a more convincing empirical argument even if it is for toy tasks,8.0
378.json,the paper proposes a new algorithm based on reinforce which aims at exploring under appreciate action sequences the idea is to compare the probability of a sequence of actions under the current policy with the estimated reward actions where the current policy under estimate the reward will provide a higher feedback thus encouraging exploration of particular sequences of actions the urex model is tested on algortihmic rl problems and show interesting properties in comparison to the standard regularized reinforce ment model and to q learning the model is interesting well defined and well explained as far as i know the urex model is an original model which will certainly be useful for the rl community the only drawback of the paper is to restrict the evaluation of this algortihm to algorithmic problems that are specific while it would be easy to test the proposed model onto other standard rl problems this would clearly help to make the article stronger and i greatly encourage the authors to add some other tasks in their paper,7.0
689.json,this paper uses tensors to build generative models the main idea is to divide the input into regions represented with mixture models and represent the joint distribution of the mixture components with a tensor then by restricting themselves to tensors that have an efficient decomposition they train convolutional arithmetic circuits to generate the probability of the input and class label providing a generative model of the input and labels this approach seems quite elegant it is not completely clear to me how the authors choose the specific architecture for their model and how these choices relate to the class of joint distributions that they can represent but even if these choices are somewhat heuristic the overall framework provides a nice way of controlling the generality of the distributions that are represented the experiments are on simple synthetic examples of missing data this is somewhat of a limitation and the paper would be more convincing if it could include experiments on a real world problem that contained missing data one issue here is that it must be known which elements of the input are missing which somewhat limits applicability could experiments be run on problems relating to the netflix challenge which is the classic example of a prediction problem with missing data in spite of these limitations the experiments provide appropriate comparisons to prior work and form a reasonable initial evaluation i was a little confused about how the input of missing data is handled experimentally from the introductory discussion my impression was that the generative model was built over region patches in the image this led me to believe that they would marginalize over missing regions however when the missing data consists of iid randomly missing pixels it seems that every region will be missing some information why is it appropriate to marginalize over missing pixels specifically xi in equation represents a local region and the ensuing discussion shows how to marginalize over missing regions how is this done when only a subset of a region is missing it also seems like the summation in the equation following equation could be quite large what is the run time of this the paper is also a bit schizophrenic about the extent to which the results are applicable beyond images the motivation for the probabilistic model is mostly in terms of images but in the experiments the authors state that they do not use state of the art inpainting algorithms because their method is not limited to images and they want to compare to methods that are restricted to images this would be more convincing if there were experiments outside the image domain it was also not clear to me how if at all the proposed network makes use of translation invariance it is widely assumed that much of the success of cnns comes from their encoding of translation invariance through weight sharing is such invariance built into the authors network if not why would we expect it to work well in challenging image domains as a minor point the paper is not carefully proofread to just give a few examples from the first page or so significantly lesser significantly less the the provenly provably,7.0
689.json,the paper provides an interesting use of generative models to address the classification with missing data problem the tensorial mixture models proposed take into account the general problem of dependent samples this is an nice extension of current mixture models where samples are usually considered as independent indeed the tmm model is reduced to the conventional latent variable models as much as i love the ideas behind the paper i feel pitiful about the sloppiness of the presentation such as missing notations and flaws in the technical derivations before going into the technical details my high level concerns are as follows the joint density over all samples is modeled as a tensorial mixture generative model the interpretation of the cp decomposition or ht decomposition on the prior density tensor is not clear the authors have an interpretation of tmm as product of mixture models when samples are independent however their interpretation seems flawed to me and i will elaborate on this in the detailed technical comments below the authors employ convolution operators to compute an inner product it is realizable by zero padding but the invariance structure which is the advantage of cnn compared to feed forward neural network will be lost however i am not sure how much this would affect the performance in practice the author could comment in the paper a little bit on the sample complexity of this method given the complexity of the model because i liked the ideas of the paper so much and the iclr paper submitted did not present the technical details well due to sloppiness of notations so i read the technical details in the arxiv version the authors pointed out there are a few technical typos that i would like to point out my reference to equations are to the ones in the arxiv paper the generative model as in figure is flawed p xi di theta di are vectors of length s there the product of vectors is not well defined it is obvious that the dimensions of the terms between two sides of the equation are not equal in fact this should be a tucker decomposition instead of multiplication it should be p x sum d ldots dn p d ldots dn p x d theta d p x d theta d ldots p xn dn theta dn which means a sum of multi linear operation on tensor p d ldots dn and each mode is projected onto p xi di theta di i suspect the special case for diagonal gaussian mixture models has some typos as i could not derive the third last equation on page but it might be just i did not understand this example the claim that tmm reduces to product of mixture model is not accurate the first equation on page is only right when sum of product operation is equal to product of sum operation similarly in equation the second equality does not hold unless in some special cases however this is not true this might be just a typo but it is good if the authors could fix this i also suspect that if the authors correct this typo the performance on mnist might be improved overall i like the ideas behind this paper very much i suggest the authors fix the technical typos if the paper is accepted,5.0
328.json,this paper explores the ability of nonlinear recurrent neural networks to account for neural response properties that have otherwise eluded the ability of other models a multilayer rnn is trained to imitate the stimulus response mapping measured from actual retinal ganglion cells in response to a sequence of natural images the rnn performs significantly better especially in accounting for transient responses than conventional ln glm models this work is an important step in understanding the nonlinear response properties of visual neurons recent results have shown that the responses of even retinal ganglion cells in response to natural movies are difficult to explain in terms of standard receptive field models so this presents an important challenge to the field if we even had a model that works it would be a starting point so this work should be seen in that light the challenge now of course is to tease apart what the rnn is doing perhaps it could now be pruned and simplified to see what parts are critical to performance it would have been nice to see such an analysis nevertheless this result is a good first start and i think important for people to know about i am a bit confused about what is being called a movie my understanding is that it is essentially a sequence of unrelated images shown for sec each but then it is stated that the frame rate is ms i think this must refer to the refresh rate of the monitor right i would guess that the deviations from the ln model are even stronger when you show actual dynamic natural scenes i e real movies here i would expect the rnn to have an even more profound effect and potentially be much more informative,8.0
328.json,this is a clearly written paper with a nice if straightforward result rnns can be good predictive models of neuron firing rates in the retina on the one hand the primary scientific contribution seems to just be to confirm that this approach works on this particular stimulus locked task the gains from using the rnn seemed relatively modest and it has not yet taught us anything new about the biology on the other hand this along with the concurrent work of mcintosh et al is introducing neural network modeling to a field that is not currently using it and where it should prove very effective i think it would be very interesting to see the results of applying a framework like this one with lfp and other neurons as input and on a shorter discretization time scale i suspect followup work building on this proof of concept will be increasingly exciting minor comments sec i did not understand the role of the ms bins use epoch throughout rather than alternating between epoch and pass through data fig would be better with the x axis on a log scale,7.0
484.json,this paper investigates the fact why deep networks perform well in practice and how modifying the geometry of pooling can make the polynomially sized deep network to provide a function with exponentially high separation rank for certain partitioning in the authors previous works they showed the superiority of deep networks over shallows when the activation function is relu and the pooling is max mean pooling but in the current paper there is no activation function after conv and the pooling is just a multiplication of the node values although for the experimental results they have considered both scenarios actually the general reasoning for this problem is hard therefore this drawback is not significant and the current contribution adds a reasonable amount of knowledge to the literature this paper studies the convolutional arithmetic circuits and shows how this model can address the inductive biases and how pooling can adjust these biases this interesting contribution gives an intuition about how deep network can capture the correlation between the input variables when its size is polynomial but and correlation is exponential it worth to note that although the authors tried to express their notation and definitions carefully where they were very successful it would be helpful if they elaborate a bit more on their definitions expressions and conclusions in the sense to make them more accessible,7.0
484.json,this paper addresses the question of which functions are well suited to deep networks as opposed to shallow networks the basic intuition is convincing and fairly straightforward pooling operations bring together information when information is correlated it can be more efficiently used if the geometry of pooling regions matches the correlations so that it can be brought together more efficiently shallow networks without layers of localized pooling lack this mechanism to combine correlated information efficiently the theoretical results are focused on convolutional arithmetic circuits building on prior theoretical results of the authors the results make use of the interesting technical notion of separability which in some sense measures the degree to which a function can be represented as the composition of independent functions because separability is measured relative to a partition of the input it is an appropriate mechanism for measuring the complexity of functions relative to a particular geometry of pooling operations many of the technical notions are pretty intuitive although the tensor analysis is pretty terse and not easy to follow without knowledge of the authors prior work in some sense the comparison between deep and shallow networks is somewhat misleading since the shallow networks lack a hierarchical pooling structure for example a shallow convolutional network with relu and max pooling does not really make sense since the max occurs over the whole image so it seems that the paper is really more of an analysis of the effect of pooling vs not having pooling for example it is not clear that a deep cnn without pooling would be any more efficient than a shallow network from this work it is not clear how much the theoretical results depend on the use of a model with product pooling and how they might be extended to the more common max pooling even if theoretical results are difficult to derive in this case simple illustrative examples might be helpful in fact if the authors prepare a longer version of the paper for a journal i think the results could be made more intuitive if they could add a simple toy example of a function that can be efficiently represented with a convolutional arithmetic circuit when the pooling structure fits the correlations and perhaps showing also how this could be represented with a convolutional network with relu and max pooling i would also appreciate a more explicit discussion of how the depth of a deep network affects the separability of functions that can be represented a shallow network doesn t have local pooling so the difference between deep and shallow if perhaps mostly one of pooling vs not pooling however practitioners find that very deep networks seem to be more effective than deep networks with only a few convolutional layers and pooling the paper does not explicitly discuss whether their results provide insight into this behavior overall i think that the paper attacks an important problem in an interesting way it is not so convincing that this really gets to the heart of why depth is so important because of the theoretical limitation to arithmetic circuits and because the comparison is to shallow networks that are without localized pooling,6.0
580.json,summary the authors present a simple rnn with linear dynamics for language modeling the linear dynamics greatly enhance the interpretability of the model as well as provide the potential to improve performance by caching the dynamics for common sub sequences overall the quantitative comparison on a benchmark task is underwhelming it s unclear why the authors didn t consider a more common dataset and they only considered a single dataset on the other hand they present a number of well executed techniques for analyzing the behavior of the model many of which would be impossible to do for a non linear rnn overall i recommend that the paper is accepted despite the results it provides an interesting read and an important contribution to the research dialogue feedback the paper could be improved by shortening the number of analysis experiments and increasing the discussion of related sequence models some of the experiments were very compelling whereas some of them eg sort of feels like you re just showing the reader that the model fits the data well not that the model has any particularly important property we trust that the model fits the data well since you get reasonable perplexity results lstms grus are great for for language modeling for data with rigid combinatorial structure such as nested parenthesis it would have been nice if you compared your model to non linear methods on this sort of data don t be scared of negative results it would be interesting if the non linear methods were substantially better on these tasks you should definitely add a discussion of belanger and kakade to the related work they have different motivations fast scalable learning algorithms rather than you interpretable latent state dynamics and simple credit assignment for future predictions given past on the other hand they also have linear dynamics and look at the singular vectors of the transition matrix to analyze the model more broadly it would be useful for readers if you discussed lds more directly a lot of this comparison came up in the openreview discussion and i recommend folding this into the paper for example it would be useful to emphasize that the bias vectors correspond to columns of the kalman gain matrix one last thing regarding lds your model corresponds to kalman filtering but in an lds you can also do kalman smoothing where state vectors are inferred using the future in addition to the past observations could you do something similar in your model what if you said that each matrix is a sparse convex combination of a set of dictionary matrices this parameter sharing could provide even more interpretability since the characters are then represented by the low dimensional weights used to combine the dictionary elements this could also provide more scalability to word level problems,6.0
580.json,summary the authors propose an input switched affine network to do character level language modeling a kind of rnn without pointwise nonlinearity but with switching the transition matrix bias based on the input character this is motivated by intelligibility since it allows decomposition of output contribution into these kappas t terms and use of basic linear algebra to probe the network regarding myself as a reviewer i am quite sure i understood the main ideas and arguments of this paper but am not an expert on rnn language models or intelligibility interpretability in ml i did not read any papers with a similar premise closest related work i am familiar with would be deconvnet for insight into vision cnns pro i think this is original and novel work this work is high quality well written and clearly is the result of a lot of work i found section about projecting into readout subspace vs computational subspace most interesting and meaningful con the main hesitation i have is that the results on both parts isan model and analysis of it are not entirely convincing isan is only trained on small task text not clear whether it can be a strong char lm on larger scale tasks nor do the analysis sections provide all that much real insight in the learned network b other caveat towards isan architecture this model in its proposed form is really only fit for small vocabulary i e character based language modeling not a general rnn with large vocab discrete input nor continuous input a for analysis many cute plots and fun ideas of quantities to look at but not much concrete insights b not very clear which analysis is specific to the isan model and which ideas will generalize to general nonlinear rnns c re sec it seems that the quantity kappas t on which analysis rests is not all that meaningful elaborating a bit on what i wrote in the question for example fig for input letter u in revenue there a red spot where  character massively positively impacts the logit of e this seems quite meaningless what would be the meaning of influence of  character so it looks ot me that the switching matrix wu and prior wn we etc are using previous state in an interesting way to produce that following e so that metric kappas t just does not seem very meaningful this remark relates to the last paragraph of sec even though the list of cons here is longer than pro i recommend accept specifically because the originality of this work will in any case make it more vulnerable to critiques this work is well motivated very well executed and can inspire many more interesting investigations along these lines,7.0
580.json,the authors present a character language model that gains some interpretability without large losses in predictivity contribution i would characterize the paper as some experimental investigation of a cute insight recall that multi class logistic regression allows you to apportion credit for a prediction to the input features some features raised the probability of the correct class while others lowered it this paper points out that a sufficiently simple rnn model architecture is log linear in the same way so you can apportion credit for a prediction among elements of the past history pros the paper is quite well written and was fun to read it nice to see that a simple architecture still does respectably it easy to imagine using this model for a classroom assignment it should be easy to implement and the students could replicate the authors investigation of what influences the network predictions the authors present some nice visualizations section also describes some computational benefits caveats on predictive accuracy figure says that the isan has near identical performance to other architectures but this appears true only when comparing the largest models explanation it appears that for smaller parameter sizes a gru still beats the authors model by to in the usual metric of perplexity per word ppw that how lm people usually report performance with a reduction in ppw traditionally being considered a good ph d dissertation i assumed an average of chars word when converting cross entropy char to perplexity word in addition it not known whether this model family will remain competitive beyond the toy situations tested here explanation the authors tried it only on character based language modeling and only on a m char dataset so their ppw is extremely high for the best models in this paper by contrast a word based rnn lm trained on m words gets ppw of and trained on m words gets ppw of numbers copied from the paper i cited before,6.0
738.json,the findings of applying sparsity in the backward gradients for training lstms is interesting but the paper seems incomplete without the proper experimental justification only the validation loss is reported which is definitely insufficient proper testing results and commonly reported evaluation criterion needs to be included to support the claim of no degradation when applying the proposed sparsity technique also actual justification of the gains in terms of speed and efficiency would make the paper much stronger,4.0
738.json,this paper presents the observation that it is possible to utilize sparse operations in the training of lstm networks without loss of accuracy this observation is novel although not too surprising to my knowledge but i must state that i am not very familiar with research on fast rnn implmentations minor note the lstm language model does not use a wordvec layer it is simply a linear embedding layer wordvec is the name of a specific model which is not directly to character level language models the paper presents the central observation clearly however it will be much more convincing if a well known dataset and experiment set up are used such as graves or sutskever et al and actual training validation and test performances are reported while the main observation is certainly interesting i think it is not sufficient to be the subject of a full conference paper without implementation or simulation and benchmarking of the promised speedups on multiple tasks for example how would the gains be affected by various architecture choices at present this is an interesting technical report and i would like to see more detailed results in the future,5.0
738.json,contributions when training lstms many of the intermediate gradients are close to zero due to the flat shape of the tanh and sigmoid nonlinearities far from the origin this paper shows that rounding these small gradients to zero results in matrices with up to sparsity during training and that training character level lstm language models with this sparsification does not significantly change the final performance of the model the authors argue that this sparsity could be exploited with specialized hardware to improve the energy efficiency and speed of recurrent network training novelty thresholding gradients to induce sparsity and improve efficiency in rnn training is a novel result to my knowledge missing citations prior work has explored low precision arithmetic for recurrent neural network language models hubara et al quantized neural networks training neural networks with low precision weights and activations,4.0
684.json,the term strategy is a bit ambiguous could you please explain more in formal terms what is strategy is r the discounted return at time t or the reward at time t could the author compare the method to td learning the paper is vague and using many rl terms with different meanings without clarifying those diversions so the output for a given state actions pair is always same q function by definition is the value of state action so as long as the policy is deterministic the output would be always same too how this different from q learning the model description does not specify what is the policy and it only being mentioned in data generation part why is it a model based approach the learning curves are only for iterations which does not give any useful information the final results are clearly nothing comparable to previous works the model is only being tested on three games the paper is vague and using informal language or sometimes misusing the common rl terms the experiments are very small scale and even in that scenario performing very bad it not clear why it a model based approach,2.0
734.json,this paper considers the case where multiple views of data are learned through a probabilistic deep neural network formulation this makes the model non linear unlike e g cca but makes inference difficult therefore the vae framework is invoked for inference in ref the authors show that maximum likelihood estimation based on their linear latent model leads to the canonical correlation directions but in the non linear case with dnns it not clear at least with the present analysis what the solution is wrt to the canonical directions there no such analysis in the paper hence i find it a stretch to refer to this model as a cca type of model in contrast e g dcca dccae are taking the canonical correlation between features into account inside the objective and provide interpretations ref f r bach and m i jordan a probabilistic interpretation of canonical correlation analysis technical report there is also a significant body of very related work on non linear multi view models which is not discussed in this paper for example there been probabilistic non linear multi view models ref also extended to the bayesian case with common private spaces ref and the variational deep learning case ref ref ek et al gaussian process latent variable models for human pose estimation mlmi ref shon et al learning shared latent structure for image synthesis and robotic imitation nips ref damianou et al manifold relevance determination icml ref damianou and lawrence deep gaussian processes aistats i can see the utility of this model as bringing together two elements multi view modeling and vaes this seems like an obvious idea but to the best of my knowledge it has not been done before and is actually a potentially very useful model however the question is what is the proper way of extending vae to multiple views the paper did not convince me that vae can work well with multiple views using the shown straightforward construction specifically vcca does not seem to promote the state of the art in terms of results it actually is overall below the soa while the vcca private seems a quite ill posed model the dimensionalities d have to be manually tuned with exhaustive search further the actual model does not provide a consinstent way of encouraging the private and common variables to avoid learning redundant information relying only on dropout for this seems a quite ad hoc solution in fact from fig ver it seems that the dropout rate is quite crucial perhaps good performance might be achieved with a lot of tuning which might be why the flickr results got better in ver without changing the model but it seems quite difficult to optimize for the above reasons from a purely experimental point of view vcca private does not seem to promote the soa either of course one would not expect any new published paper to beat all previous baselines but it seems that extension of vae to multiple views is a very interesting idea which deserves some more investigation of how to do it efficiently another issue is the approximate posterior being parameterized only from one of the views this makes the model less useful as a generic multi view model since it will misbehave in tasks other than classification but if classification is the main objective then one should compare to a proper classification model e g a feedforward neural network the plots of fig are very nice overall the paper convinced me that there is merit in attaching multiple views to vae however it did not convince me a that the proposed way to achieve this is practical b that there is a connection to cca other than being a method for multiple views the bottom line is that although the paper is interesting it needs a little more work,5.0
775.json,this paper addresses a question that is often overlooked in reinforcement learning or locomotion experiment my biggest point of critique is that it difficult to draw conclusions or reason beyond the results of the experiments the authors only consider a single neural network architecture and a single reward function for example is the torque controller limited by the policy network my suggestion is to vary the number of neurons or show that the same results hold for a different state representation e g trained on pixel data in the paper current form the term deeprl seems arbitrary on the positive side the paper is well structured and easy to read the experiments are sound clear and easy to interpret it definitely an interesting line of work and beyond the extension to d i would argue that considering more realistic physical constraints e g actuator constraints communication delays etc on real robots could greatly improve the impact of this work,6.0
325.json,the paper presents a method for training a generative model via an iterative denoising procedure the denoising process is initialized with a random sample from a crude approximation to the data distribution and produces a high quality sample via multiple denoising steps training is performed by setting up a markov chain that slowly blends propositions from the current denoising model with a real example from the data distribution using this chain the current denoising model is updated towards reproducing the changed better samples from the blending process this is a clearly written paper that considers an interesting approach for training generative models i was intrigued by the simplicity of the presented approach and really enjoyed reading the paper the proposed method is novel although it has clear ties to other recent work aiming to use denoising models for sampling from distributions such as the work by sohl dickstein and the recent work on using daes as generative models i think this general direction of research is important the proposed procedure takes inspiration from the perspective of generating samples by minimizing an energy function via transitions along a markov chain and if successful it can potentially sidestep many problems of current procedures for training directed generative models such as convergence and mode coverage problems as in generative adversarial networks problems with modeling multi modal distributions which can arise when a too restrictive approximate inference model is paired with a powerful generative model that being said another method that seems promising for addressing these issues that also has some superficially similarity to the presented work is the idea of combining hamiltonian monte carlo inference with variational inference as in as such i am not entirely convinced that the method presented here will be able to perform better than the mentioned paper although it might be simpler to train similarly although i agree that using a mcmc chain to generate samples via a mc em like procedure is likely very costly i am not convinced such a procedure wo not at least also work reasonably well for the simple mnist example in general a more direct comparison between different inference methods using an mcmc chain like procedure would be nice to have but i understand that this is perhaps out of the scope of this paper one thing that i would have expected however is a direct comparison to the procedure from sohl dickstein in terms of sampling steps and generation quality as it is so directly related other major points good and bad although in general the method is explained well some training details are missing most importantly it is never mentioned how alpha or omega are set i am assuming omega is as that is the increase mentioned in the experimental setup it is also unclear how alpha affects the capabilities of the generator while it intuitively seems reasonable to use a small alpha over many steps to ensure slow blending of the two distributions it is not clear how necessary this is or at what point the procedure would break i assume alpha wo not work as the generator then would have to magically denoise a sample from the relatively uninformative draw from p the authors do mention in one of the figure captions that the denoising model does not produce good samples in only steps but that might also be an artifact of training the model with small alpha at least i see no a priori reason for this more experiments should be carried out here no infusion chains or generating chains are shown for any of the more complicated data distributions this is unfortunate as i feel these would be interesting to look at the paper does a good job at evaluating the model with respect to several different metrics the bound on the log likelihood is nice to have as well unfortunately the current approach does not come with any theoretical guarantees it is unclear for what choices of alpha the procedure will work and whether there is some deeper connection to mcmc sampling or energy based models in my eyes this does not subtract from the value of the paper but would perhaps be worth a short sentence in the conclusion minor points the second reference seems broken figure starts at epochs and as a result contains little information perhaps it would be more useful to show the complete training procedure and put the x axis on a log scale the explanation regarding the convolutional networks you use makes no sense to me you write that you use the same structure as in the improved gans paper which unlike your model generates samples from a fixed length random input i thus suppose you do not really use a generator with fully connected network followed by up convolutions but rather have several stages of convolutions followed by a fully connected layer and then up convolutions the choice of parametrizing the variance via a sigmoid output unit is somewhat unusual was there a specific reason for this choice footnote contains errors this allow to allows to few informations little information this force the network forces page error etc page error operator should to learn markov chain monte carlo and variational inference bridging the gap tim salimans and diedrik p kingma and max welling icml update copied here from my response below i believe the response of the authors clarifies all open issues i strongly believe the paper should be accepted to the conference the only remaining issue i have with the paper is that as the authors acknowledge the architecture of the generator is likely highly sub optimal and might hamper the performance of the method in the evaluation this however does not at all subtract from any of the main points of the paper i am thus keeping my score as a clear accept i want to emphasize that i believe the paper should be published just in case the review process results in some form of cut off threshold that is high due to overall inflated review scores,7.0
598.json,this paper describes an end to end system for speech recognition that uses a linear conditional random field framework a convnet estimates node potentials while transition scores are provided by trained scalar values the convnet acoustic model computes scores for letters not phones which reduces the need for expert knowledge in training the system at test time scores from a word level language model the convnet node potentials learned letter to letter transition scores and a word insertion penalty are combined to find the best scoring word hypothesis the model may be trained from the raw audio waveform power spectra or mfcc features using conditional maximum likelihood estimation experiments on the librispeech corpus show that the model achieves a wer on the test clean set from librispeech using mfcc features a wer using power spectral features and a wer using the raw waveform pros it is interesting to see that a convnet trained from scratch using conditional maximum likelihood can perform reasonably well in a speech recognition system for english that uses graphemic letter based acoustic models instead of phonetic models this is a promising research direction cons the paper is missing a lot of context prior work that deserves to be cited in addition to the papers i already mentioned in various comments the authors should also be aware of another interspeech paper zhang et al towards end to end speech recognition with deep convolutional neural networks,4.0
517.json,i sincerely apologize for the late arriving review this paper proposes to frame the problem of structure estimation as a supervised classification problem the input is an empirical covariance matrix of the observed data the output the binary decision whether or not two variables share a link the paper is sufficiently clear the goals are clear and everything is well described the main interesting point is the empirical results of the experimental section the approach is simple and performs better than previous non learning based methods this observation is interesting and will be of interest in structure discovery problems i rate the specific construction of the supervised learning method as a reasonable attempt attempt to approach this problem there is not very much technical novelty in this part e g an algorithmic contribution would have been a method that is invariant to data permutation could have been a possible target for a technical contribution the paper makes no claims on this technical part as said the method is well constructed and well executed it is good to precisely state the theoretical parts of a paper the authors do this well all results are rather straight forward i like that the claims are written down but there is little surprise in the statements in summary the paper makes a very interesting observation graph estimation can be posed as a supervised learning problem and training data from a separate source is sufficient to learn structure in novel and unseen test data from a new source practically this may be relevant on one hand the empirical results are stronger with this method on the other hand a practitioner who is interested in structural discovery may have side constraints about interpretability of the deriving method from the discussion and conclusion i understand that the authors consider this as future work it is a good first step it could be stronger but also stands on its own already,6.0
517.json,this paper proposes a new method for learning graphical models combined with a neural network architecture some sparse edge structure is estimated via sampling methods in introduction the authors say that a problem in graphical lasso is model selection however the proposed method still implicitly includes model selection in the proposed method p g is a sparse prior and should include some hyper parameters how do you tune the hyper parameters is this tuning an equivalent problem to model section therefore i do not understand real advantage of this method over previous methods what is the advantage of the proposed method another concern is that this paper is unorganized in algorithm first gi and sigmai are sampled and then xj is sampled from n sigma here what is sigma is it different from sigmai furthermore how do you construct yi hat sigma i from gi xi finally i have a simple question where is input data x not sampled data is used in algorithm what is the definition of the receptive field in proposition and proposition,5.0
350.json,an interesting architecture that accumulates and continuously corrects mistakes as you see more and more of a video sequence clarity the video you generated seems very helpful towards understanding the information flow in your network it would be nice to link to it from the paper our model with hyperparameters optimized for kitti underperforms the model of finn et al but outperforms the previous state of the art model by mathieu et al it is not clear how different are the train and test sequences at the moment since standard benchmarks do not really exist for video prediction and each author picks his her favorite underperforming finn et al at the h m walking videos is a bit disappointing,6.0
350.json,learning about the physical structure and semantics of the world from video without supervision is a very hot area in computer vision and machine learning in this paper the authors investigate how the prediction of future image frames inherently unsupervised can help to deduce object s structure and it properties in this case single object pose category and steering angle after a supervised linear readout step i enjoyed reading this paper it is clear interesting and proposes an original network architecture prednet for video frame prediction that has produced promising results on both synthetic and natural images moreover the extensive experimental evaluation and analysis the authors provide puts it on solid ground to which others can compare the weaknesses the link to predictive coding should be better explained in the paper if it is to be used as a motivation for the prednet model any idea that the proposed method is learning an implicit model of the objects that make up the scene is vague and far fetched but it sounds great minor comment next to the number of labeled training examples fig it would be interesting to see how much unsupervised training data was used to train your representations,8.0
448.json,i am not familiar enough with mean field techniques to judge the soundness of eq but i am willing to roll with it minor point on presentation speaking of the evolution of x i a as it travels through the network could give some readers helpful intuition but for me it was confusing because x a is the immutable input vector and it the just introduced z and y variables that represent its so called evolution no in interpreting this analysis a network may be trainable if information does not pass through it if the training steps by whatever reason perturb the weights so that information starts to pass through it without subsequently perturbing the weights to stop information from passing through it perhaps this could be clarified by a definition of training algorithm comments on central claims previous work on initializing neural networks to promote information flow e g glorot bengio,8.0
448.json,the paper expands a recent mean field approximation of deep random neural networks to study depth dependent information propagation its phase dependence and the influence of drop out the paper is extremely well written the mathematical analysis is thorough and numerical experiments are included that underscore the theoretical results overall the paper stands out as one of the few papers that thoroughly analyses training and performance of deep nets,9.0
673.json,the hierarchical memory is fixed not learned and there is no hierarchical in the experimental section only one layer for softmax layer it shows the mips mips mips does it mean mips is the best one we should adopt approximated k mips is worse than even original method why does it need exact k mips it seems the proposed method is not robust,5.0
673.json,the paper proposes an algorithm for training memory networks which have very large memories training such models in traditional ways by using soft attention mechanism over all the memory slots is not only slow it is also harder to train due to dispersion of gradients the paper proposes to use the k mips algorithm over the memories to choose a subset of the memory slots over which the attention is applied since the cost of exact k mips is the same as doing full attention the authors propose to use approximate k mips which while faster to compute results in inferior performance an artifact of using k mips is that one cannot learn the memory slots hence they are pre trained and kept fixed during entire training the experimental section shows the efficacy of using k mips using the simplequestions dataset the exact k mips results in the same performance as the full attention the approximate k mips results in deterioration in performance the paper is quite clearly written and easy to understand i think the ideas proposed in the paper are not super convincing i have a number of issues with this paper the k mips algorithm forces the memories to be fixed this to me is a rather limiting constraint especially on problems dataset which will require multiple hops of training to do compounded reasoning as a results i am not entirely sure about the usefulness of this technique furthermore the exact k mips is the sample complexity as the full attention the only way to achieve speedup is to use approx k mips that as expected results in a significant drop in performance the paper motivates the ideas by proposing solutions to eliminate heuristics used to prune the memories however in section the authors themselves end up using multiple heuristics to make the training work agreed that the used heuristics are not data dependent but still it feels like they are kicking the can down the road as far as heuristics are concerned the experimental results are not very convincing first there is no speed comparison second the authors do not compare with methods other than k mips which do fast nearest neighbor search such as flann,5.0
366.json,the authors propose nvi for lda variants the authors compare nvi lda to standard inference schemes such as cgs and online svi the authors also evaluate nvi on a different model prodlda not sure this model has been proposed before in the topic modeling literature though in general i like the direction of this paper and nvi looks promising for lda the experimental results however confound model vs inference which makes it hard to understand the significance of the results furthermore the authors do not discuss hyper parameter selection which is known to significantly impact performance of topic models this makes it hard to understand when the proposed method can be expected to work can you maybe generate synthetic datasets with different dirichlet distributions and assess when the proposed method recovers the true parameters figure is this prior or posterior the text talks about sparsity whereas the y axis reads log p topic proportions which is a bit confusing section it is not clear what you mean by unimodal in softmax basis consider a dirichlet on k dimensional simplex with concentration parameter alpha k where alpha makes it multimodal is not the softmax basis still multimodal none of the numbers include error bars are the results statistically significant minor comments last term in equation is not error reconstruction accuracy or negative reconstruction error perhaps the idea of using an inference network is much older cf helmholtz machine,6.0
366.json,the comparison to nvdm looks unfair since the user introduces a couples tricks dirichlet prior batch normalisation high momentum training etc which nvdm does not use a more convincing experimental design is to explore the effect of each trick separately in neural variational inference,5.0
537.json,the paper proposes an approach to generating synthetic training data for deep networks based on rendering d models and learning additional transformations with adversarial training the approach is applied to generating barcode like markers used for honeybee identification the authors demonstrate that a classifier trained on synthetic data generated with the proposed approach outperforms both training on limited real data and training on data with hand designed augmentations the topic of the paper using machine learning in particular adversarial training for generating realistic synthetic training data is very interesting and important the proposed method looks reasonable and the paper is written well the downside is that experiments are limited to a fairly simple and not widely known domain of honeybee marker classification while i am sure this is an important task by itself in order to demonstrate general applicability of the method and to allow comparison with existing techniques experiments on some standard and or realistic datasets would be very helpful overall i recommend acceptance but encourage the authors to perform experiments on more datasets i appreciate that the authors added a baseline with manually designed transformations this strengthens the paper as reviewer points out it would be interesting to analyze if restricting gan to a fixed set of transformations is necessary here and which transformations are most important perhaps this would provide some guidelines for designing sets of transformations for more complicated scenarios the authors should tone down their claims such as our method is an improvement over previous work whereas previous work relied on real data for training using pre trained models or mixing real and generated data we were able to train a dcnn from scratch with generated data that performed well when tested on real data this is not a fair comparison the domain studied by authors in this work is much simpler than what was studied in these previous works so this comparison is not appropriate,6.0
537.json,the submission proposes an interesting way to match synthetic data to real data in a gan type architecture the main novelty are parametric modules that emulate different transformations and artefact that allow to match the natural appearance several points were raised during the discussion the proposed method is more model driven that previous gan models but does it pay off how would a traditional gan approach perform the mentioned effects like blur lighting and background could also potentially be modelled by upsamling network that directly predicts the image i would assume that blur and lighting can be modelled by convolutions transformations to some extend by convolutions or spatial transformer networks the answers of the authors only partially addresses the point the key proposal of the submission seems parameterised modules that can be trained to match the real data distribution but it remains unclear why not a more generic parameterisation can also do the job e g a neural network as done in regular gans the benefit of introducing a stronger model is unclear using a render engine to generate the initial sample appearance if of limited novelty how does it compare to traditional data augmentation techniques e g noise dropout transformations you are linking to keras code where data augmentation is readily available and could be tested imagedatagenerator the authors reply that plenty of such augmentation was used and more details are going to be provided in the appendix it would have been appreciated if such information was directly included in the revision so that the procedure could be directly checked right now this remains a point of uncertainty how do the different stages phis effect performance which are the most important ones the authors do evaluate the effect of hand tuning the transformation stages vs learning them it would be great to also include results of including excluding stages completely and also reporting how much the initial jittering of the data helps while there is an interesting idea of limited novelty to the paper there are some concerns about evalations and comparisons as outlined above in addition only success on a single dataset task is shown yet the task is interesting and seems challenging overall this remains makes only a weak recommendation for acceptance,6.0
496.json,this paper proposes a new multiscale recurrent neural network where each layer has different time scale and the scale is not fixed but variable and determined by a neural network the method is elegantly formulated within a recurrent neural network framework and shows the state of the art performance on several benchmarks the paper is well written question can you extend it to bidirectional rnn,8.0
496.json,the paper proposes a modified rnn architecture with multiple layers where higher layers are only passed lower layer states if a flush operation is predicted consisting of passing up the state and reseting the lower layer state in order to select one of three operations at each time step the authors propose using the straight through estimator with a slope annealing trick during training empirical results and visualizations illustrate that the modified architecture performs well at boundary detection pros paper is well motivated exceptionally well composed provides promising initial results on learning hierarchical representations through visualizations and thorough experiments on language modeling and handwriting generation the annealing trick with the straight through estimator also seems potentially useful for other tasks containing discrete variables and the trade off in the flush operation is innovative cons in a couple cases the paper does not fully deliver empirical results on computational savings are not given and hierarchy beyond a single level where the data contains separators such as spaces and pen up down does not seem to be demonstrated it unclear whether better downstream performance is due to use of hierarchical information or due to the architecture changes acting as regularization something which could hopefully be addressed,7.0
316.json,this paper addresses the problem of achieving differential privacy in a very general scenario where a set of teachers is trained on disjoint subsets of sensitive data and the student performs prediction based on public data labeled by teachers through noisy voting i found the approach altogether plausible and very clearly explained by the authors adding more discussion of the bound and its tightness from theorem itself would be appreciated a simple idea of adding perturbation error to the counts known from differentially private literature is nicely re used by the authors and elegantly applied in a much broader non convex setting and practical context than in a number of differentially private and other related papers the generality of the approach clear improvement over predecessors and clarity of the writing makes the method worth publishing,9.0
377.json,this paper addresses the question of how to utilize physical interactions to answer questions about physical outcomes this question falls into a popular stream in ml community understanding physics the paper moved a step further and worked on experimental setups where there is no prior about the physical properties rules and it uses a deep reinforcement learning drl technique to address the problem my overall opinion about this paper is an interesting attempt and idea yet without a clear contribution the experimental setups are quite interesting the goal is to figure out which blocks are heavier or which blocks are glued together only by pushing and pulling objects around without any prior the paper also shows reasonable performances on each task with detailed scenarios while these experiments and results are interesting the contribution is unclear my main question is does this result bring us any new insight while the scenarios are interesting and focused on physical experiments this is not any more different potentially easier than learning from playing games e g atari in other words are the tasks really different from other typical popular drl tasks to this end i would have been more excited if authors showed some more new insights or experiments on learned representations and etc currently the paper only discusses the factual outcome for example it describes the experimental setup and how much performances an agent could achieve the authors could probably dissect the learned representations further or discuss how the experimental results are linked to the human behavior or physical properties laws i am very in between for my overall rating i think the paper could have a deeper analysis i however recommend the acceptance because of its merit of the idea the followings are some detailed questions not directly impacting my overall rating page we assume that the agent has no prior knowledge about the physical properties of objects or the laws of physics and hence must interact with the objects in order to learn to answer questions about these properties why does one must interact with objects in order to learn about the properties can not we also learn through observation figure right is missing a y axis label page a relating to bandit is interesting but the formal approach is all based on drl page which makes distinguishing between the two heaviest blocks very difficult i am a bit confused why having a small mass gap makes the task harder unless it really close to should not a machine be possible to distinguish even a pixel difference of speed if not is not this just because of the network architecture page since the agents exhibit similar performance using pixels and features we conduct the remaining experiments in this section using feature observations since these agents are substantially faster to train how about at least showing a correlation of performances at the instance level rather than average performances even so i think this is a bit of big conclusion throughout the papers i felt that many conclusions e g difficulty and etc are based on a particularly chosen training distribution for example how does an agent really know when the instance is any more difficult does not this really depend on the empirically learned distribution of training samples i e p m m m where mi indicates masses of object and in other words does what is hard easy matter much unless this is more thoroughly tested over various types of distributions any baseline approach,6.0
377.json,this paper investigates the question of gathering information answering question through direct interaction with the environment in that sense it is closely related to active learning in supervised learning or to the fundamental problem of exploration exploitation in rl the authors consider a specific instance of this problem in a physics domain and learn information seeking policies using recent deep rl methods the paper is mostly empirical and explores the effect of changing the cost of information via the discount factor on the structure of the learned policies it also shows that general purpose deep policy gradient methods are sufficient powerful to learn such tasks the proposed environment is to my knowledge novel as well the task formulation in section and it would be very valuable to the the community if the environment would be open sourced the expression latent structure dynamics is used throughout the text and the connection with bandits is mentioned in section it therefore seems that authors aspire for more generality with their approach but the paper does not quite fully ground the proposed approach formally in any existing framework nor does it provide a new one completely for example how does your approach formalize the concept of questions and answers what makes a question difficult how do you quantify difficulty how do you define the cost of information what are its units bits scalar reward its semantics do you you have an mdp or a pomdp what kind of mdp do you consider how do you define your discounted mdp what is the state and action spaces some important problem structure under the interaction labeling reward paragraph of section would be worth expressing directly in your definition of the mdp labeling actions can only occur during the labeling phase and that the transition and reward functions have a specific structure positive negative lead to absorbing state the notion of phase could perhaps be implemented by considering an augmented state space tilde s s phase,7.0
377.json,this paper purports to investigate the ability of rl agents to perform physics experiments in an environment to infer physical properties about the objects in that environment the problem is very well motivated indeed inferring the physical properties of objects is a crucial skill for intelligent agents and there has been relatively little work in this direction particularly in deep rl the paper is also well written as there are no architectural or theoretical contributions of the paper and none are claimed the main novelty comes in the task application using a recurrent ac model for two tasks that simulate an agent interacting with an environment to infer physical properties of objects more specifically two tasks are considered moving blocks to determine their mass and poking towers such that they fall to determine the number of rigid bodies they are composed of these of course represent a very limited cross section of the prerequisite abilities for an agent to understand physics this in itself is not a bad thing but since there is no comparison of different simpler rl agents on the tasks it is difficult to determine if the tasks selected are challenging as mentioned in the pre review question the which is heavier task seems quite easy due to the actuator set up and the fact that the model simply must learn to take the difference between successive block positions which are directly encoded as features in most experiments thus it is not particularly surprising that the rl agent can solve the proposed tasks the main claim beyond solving two proposed tasks related to physics simulation is that the agents learn different strategies for these tasks that balance the cost of gathering information against the cost of making mistakes the cost of gathering information is implemented by multiplying the reward with a value of gamma this is somewhat interesting behaviour but is hardly surprising given the problem setup one item the authors highlight is that their approach of learning about physical object properties through interaction is different from many previous approaches which use visual cues however the authors also note that this in itself is not novel and has been explored in other work e g agrawal et al i think it s crucial for the authors to discuss these approaches in more detail potentially along with removing some other less relevant information from the related work section and specifically highlight why the proposed tasks in this paper are interesting compared to for example learning to move objects towards certain end positions by poking them to discern the level of contribution of the paper one must ask the following questions how much do these two tasks contribute above previous work to the goal of having agents learn the properties of objects by interaction and how much do the results of the rl agent on these tasks contribute to our understanding of agents that interact with their environment to learn physical properties of objects it is difficult to know exactly but due to the concerns outlined above i am not convinced that the answers to or are to a significant extent in particular for since the proposed agent is able to essentially solve both tasks it is not clear that the tasks can be used to benchmark more advanced agents e g it can t be used as a set of babi like tasks another possible concern as pointed out by reviewer is that the description of the model is extremely concise it would be nice to have for example a diagram illustrating the inputs and outputs to the model at each time step to ease replication overall it is important to make progress towards agents that can learn to discover physical properties of their environment and the paper contributes in this direction however the technical contributions of this paper are rather limited thus it is not clear to what extent the paper pushes forward research in this direction beyond previous work that is mentioned it would be nice for example to have some discussion about the future of agents that learn physics from interaction speculation on more difficult versions of the tasks in this paper and how the proposed approach fits into that picture edit score updated see comments below,7.0
377.json,this paper presents interesting experimental findings that state of the art deep reinforcement learning methods enable agent learning of latent physical properties in its environment the paper formulates the problem of an agent labeling environmental properties after interacting with the environment based on its actions and applies the deep reinforcement learning model to evaluate whether such learning is possible the approach jointly learns the convolutional layers for pixel based perception and its later layers for learning actions based on reinforcement signals we have a mixed opinion about this paper the paper is written clearly and presents interesting experimental findings it introduces and formulates a problem potentially important for many robotics applications simultaneously the paper suffers from lacking algorithmic contributions and missing some of crucial experiments to confirm its true benefits pros this paper introduces a new problem of learning latent properties in the agent environment the paper presents a framework to appropriately combine existing tools to address the formulated problem the paper tries reinforcement learning with image inputs and fist like actuator actions this will lead to its direct application to robots cons lacking algorithmic contribution this paper applies existing tools methods to solve the problem rather than developing something new or extending them the approach essentially is training lstms with convolutional layers using the previous asynchronous advantage actor critic in the towers experiment the results of probably the most important setting fist pixels are missing this setting receiving pixel inputs and using the fist actuator in a continuous space is the setting closest to real world robots and thus is very important to confirm whether the proposed approach will be directly applicable to real world robots however figure is missing the results with this setting is there any reason behind this the paper lacks its comparison to any baseline methods without explicit baselines it is difficult to see what the agent is really learning and what aspect of the proposed approach is benefitting the task for instance in the towers task how would an agent randomly pushing hitting the tower using fist a number of times and then passively observing its consequence to produce a label perform compared to this approach that is how would an approach with a fixed action policy but with everything else perform compared to the full deep reinforcement learning version,7.0
663.json,this paper introduces a large scale multi model product classification system the model consists of three modules image cnn vgg architecture text cnn kim and decision level fusion policies the authors have tried several fusion methods including policies taking inputs from text and image cnn probabilities choose either cnn average the predictions end to end training experimental results show that text cnn alone works better than image cnn and multi model fusion can improve the accuracy by a small margin it is a little bit surprising that end to end feature level fusion works worse than text cnn alone the writing is clear and there are a lot of useful practical experiences of learning large scale model however i lean toward rejecting the paper because the following no other dataset reported the authors have not mentioned releasing the walmart dataset and it is going to be really hard to reproduce the results without the dataset technical novelty is limited all the decision level fusion policies have been investigated by some previous methods before performance gain is also limited,5.0
663.json,this paper tackles the problem of multi modal classification of text and images pros interesting dataset and application cons the results are rather lacklustre showing a very mild improvement compared to the oracle improvement but perhaps some insights as to whether the incorrect decisions are humanly possible would help with significance of the results could have explored some intermediate architectures such as feature fusion class probabilities with without finetuning there are no feature fusion results reported no evaluation on standard datasets or comparison to previous works what is the policy learnt for cp given input class probabilities how does the network perform better than max or mean,5.0
663.json,this paper presents a system approach to combine multiple modalities to perform classification in a practical scenario e commerce in general i find the proposed approach in the paper sound and solid but do not see novelty in the paper feature fusion and decision time fusion are both standard practices in multi modal analysis and the rest of the paper offers no surprise in implementing such approaches this seems to be a better fit for venues that focus more on production systems and seems to be a bad fit for iclr where the focus is more on research of novel algorithms and theories,4.0
419.json,this paper introduces a model that blends ideas from generative topic models with those from recurrent neural network language models the authors evaluate the proposed approach on a document level classification benchmark as well as a language modeling benchmark and it seems to work well there is also some analysis as to topics learned by the model and its ability to generate text overall the paper is clearly written and with the code promised by the authors others should be able to re implement the approach i have potentially major questions i would ask the authors to address lda topic models make an exchangability bag of words assumption the discussion of the generative story for topicrnn should explicitly discuss whether this assumption is also made on the surface it appears it is since yt is sampled using only the document topic vector and ht but we know that in practice ht comes from a recurrent model that observes yt not clear how this clean exposition of the generative model relates to what is actually done in the generating sequential text section it s clear the topic model can t generate words without using y t but this seems inconsistent with the generative model specification this needs to be shown in the paper and made clear to have a complete paper the topic model only allows for linear interactions of the topic vector theta it seems like this might be required to keep the generative model tractable but seems like a very poor assumption we would expect the topic representation to have rich interactions with a language model to create nonlinear adjustments to word probabilities for a document please add discussion as to why this modeling choice exists and if possible how future work could modify that assumption or explain why it s not such a bad assumption as one might imagine figure colors very difficult to distinguish,6.0
462.json,this paper explores an important angle to adversarial examples the detection of adversarial images and their utilization for trainig more robust networks this takes the competition between adversaries and models to a new level the paper presents appealing evidence for the feasibility of robustifying networks by employing the a detector subnetwork that is trained particularly for the purpose of detecting the adversaries in a terget manner rather than just making the networks themselves robust to adversarial examples the jointly trained primary detector system is evaluated in various scenarios including the cases when the adversary generator has access to the model and those where they are generated in a generic way the results of the paper show good improvements with the approach and present well motived thorough analyses to back the main message the writing is clear and concise,7.0
383.json,this paper introduces a reinforcement learning framework for designing a neural network architecture for each time step the agent picks a new layer type with corresponding layer parameters e g filters in order to reduce the size of state action space they used a small set of design choices strengths a novel approach for automatic design of neural network architectures shows quite promising results on several datasets mnist cifar weakness limited architecture design choices due to many prior assumptions e g a set of possible number of convolution filters at most fully connected layers maximum depth hard coded dropout etc the method is demonstrated in tabular q learning setting but it is unclear whether the proposed method would work in a large state action space overall this is an interesting and novel approach for neural network architecture design and it seems to be worth publication despite some weaknesses,6.0
383.json,authors learn deep architectures on a few small vision problems using q learning and obtain solid results sota results when limiting to certain types of layers and competitive against everything else it would be good to know how well this performs when allowing more complex structures paper would be much more convincing on a real size task such as imagenet,6.0
340.json,this paper presents an unsupervised image transformation method that maps a sample from source domain to target domain the major contribution lies in that it does not require aligned training pairs from two domains the model is based on gans to make it work in the unsupervised setting this paper decomposes the generation function into two modules an encoder that identify a common feature space between two domains and an decoder that generates samples in the target domain to avoid trivial solutions this paper proposed two additional losses that penalize the feature difference between a source sample and its transformed sample and the pixel difference between a target sample and its re generated sample this paper presents extensive experiments on transferring svhn digit images to mnist style and transferring face images to emoji style the proposed learning method enables unsupervised domain transfer that could be impactful in broad problem contexts this paper presents careful ablation studies to analyze the effects of different components of the system which is helpful for understanding the paper the transferred images are visually impressive and quantitative results also show the image identities are preserved across domains to some degree it will be more interesting to show results in other domains such as texts and images in addition to the face identities it is also of great interest to analyze how well the facial attributes are preserved when mapping to target domain,7.0
340.json,update thank you for running more experiments and add more explanations in the manuscript they addressed most of my concerns so i updated the score accordingly the work aims at learning a generative function g that can maps input from source domain to the target domain such that a given representation function f remain unchanged accepting inputs from either domain the criteria is termed f constancy the proposed method is evaluated on two visual domain adaptation tasks the paper is relatively easy to follow and the authors provided quite extensive experimental results on the two datasets f constancy is the main novelty of the work it seems counter intuitive to force the function g to be of g o f i e starting from a restricted function f which might have already lost information as in the face dataset f is learned to optimize the performance of certain task on some external dataset it is not clear if an input from the source or target domain can be recovered from applying g as in equation and also the f function is learned with a particular task in mind as in the two experiments the representation function f is learned to identify the digits in the source svhn dataset or the identity of some face dataset as a result the procedure has to be repeated if we were to perform domain adaptation for the same domains but for different tasks such as recognizing expressions instead of identity do the authors have insight on why the baseline method proposed in equation and perform so poorly figure shows some visual comparison between style transfer and the proposed method it is not clear though which method is better will it be possible to apply style transfer to generate emojis from photos and repeat the experiments shown in table,6.0
356.json,the paper presents a method to synthesize string manipulation programs based on a set of input output pairs the paper focuses on a restricted class of programs based on a simple context free grammar sufficient to solve string manipulation tasks from the flashfill benchmark a probabilistic generative model called recursive reverse recursive neural network rnn is presented that assigns a probability to each program parse tree after a bottom up and a top down pass results are presented on a synthetic dataset and a microsoft excel benchmark called flashfill the problem of program synthesis is important with a lot of recent interest from the deep learning community the approach taken in the paper based on parse trees and recursive neural networks seems interesting and promising however the model seems too complicated and unclear at several places details below on the negative side the experiments are particularly weak and the paper does not seem ready for publication based on its experimental results i was positive about the paper until i realized that the method obtains an accuracy of on flashfill benchmark when presented with only input output examples but the performance degrades to when input output examples are used this was surprising to the authors too and they came up with some hypothesis to explain this phenomenon to me this is a big problem indicating either a bug in the code or a severe shortcoming of the model any model useful for program synthesis needs to be applicable to many input output examples because most complicated programs require many examples to disambiguate the details of the program given the shortcoming of the experiments i am not convinced that the paper is ready for publication thus i recommend weak reject i encourage the authors to address the comments below and resubmit as the general idea seems promising more comments i am unclear about the model at several places how is the probability distribution normalized given the nature of bottom up top down evaluation of the potentials should one enumerate over different completions of a program and the compare their exponentiated potentials if so does this restrict the applicability of the model to long programs as the enumeration of the completions gets prohibitively slow what if you only use input output pair for each program instead of do the results get better section is not clear to me can you elaborate by potentially including some examples does your input output representation pre supposes a fixed number of input output examples across tasks e g or for all of the tasks regarding the experiments could you present some baseline results on flashfill benchmark based on previous work is your method only applicable to short programs based on the choice of for the number of instructions does a program considered correct when it is identical to a test program or is it considered correct when it succeeds on a set of held out input output pairs when using or more program samples do you report the accuracy of the best program out of i e recall or do you first filter the programs based on training input output pairs and then evaluate a program that is selected your paper is well beyond the recommended limit of pages please consider making it shorter,5.0
614.json,the paper introduces a time dependent recommender system based on point processes parametrized by time dependent user and item latent representations the later are modeled as coupled autoregressive processes i e the representation of a user item changes when he interacts with an item user and is a function of both the user and the item representations before time t this is called coevolution here and the autoregressive process is called recurrent nn the model may also incorporate heterogeneous inputs experiments are performed on several datasets and the model is compared with different baselines there are several contributions in the paper modeling recommendation via parametrized point processes where the parameter dynamics are modeled by latent user item representations an optimization algorithm for maximizing the likelihood of this process with different technical tricks that seem to break its intrinsic complexity evaluation experiments for time dependent recommendation the paper by the same authors nips describes a similar model of continuous time coevolution and a similar evaluation the difference lies in the details of the model the point process model is not the same and of the latent factor dynamic model is slightly different but the modeling approach and the arguments are exactly the same by the end one does not know what makes this model perform better than the one proposed in nips is it the choice for the process the new parametrization both are quite similar there is no justification on the choice of the specific form of the point process in the two papers did the authors tried other forms as well the same remark applies for the form of the dynamical process the non linearity used for the modeling of the latent user item vectors here is limited to a sigmoid function which probably does not change much w r t a linear model but there is no evidence of the role of this non linearity in the paper note that there are some inconsistencies between the results in the two papers concerning the evaluation the authors introduce two criteria i did not get exactly how they evaluate the item recommendation it is mentioned that at each time t the model predicts the item the user will interact with do you mean the next item the user will interact with after time t for the time prediction why is it a relevant metric for recommendation a comparison of the complexity or execution time of the different methods would be helpful the complexity of your method is apparently proportional to items users what are the complexity limits of your methods overall the paper is quite nice and looks technically sound albeit many details are missing on the other hand i have a mixed feeling because of the similarity with nips paper the authors should have make a better work at convincing us that this is not a marginal extension of previous work by the authors i was not convinced either by the evaluation criteria and there is no evidence that the model can be used for large datasets,6.0
614.json,this paper proposes a method to model time changing dynamics in collaborative filtering comments the main idea of the paper is build upon similar to a previous work by the same group of author wang et al kdd the major difference appears to be change some of the latent factors to be rnn the author describes a bptt technique to train the model the author introduced time prediction as a new metric to evaluate the effectiveness of time dependent model however this need to be condition on a given user item pair it would be interesting to consider other metrics for example the switching time where a user changes his her to another item jointly predict the next item and switching time in summary this is a paper that improves over an existing work on time dynamics model in recommender system the time prediction metric is interesting and opens up interesting discussion on how we should evaluate recommender systems when time is involved see also comments,6.0
614.json,the paper seeks to predict user events interactions with items at a particular point in time roughly speaking the contributions are as follows a the paper models the co evolutionary process of users preferences toward items b the paper is able to incorporate external sources of information such as user and item features c the process proposed is generative so is able to estimate specific time points at which events occur d the model is able to account for non linearities in the above following the pre review questions i understand that it is the combination of a and c that is the most novel aspect of the paper a fully generative process which can be sampled is certainly nice though of course non generative processes like regular old regression can estimate specific time points and such too so not sure in practice how relevant this distinction is other than that the above parts have all appeared in some combination in previous work though the combination of parts here certainly passes the novelty bar i had not quite followed the issue mentioned in the pre review discussion that the model requires multiple interactions per userxitem pair in order to fit the model e g a user interacts with the same business multiple times this is a slightly unusual setting compared to most temporal recommender systems work i question to some extent whether this problem setting is not a bit restrictive that being said i take the point about why the authors had to subsample the yelp data but keeping only users with hundreds of events means that you are left with a very biased sample of the user base other than the above issues the paper is technically nice and the experiments include strong baselines and reports good performance,6.0
478.json,i am torn on this one seeing the mpeg dataset and references to curvature scale space brought to mind the old saying that if it not worth doing it not worth doing well there is no question that the mpeg dataset benchmark got saturated long ago and it quite surprising to see it in a submission to a modern ml conference i brought up the question of why use this representation with the authors and they said their main purpose was to connect the theory of differential geometry of curves with the computational engine of a convolutional neural network fair enough i agree these are seemingly different fields and the authors deserve some credit for connecting them if we give them the benefit of the doubt that this was worth doing then the approach they pursue using a siamese configuration makes sense and their adaptation of deep convnet frameworks to d signals is reasonable to the extent that the old invariant based methods made use of smoothed filtered representations coupled with nonlinearities it sensible to revisit this problem using convnets i would not mind seeing this paper accepted since it different from the mainstream but i worry about there being too narrow an audience at iclr that still cares about this type of shape representation,6.0
478.json,authors show that a contrastive loss for a siamese architecture can be used for learning representations for planar curves with the proposed framework authors are able to learn a representation which is comparable to traditional differential or integral invariants as evaluated on few toy examples the paper is generally well written and shows an interesting application of the siamese architecture however the experimental evaluation and the results show that these are rather preliminary results as not many of the choices are validated my biggest concern is in the choice of the negative samples as the network basically learns only to distinguish between shapes at different scales instead of recognizing different shapes it is well known fact that in order to achieve a good performance with the contrastive loss one has to be careful about the hard negative sampling as using too easy negatives may lead to inferior results thus this may be the underlying reason for such choice of the negatives unfortunately this is not discussed in the paper furthermore the paper misses a more thorough quantitative evaluation and concentrates more on showing particular examples instead of measuring more robust statistics over multiple curves invariance to noise and sampling artifacts in general the paper shows interesting first steps in this direction however it is not clear whether the experimental section is strong and thorough enough for the iclr conference also the novelty of the proposed idea is limited as siamese networks are used for many years and this work only shows that they can be applied to a different task,5.0
400.json,the paper propose drnn as a neural decoder for tree structures i like the model architecture since it has two clear improvements over traditional approaches the information flows in two directions both from the parent and from siblings which is desirable in tree structures the model use a probability distribution to model the tree boundary i e the last sibling or the leaf this avoids the use of special ending symbols which is larger in size and putting more things to learn for the parameters shared with other symbols the authors test the drnn using the tasks of recovering the synthetic trees and recovering functional programs the model did better than traditional methods like seqseq models i think the recovering synthetic tree task is not very satisfying for two reasons the surface form itself already containing some of the topological information which makes the task easier than it should be as we can see from figure when the number of nodes grows even to a number not very large the performance of the model drops dramatically i am not sure if a simple baseline only captures the topological information in the surface string would be much worse than this and drnn in this case seems can t show its full potentials since the length of the information flow in the model won t be very long i think the experiments are interesting but i think there are some other tasks which are more difficult and the tree structure information are more important in such tasks for example we have the seqseq parsing model vinyals et al is it possible to use the drnn proposed here on the decoder side i think tasks like this can show more potentials of the drnn and can be very convincing that model architectures like this are better than traditional alternatives,6.0
457.json,there is a great deal of ongoing interest in compressing neural network models one line of work has focused on using low precision representations of the model weights even down to or bits however so far these approaches have been accompanied by a significant impact on accuracy the paper proposes an iterative quantization scheme in which the network weights are quantized in stages the largest weights in absolute value are quantized and fixed while unquantized weights can adapt to compensate for any resulting error the experimental results show this is extremely effective yielding models with bit or bit weights with essentially no reduction in accuracy while at bits the accuracy decreases slightly the results are substantially better than those achieved with other quantization approaches overall this paper is clear the technique is as far as i am aware novel the experiments are thorough and the results are very compelling so i recommend acceptance the paper could use another second pass for writing style and grammar also the description of the pruning inspired partitioning strategy could be clarified somewhat e g the chosen splitting ratio of only seems to be referenced in a figure caption and not the main text,8.0
457.json,the idea of this paper is reasonable gradually go from original weights to compressed weights by compressing a part of them and fine tuning the rest everything seems fine results look good and my questions have been addressed to improve the paper it would be good to incorporate some of the answers into the paper mainly the results with pruning this method as that can be compared fairly to han et al and outperforms it it would be good to better explain the encoding method my question as it is not that clear from the paper e g made me make a mistake in question for the computation of n the bits is misleading as in fact what is used is variable length encoding which is on average close to bits where is represented with bit e g other values are represented with bits where the first bit is needed to distinguish from and the remaining bits represent the different values for the powers of,7.0
482.json,in light of the detailed author responses and further updates to the manuscript i am raising my score to an and reiterating my support for this paper i think it will be among the strongest non traditional applied deep learning work at iclr and will receive a great deal of interest and attention from attendees this paper describes modern deep learning approach to the problem of predicting the medications taken by a patient during a period of time based solely upon the sequence of icd codes assigned to the patient during that same time period this problem is formulated as a multilabel sequence classification in contrast to language modeling which is multiclass classification they propose to use standard lstm and gru architectures with embedding layers to handle the sparse categorical inputs similar to that described in related work by choi et al in experiments using a cohort of k patient records they find that rnn models outperform strong baselines including an mlp and a random forest as well as a common sense baseline the differences in performance between the recurrent models and the mlp appear to be large enough to be significant given the size of the test set strengths very important problem as the authors point out two the value propositions of ehrs which have been widely adopted throughout the us due to a combination of legislation and billions of dollars in incentives from the federal government included more accurate records and fewer medication mistakes these two benefits have largely failed to materialize this seems like a major opportunity for data mining and machine learning paper is well written with lucid introduction and motivation thorough discussion of related work clear description of experiments and metrics and interesting qualitative analysis of results empirical results are solid with a strong win for rnns over convincing baselines this is in contrast to some recent related papers including lipton kale et al iclr where the gap between the rnn and mlp was relatively small and choi et al mlhc which omitted many obvious baselines discussion is thorough and thoughtful the authors are right about the kidney code embedding results this is a very promising result weaknesses the authors make several unintuitive decisions related to data preprocessing and experimental design foremost among them the choice not to use full patient sequences but instead only truncated patient sequences that each ends at randomly chosen time point this does not necessarily invalidate their results but it is somewhat unnatural and the explanation is difficult to follow reducing the paper potential impact it is also reduces the rnn potential advantage the chosen metrics seem appropriate but non experts may have trouble interpreting the absolute and relative performances beyond the superficial e g rnn score more than nn the authors should invest some space in explaining what level of performance for each metric would be necessary for the model to be useful in a real clinical setting and whether the gaps between the various models are significant even in an informal sense the paper proposes nothing novel in terms of methods which is a serious weakness for a methods conference like iclr i think it is strong enough empirically and sufficiently interesting in application to warrant acceptance regardless but there may be things the authors can do to make it more competitive for example one potential hypothesis is that higher capacity models are more prone to overfitting noisy targets is there some way to investigate this perhaps by looking at the kinds of errors each model makes i have a final comment as a piece of clinical work the paper has a huge weakness the lack of ground truth labels for missing medications models are both trained and tested on data with noisy labels for training the authors are right that this should not be a huge problem provided the label noise is random even class conditional is not too big of a problem for testing though this seems like it could skew metrics further the assumption that the label noise is not systemic seems very unlikely given that these data are recorded by human clinicians the cases shown in appendix c lend some credence to this assertion for case actual medications received probabilities my hunch is that clinical reviewers would view the paper with great skepticism the authors will need to get creative about evaluation or invest a lot of time money in labeling data to really prove that this works for what it is worth i hope that this paper is accepted as i think it will be of great interest to the iclr community however i am borderline about whether i would be willing to fight for its acceptance if the authors can address the reviewers critiques and in particular dive into the question of overfitting the imperfect labels and provide some insights i might be willing to raise my score and lobby for acceptance,8.0
363.json,this paper proposed a compare aggregate model for the nlp tasks that require semantically comparing the text sequences such as question answering and textual entailment the basic framework of this model is to apply a convolutional neural network aggregation after a element wise operation comparison over the attentive outputs of the lstms the highlighted part is the comparison where this paper compares several different methods for matching text sequences and the element wise subtraction multiplication operations are demonstrated to achieve generally better performance on four different datasets while the weak point is that this is an incremental work and a bit lack of innovation a qualitative evaluation about how subtraction multiplication and other comparison functions perform on varied kinds of sentences would be more interesting,6.0
363.json,this paper proposes a compare aggregate framework that performs word level matching followed by aggregation with convolutional neural networks it compares six different comparison functions and evaluates them on four datasets extensive experimental results have been reported and compared against various published baselines the paper is well written overall a few detailed comments page line including a some including some what is the benefit of the preprocessing and attention step can you provide the results without it figure is hard to read esp when on printed hard copy please enhance the quality,7.0
363.json,the paper presents a general approach to modeling for natural language understanding problems with two distinct textual inputs such as a question and a source text that can be aligned in some way in the approach soft attention is first used to derive alignments between the tokens of the two texts then a comparison function uses the resulting alignments represented as pairs of attention queries and attention results to derive a representations that are aggregated by cnn into a single vector from which an output can be computed the paper both presents this as an overall modeling strategy that can be made to work quite well and offers a detailed empirical analysis of the comparison component of the model this work is timely language understanding problems of this kind are a major open issue in nlp and are just at the threshold of being addressable with representation learning methods the work presents a general approach which is straightforward and reasonable and shows that it can yield good results the work borders on incremental relative to their earlier work or that of parikh et al but it contributes in enough substantial ways that i would strongly recommend acceptance detail the model at least as implemented for the problems with longer sequences everything but snli is not sensitive to word order it is empirically competitive but this insensitivity places a strong upper bound on its performance the paper does make this clear but it seems salient enough to warrant a brief mention in the introduction or discussion sections if i understand correctly your attention strategy is based more closely on the general bilinear strategy of luong et al than it is on the earlier bahdanau work you should probably cite the former or some other more directly relevant reference for that strategy since the ntn risks overfitting because of its large number of parameters did you try using a version with input dimension l and a smaller output dimension m so an l l m tensor you should probably note that submultnn looks a lot like the strategy for sentence level matching in the lili mou paper you cite is there a reason you use the same parameters for preprocessing the question and answer in these could require different things to be weighted highly,8.0
498.json,this paper introduces dropout as a latent variable model lvm leveraging this formulation authors analyze the dropout inference gap which they define to be the gap between network output during training where an instance of dropout is used for every training sample and test where expected dropout values are used to scale node outputs they introduce the notion of expectation linearity and use this to derive bounds on the inference gap under some mild assumptions furthermore they propose use of per sample based inference gap as a regularizer and present analysis of accuracy of models with expectation linearization constraints as compared to those without one relatively minor issue i see with the lvm view of dropout is that it seems applicable only to probabilistic models whereas dropout is more generally applicable to deep networks however i d expect that the regularizer formulation of dropout would be effective even in non probabilistic models mc dropout on page is not defined please define on page it is mentioned that with the proposed regularizer the standard dropout networks achieve better results than when monte carlo dropout is used this seems to be the case only on mnist dataset and not on cifar from tables and it also appears that mc dropout achieves best performance across tasks and methods but it is of course an expensive procedure comments on the computational efficiency of various dropout procedures to go with the accuracy results would be quite valuable couple of typos pg x is he input x is the input pg as defined in is ref to is not right at two places in this paragraph overall it is a good paper i think should be accepted and discussed at the conference,7.0
358.json,this paper proposes a hierarchical generative model where the lower level consists of points within datasets and the higher level models unordered sets of datasets the basic idea is to use a double variational bound where a higher level latent variable describes datasets and a lower level latent variable describes individual examples hierarchical modeling is an important and high impact problem and i think that it under explored in the deep learning literature pros the few shot learning results look good but i am not an expert in this area the idea of using a double variational bound in a hierarchical generative model is well presented and seems widely applicable questions when training the statistic network are minibatches i e subsets of the examples used if not does using minibatches actually give you an unbiased estimator of the full gradient if you had used all examples for example what if the statistic network wants to pull out if any example from the dataset has a certain feature and treat that as the characterization this seems to fit the graphical model on the right side of figure if your statistic network is trained on minibatches it wo not be able to learn this characterization because a given minibatch will be missing some of the examples from the dataset using minibatches as opposed to using all examples in the dataset to train the statistic network seems like it would limit the expressive power of the model suggestions hierarchical forecasting electricity sales could be an interesting and practical use case for this type of model,8.0
358.json,sorry for the late review i have been having technical problems with openreview which prevented me from posting this paper presents a method for learning to predict things from sets of data points the method is a hierarchical version of the vae where the top layer consists of an abstract context unit that summarizes a dataset experiments show that the method is able to learn to learn by acquiring the ability to learn distributions from small numbers of examples overall this paper is a nice addition to the literature on one or few shot learning the method is conceptually simple and elegant and seems to perform well compared to other recent papers on one shot learning the proposed method is simpler and is based on unsupervised representation learning the paper is clearly written and a pleasure to read the name of the paper is overly grandiose relative to what was done the proposed method doesn t seem to have much in common with a statistician unless one means by that someone who thinks up statistics the experiments are well chosen and the few shot learning results seem pretty solid given the simplicity of the method the spatial mnist dataset is interesting and might make a good toy benchmark the inputs in figure seem pretty dense though shouldn t the method be able to recognize the distribution with fewer samples nitpick the red points in figure don t seem to correspond to meaningful points as was claimed in the text will the authors release the code,8.0
749.json,the authors take on the task of figuring out a set of design patterns for current deep architectures namely themes that are recurring in the literature if one may say so a distributed representation of deep architectures there are two aspects of the paper that i particularly valued firstly the excellent review of recent works which made me realize how many things i have been missing myself secondly the community service aspect of helping someone who starts figure out the coordinate system for deep architectures this could potentially be more important than introducing yet another trick of the trade as most other submissions may do however i think this work is still half done and even though working on this project is a great idea the authors do not yet do it properly firstly i am not too sure how the choice of these patterns was made maxout for instance pattern is one of the many nonlinearities prelu relu and i do not see how it stands on the same grounds as something as general as strive for simplicity similarly some of the patterns are as vague as increase symmetry and are backed up by statements such as we noted a special degree of elegance in the fractalnet i do not see how this leads to a design pattern that can be applied to a new architecture or if it applies to anything other than the fractalnet some other patterns are phrased with weird names cover the problem space which i guess stands for dataset augmentation or over train which is not backed up by a single reference unless the authors relate it to regularization text preceding overtrain which then has no connection to the description of over train provided by the authors training a network on a harder problem to improve generalization if harder problem means one where one adds an additional term i e the regularizer the authors are doing harm to the unexperienced reader confusing regularization with something that sounds like overfitting i e the exact opposite furthermore the extensions proposed in section seem a bit off tune in particular i could not figure out how the taylor series networks stem from any of the design patterns proposed in the rest of the paper whether the text between and is another of the architecture innovations and if yes why it is not in the or and most importantly how these design patterns would be deployed in practice to think of a new network to be more concrete the authors mention that they propose the freeze drop path variant from symmetry considerations to drop path is this an application of the increase symmetry pattern how would freeze drop path be more symmetric that drop path can this be expressed concretely or is it some intuitive guess if the second it is not really part of applying a pattern in my understanding if the first this is missing what i would have appreciated more and would like to see in a revised version would have been a table of design patterns on one axis deep network on another and a breakdown of which network applies which design pattern a big part of the previous work is also covered in cryptic language some minimal explanation of what is taking place in the alternative works would be useful,4.0
460.json,this paper studies the off policy learning of actor critic with experience replay this is an important and challenging problem in order to improve the sample efficiency of the reinforcement learning algorithms the paper attacks the problem by introducing a new way to truncate importance weight a modified trust region optimization and by combining retrace method the combination of the above techniques performs well on atari and mujoco in terms of improving sample efficiency my main comment is how does each of the technique contribute to the performance gain if some experiments could be carried out to evaluate the separate gains from these tricks it would be helpful,7.0
460.json,this paper introduces an actor critic deep rl approach with experience replay which combines truncated importance sampling and trust region policy optimization the paper also proposes a new method called stochastic duelling networks to estimate the critic for continuous action spaces the method is applied to atari games and continuous control problems where it yields performance comparable to state of the art methods as mentioned in the beginning of the paper the main contributions of this work lies in combining truncated importance sampling with retrace trust region policy optimization and stochastic duelling networks these improvements work well and may be beneficial to future work in rl however each improvement appears to be quite incremental moreover the acer framework seems much more complex and fragile to implement compared to the standard deep q learning with prioritized replay which appears to perform just as well on atari games so for the atari domain i would still put my money on prioritized replay due to its simplicity thirdly improving sample efficiency for deep rl is a laudable goal but really this goal should be pursued in a problem setting where sample efficiency is important unfortunately the paper only evaluates sample efficiency in the atari and continuous control tasks domain two domains where sample efficiency is not important thus it is not clear that the proposed method acer will generalize to problems where we really care about sample efficiency some technical aspects which need clarifications for retrace i assume that you compute recursively q ret starting from the end of each trajectory please comment on this it not clear to me how to derive eq is an approximation double tilde sign missing in section the paper argued that q ret gives a lower variance estimate of the action value function then why not use it in eq for the bias correction term the paper states that it uses a replay memory of frames so that across threads it is comparable in size to previous work however for each thread this is much smaller compared to earlier experiments on atari games for example one million experience replay transitions were used in the paper prioritized experience replay by schaul et al this may have a huge impact on performance of the models both for acer and for the competing models in order to properly assess the improvements of acer over previous work the authors need to also experiment with larger experience replay memories other comments please move section to the appendix moreover when using small values of lambda to reduce variance occasional large importance weights can still cause instability i think what is meant is using large values of lambda above eq mention that the squared error is used missing a t subscript at the beginning of eq it was hard to understand the stochastic duelling networks please rephrase this part please clarify this sentence to compare different agents we adopt as our metric the median of the human normalized score over all games figure bottom please add label to vertical axes,6.0
460.json,the paper looks at several innovations for deep rl and evaluates their effect on solving games in the atari domain the paper reads a bit like a laundry list of the researcher s latest tricks it is written clearly enough but lacks a compelling message i expect the work will be interesting to people already implementing deep rl methods but will probably not get much attention from the broader community the claims on p suggest the approach is stable and sample efficience and so i expected to see some theoretical analysis with respect to these properties but this is an empirical claim it would help to clarify that in the abstract the proposed innovations are based on sound methods it is particularly nice to see the same approach working for both discrete and continuous domains the paper has reasonably complete empirical results it would be nice to see confidence intervals on more of the plots also the results don t really tease apart the effect of each of the various innovations so it s harder to understand the impact of each piece and to really get intuition for example about why acer outperforms ac also it wasn t clear to me why you only get matching results on discrete tasks but get state of the art on continuous tasks the paper has good coverage of the related literature it is nice to see this work draw more attention to retrace including the theoretical characterization in sec,6.0
773.json,the paper presents a repurposing of rectified factor networks proposed earlier by the same authors to biclustering the method seems potentially quite interesting but the paper has serious problems in the presentation quality the method relies mainly on techniques presented in a nips paper by mostly the same authors the experimental procedure should be clarified further the results especially table seem to depend critically upon the sparsity of the reported clusters but the authors do not explain in sufficient detail how the sparsity hyperparameter is determined clarity the style of writing is terrible and completely unacceptable as a scientific publication the text looks more like an industry white paper or advertisement not an objective scientific paper a complete rewrite would be needed before the paper can be considered for publication specifically all references to companies using your methods must be deleted additionally table is essentially unreadable i would recommend using a figure or cleaning up the table by removing all engineering notation and reporting numbers per so that e g e would become in general figures would be preferred as a primary means for presenting the results in text while tables can be included as supplementary information originality the novelty of the work appears limited the method is mostly based on a nips paper by the same authors the experimental evaluation appears at least partially novel but for example the ibd detection is very similar to hochreiter but without any comparison significance the authors strongest claim is based on strong empirical performance in their own benchmark problems it is however unclear how useful this would be to others as there is no code available and the details of the implementation are less than complete furthermore the method depends on many specific tuning parameters whose tuning method is not fully defined leaving it unclear how to guarantee the generalisation of the good performance,4.0
773.json,clarity the novel contribution of the paper section was very difficult to understand the notation seemed inconsistent particularly the use of l p and m and i am still not confident that i understand the model being used originality the novelty comes from applying the rfn model including the relu non linearity and dropout training to the problem of biclustering it sounds like a good idea significance the proposed algorithm appears to be a useful tool for unsupervised data modelling and the authors make a convincing argument that it is significant i e the previous state of the art fabia is widely used and this method both outperforms and addresses some of the practical difficulties with that method quality the experiments are high quality comments the introduction claims that this method is much faster than fabia because the use of rectified units allow it to be run on gpus it is not clear to me how this works how many biclusters can be supported with this method it looks like the number of biclusters used for this method in the experiments is only the introduction claims that using dropout during training increases sparsity in the bicluster assignments this seems like a reasonable hypothesis but this claim should be supported with a better argument or experiments how is the model deep the model is not deep just because it uses a relu and dropout,5.0
745.json,overall the idea in this paper is interesting and the paper is well written and well motivated however i think it is not ready to publish in iclr for the following reasons this paper is not related to representation learning it may be more suitable for a general machine learning or data mining conference the proposed approach can only work for a small class of models and cannot apply to popular formulations such as svm logistic regression and neural network it is unclear why we want to use sgd for this specific type of formulations for model like linear regression the authors should compare their methods with linear programming approaches also it is unclear why we need to develope parallel algorithm for linear regressio problems as they are relatively easy to solve unless the data are big see next comment the dataset used in the paper are relatively small and can be only used for proving the concept most datasets considered in the paper can be solved in a few second using a single core cpu hogwild is suitable for sparse dataset because of its asynchronized nature on data that are very sparse the proposed approach is only slightly better or is worse than hogwild for dense dataset it is unclear why we need to use symsgd instead of simply parallelizing the gradient computation using gpus put them together the experiment results are not convincing,4.0
745.json,this paper describes a correction technique to combine updates from multiple sgd to make it statistically equivalent to sequential technique comments the proposed method is novel and interesting to allow update to be corrected even when the update is delayed the proposed theory can only be applied to square loss setting with linear update rule making it somewhat limited this paper would be much more interesting to iclr community if the technique is applicable to general objective function and settings of deep neural networks the resulting technique requires book keeping of a dimensional reduced combiner matrix which causes more computation in terms of complexity the authors argue that the overhead can be canceled with simd support for symbolic update however the normal update of sgd might also benefit from simd especially when the dataset is dense overall even though the practical value of this work is limited by and the technique specifically the correction rule proposed in the paper could be of interest to people scaling up learning i would encourage the author to extend the method to the cases of non linear objective function which could make it more interesting to the iclr community,6.0
518.json,this paper proposes an amortized version of the stein variational gradient descent svgd method in which a neural network is trained to mimic the svgd dynamics it applies the method to generative adversarial training to yield a training procedure where the discriminator is interpreted as an energy based probabilistic model one criticism i have of the presentation is that a lot of time and energy is spent setting the table for a method which is claimed to be widely applicable and the scope of the empirical evaluation is narrowed down to a single specific setting in my view either the paper falls short of its goal of showing how widely applicable the proposed method is or it spends too much time setting the table for steingan and not enough time evaluating it the consequence of this is that the empirical results are insufficient in justifying the approach proposed by the paper as another reviewer pointed out dcgan is becoming outdated as a benchmark for comparison qualitatively steingan samples do not look significantly better than dcgan samples except for the celeba dataset in that particular case the dcgan samples do not appear to be the ones presented in the original paper where do they come from quantitatively dcgan beats steingan by a small margin for the imagenet inception score and steingan beats dcgan by an even smaller margin for the cifar inception score also in my opinion the testing accuracy score is not a convincing evaluation metric while it is true that it measures the amount of information captured in the simulated image sets it is only sensitive to information useful for the discrimination task not for the more general modeling task for instance this score is likely completely blind to information present in the background of the image because of the reasons outlined above i do not think the paper is ready for publication at iclr,4.0
518.json,the authors propose amortized svgd an amortized form of prior work on svgd which is a particle variational method that maximally decreases the kl divergence at each update amortized svgd is done by training a neural network to learn this dynamic they then apply this idea to train energy based models which admit a tractable unnormalized density in svgd the main difference from just map is the addition of a repulsive force that prevents degeneracy by encouraging probability mass to be spread to locations outside the mode how this is able to still act as a strong enough entropy like term in high dimensions is curious from my understanding of their previous work this was not a problem as the only experiments were on toy and uci data sets in the experimental results here they apply the kernel on the hidden representation of an autoencoder which seems key similar to li et al where their kernel approach for mmd would not work as well otherwise however unlike li et al the autoencoder is part of the model itself and not fixed this breaks much of the authors proposed motivation and criticisms of prior work if they must autoencode onto some low dimensional space putting most effort then on the autoencoder which changes per iteration before then applying their method unlike previous literature which uses inference networks their amortized svgd approach seems in fact slower than the non amortized approach this is because they must make the actual update on xi before then regressing to perform the update on eta in previous approaches this would be like having to perform local inferences before then updating inference network parameters or at least partially performing the local inference this seems quite costly during training i recommend the paper be rejected and that the authors provide more comprehensive experimental results expecially around the influence of the autoencoder the incremental updates versus full updates and the training time of amortized vs non amortized approaches the current results are promising but unclear why given the many knobs that the authors are playing with references li y swersky k zemel r generative moment matching networks presented at the international conference on machine learning,4.0
670.json,this paper is about learning unsupervised state representations using multi task reinforcement learning the authors propose a novel approach combining gated neural networks with multitask learning with robotics priors they evaluated their approach on two simulated datasets and showed promising results the paper is clearly written and is theoretically sound positives gating to enable learning a joint representation multi task learning extended from a single task in prior work combining multiple types of losses to learn a strong representation coherence proportionality causality repeatability consistency and separation negatives parameters choice is arbitrary w parameters limiting the multi task learning to be different to individual tasks rather than sharing and transferring knowledge between tasks the experiments could have been conducted using a standardized simulation tool such as openai gym to make it easy to compare i would recommend that the authors consider a more standardized way of picking the model parameters and evaluate on a more standard and high dimensional datasets,6.0
670.json,this paper builds upon the method of jonschkowski brock to learn state representations for multiple tasks rather than a single task the research direction of learning representations for multiple tasks is an interesting one and largely unexplored the approach in the paper is to learn a different representation for each task and a different policy for each task where the task is detected automatically and built into the neural network the authors state that the proposed method is orthogonal to multi task learning though the end goal of learning to solve multiple tasks is the same it would be interesting and helpful to see more discussion on this point in the paper as discussed in the pre review question phase references to other multi task learning works e g policy distillation and actor mimic both iclr may be appropriate as well the method proposes to jointly learn a task classifier with a state representation learner by using a differentiable gating mechanism to control the flow of information the paper proposes a task coherence prior for this gating mechanism to ensure that the learned task classifier is temporally coherent introducing this structure is what enables the method to improve performance over the standard non multitask approach the evaluation involves two toy experimental scenarios the first involves controlling one of two cars to drive around a track in this task detecting the task is very easy and the learned state representation is linear in the observation the paper evaluates the performance of the policies learned with the proposed approach and shows sufficient comparisons to demonstrate the usefulness of the approach over a standard non multitask set up in the second navigation scenario only the state representation is qualitatively shown not the resulting control policy nor any other learned state representations for comparison since the multi task state representation learning approach is only useful if you can also learn control better the paper should also evaluate on control with the same comparisons as in the first experiment without this evaluation the experiment is incomplete lastly to be on par with publications at a venue like iclr the method should be evaluated more thoroughly on a wider range of set ups to demonstrate the generality of the approach and show that the method applies to more complex tasks while in theory the method should scale the experiments do not demonstrate that it can handle more realistic scenarios such as scaling beyond mnist level images to d or real images or higher dimensional control tasks evaluating the method in this more complex scenario is important because unexpected issues can come up when trying to scale if scaling up is straight forward then running this experiment and including it in the paper should be straight forward in summary here are the pros and cons of this paper cons the approach does not necessarily share information across tasks for better learning and requires learning a different policy for each task only one experimental set up that evaluates learned policy with multi task state representation no experiments on more realistic scenarios such d environments or high dimensional control problems pros this approach enables using the same network for multiple tasks which is often not true for transfer and multi task learning approaches novel way to learn a single policy for multiple tasks including a task coherence prior which ensures that the task classification is meaningful experimentally validated on two toy tasks one task shows improvement over baseline approaches thus my rating would be higher if the paper included an evaluation of the control policy for navigation and included another more challenging and compelling scenario lastly here are some minor comments questions on how i think the paper could be improved but are not as important as the above approach could this approach be combined with other state representation learning approaches e g approaches that use an autoencoder experiments one additional useful comparison would be to evaluate performance in the single task setting e g only controlling the red car as an upper bound on how well the policy should be able to perform does the learned multi task policy reach the same level of performance this upper bound will be tighter than the known car position baseline which is also useful in its own right does the observations baseline eventually reach the performance of the lrp approach it would be useful to know if this approach simply speeds up learning significantly or if it enables better performance if there are aliasing issues with the images why not just use higher resolution images,5.0
719.json,the paper presents an alternative way of supervising the training of neural network without explicitly using labels when only link not link information is available between pairs of examples a pair of network is trained each of which is used to supervise the other one the presentation of the paper is not very clear the writing can be improved some design choice are not explained why is the power function used in the e step for approximating the distribution section why do the authors only consider a uniform distribution i understand that using a different prior breaks the assumption that nothing is known about the classes however i do not see a practical situations where the proposed setting work would be useful also there exist a large body of work in semi supervised learning with co training based on a similar idea overall i think this work should be clarified and improved to be a good fit for this venue,5.0
719.json,the paper explores a new technique for classless association a milder unsupervised learning where we do not know the class labels exactly but we have a prior about the examples that belong to the same class authors proposed a two stream architecture with two neural networks as streams process examples from the same class simultaneously both streams rely on the target pseudo classes or cluster indices of each other and the outputs an intermediate representation z which is forced to match with a statistical distribution uniform in their case the model is trained with em where the e step obtains the current statistical distribution given output vectors z and m step updates the weights of the architecture given z and pseudo classes experimental results on re organized mnist exhibits better performance compared to classical clustering algorithms in terms of association accuracy and purity the authors further provide comparison against a supervised method where proposed architecture expectedly performs worse but with promising results the basic motivation of the architecture apparently relies on unlabeled data and agreement of the same pseudo labels generated by two streams but the paper is hard to follow and the motivation for the proposed architecture itself is hidden in details what is trying to be achieved by matching distributions and using the pseudo targets of the each other perhaps the statistical distribution of the classes is assumed to be uniform but how will it extend to other priors or even the case where we do not assume that we know the prior the current setup needs justifications what would be very interesting is to see two examples having the same class but one from mnist the other from rotated mnist or background mnist because it is hard to guess how different the examples in two streams at the end i feel like the authors have found a very interesting approach for classless association which can be extended to lots of many to one problems this is a good catch i would like to see the idea in the future with some extensive experiments on large scale datasets and tasks but the current version lacks the theoretical motivations and convincing experiments i would definitely recommend this paper to be presented in iclr workshop few more points typo figure second line in the caption that than necessity of equation is not clear batch size m is enormous compared to classical models there is no explanation for this why uniform should be clarified of course it is the simplest prior to pick but just a few words about it would be good for completeness typo page second paragraph line that than,5.0
719.json,the paper looks correct but still i am not convinced about the experimentation performed perhaps another experiment with more challenging data would be welcome honestly i do not find a clear motivation for this work however it could have some potential and it would be interested to be presented in conference,6.0
471.json,this paper extends neural conversational models into the batch reinforcement learning setting the idea is that you can collect human scoring data for some responses from a dialogue model however such scores are expensive thus it is natural to use off policy learning training a base policy on unsupervised data deploying that policy to collect human scores and then learning off line from those scores while the overall contribution is modest extending off policy actor critic to the application of dialogue generation the approach is well motivated and the paper is written clearly and is easy to understand my main concern is that the primary dataset used restaurant recommendations is very small conversations in fact it is several orders of magnitude smaller than other datasets used in the literature e g twitter the ubuntu dialogue corpus for dialogue generation it is a bit surprising to me that rnn chatbots with no additional structure are able to generate reasonable utterances on such a small dataset wen et al are able to do this on a similarly small restaurant dataset but this is mostly because they map directly from dialogue states to surface form rather than some embedding representation of the context thus it remains to be seen if the approaches in this paper also result in improvements when much more unsupervised data is available references wen tsung hsien milica gasic nikola mrksic lina m rojas barahona pei hao su stefan ultes david vandyke and steve young a network based end to end trainable task oriented dialogue system arxiv preprint arxiv,6.0
471.json,the author propose to use a off policy actor critic algorithm in a batch setting to improve chat bots the approach is well motivated and the paper is well written except for some intuitions for why the batch version outperforms the on line version see comments on clarification regarding batch vs online setting the artificial experiments are instructive and the real world experiments were performed very thoroughly although the results show only modest improvement,7.0
471.json,the paper discuss a batch method for rl setup to improve chat bots the authors provide nice overview of the rl setup they are using and present an algorithm which is similar to previously published on line setup for the same problem they make a comparison to the online version and explore several modeling choices i find the writing clear and the algorithm a natural extension of the online version below are some constructive remarks comparison of the constant vs per state value function in the artificial experiment there was no difference between the two while on the real life task there was it will be good to understand why and add this to the discussion here is one option for the artificial task it seems like you are giving the constant value function an unfair advantage as it can update all the weights of the model and not just the top layer like the per state value function section sentence before last s is not defined last sentence missing in the stochastic case at the end section last paragraph while bot is not significant while bot is not significantly different from ml,8.0
778.json,i do need to see the results in a clear table original results and results when compression is applied for all the tasks in any case i would like to see the results when the compression is applied to state of the art nets where the float representation is important for instance a network with in mnist a imagenet lower that some of this results are feasible with float representation but probably imposible for restricted representations,5.0
778.json,this paper explores a new quantization method for both the weights and the activations that does not need re training in vgg the method reaches compression ratios of x and experiences a speed up of x the paper is very well written and clearly exposes the details of the methodology and the results my major criticisms are three fold for one the results are not compared to one of the many other pruning methods that are described in section and as such the performance of the method is difficult to judge from the paper alone second there have been several other compression schemes involving pruning re training and vector quantization e g that seem to achieve much higher accuracies compression ratios and speed ups hence for the practical application of running such networks on low power low memory devices other methods seem to be much more suited the advantage of the given method other then possibly reducing the time it takes to compress the network is thus unclear in particular taking a pre trained network as a starting point for a quantized model that is subsequently fine tuned might not take much longer to process then the method given here but maybe the authors can quantify this finally much of the speed up and memory reduction in the vgg model seems to arise from the three fully connected layers in particular the last one the speed up in the convolutional layers is comparably small making me wonder how well the method would work in all convolutional networks such as the inception architecture deep compression compressing deep neural networks with pruning trained quantization and huffman coding,4.0
739.json,this paper proposes an algorithm for polynomial feature expansion on csr matrices which reduces the time complexity of the standard method by a factor d k where d is the density of the sparse matrix the main contribution of this work is not significant enough the experiments are incomplete and not convincing the background of the problem is not sufficiently introduced there are only two references in the introduction part overall only three papers are cited which are from decades ago many more relevant papers should be cited from the recent literature the experiment part is very weak this paper claims that the time complexity of their algorithm is o d k d k which is an improvement over standard method o d k by a factor d k but in the experiments when d there is still a large gap s vs s between the proposed method and the standard one the authors explain this as likely a language implementation which is not convincing to fairly compare the two methods of course you need to implement both in the same programming language and run experiments in the same environment for higher degree feature expansion there is no empirical experiments to show the advantage of the proposed method some minor problems are listed below in section the notation pi pi is not clearly defined in section typo efter after all the algorithms in this paper are not titled the input and output is not clearly listed in figure the meaning of the colored area is not described is it standard deviation or some quantile of the running time how many runs of each algorithm are used to generate the ribbons many details of the experimental settings are missing,3.0
611.json,the authors proposed to learn embeddings of users and items by using deep neural network for a recommendation task the resulting method has only minor differences from the previous cdl in which neural networks were also used for recommendation tasks in the experiments since the proposed method dualnets have use more item features than wmf and cdl the comparisons are unfair,5.0
611.json,this paper provides a minor improvement paper of deeprs the major improvement comes from the coupling of user item factors in prediction while the motivation is clear the improvement of the model architecture is minor i think the author should improve the paper to discuss more on the impact of introduction of coupling which might make this paper stronger specifically conduct isolate experiment to change loss architecture gradually from a non coupled network to a final proposed coupled network to demonstrate the importance of coupling another important missing part of the paper seems to be time complexity since coupled net would be much more costly to generate recommendations a discussion on how it would impact real world usages should be added overall i think this is a paper that should be improved before accepted,5.0
611.json,the responses to the pre review questions are not strong especially w r t the question about dataset density and why the dataset had to be subsampled the authors responded that subsampling is common in recommender systems work including the papers cited this is not a particularly strong justification of why subsampling is a good idea and in particular does not answer the question of how would the results look without subsampling which i think is a question that could easily have been answered directly especially given that the goal of dealing with the cold start issue is so heavily emphasized in the paper in seems odd to sample the data to reduce sparsity other than that the pre review questions seem to have been answered satisfactorily the contribution of the paper is to propose user and item embedding methods as a means of learning complex non linear interactions between users and items this is fairly similar to recent work on deep rs though the network formulation has some differences overall this is an reasonably put together paper that makes a contribution in an important area though there are still some shortcomings that should be addressed namely the evaluation is unusual recall m is the only result reported though this is not usually an evaluation seen in recommender systems research at the very least other performance measures rmse or auc should be reported for completeness even if the results are not strong given that the contribution is fairly simple i e the standard recommender systems task but with a new model it a shame that unusual data samples have to be taken this should be a case where it possible to report results against competing methods using exactly the same data they used and exactly the same error measure for the fairest comparison possible without the above it hard to tell how much the performance improvements are really due to the method being better versus the choice of datasets and the choice of loss functions,4.0
597.json,this paper is methodologically very interesting and just based on the methodological contribution i would vote for acceptance however the paper sweeping claims of clearly beating existing baselines for tsp have been shown to not hold with the local search method lk h solving all the authors instances to optimality in seconds on a cpu compared to clearly suboptimal results by the authors method in h on a gpu seeing this clear dominance of the local search method lk h i find it irresponsible by the authors that they left figure as it is with the line for local search referring to an obviously poor implementation by google rather than the lk h local search method that everyone uses for example at nips i saw this figure being used in a talk i am not sure anymore by whom but i do not think it was by the authors the narrative being rnns now also clearly perform better than local search of course people would use a figure like that for that purpose and it is clearly up to the authors to avoid such misconceptions the right course of action upon realizing the real strength of local search with lk h would have been to make local search the same line as optimal showing that the authors method is still far worse than proper local search but the authors chose to leave the figure as it was still suggesting that their method is far better than local search probably the authors did not even think about this but this of course will mislead the many superficial readers to people outside of deep learning this must look like a sensational yet obviously wrong claim i thus vote for rejection despite the interesting method update after rebuttal and changes i am torn about this paper on the one hand the paper is very well written and i do think the method is very interesting and promising i would even like to try it and improve it in the future so from that point of view a clear accept on the other hand the paper was using extremely poor baselines making the authors method appear sensationally strong in comparison and over the course of many iterations of reviewer questions and anonymous feedback this has come down to the authors methods being far inferior to the state of the art that fine i expected that all along but the problem is that the authors do not seem to want this to be true e g they make statements such as we find that both greedy approaches are time efficient and just a few percents worse than optimality that statement may be true but it is very well known in the tsp community that it is typically quite trivial to get to a few percent worse than optimality what is hard and interesting is to push those last few percent as a side note the authors probably do not stop lk h once it has found the optimal solution like they do with their own method after finding a local optimum lk h is an anytime algorithm so even if it ran for a day that does not mean that it did not find the optimal solution after milliseconds and a solution a few percent suboptimal even faster nevertheless since the claims have been toned down over the course of the many iterations i was starting to feel more positive about this paper when just re reading it that is until i got to the section on knapsack solving the version of the paper i reviewed was not bad here as it at least stated two simple heuristics that yield optimal solutions two simple heuristics are expknap which employs brand and bound with linear programming bounds pisinger and minknap which employs dynamic programming with enumerative bounds pisinger exact solutions can also be optained by quantizing the weights to high precisions and then performing dynamic programming with a pseudo polynomial complexity bertsimas demir that version then went on to show that these simple heuristics were already optimal just like their own method in a revision between december and however that paragraph along with the optimal results of expknap and minknap seems to have been dropped and the authors instead introduced two new poor baseline methods random search and greedy this was likely in an effort to find some methods that are not optimal on these very easy instances i personally find it pointless to present results for random search here as nobody would use that for tsp it like comparing results on mnist against a decision stump yes you will do better than that but that is not surprising the results for greedy are interesting to see however dropping the strong results of the simple heuristics expknap and minknap and their entire discussion appears unresponsible since the resulting table in the new version of the paper now suggests that the authors method is better than all baselines of course if all that one is after is a column of bold numbers for ones own approach that what one can do but i do not find it responsible to hide the better baselines also why do not the authors try at least the same or tools solver from google that they tried for tsp it seems to support knapsack directly,6.0
554.json,the paper presents a deep rl with eligibility traces the authors combine drqn with eligibility traces for improved training the new algorithm is evaluated on a two problems with a single set of hyper parameters and compared with dqn the topic is very interesting adding eligibility traces to rl updates is not novel but this family of the algorithms have not been explored for deep rl the paper is written clearly and the related literature is well covered more experiments would make this promising paper much stronger as this is an investigative experimental paper it is crucial for it to contain a wider range of problems different hyper parameter settings and comparison with vanilla drqn deepmind dqn implementation as well as other state of the art methods,4.0
574.json,the paper presents a large scale visual search system for finding product images given a fashion item the exploration is interesting and the paper does a nice job of discussing the challenges of operating in this domain the proposed approach addresses several of the challenges however there are several concerns the main concern is that there are no comparisons or even mentions of the work done by tamara berg s group on fashion recognition and fashion attributes e g automatic attribute discovery and characterization from noisy web data eccv where to buy it matching street clothing photos in online shops iccv retrieving similar styles to parse clothing tpami etc it is difficult to show the contribution and novelty of this work without discussing and comparing with this extensive prior art there are not enough details about the attribute dataset and the collection process what is the source of the images are these clean product images or real world images how is the annotation done what instructions are the annotators given what annotations are being collected i understand data statistics for example may be proprietary but these kinds of qualitative details are important to understand the contributions of the paper how can others compare to this work there are some missing baselines how do the results in table compare to simpler methods e g the bm or cm methods described in the text while the paper presents an interesting exploration all these concerns would need to be addressed before the paper can be ready for publication,4.0
574.json,this paper introduces a pratical large scale visual search system for a fashion site it uses rnn to recognize multi label attributes and uses state of art faster rcnn to extract features inside those region of interest roi the technical contribution of this paper is not clear most of the approaches used are standard state of art methods and there are not a lot of novelties in applying those methods for multi label recognition task there are other available methods e g using binary models changing cross entropy loss function etc there are not any comparison between the rnn method and other simple baselines the order of the sequential rnn prediction is not clear either it seems that the attributes form a tree hierarchy and that is used as the order of sequence the paper is not well written either most results are reported in the internal dataset and the authors wo not release the dataset,3.0
333.json,this work proposed a simple but strong baseline for parametric texture synthesis in empirical experiments samples generated by the baseline composed by multi scale and random filters sometime rival the vgg based model which has multi layer and pre trained filters the authors concluded that texture synthesis does not necessarily depend on deep hierarchical representations or the learned feature maps this work is indeed interesting and insightful however the conclusions are needed to be further testified especially for deep hierarchical representations firstly all of generated samples by both vgg and single layer model are not perfect and much worse than the results from non parametric methods besides vgg based model seems to do better in inpainting task in figure last but not least would a hierarchical model instead of lots of filters with different size handle multi scale more efficiently,7.0
333.json,the framework of gatys et al demonstrated that correlation statistics empirical gram matrices of deep feature responses provide an excellent characterisation of visual textures this paper investigates in detail which kind of deep or shallow networks may work well in this framework one of the main findings is that that very shallow nets consisting of a single filter bank with random weights work surprisingly well and for simple and regular textures may produce results which are visually superior to complex data adapted filters such as the ones in networks like vgg more broadly the paper contains an interesting and informative discussion on the strength and limitations on such methods for texture synthesis figure shows that the optimisation of images with respect to shallow filter banks may result in texture images that have a lower vgg loss than optimising the vgg objective directly this is imputed to the difficulty of optimising the highly non linear vgg cost function which is a reasonable explanation in the new supplementary material the authors show that better optimisation results can be obtained by initialising the vgg based optimisation with the shallow network optimisation results which is a useful complement to the original experiments the main limitation of the paper is that it does not systematically compare different methods against a quantifiable objective it is trivial to define image statistics that would allow to simply generate an exact copy of any reference texture hence with very good visual quality such trivial statistics would also be very shallow the aim is instead to capture a texture distribution and measuring how well a method meets this challenge remains an open problem hence while the empirical results seem to confirm the intuition that simple statistics are good enough for texture synthesis both in terms of quality and diversity when compared to more complex statistics it is difficult to conclusively confirm that this is the case the authors indicate that diversity could be measured in terms of entropy this is reasonable but as they acknowledge in their answers to questions difficult to do in practice furthermore this would still not account for the other aspect of the problem namely visual quality they also suggest to perform a psychophysical assessment which may be the only practical way of addressing this problem but deem that to be material for future work overall since evaluation of image generation is such an hard problem i think the paper still has sufficient strengths to warrant publication in iclr still some form of psychophysical assessment would be useful to confirm the intuitions that at present can only be obtained by inspecting the figure sin the paper and in the supplementary material,8.0
648.json,this paper presents a semi supervised algorithm for regularizing deep convolutional neural networks they propose an adversarial approach for image inpainting where the discriminator learns to identify whether an inpainted image comes from the data distribution or the generator while at the same time it learns to recognize objects in an image from the data distribution in experiments they show the usefulness of their algorithm in which the features learned by the discriminator result in comparable or better object recognition performance to the reported state of the art in two datasets overall the proposed idea seems a simple yet an effective way for regularize cnns to improve the classification performance,6.0
648.json,this paper proposes a method to incorporate super resolution and inpainting in the gan framework for semi supervised learning using the gan discriminative features on larger images the core idea of the paper is not very novel the usefulness of the gan discriminative features for semi supervised learning is already established in previous works such as catgan dcgan and salimans et al however this paper does a good job in actually getting the semi supervised gan framework working on larger images such as stl and pascal datasets using the proposed context conditioning approach and achieves the state of the art on these datasets i think that the authors should provide the ssl gan baseline for the pascal dataset as it is very important to compare the contribution of the context conditioning idea with the standard way of using gan for semi supervised learning i e ssl gan i can not see why the ssl gan can not be applied to the and version of the pascal dataset table if they have trouble training the vanilla gan on pascal even on the image size this should be mentioned in the paper and be explained i am concerned about this specially because cc gan almost matches the ssl gan baseline on stl and cc gan to me seems like a hacky way to improve upon the core cc gan idea so it would be great to compare cc gan and ssl gan on some other dataset even if it is a downsampled pascal dataset,6.0
648.json,after rebuttal thanks for reporting the alexnet results the fact that they are not great is not so bad by itself and as the authors mention it would be interesting to understand why this happens but the fact that these results were not in the paper and in fact still are not there is disturbing moreover some claims in the paper look wrong in the light of these results for example this suggests that our gains stem from the cc gan method rather than the use of a better architecture since discrimination of real fake in paintings is more closely related to the target task of object classification than extracting a feature representation suitable for in filling it is not surprising that we are able to exceed the performance of pathak et al on pascal classification these statements and possibly other parts of the paper have to be updated i think the paper cannot be published in its current form perhaps after a revision initial review the paper demonstrates an application of generative adversarial networks gan to unsupervised feature learning the authors show that the representation learned by the discriminator of a conditional gan trained for image inpainting performs well on image classification as a side effect fairly convincing inpaintings are produced the proposed method combines two existing ideas using the discriminator of a gan as a feature learner radford et al and performing unsupervised feature learning with image inpainting pathak et al therefore conceptual novelty of the paper is limited on the plus side the authors implement their idea well and demonstrate state of the art results on stl and good results on pascal voc although pascal experiments are incomplete see below overall i am in the borderline mode and i will gladly raise the score if the authors address my concerns regarding the experiments experimental evaluation on pascal voc is not quite satisfactory comparison with prior work is unfair because the network architecture used by the authors vgg is different from the architecture used by all existing methods alexnet it is great that the authors do not try to hide this fact in the paper but i do not understand why the authors are not willing to simply run their method with alexnet architecture although two commenters asked them to do so such an experiment would strongly support authors claims current reasoning that we thought it reasonable to use more current models while making the difference clear is not convincing it is great that better architectures lead to better results but it is also very important to properly compare to prior work on a related topic doersch et al also tried using vgg architecture would it be possible to compare to that yet another question why are you not comparing to noroozi favaro eccv i would also like the authors to address the comment by richard zhang qualitative inpainting results are incomplete comparison with previous methods for instance pathak et al is missing and it is impossible to compare different versions of the proposed method because different images are used for different variants i realize there may be too little space in the main paper to show all the results but many more results should be shown in the supplementary material quantitative results are missing currently the inpainting results are just interesting pictures to look at but they do not add as much to the paper as they could,5.0
330.json,this paper discusses a method for computing vector representations for documents by using a skip gram style learning mechanism with an added regularizer in the form of a global context vector with various bits of drop out while none of the individual components proposed in this paper are new i believe that the combination in this fashion is further i appreciated the detailed analysis of model behaviour in section the main downside to this submission is in its relative weakness on the empirical front arguably there are more interesting tasks than sentiment analysis and k way classification likewise why waste of a page on t sne projections rather than use that space for further analysis while i am a bit disappointed by this reduced evaluation and agree with the other reviewers concerning soft baselines i think this paper should be accepted it an interesting algorithm nicely composed and very efficient so it reasonable to assume that other readers might have use for some of the ideas presented here,7.0
330.json,this paper presents a framework for creating document representations the main idea is to represent a document as an average of its word embeddings with a data dependent regularization that favors informative or rare words while forcing common words to be close to experiments on sentiment analysis and document classification show that the proposed method has the lowest error rates compared to baseline document embedding methods while i like the motivation of finding the best way to encode a document into a vector the paper does not offer significant technical contributions most of the techniques are not new and the main selling point is the simplicity and speed of the proposed method for this reason i would like to see good results for more than two tasks to be convinced that this is the best way to learn document representations for rnn lm is the lm trained to minimize classification error or is it trained as a language model did you use the final hidden state as the representation or the average of all hidden states one of the most widely used method to represent documents now is to have a bidirectional lstm and concatenate the final hidden states as the document representation i think it would be useful to know how the proposed method compares to this approach for tasks such as document classification or sentiment analysis,6.0
330.json,this paper proposes learning document embeddings as a sum of the constituent word embeddings which are jointly learned and randomly dropped out corrupted during training while none of the pieces of this model are particularly novel the result is an efficient learning algorithm for document representation with good empirical performance joint training of word and document embeddings is not a new idea nor is the idea of enforcing the document to be represented by the sum of its word embeddings see e g the sum of its parts joint learning of word and phrase representations with autoencoders by lebret and collobert furthermore the corruption mechanism is nothing other than traditional dropout on the input layer coupled with the wordvec style loss and training methods this paper offers little on the novelty front on the other hand it is very efficient at generation time requiring only an average of the word embeddings rather than a complicated inference step as in docvec moreover by construction the embedding captures salient global information about the document it captures specifically that information that aids in local context prediction for such a simple model the performance on sentiment analysis and document classification is quite encouraging overall despite the lack of novelty the simplicity efficiency and performance of this model make it worthy of wider readership and study and i recommend acceptance,7.0
756.json,this paper proposes to use feed forward neural networks to learn similarity preserving embeddings they also use the proposed idea to represent out of vocabulary words using the words in given context first considering the related work the proposed approach brings marginal novelty especially context encoders is just a small improvement over wordvec experimental setup should provide more convincing results other than visualizations and non standard benchmark for ner evaluation with word vectors,2.0
756.json,this paper introduces a similarity encoder based on a standard feed forward neural network with the aim of generating similarity preserving embeddings the approach is utilized to generate a simple extension of the cbow wordvec model that transforms the learned embeddings by their average context vectors experiments are performed on an analogy task and named entity recognition while this paper offers some reasonable intuitive arguments for why a feed forward neural network can generate good similarity preserving embeddings the architecture and approach is far from novel as far as i can tell the model is nothing more than the most vanilla neural network trained with sgd on similarity signals slightly more original is the idea to use context embeddings to augment the expressive capacity of learned word representations of course using explicit contextual information is not a new idea especially for tasks like word sense disambiguation see e g efficient non parametric estimation of multiple embeddings per word in vector space by neelakantan et al which should also be cited but the specific method used here is original as far as i know the evaluation of the method is far from convincing the corpora used to train the embeddings are far smaller than would ever be used in practice for unsupervised or semi supervised embedding learning the performance on the analogy task says little about the benefit of this method for larger corpora and as the authors mentioned in the comments they expect the gain will be less significant as the global context statistics brought in by the conec can also be picked up by wordvec with more training the argument can be made and the authors do claim that extrinsic evaluations are more important for real world applications so it is good to see experiments on ner however again the embeddings were trained on a very small corpus and i am not convinced that the observed benefit will persist when trained on larger corpora overall i believe this paper offers little novelty and weak experimental evidence supporting its claims i cannot recommend it for acceptance,3.0
486.json,the paper introduces a method for semi supervised learning in graphs that exploits the spectral structure of the graph in a convolutional nn implementation the proposed algorithm has a limited complexity and it is shown to scale well on a large dataset the comparison with baselines on different datasets show a clear jump of performance with the proposed method the paper is technically fine and clear the algorithm seems to scale well and the results on the different datasets compare very favorably with the different baselines the algorithm is simple and training seems easy concerning the originality the proposed algorithm is a simple adaptation of graph convolutional networks ref defferrard in the paper to a semi supervised transductive setting this is clearly mentioned in the paper but the authors could better highlight the differences and novelty wrt this reference paper also there is no comparison with the family of iterative classifiers which usually compare favorably both in performance and training time with regularization based approaches although they are mostly used in inductive settings below are some references for this family of methods the authors mention that more complex filters could be learned by stacking layers but they limit their architecture to one hidden layer they should comment on the interest of using more layers for graph classification some references on iterative classification qing lu and lise getoor link based classification in icml vol gideon s mann and andrew mccallum generalized expectation criteria for semi supervised learning with weakly labeled data the journal of machine learning research david jensen jennifer neville and brian gallagher why collective inference improves relational classification in proceedings of the tenth acm sigkdd international conference on knowledge discovery and data mining acm joseph j pfeiffer iii jennifer neville and paul n bennett overcoming relational learning biases to accurately predict preferences in large scale networks in proceedings of the th international conference on world wide web international world wide web conferences steering committee stephane peters ludovic denoyer and patrick gallinari iterative annotation of multi relational social networks in advances in social networks analysis and mining asonam international conference on ieee,7.0
412.json,this paper presents a novel layer wise optimization approach for learning cnn with piecewise linear nonlinearities the proposed approach trains piecewise linear cnns layer by layer and reduces the sub problem into latent structured svm which has been well studied in the literature in addition the paper presents improvements of the bcfw algorithm used in the inner procedure overall this paper is interesting however unfortunately the experiment is not convincing pros to my best knowledge the proposed approach is novel and the authors provide nice theoretical analysis the paper is well written and easy to follow cons although the proposed approach can be applied in general structured prediction problem the experiments only conduct on a simple multi class classification task this makes this work less compelling the test accuracy performance on cifar reported in the paper does not look right the accuracy of the best model reported in this paper is while existing work often reports for example,5.0
412.json,this paper proposes a new approaches for optimizing the objective of cnns the proposed method uses a lay wise optimization i e at each step it optimizes the parameters in one layer of cnn while fixing the parameters in other layers the key insight of this paper is that for a large class of cnns the optimization problem at a particular can be formulated as optimizing a piecewise linear pl function this pl function optimization happens to be the optimization problem commonly encountered in latent structural svm this connection allows this paper to borrows ideas from the latent structural svm literature in particular concave convex procedure to learn the parameters of cnns overall the paper is well written traditional cnns and structural svms are almost two separate research communties the connection of cnns to latent structural svm is interesting and might bridge the gap and facilitate the transferring of ideas between these two camps of course the proposed method also has some limitations it is limited to layer wise optimization nowadays layer wise optimization is essentially a coordinate descent algorithm and is not really a competitive strategy in learning cnns when you choose layer wise optimization you already lose something in terms of optimizing the objective since you are using coordinate descent instead of gradient descent of course you also gain something since now you can guarantee that each coordinate descent step always improve the objective it is not clear to me how the loss gain balances each other this paper focues on improving the optimization of cnn objective however we all know that a better objective does not necessarily correspond to a good model e g due to overfitting although the sgd with backprop in standard cnn learning does not always improve the solution of the objective unlike the proposed method in this paper but to me this might be a good thing since it can prevent overfitting the goal of learning is not to get better solution for the optimization problem in the first place the optimization problem is merely a proxy to learn a model with good generalization ability the experiment is a bit weak only cifar is used this is a very small dataset by today standard while cnns are typically used in large scale datasets such as imagenet it is not clear whether the conclusions of this paper still hold when applied on imagenet this paper only compares with a crippled variant of sgd without batch normalization dropout etc although this paper mentions that the reason is that it wants to focus on optimization but i mentioned earlier sgd is not designed to purely obtain the best solution that optimizes the objective the goal of sgd is to reasonably optimize the objective while preventing overfitting so the comparison to sgd purely in terms of the optimization is that meaningful in the first place,6.0
691.json,the paper presents a new environment called retro learning environment rle for reinforcement learning the authors focus on super nintendo but claim that the interface supports many others including ale benchmark results are given for standard algorithms in new super nintendo games and some results using a new rivalry metric these environments or more generally standardized evaluation methods like public data sets competitions etc have a long history of improving the quality of ai and machine learning research one example in the past few years was the atari learning environment ale which has now turned into a standard benchmark for comparison of algorithms and results in this sense the rle could be a worthy contribution to the field by encouraging new challenging domains for research that said the main focus of this paper is presenting this new framework and showcasing the importance of new challenging domains the results of experiments themselves are for existing algorithms there are some new results that show reward shaping and policy shaping having a bias toward going right in super mario help during learning and yes domain knowledge helps but this is obvious the rivalry training is an interesting idea when training against a different opponent the learner overfits to that opponent and forgets to play against the in game ai but then oddly it gets evaluated on how well it does against the in game ai also the part of the paper that describes the scientific results especially the rivalry training is less polished so this is disappointing in the end i am not very excited about this paper i was hoping for a more significant scientific contribution to accompany in this new environment it not clear if this is necessary for publication but also it not clear that iclr is the right venue for this work due to the contribution being mainly about the new code for example mloss org could be a better have nue jmlr has an associated journal track for accompanying papers,5.0
691.json,this paper presents a valuable new collection of video game benchmarks in an extendable framework and establishes initial baselines on a few of them reward structures for how many of the possible games have you implemented the means to extract scores and incremental reward structures from the github repo it looks like about do you plan to add more and when rivalry training this is one of the weaker components of the paper and it should probably be emphasised less on this topic there is a vast body of uncited multi agent literature it is a well studied problem setup more so than rl itself to avoid controversy i would recommend not claiming any novel contribution on the topic i don t think that you really invented a new method to train an agent by enabling it to train against several opponents nor a new benchmarking technique for agents evaluation by enabling them to compete against each other rather than playing against the in game ai instead just explain that you have established single agent and multi agent baselines for your new benchmark suite your definition of q function predicts the score at the end of the game given the current state and selected action is incorrect it should read something like it estimates the cumulative discounted reward that can be obtained from state s starting with action a and then following a certain policy minor eq the q net inside the max is the target network with different parameters theta the du et al reference is missing the year some of the other references should point at the corresponding published papers instead of the arxiv versions,7.0
687.json,the authors have put forward a sincere effort to investigate the fundamental nature of learning representations in neural networks a topic of great interest and importance to our field they propose to do this via a few simplistic pruning algorithms to essentially monitor performance decay as a function of unit pruning this is an interesting idea and one that could potentially be instructive though in total i do not think that has been achieved here first i find the introduction of pruning lengthy and not particularly novel or surprising for example fig is not necessary nor is most of the preamble section the pruning algorithms themselves are sensible though overly simplistic approaches which of course would not matter if they were effective in addressing the question however in looking for contributions this paper makes an interesting pithy or novel take on pruning is not one of them in my opinion second and most relevant to my overall rating section does not get deeper than scratching the surface the figures do not offer much beyond the expected decay in performance as a percentage of neurons removed or gain value the experiments themselves are not particularly deep covering a toy problem and mnist which does not convince me that i can draw lessons to the broader story of neural networks more generally third there is no essential algorithmic architectural or mathematical insight which i expect out of all but the most heavily experimental papers,3.0
687.json,i did enjoy reading some of the introductions and background in particular that of reminding readers of popular papers from the late s and early s the idea of the proposal is straight forward remove neurons based on the estimated change in the loss function from the packpropagation estimate with either first or second order backpropagation the results are as expected that the first order method is worse then the second order method which in turn is worse than the brute force method however there are many reasons why i think that this work is not appropriate for iclr for one there is now a much stronger comprehension of weight decay algorithms and their relation to bayesian priors which has not been mentioned at all i would think that any work in this regime would require at least some comments about this furthermore there are many statements in the text that are not necessarily true in particular in light of deep networks with modern regularization methods for example the authors state that the most accurate method is what they call brute force however this assumes that the effects of each neurons are independent which might not be the case so the serial order of removal is not necessarily the best i also still think that this paper is unnecessarily long and the idea and the results could have been delivered in a much compressed way i also don t think just writing a q a section is not enough and the points should be included in the paper,3.0
444.json,edit the revisions made to this paper are very thorough and address many of my concerns and the paper is also easier to understand i recommend the latest version of this paper for acceptance and have increased my score this paper presents a way of interpreting lstm models which are notable for their opaqueness in particular the authors propose decomposing the lstm predictions for a qa task into importance scores for words which are then used to generate patterns that are used to find answers with a simple matching algorithm on the wikimovies dataset the extracted pattern matching method achieves accuracies competitive with a normal lstm which shows the power of the proposed approach i really like the motivation of the paper as interpreting lstms is definitely still a work in progress and the high performance of the pattern matching was surprising however several details of the pattern extraction process are not very clear and the evaluation is conducted on a very specific task where predictions are made at every word as such i recommend the paper in its current form as a weak accept but hope that the authors clarify their approach as i believe the proposed method is potentially useful for nlp researchers comments please introduce in more detail the specific qa tasks you are applying your models on before section as it not clear at that point that the answer is an entity within the document is the softmax predicting a value e g is this word the answer or not what are the p and q vectors do you just mean that you are transforming the hidden state into a dimensional vector for binary prediction how does performance of the pattern matching change with different cutoff constant values are there questions whose answers are not entities how could the proposed approach be used when predictions are not made at every word is there any extension for say sentence level sentiment classification,7.0
444.json,this work proposes a pattern extraction method to both understand what a trained lstm has learnt and to allow implementation of a hand coded algorithm that performs similarly to the lstm good results are shown on one dataset for one model architecture so it is unclear how well this approach will generalize however it seems it will be a useful way to understand and debug models the questions in wikimovies seem to be generated from templates and so this pattern matching approach will likely work well however from the experiments it not clear if this will extend to other types of q a tasks where the answer may be free form text and not be a substring in the document is the model required to produce a continuous span over the original document the approach also seems to have some deficiencies in how it handles word types such as numbers or entity names this can be encoded in the embedding for the word but from the description of the algorithm it seems that the approach requires an entity detector does this mean that the approach is unable to determine when it has reached an entity from the decomposition of the output of the lstm the results where manual pattern matching where explicit year annotations are used seem to show that the automatic method is unable to deal with word types it would also be good to see an attention model as a baseline in addition to the gradient based baseline minor comments p and q seem to be undefined some references seem to be bad e g in section in instead of in table similarly above section as shown in and in section in the paragraph above section adam adam,7.0
556.json,first of all i would like to thank the authors for putting this much work into a necessary but somewhat tedious topic while i think the paper is somewhat below the standard of a conference paper see detailed comments below i would definitely love to see a version of this paper published with some of the issues ironed out i also agree with many of the points raised by other reviewers and will not repeat them here major points as we saw in the previous section the minima of deep network loss functions are for the most part decent all you said in the previous section was that theory shows that there are no bad minima under strong assumptions there is no practical proof that minima do not vary in quality this implies that we probably do not need to take many precautions to avoid bad minima in practice if all minima are decent then the task of finding a decent minima quickly is reduced to the task of finding any minima quickly first of all as one of the reviewers pointed out we are never guaranteed in practice to actually reach a local minimum we could always hit a region of the objective function where the algorithm makes essentially no further progress the final error level in practice actually does depend significantly on many factors such as i optimization algorithm ii learning rate schedule iii initialization of weights iv presence of unsupervised pretraining v whether neurons are added or eliminated during training etc etc therefore the task of optimizing neural networks is far from being reduced to finding any minima quickly figure i do not like figure because it suggests to me that you diagnosed exactly where the transition between the two phases happened which i do not think you did also the concept of having a fast decaying error followed by a slow decaying error is simple enough for readers to understand without a dedicated graph minor point on presentation the red brace is positioned lower in the figure than the blue brace and the braces do not join up horizontally please be more careful misuse of the transient phase minimization phase concept in section you talk about the transient and minimization phase of optimization however you have no way of diagnosing when or if your algorithm reaches the minimization phase you seem to think that the minimization phase is simply the part of the optimization process where the error decreases slowly afaik this is not the case the minimization phase is where the optimization algorithm enters the vicinity of the local minimum that can be approximated by the second order taylor expansion for this to even occur one would have to verify for example that the learning rate is small enough you change the algorithm after and of training but these points seem arbitrary what is the minimization phase was reached at or epochs after you decided to stop training only dataset you run most experiments on only dataset cifar please replicate with at least one more dataset many figures are unclear for each figure the following information are relevant network used dataset used learning rate used batch norm yes no whether figure shows train test or validation error it should be easy for the reader to ascertain this information for all figures not just for some you say at the beginning of section that each algorithm finds a different minimum as if this is a significant finding however this is obvious because the updates taken by these algorithms vary wildly keep in mind that there is an exponentially large number of minima the probability of different algorithms choosing the same minimum is essentially zero because of their sheer number the same would be true if you even shift the learning rate slightly or use a different random seed for minibatch generation etc etc lack of confidence intervals the value of figures and is limited is because it is unclear how these plots would change if the random seed were changed we only get information for a single weight initialization and a single minibatch sequence while figures and can be used to try and infer what confidence intervals around plots in figures and might look like i think those confidence intervals should still be shown for at least a subset of the configurations presented lack of information regarding learning rate there is big question mark left open regarding how all your results would change if different learning rates were used you do not even tell us how you chose the learning rates from the intervals you gave in section lack of information regarding the absolute distance of interpolated points in most figures you interpolate between two or three trained weight configuration however you do not say how far the interpolated points are apart this is highly significant because if points are close together and there is a big hump between them it means that those points are more brittle than if they are far apart and there is a big hump between them minor points lstm is not a fixed network architecture like nin or vgg but a layer type lstm would be equivalent to cnn also the vgg paper has multiple versions of vgg you should specify which one you used the font size for the legends in the upper triangle of table is too small you can not just write best viewed in zoom in the table caption and pretend that somehow fixes the problem personally i prefer no legend over an unreadable legend,4.0
556.json,the paper is dedicated to better understanding the optimization landscape in deep learning in particular when explored with different optimization algorithms and thus it also characterizes the behavior of these algorithms it heavily re uses the approach of goodfellow et al i find it hard to understand the contributions of the paper for example is it surprising that different algorithms reach different solutions when starting from the same initialization it would be useful if the authors build such basic intuition in the paper i also did not receive a clear answer to the question i posed to reviewers regarding clarifying how does the findings of the paper can contribute to future works on optimization in deep learning and this is what i find fundamentally missing so for example there are probably plenty of ways to modify approach of goodfellow et al and similar works and come up with interesting visualization methods for deep learning but the question is how is this helpful in terms of designing better algorithms gaining more intuition how the optimization surface looks like in general etc this is an interesting paper though i am fairly confident it is a better fit for the journal than this conference it would be interesting and instructive even for sanity check to plot the eigenspectra of the solutions recovered by the algorithms to see the order of critical points recovered,4.0
556.json,this paper provides an extensive analysis of the error loss function for different optimization methods the presentation is well done and informative the experimental procedure is clarified sufficiently well theoretical evaluations like this are crucial for a wide range of applications and help to better understand and improve the convergence behavior for a given system pros important analysis good visualizations cons the paper describes mostly the observation that the optima vary for different methods however does not attempt to explain why it happens and how to solve it aside from batch norm some fonts are very small e g fig,6.0
612.json,the paper proposes a method for future frame prediction based on transformation of previous frame rather than direct pixel prediction many previous works have proposed similar methods the authors in their responses state that previous work is deterministic yet the proposed model also does not handle multimodality further i asked if they could test their method using rgb frames as input and predicting the transformation as output to be able to quantify the importance of using transformations both as input and output since this is the first work that uses transformations as input also the authors dismissed the suggestion by saying if we were to use rgb frames as input and ask the model to output future frames it would produce very blurry results that is misunderstanding what the suggestion was so currently it does not seem to be a valid novel contribution in this work compared to previous works,5.0
612.json,this paper describes an approach to predict unseen future frames of a video given a set of known past frames the approach is based on a cnn that in contrast to most related papers work in the space of affine transformations instead of pixels or flow said another way the network takes as input a set of affine transforms that describe the motion of patches in the past frames and likewise outputs a set of affine transforms that predict future patch motion to that aim the authors make a few simplifying hypotheses namely that a sequence of frames can be modeled accurately enough in their patch affine framework this is not unreasonable a lot of papers in the optical flow community are based on similar hypotheses i e model the flow as a smoothly varying affine field for instance see locally affine sparse to dense matching for motion and occlusion estimation by leordeanu et al epicflow edge preserving interpolation of correspondences for optical flow by revaud et al optical flow with semantic segmentation and localized layers by sevilla lara et al these methods are state of the art which gives a hint about the validity of this kind of approach in addition it also seems very reasonable to reformulate the prediction task as predicting motion rather than predicting raw pixels indeed the patch affine motion space is considerably smaller than the image space making the problem much more tractable and amenable to high resolution videos while i agree with the authors on these points i also find that the paper suffer from important flaws specifically the choice of not comparing with previous approaches in term of pixel prediction error seems very convenient to say the least while it is clear that the evaluation metric is imperfect it is not a reason to completely dismiss all quantitative comparisons with previous work the frames output by the network on e g the moving digits datasets figure looks ok and can definitely be compared with other papers yet the authors chose not to which is suspicious the newly proposed metric poses several problems first action classification is evaluated with cd which is not a state of the art approach at all for this task second this metric actually does not evaluate what the network is claimed to do that is next frame prediction instead it evaluates if another network which was never trained to distinguish between real or synthetic frames by the way can accurately classify an action from the predicted frames i find that this proxy metric is only weakly related to what is supposed to be measured in adition it does not really make sense to train a network for something else that the final task it is evaluated for how is the affine motion of patches estimated it is only explained that the problem is solved globally not treating each patch independently in a pretty vague manner estimating the motion of all patches is akin to solving the optical flow which is still an active subject of research therefore an important flaw of the paper lies in the potentially erroneous etimation of the motion input to the network in the videos made available it is clear that the motion is wrongly estimated sometimes since the entire approach depends on this input i find it important to discuss this aspect how do motion estimation failures impact the network also the patch affine hypothesis does not hold when patches are large enough that they cover several objects with contradictory motion which appears to be the case on ucf videos even ignoring the weird proxy evaluation part the network is still not trained end to end that is the network is trained to minimize the difference between noisy ground truth and output affine transforms instead of minimizing a loss in the actual output space frame pixels for which an exact ground truth is available it is true that the mse loss on raw pixels leads to blurry results but other types of losses do exist for instance the gradient loss introduced by mathieu et al was shown to solve this issue as noted by the authors themselves minimizing a loss in the transformation space where affine parameters are harder to intepret introduces unexpected artifacts the motion is often largely underestimated as is obvious in figure where it is hard to tell the difference between the input and output frames the proposed approach is not sufficiently compared to previous work in particular the approach is closely related to spatio temporal video autoencoder with differentiable memory of taraucean et al iclr this paper also output prediction in the motion space experimental results should compare against it the comparison with optical flow is unfair first the approach of brox et al is more than years old second it is not really fair to assume a constant flow for all frames at least some basic extrapolation could be done to take into account the flow of all pairs of input frames and not just the last one overall the approach is not compared to very challenging baselines i disagree with the answer that the authors gave to a reviewer question denote ground truth frames as x x and predicted frames as y y when asked if the videos at,3.0
632.json,the contribution of this paper can be summarized as a transgaussian model in a similar idea of transe which models the subject object embeddings in a parameterization of gaussian distribution the model can be naturally adapted to path queries like the formulation of guu et al along with the entity relation representations trained by transgaussian an lstm attention model is built on natural language questions aiming at learning a distribution not normalized though over relations for question answering experiments on a generated worldcup dataset focusing on path queries and conjunctive queries overall i think the gaussian parameterization exhibits some nice properties and could be suitable to kb completion and question answering however some details and the main experimental results are not convincing enough to me the paper writing also needs to be improved more comments below major comments my main concern is that that evaluation results are not strong either knowledge base completion or kb based question answering there are many existing and competitive benchmarks e g fbk webquestions experimenting with such a tiny wordcup dataset is not convincing moreover the questions are just generated by a few templates which is far from nl questions i am not even not sure why we need to apply an lstm in such scenario the paper would be much stronger if you can demonstrate its effectiveness on the above benchmarks conjunctive queries the current model assumes that all the detected entities in the question could be aligned to one or more relations and we can take conjunctions in the end this assumption might be not always correct so it is more necessary to justify this on real qa datasets the model is named as gaussian attention and i kind of think it is not very closely related to well known attention mechanism but more related to kb embedding literature minor comments i find figure a bit confusing the first row of orange blocks denote kb relations and the second row of those denote every single word of the nl question maybe make it clearer besides entity recognition usually we still need an entity linker component which links the text mention to the kb entity,5.0
632.json,this paper presents extensions to previous work using embeddings for modeling knowledge bases and performing q a on them centered around the use of multivariate gaussian likelihood instead of inner products to score attention this is supposed to allow more control on the attention by dealing with its spread this is a dense paper centered around a quite complicated model with the supplementary material this makes a p paper it might be clearer to make separate papers one on kb completion and another one on q a i like the idea of controlling the spread of the attention this makes sense however i do not feel that this paper is convincing enough to justify its use compared to usual inner products for several reasons these should be more ablation experiments to separate the different pieces of the model and study their influence separately the only interesting point in that sense is table in appendix b we need more of this in particular a canonical experiments comparing gaussian interaction vs inner product would be very useful experiments on existing benchmarks for kb completion or qa would help i agree with the authors that it is difficult to find the perfect benchmark so it is a good idea to propose a new one worldcup but this should come in addition to experiments on existing data table of appendix c page that compares transe and transgaussian for the task of link prediction on wordnet can be seen as fixing the two points above simple setting on existing benchmark unfortunately transgaussian does not perform well compared to simpler transe this along with the poor results of transgaussian single of table indicate that training transgaussian seems pretty complex and hence question the actual validity of this architecture,4.0
438.json,i do like the demonstration that including learning of auxiliary tasks does not interfere with the rl tasks but even helps this is also not so surprising with deep networks the deep structure of the model allows the model to learn first a good representation of the world on which it can base its solutions for specific goals while even early representations do of course depend on the task performance itself it is clear that there are common first stages in sensory representations like the need for edge detection etc thus training by additional tasks will at least increase the effective training size it is of course unclear how to adjust for this to make a fair comparison but the paper could have included some more insights such as the change in representation with and without auxiliary training i still strongly disagree with the implied definition of supervised or even self supervised learning the definition of unsupervised is learning without external labels it does not matter if this comes from a human or for example from an expensive machine that is used to train a network so that a task can be solved later without this expensive machine i would call em a self supervised method where labels are predicted from the model itself and used to bootstrap parameter learning in this case you are using externally supplied labels which is clearly a supervised learning task,5.0
438.json,this relatively novel work proposes to augment current rl models by adding self supervised tasks encouraging better internal representations the proposed tasks are depth prediction and loop closure detection while these tasks assume a d environment as well some position information such priors are well suited to a large variety of tasks pertaining to navigation and robotics extensive experiments suggest to incorporating such auxiliary tasks increase performance and to a large extent learning speed additional analysis of value functions and internal representations suggest that some structure is being discovered by the model which would not be without the auxiliary tasks while specific to d environment tasks this work provides additional proof that using input data in addition to sparse external reward signals helps to boost learning speed as well as learning better internal representation it is original clearly presented and strongly supported by empirical evidence one small downside of the experimental method or maybe just the results shown is that by picking top runs it is hard to judge whether such a model is better suited to the particular hyperparameter range that was chosen or is simply more robust to these hyperparameter settings maybe an analysis of performance as a function of hyperparameters would help confirm the superiority of the approach to the baselines my own suspicion is that adding auxiliary tasks would make the model robust to bad hyperparameters another downside is that the authors dismiss navigation literature as not rl i sympathize with the limit on the number of things that can fit in a paper but some experimental comparison with such literature may have proven insightful if just in measuring the quality of the learned representations,7.0
678.json,first i would like to apologize for the delay in reviewing summary this work explores several experiments to transfer training a specific model of reading comprehension as reader in an artificial and well populated dataset in order to perform in another target dataset here is what i understand are their several experiments to transfer learning but i am not sure the model is trained on the big artificial dataset and tested on the small target datasets section the model is pre trained on the big artificial dataset like before then fine tuned on a few examples from the target dataset and tested on the remaining target examples several such models are trained using different sub sets of fine tuning examples the results are tested against the performance of randomly intialized then fine tuned models section the model is pre trained on the big artificial dataset like before the model is made of an embedding component and an encoder component alternatively each component is reset to a random initialization to test the importance of the pre training in each component then the model is fine tuned on a few examples from the target dataset and tested on the remaining target examples section i think what makes things difficult to follow is the fact that the test set is composed by several sub tasks and sometimes what is reported is the mean performance across the tasks sometimes the performance on a few tasks sometimes what we see is the mean performance of several models you should report standard deviations also could you better explain what you mean by best validation interesting and unpretentious work the clarity of the presentation could be improved maybe by simplifying the experimental setup the interesting conclusion i think is reported at the end of the section when the nuanced difference between the datasets are exposed minor unexplained acronyms gru bt cbt benfits p subsubset p,6.0
678.json,this paper proposes a study of transfer learning in the context of qa from stories a system is presented with a a short story and has to answer a question about it this paper studies how a system trained to answer questions on a dataset can eventually be used to answer questions from another dataset the results are mostly negative transfer seems almost non existant this paper is centered around presenting negative results indeed the main hypothesis of transferring between qa datasets with the attention sum reader turns out impossible and one needs a small portion of labeled data from the target dataset to get meaningful performance having only negative results could be fine if the paper was bringing some value with a sharp analysis of the failure modes and of the reasons behind it because this might indicate some research directions to follow however there is not much of that the answers to the pre review questions actually start to give some insights typing seems to be transferred for instance how about the impact of syntax very different between babi gutenberg books and cnn news articles and the word entity ngrams distributions overlap between the datasets unfortunately there is not much to take away from this paper,4.0
678.json,this work investigates the performance of transfer learning from resource rich setup booktest cnn daily mail corpora to low resource babi squad benchmarks settings experiments show poor improvements in shot learning however when the model is exposed to few training instances some improvements are observed the claims made here require a more comprehensive analysis i criticize the use of babi as a low resource real world scenario babi is designed as a unit test and is far from representing many natural language phenomena thus the claims related to babi can only be weak evidence for questioning transfer learning high resource to low resource in real world scenarios i highly recommend using recently proposed real world scenarios more importantly the work does not explain why and how do we get improvement using transfer learning they remotely address this by hypothesizing the knowledge of transfer is not just encoded in embeddings but also in the model considering the related work these claims bring a marginal novelty and still how and why should be central in this work,3.0
697.json,the paper considers grassmannian sgd to optimize the skip gram negative sampling sgns objective for learning better word embeddings it is not clear why the proposed optimization approach has any advantage over the existing vanilla sgd based approach neither approach comes with theoretical guarantees the empirical comparisons show marginal improvements furthermore the key idea here that of projector splitting algorithm has been applied on numerous occasions to machine learning problems see references by vandereycken on matrix completion and by sepulchre on matrix factorization the computational cost of the two approaches is not carefully discussed for instance how expensive is the svd in one can always perform an efficient low rank update to the svd therefore a rank one update requires o nd operations what is the computational cost of each iteration of the proposed approach,4.0
697.json,this paper presents a principled optimization method for sgns wordvec while the proposed method is elegant from a theoretical perspective i am not sure what the tangible benefits of this approach are for example does using riemannian optimization allow the model to converge faster than the alternatives the evaluation does not show a dramatic advantage to ro sgns the difference on the word similarity benchmarks is within the range of hyperparameter effects see improving distributional similarity with lessons learned from word embeddings levy et al the theoretical connection to riemannian optimization is nice though and it might be useful for understanding related methods in the future,6.0
398.json,the authors of the paper set out to answer the question whether chaotic behaviour is a necessary ingredient for rnns to perform well on some tasks for that question sake they propose an architecture which is designed to not have chaos the subsequent experiments validate the claim that chaos is not necessary this paper is refreshing instead of proposing another incremental improvement the authors start out with a clear hypothesis and test it this might set the base for future design principles of rnns the only downside is that the experiments are only conducted on tasks which are known to be not that demanding from a dynamical systems perspective it would have been nice if the authors had traversed the set of data sets more to find data where chaos is actually necessary,8.0
398.json,i think the authors provide an interesting direction for understanding and maybe constructing recurrent models that are easier to interpret is not clear where such direction will lead but i think it could be an interesting starting point for future work one that worth exploring,7.0
767.json,the authors present a method for adaptively setting the step size for sgd by treating the learning rate as an action in an mdp whose reward is the change in loss function the method is presented against popular adaptive first order methods for training deep networks adagrad adam rmsprop etc the results are interesting but difficult to assess in a true apples to apples manner some specific comments what is the computational overhead of the actor critic algorithm relative to other algorithms no plots with the wall time of optimization are presented even though the success of methods like adagrad was due to their wall time performance not the number of iterations why was only a single learning rate learned to accurately compare against other popular first order methods why not train a separate rl model for each parameter similar to how popular first order methods adaptively change the learning rate for each parameter since learning is a non stationary process while rl algorithms assume a stationary environment why should we expect an rl algorithm to work for learning a learning rate in figure how does the proposed method compare to something like early stopping it may be that the actor critic method is overfitting less simply because it is worse at optimization,5.0
767.json,the paper proposes using an actor critic rl algorithm for training learning rate controllers for supervised learning the proposed method outperforms standard optimizers like sgd adam and rmsprop in experiments conducted on mnist and cifar i have two main concerns one is the lack of comparisons to similar recently proposed methods learning step size controllers for robust neural network training by daniel et al and learning to learn by gradient descent by gradient descent by andrychowicz et al the work of daniel et al is quite similar because it also proposes using a policy search rl method reps and it is not clear what the downsides of their approach are their work does use more prior knowledge as the authors stated but why is this a bad thing my second concern is with the experiments some of the numbers reported for the other methods are surprisingly low for example why is rmsprop so bad in table and table these results suggest that the methods are not being tuned properly which reinforces the need for comparisons on standard architectures with previously reported results for example if the baselines used a better architecture like a resnet or for simplicty network in network from this list,4.0
767.json,in the question response the authors mention and compare other works such as learning to learn by gradient descent by gradient descent but the goal of current work and that work is quite different that work is a new form of optimization algorithm which is not the case here and bayesian hyper parameter optimization methods aim for multiple hyper parameters but this work only tune one hyper parameter the network architecture used for the experiments on cifar is quite outdated and the performances are much poorer than any work that has published in last few years so the comparison are not valid here as if the paper claim the advantage of their method they should use the state of the art network architecture and see if their claim still holds in that setting too as discussed before the extra cost of hyper parameter optimizers are only justified if the method could push the sota results in multiple modern datasets in summary the general idea of having an actor critic network as a meta learner is an interesting idea but the particular application proposed here does not seems to have any practical value and the reported results are very limited and it hard to draw any conclusion about the effectiveness of the method,3.0
566.json,the paper proposes to perform active learning using pool selection of deep learning mini batches using an approximation of the bayesian posterior several terms are in turn approximated the maximum likelihood estimation mle bayesian inference approach to active learning the various approximations and more generally the theoretical framework is very interesting but difficult to follow the paper is written in poor english and is sometimes a bit painful to read alternative active learning strategies and techniques do not need to be described with such detail on the other hand the proposed approach has a lot of complex approximations which would benefit from a more detailed structured presentation another dataset would be a big plus both datasets concern gray digits and usps and are arguably somewhat similar,6.0
566.json,quality the paper initiates a framework to incorporate active learning into the deep learning framework mainly addressing challenges such as scalability that accompanies the training of a deep neural network however i think the paper is not well polished there are quite a lot of grammatical and typing errors clarity the paper needs major improvements in terms of clarity the motivations in the introduction i e why it is difficult to do active learning in deep architectures could be better explained and tied to the explanation in section of the paper for example the authors motivated the need of mini batch label queries but never mention it again in section when they describe their main methodology the related work section although appearing systematic and thorough is a little detached from the main body of the paper related work section should not be a survey of the literature but help readers locate your work in the relevant literature and highlight the pros and cons in this perspective maybe the authors could shorten some explanations over the related work that are not directly related while spending more time on discussing comparing with works that are most related to your current work e g that of graves originality significance the authors proposed an active learning training framework the idea is to treat the network parameter optimization problem as a bayesian inference problem which is proposed previously by graves and formulate the active learning problem as that of sampling the most informative data where the informativeness is defined by the variational free energy which depends on the fisher information to reconcile the computational burden of computing the inverse of fisher information matrix the authors proposed techniques to approximate it which seems to be novel i think that this paper initiates an interesting direction one that adapts deep learning to label expensive problems via active learning but the paper needs to be improved in terms of presentation,6.0
566.json,this paper introduces a mechanism for active learning with convolutional neural networks cnns i would not go as far as the authors in calling these deep seeing that they seem to have only hidden layers with only filters each the active learning criterion is a greedy selection scheme based on variational free energy and a series of approximations the paper is sometimes hard to read due to a many grammatical errors and b sloppy notation in some places e g on page line f is used but never introduced before overall i give an accepting score but a weak one because of the grammatical errors if the paper is accepted these should be fixed for the final version optimally by a native speaker the paper topic is interesting and the paper appears to succeed in its goal of showing a proof of concept for active learning in cnns if only on toy datasets i am surprised by the new results on uncertainty sampling and curriculum learning the authors added why do these methods both break for usps in particular uncertainty sampling did very well in fact better than the authors new method on mnist but apparently horribly on usps some explanation for this would be useful i have one more question why is it necessary to first sample a larger subset d subset u from which we select using active learning is this merely done for reasons of computational efficiency or can it actually somehow improve results if so it would be instrumental to see the worse results when this is not done,6.0
